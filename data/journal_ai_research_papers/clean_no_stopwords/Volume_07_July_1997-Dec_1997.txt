
ff fi


!"$#%$&('*),+--.'/1023%+465

789:;<>=.?6-.'A@B9
#& <C-.?-.'

DFEHGJILK>MONQPSR.TVUXW.YZR.TQD[T(I]\^GJE_K>`

acbd%begfihVjlknmCo

prqtsVu!vtwyx%z8x|{ v }~

8.A%8%!|6Vr _XHH8%8L]8r
"1,8] 8 .8 %
1.__,|O
AH" r]

[V l!
OrV_8.|$ $ A$$r Z 1, 8_AL% ">rr
$r] .;$[r$r.1 8 n$$.r ;
r$ 8A!% $$ r|$ "!.6 y$ ! $6.;r%$ $1 8|r
$8VO1 "rr,V $66 $ryAC tCO$6 ,.1.
8l%$8 1$Vrt ! $ ! $ 6 $$rCr8;" Cr
r rA1 $ $ !.c!;O !.$.rOt _8! $1
8(1 A. ! $ 1$.y* r r$! 18
$ O$$ 6r.O $ rr,r> rL;$
r|r , ;! ;r C Cr 8 $ $.t
Vr$.6t H
1rCr! $ $L$y$ 8OO$$Z OO$ O(1r,r
r;$ 1|".t!VrC l$ rl $$.A
$ ! 1r r$ , $,r $. _6 $ 8
$ r_1$ Z $ .l! $FAr1O r|$ Z% $
$6C; V$, 8r 8|l,HH r8g$.C $tA
rVg(; ,y1 11 $O$.C $rVlH.,(,r8rr_C
l. !._rVlQ. r$.r ,r _ $,, |
$rOt rVrr$ _%$ (18|$XH8>H| . y$r!A
l, ..
81 $ $ $ rOrVl( !C > $.Z ;!r,r
8.88% A$ $181V1$. 1.$|$>r.rA r1 $,C
18.$rVlQ $ $.r$ 6 1 ,$_ 8 .rV$.
C $1; ,y$ $r$$ 8r 8"r .C; ($6_r|68
rVg( ( ,$ 1r8r(6 16r . 8ryr8|.8 ,
$ $.


fiff V!

ojlkfi !#"
$&%(')&*+
!$+,.-/$102)334,56!578:94";$&"<3=$&;"
.02%16'>"/
33
?
@ 6"<ACBED>FHGJI.K#L(M.NOQPRI.K#LTSNU
IWVRL(MS#LTX
OYNZK\[
]^I6NG_X
K\`aL(bcYI6MX<GLTOdULTOYMK\I6N
beLTOdUfT[QMK:LCS:LgM.NhfLTO;G>NOi[)GjifCS:LCkNZU
I.O2SI.Oil
LTK\X<OdG)I.O2Sb.mYb#jYM5noN
b.m
l<LCK5S\jYNfYS\KNhLCOiLTOdUJpq]ENZG8crIsI.SsNftTmru6v
v
wyxhz{NZX|I.SsNftTmdu6v
v
} ~m.LTOiS\I.KN
MS:LCl<I{I6ijYM.NS#LTX
O/pX
K^LTOYb#SNOYMI
mZLTO
l<LCK5S\jYNffiniLgb:S\X
K#L(M.Nfb#I.S5S#LTOdU2b.mLTG)I.OiS\Ifs]ILdILCKNdmsu6v<vd~miLTOiS\I.K\OdI.S\k&cYN<b#I6LCOi&X
K\GNS#LTX
O;LTO2S\I.U<KNk
S#LTX
OpLffLgNZG>b#X
Om^
[ M.NZKNdmdV+I6M\`<I.K6mu6v
v
i~m2zX
crXdsjd;K\X
cYX<S#L(M|NOY/b#[iO2S\ndI.S:LgM|b:X M.MI.K|p#RLCSNOdX
I.SNhftgmYu6v
v<wdmdu6v
vi<~m.LTOiS\I.KN
MS:LCl<IHI.OiS\I.K\SNhLCOdGJI.O2SRpqPHN[
I6b:kzX
S\nm
K\X_{OYb#S5X
Om2+I.OmYu6v<v
wdx2zILffT[

u6v
v<i~mfiNOYYX<S\I.O2S:LgNhfGjifTS#LTk&K\X
crX
S#L(Mob:YN
MI/GL(b\beLTX
OYb.t]I6NZG8_X
K5`LTOb#jYM\nMX<G)ifTImi[2OYNZGL(M
iX
G>NhLCOYbL(b+G)X
K\I|S5nYNOQNbeLTG)ifTIjdOiLCX<OQXZbeLTGjifTSNOdI.X
jYb|MXiX
K<LTOYNS5I6QN<MS#LTl
LTS#[
tFHOLffTjYb#S5KNS#LTl

+--A'>fitfi"$##d < <8slff:Vs19
#& # fi

r%&# #&<


fidsi

Y)iT{d\<gi642s
d.)YJ.
6\<d|6<d.r
\\a\.Y6:Cdr

.)5Yfi\d{<.5
.YY.#..QeT)iT)i
<TY#T
Y\6
\(R5.odY
52dT6i
6To5d|T\.\d5

dY#6a
\d<g:#TY#T
r.q..<<TY\\)Yi#T
TdTo


;{<TY\
\hR(|eT8iTZd.
Y|Yoi
<TY56oi\aeT
Y.rdd{TR(+d
<Ye(i.\6;\6
\
#T<CdT/<2

rd.<.6r(|yJiCJs\6
\|d)<.\.Y4C\dq>qC5d
#T
Y(+\Y+{iT)\6
\>ii6RT2<T
)2
<CYZ#T
rT<d<C:C<TZ{T6
#RT2<T
6|

)J
/\6
2h^ZYoi
Y.Z#T
o)
dJ\6).r..
igJ\#(5T/& Y:6
\doi.

dJ.2)Z;
.d.hH)diZ\6Z8
5Q5Q.YZiC
\6\Q<4<d.\.2:C
h<.
Tdo5d>dY.\T2#T6ZR<)iTsiiY(.i
T\<d).2.
Y\#(i(6C\d6#.i
T\<d).2.\6Z).Y.5.Q.Y<d2\.<.:CdrTY
)iT.\
Yr2\eTiTTY
Ye(#\.i)<C.+H\d/
:gYJ.2hW#\)+
\d.)
.i.^


d.\.i#T
\6).r.+Y#+Y2TiT
)di(.\)\/
((\i
<TY:C<>dd5\d.\
)
5
#Y5.i<C5
d).i>.Z&\..ZY#oY5#(igZ>\6Z).Y.J\dddY656<C
T&idTd\6#r
YeTiC:C6fi
|\/<(\
.WdddY6\6
dY
5\diT#T6.)6Z>+Y#H52Y+r
.YiTas)
iT\
:CdJY.#&
\>ZY
YJYiTiTQ5.
\2iTTd/Y\6T .Z#Td/\6#
d6R\
)..HZ2><2#Td
.Y5T6.{Ri&
\\dY5C
CJiC.J.2\6iC:CZ
.2+# :\.>&\.Jh\d\

<gia\dWd665\\JY2TiTq;TQi
<TY:C<QY;
)di(.#T
/&
{
d.\.i+\6
\aT
#Y5i
>TY#.diTd2.6
r6

Y5#(igZ6T\d6:>#d#\.>.
.i|54:ddiT6

iTT\/d\.i(dd6i
>Td#r65i
<TY#T
d.<6T\/\d+&id\d2dd
.\hCi#T6+s
)iTi2Y4gi
TY.Y5d|TiY2Ti(##Y5od\.i(dd6i
<TY:C<
T6
dfi5Wi
##(Cd56T(seT)iT><iT\Wi#(5CYZ\HYad\.i(J<Y2\qCiT|

#Td
.Y5T6.Wyd\\d.\J
\
yC\.hTd;dQ5)TY\6
qCdZC
JiC\6
\/eT\Y#T
Y\d6#

<TY#T
Td\6)
i#T2YhT\6d6
d<T#T
eTYo2
<CYZ#T
i(YJ\/i
>T
#r65i\d..dd
fir{\.Y#6T)
\d.si<>TY. Y#56
2i
<TY#T
JY
5|Y{\6i6qC<d6
&
{6
5/d.i
>hC
dQ.i\HiiY
\d6qgJT\i(\#(5T;g5Y)d\<g<Td<.24T\
.d.H)di
|\6
\.YiT6\d.\
di\65>#Y5<iT#T6.
Y5)diH.YiT6/<.2J\
d\<d
)
YeT)56
#
>ZY
d{i
<TY#T
oY
)di(.#T
yd\
(<Td)\d.\d+\6<igqC5
YiCiT#T\6Z8
5
Y5
.d.J i((#T\.Y#\6
\.YZiT#T6

\i\|i
>TY.{<|
iTii6W:Y\5.Y#>\
aT)iT.).i#T

\6ddC(#/.Y#d\6

Ye(#5.YT\6Z8
5
\25)di(.#T
Y;q(5gid.W6


5\dY\T
\6.i
\d.
:C6Y\6
\|Y
r.
d)\+d\
(i{5d56
iT\6J)dig<YiTiC|56
#
iTdWr

\6
\
YTr.
1Y|1Y&6r&(<d\s
d. .
65

|6<d.
s.<6\

Rs
d.Rdd6.
6



ffq fi < +\2#
6<
H\2:
+Y.+6

H52#/gid.H6<
iZY
qTi
\6#r
YeTiC# q.diTd2.a6

iZ\o#
)|\d/d\
4Cd.i)
d6J)
d5d6#

{.
.6
)2:856#65
\aY
C6 \diTT#Y556<\\d.
#T6aTdi(<Tdd<#(.
di(.#T
YaqZ.diCdi.E
Y6
<i
ig+\:g5Td\6#.i+ !"# 6r&$ fia
.d.hE)dis56<\d.T62&
%('*) qeT)

Y,
+d&

-/.1032<\Y5 46'{T
\
r2&
%('*) gY
#6J
>5d
1Yfi1Y&Y&1
d\d.
\
q.<6\
da.HT6

rs
d.o .
6\<d
E6<d.Y
d6i
ddRC+(#)YhT(|YJTQ:
)
.
#6Y
5\HR5
\d3
7
ff#$ fi89:
d+\d.
\ H52#


(H\2:4;
+Y.6

(H\i#>
(id.6Y

iiY.{iT|2&
%<'=)Y#67
#TiCi\.i#T
Ys<\dY
qgdi(<Td)iT 5WY56)

\

^T)\d|
YZ\6
>(\d.
\
56).Y.digJd>a
)iT)iC.5ig.h#\5Y\d\
?
qTi+T2\.i#T
Y.TY<C<(iY{Ti\.2:C<YWY;YT8ZY
d|
5d.A @rT25.2#T
2&
%('*)

B C"DAEGFIHKJMLONAPRQ&SUTWV5XZY1P#NAL\[R]9Q\^AX`_aX V5N$^bXZc`_aL\Q\d`e?V5d<_\f$_gVih_jkh5Ql_d?_^1N$^khiV5^#QH?m#mQ\^#PAV5nC
oAp

fiq9rtsvuwxWy{z|#}~
|R}q}uvs=rw

6tA\U&t\UAt3 6UAt$A67U#U\U
tAt\UA#
A6A R 6tA RU6Rl7 : &t:Ut:U\UOUt

U
aA
\Uk
A\U
6UtAt\U6t
<=\UaUtU#Z$A6#\tU
7* 6tA8\UWUOt"A8
1 tUt:U\{
&<=R\,`a:U$8#=ta\U
#7A\Z ,
t8g t:aUaA#\At$\U89#
R=t8A{ZU
UtR1#gUtU98\ t*g$\(R:Ut::: U&#\7Ut::gAW:vA
$g=a A#U8g8OA
9a#A67A$={Zt::aA
#A
tU#\UAA RA
tU#\U9 :l# AZ`R:a#U
AA$1R\tgAt#\UtU
At\UA

<=?A$8\UR:U#\U{U tU
a#RUZ9\t{RU&\t# \U#,U{l &\#
\UWWAA6A1U GtA U,A
<1t#Ua$tG#8a\#< \#,
`/g3U#
<=t#/g$ \ARv\#kG/t#\#Ua#693A
\U#A&A3::U\$8\U1U
&<=5=tA$R:U#aA
ga ,tAgAa#
ggA&tA7Ot"A8
#
&<=U
aA$#=t#aUaAA\ ,tAg
\ U# \U\
${t :UA$a7 6tA\U# #Og#\`ZU AA U
#6W&t=t#aUAA\$8A{
1A8t#Ua#3 tUt:U\U 6
tA\U#\7\/a 7# #a#UAtUA
RG U\UA
&7A$\UU UAA$R<t 1<#6W\a1
&<=# #aU$#A3U
"A\U*U6tA\UUAt/$atU# #k/1At/$ata# #=\a
8/OA :
# $v=\a
#t $vv*O&A{R`U R $9 \lR#\`AR`U # v
OO?:W R R&\( \#,6UUtR<At#5 ttU=7A#U$#a
t\\a 6U,A
$,# \U&tk3$atU# $"#at\A#{=7
#Z ttUa#69"?g tR" t:aU/Aa#\A
\U3v6R7 U `A
# gZ$t&8{#
R#a\A
g=gRG\
7#v 6U,A
$kgt tU
Z/{# #WRA#3A67U#U8$tU# a#=1 :,a\a
$atU# $t\U
kAt$G8vtU&al tUUvAA$t ?#6W=#\
7* 6tA8\U t$U\U=t1UA 1U1
\, # $t&g$#
kAt::g##6A/{$a#/6\t#U#Ua
\$8$
&A \UR:U#\U=
&<=g#A A,A
$3a3
6$ata#
OA ` # $?tU3\A/ UtA7At#t
tU#AA:AAt
#{vR=7AAtA U7#\#{3tA$gR:#8\Uv
&(*#g=#R
,t \ a3=#`\a#tUA$8$tU#A17A$ tU AtaAt$
U #<\laAA$aU ,A$aR:U
`tA U7#UtgAtU,A
6Z
$tUt=\aU#\At$1tA$R:U# A\UAt$R#\tU$Z#\/a#AI:U\a$\U
=7A $&89
&(*Ua =tA UAt#

<={O\{AA;UtUAAt#AA$Rl,t ,/#6W&A
UaUtAtU
AA7v\AAk : Z$A6*v&
g\aAOAtU

# v`\#8t`tAt\UAa$t3a3tA#
&

W=*Oafi
ff
A# #t W`\#/al8#??A A?a/7A$( ,t tRUA?t:U
# \U ::9 =a#\=Ua#AltA$`(
&<=Ut:"At\UA$Z#\
Z$AA,U$ 13:AA
6\atUtAAlgA=v#6A8t:U\U#
1\\=UtRUU#8v=3\ZA/8A
AU/ ,t #
ttU#\URGtUA$8$tU#AW{U$ \AR?A 6tA\U
\$A


fi

"!$#&%'!(*)&!,+.-(/021354&+063$7+0!8)9-:#;63-:5!2<=#;!"+0>&)&!"+0#;6%#;?#A@B,)&C-(>;+)D)9E-:"+0F!"+0#;6
#&%?G;5HI!)&<87#;GJF(#;1/05<K$+06L)M/0N7#;"/EKE#A<K)M+063OP;-:!,+Q#A6SRT:UP;-:!"+0#;6WVJEA+-:@3,!(5#;"+0#&%
!)&<87#;GD)&63EJ"GA5!C-
!:+0$+0<=F/X+-5)&!"+0#;63$%#;PY[Z\]^UAP;-:!"+0#;6I_ 6:`!aE(-:"+013PY[Z\]^bc#;@
+0<=F/05<=56!Ed<e#'E:/#&%*!)f<g7#;(GhU8P;-:!,+Q#A6jiWEA+-:@3,=PY[Z\]^kl":/0-:!"+0>;S-:#A<=<8@6+.-5)f!"+0#;6?U
P;-:!"+0#;6nmfiF("56Y!:=)dE5!C)M+X/0Eo:`F35,+Q<e56Y!C)p/q5>&)M/0@3)&!"+0#;6?UnP;-:!"+0#;6srtEA+-:@3"e:/)&!Eu7#;(GhU
v
+063)M/X/0H;b$P;-:!"+0#;6twIF"56!CD"@<=<K)fHK)&63ES%x@!@(7*#AGhU

yBz8{&|}|}~2MfA3;Bdd?shL;;}

+[+06Y>A"!"+04Y)&!"+0#;6%#'-:@3,9#;6!(5g"5F3)&:)&!gE#A<K)M+0635U7#=#&%!=E#;<L)M+063 )&(J13);"E#;6)
)M/0N7#;"/EuEA+"!"+01@!Eb+06Y!5:);-:!"+0>;W+0<g@/)&!(#;=-:#;<=<=5C-(+)M/X/0HoE5>;:/0#;F3E%#;8<8+X/X+Q!:)&Hd!:)M+06+Q64
O*)p/.E5e5!K)M/}U0bD;;VT:Ujfi+0<g@/)&!(#;=563)&1/0e

>A+.)65!"7#;GA+Q64#&%J"5>;5:)M/ -:#;<=F@!5C

-:)&!,+Q#A6=#&%/)&4;5N}-5)p/Q;bV;n"H6!5!"+-13)&!!,/Q:3:/E5b7959@<K)&635b);7:/X/)A$Y@63EE2#;25>;56
!#;@3()&63E2#&%?+06Y!(://X+04;56! )&63EW"5<+QN+06!:/X/X+Q4A56Y!)&4;56!C-5)&6W-:#;NF3)&!"+-(+0F3)&!IO$)&<813D5!9)M/}U0b;;iT:U
3C"!E#;<L)M+06?bY\[!!C);-(G=Ov
+04;@(qfTCb&+06>;#&/0>;F+X/0#;!9)&4;56!C
%#;*)-:#A<=F3)&6Hg#f%aO@F=!#:+04;!5T
"H6Y!(5!"+-J)&!!:);-Ge:/+-:#;F!(5C5UJ-:#;<=F3)&6HW"!C)&!:*)f!9!#;<=5N13)A";b795I!J-:#;<=<L)&63E5
F+X/0#;!fi)&4;56!I3C"!W"563E=#ACE5C=)&63Ej+063"!@3-:!"+0#;63L!(#d!t-:#A<=F3)&6H^<=5<815C5Unt-:#;<eF3)&6YH
F#-:"8!("W#;CE5Ce)&63Eu!56o1354f+Q633HA+Q64u!#&79)&CEI!:+0K"F-(+X3E(;X8&5;3ba+U;U0b
!)&)%x#A<79+-n!-:#;<=F3)&6Ho7+X/X/g)&!!C)A-Gu!fi565<8H;Us+X/0d56#A@!fi!#!13)&!!"/05N
F3#+0!"+0#;6?bhE5F563EA+064fi#;6!#;CE5Ccb!g-:#A<=F3)&6HK<=5<815C9<L)He3HL!#;4;5!5[#; EH63)&<8+-5)M/X/0H
"F/X+0!8+06Y!(#tF(5N}E5!5<8+06Eo"@1!)f<K5U963-:W!S-:#A<=F3)&6Ht();-8)Y;X;Ye;3b
+0!g3)p/Q!:5U
96d#;L!"7#o:;D:/+-:#;F!(5CL3H%x#;(7)fCE)&63E3C,!S-:#A@!W!fi13)&!(!"/0tF#Y+0!"+0#;6?U);"E#;6
-:#;<=<8@6+-5)&!"+0#;6e%#;<!( -:#;@!Ccb;#;!5-:#;<=F3)&6H8<=5<8135Ca3H8%#;79)&CEI!#!D13)&!!,/Q[F3#Y+0!"+0#;6?U
[5;bM+063EA+Q>A+E@3)M/?F+X/Q#A!C5F)&!EA/0H8<K);"GO}+E&T?!:+0:/X+-:#;F!5C2)&63EI@6<K);"GI!#q,#Y#;!$<8++X/0
)&!D565<8Ht!:)&4;5!CcUJ963-:e!=)&!!C);-(Gfi-:#;<=F/05!cb!=:/X+-:#;F!5C54;#;@Fd)&63E5!(@6!#K!(:+Q
#;<=5N13)A";Udn+X/0fi56#;@!(K!#!W#A<=5N13);"O}#;I+06+0!"+)M/X/QH!#&79)&CE!(K13)&!(!"/05NF3#Y+0!"+0#;6T:b+X%
)&6Hg-:#;<eF3)&6YH8<=5<815*"F#;!C$565<8H8>;5+-(/QF3#Y+0648)D!)&!!#I!9-:#;<=F3)&6H;b&+0!)M/05!C#A!5C5U
-:#;<=F3)&6Ho!56n5>p);EW)f63Eo1HYF3);("=!(t565<8Ho>;5+-(/05bD79+X/0^)M/"#uF#;!-:!,+Q64+0!C":/X%
@3+064J4A@635Un56=! -:#A<=F3)&6HJ5!@(63)M%:/0H8!##;<=5N13);,;b&+0!)f<K)&63E8(:%x@:/5bA);EHA+Q64
+0!C":/X%%x#A!=6:`!<8++0#;6?U=\D6d#&>;5>A+057#&%*!(=#&>;5C)M/X/")fC-d)&63EE5>;:/0#;F<=56!J:?#;![+06
!+E#A<K)M+06?b+0<g@/)&!,+Q#A6=+06%C);"!(@3-:!@;b;<+/0"!(#;65b)&63E=)&4A56Y!153)>A+0#;C+F,56Y!E+06WO+X//
5! )M/}U0b
;r;T:U

HOLDING
POINT
HOME
BASE

BATTLE
POSITION

RIDGE

ENEMY
VEHICLES

v
+Q4A@=;\9!(!C);-(GKE#;<K)M+06?-:#A<=F3)&6H=3HA+064=+06t,@1!)&<K

6!K"-:#;63EE#;<L)M+06?bB
C)&63"F#;!8Ov
+04;@=RT:bh"H6!5!"+-8!C)f63"F3#;(! :/X+-:#;F!5CIF#A!-:!E
1Hfi-:#;(!:/+-:#;F!(5CD3H"HY6!5!"+-8!(#Y#AF39!#L/)&63EUI}6u)L!HF+-5)M/<8++0#;6?b?!"7#L#;D%x#A@ -:#A!
:/X+-:#;F!5C8)&63E%#;@!#W!"7:/Q>Ag!(C)&63"F#;!D:/+-:#;F!(5CI!C)&G;8#&d%#;<,5F3)&C)&!="+0F3I)&!q,)W!#
563E55>;#A@39)&!*)/X+06GYN@FF3#&+06!U(-:#;!C!56WF#&>;+EJ)F#;!-:!"+0>;J-:#&>;52!#8!D!C)&63"F#;!
:/X+-:#;F!5CE@"+064W!56!"+0+Q4AY!D!#K)&63ES%x(#;<!:+0DF5N}"F3-(+X3E/)&63EA+064W5#;6eO}795I!



fi*L?;.YM^2;

"Y(5";3A"e;YcC;KpQeKM0YA&0; (&K$&?=J55W"Y5,.0;
&;5C[}D&(;"9f3A53:;Y(5C3M0A;fi
0;g8"& :0;;

LANDING ZONE
SEA
ESCOR



LAND

ESCOR



TRANS

ESCOR

PORTS



TRANS

PORTS
ESCOR




0;(J
C&3"; ;LM0W0t"5":A9&3W:&3"3A::;(5C5


0C;LM0nfi;"Y5,."'5:5[0C&o5M}08;;:A3

.

&0Y5(3&"0;3M "5:5=;(3&=5;8;3ACJ&3o,Y5"W&;5C5M0=ofJ;e;"0
"fCQeg0"





&A5Y"',5K5

e "Y(5"9&;5C;&pA5fK$XXh3&,.(03&(

0K(
3C,*;fiff ;(3&=5*&


ff D0



&3&? "3&3"A0W
0;8"&

":A=35"0L&Kc[0;;:0Y"3$;B;5:"3;
9:;%;KpQI
XXQ3,C&"0;[&3(&8*A%q(3MX05;5



!"&fi$#

&'(

8;?00"M}

0=05=5C&"0;?(K:X:;5=X0;Kf;5Y:5K5;:0;u0u);&05;C&(^&A5Y
&C(0:+*[5*:X};9Y"50YA



5WM}0D;&:,&;(oX0;Sf;5YeA83;";

"53&:&t:AYu&-;Y&M;=A"3(X0;D&;5C&A=05C&C(Y9;=. 3
0;

/

,pDW3A"0;d&9Q5:&C(Yo"B&8;0Y(Y9&8?1

Y"50Y;*M;;C



5C&AC

&;5(08X.ffioA:"0;.f3W:;==;0n3"0;5W&;5fi&C(0:c "3(;
W&C(0:8:"0Q2;:,QA;3&;(^A35C&(;J:;3"CI&:;3A0"0;o(Q
;K":0:"0;?IXg(Q;K&X5&"0;

d:A=0:;5C&;="AYM:CD&3nXXg(Qe;

5Q3f"0;?49afYI;&0YA;0J;3&(JA;8$Q5:&C(Y.A:"0;;M} ;0M0;&;53
&03AQA3M5ff L353MA0;dAg(&8*A%t&e;Q3A0A3M59;KM0



"(6 ht:;CA03&,QA

&325 ;;:;e=;0K;0L;5"3L.7?;C
0L"3D&;LM0fi[98":
&M?;;323&;;:0;":}fi=<9:0?>5;;A"@?M0C
; ;CQ3(03A0;L&9"B&8fi5fiM}0A;C



;5AB*Q:"5?M;

/

2;C;(}

;e03"C&3:;DMx(5S:A"0o3&"0

30"0;?h8:A9:':(98&fi(J0;(Y"DpQ,Qe35033&93f"03YQ,QAL.
:;(}; "&9L0
QA



0"MXQ;0K"



/

C

(5*X0;9&;5C&355588;5(QcXQQ(L353M;0;:&3L:;



f0u&;5D0Y5:;:"0;?5&:XQu5&o:;CA03&"0;u9;;DCA3&=(t5=;3,C&
0353MA0;C5E<9&5;53A9IY85C9f*&;5C9&3;5(Qq03:;":0D353M



0;C5I5"&3;KM0W:35C}K&WX0;C:35&fiL"3(Xfi:;=0:fi80;35
0;6 h5& 835C&B3&"(03&fif;5YQ5CA:"0;39""};:;:L0WDXB

FHGJI.KMLON+P Q RSTN5UWVYX.X.Z\[JRE]TP%R^2_%`1a.S5RbDcdR]TP
eT]TcObDPL\]Te
R%]f]TUDPghLH`i_jST^
R]kKM_jLlIHNmKMP+LONP+enghLOeT]kKM]TcD]TP oigTI\gTp0U9R%e;qr_KMLDPb
KMLsKML`icOST]TUDPS0STPeTPYRSTN5U-RLDbs^tRYKML\]TPLdRLDNPE_%`fi]TUDPgTI\g4]TP%R%^EGuWU\KwvMPE]TUDP
RcD]TUD_.SN_.L\]kKML\cDPe]T_x9PSTPeTy9_jLOekKMx\vMP
`i_jSf]TUDP
]TP%R^zA_jST{|KML-]TUDPny\v}R~.PStRa.P+L\]Te[_j]TUOP+STefUdR.PE^tRbDPnekKMajLHKwdN%R%L\]EN_jL\]TSkKMxOcD]kKM_.LDe
]T_EKMLOb\KM.KMbOcRYvR%a.PL\]
x9P+U9R.KM_.STeG


fiA?

;i?%?.?%?\h?\.\WOifi

EXECUTEMISSION
Flyflightplan
Prepareto
returntobase

Engage

Fly
cntrl
route

High
level

Low
level



Select
point

Select
route

Mask



Initialize Maintain
hover
masked

Contour
NOE

Unmask

position

Employ
weapons

Initialize
hover

return

control
point

Dip
Select
Mask

Goto
newmask
location

Popup

Employmissile
............

;i?%1n%jlldfi4%Yl96i 9\DMf"\.9%i\j9j

9%?s?".\%jOiiDEi%h .-i.fifi"9s\i%?-\OA%?\9.r6i"9"5.DA;?%\
h9??D.ji"9iiD%99i\9
%D9%W5O6i?%Dsi?-d9Y"\"%ji"
9"W.?\jhDfiO951;i?%|6hj
-YlO61%9-i 91? %D9%sd}i?%DH?%?ii
%? .\
%?\W:\ \".?\%DA
?-9???D%E%?Ds5O6?DEh r?%?\(?Y9tlOi?5"D6JW.ji
"9ih9"\
9"i"\DAs
s%?"j9??%:9%\-?%DA
9\\D;%?\%9%
\\.O1}.YDH:;ijO?\%Eh?d\j9ji?Tj9\:%%"9hW\"9i9Yi"9Y
90%D9%5O6i?%D\%? %D9%O6i?%D'+"Y9?"D
%l9YY??.?"D.%Di




fi:??AWfiD?Of? ??

D0D \O5\6605%m6\m6%d\O%d065E50%% d.mDs\9Ds\9%?55mj
5EDsH5H}OD9\H9O6s% %54\A}m0\0OH9\45
\5m6:Dm656D"
0DmjDm65lOi96)\mjf5OHd3H65j?'06}W56O6-+O5\5mj96
hDmH+?
'9hDm5\5}95 D:.5j})Y+\mjW695}665i9O\
?5E55
H15
Ds\90500\6mjs}96m%6EhD0m+Oj D56 5+HDD

66D\O%9jY5j96W555.W}m665iH?D+%5
hO5
O55jTf5-5\0\+
5H556D56m}O"9066650mj\sH5%fi4%m
6h0%6\0mDsH5D
}s+OED6
m-5sDi96-H5jWT\6fiO5%E%6iO5%m(Y+\mj

OD
mD 9\0
45
D0+O5j5H556fO5656D\99\
\ 0\65j|69}m%6 h O16m1OT}m5%9
Ds\9E5
O4hDmH+?

%m 665i\D+%5Ejmj96rH6}.5lH6}%H5E5 D56-mD6 55.\

% %mj

5
OHdE %m10\6mjs}96m%6 0%-m%mjDm.5nDi96
D69j

fT5m5m6D45%949mDsH9%6}Ofi\Dd;5
mD0OHdn% %5A4%5f6D5.\j%\5
51YD\%.5j}n5%9A506};5fis% %5?4%5;5n0}mD5%A+\ff9

j 0
fi %YD
5%m
%m14%m:\65 m%6j\mDmi\5
O56Dj

661DO96H %% O%i6Ddm%5.5O5D9O%6YDm%1}6O HD%9fi.5j}
9%5m5\Oj-mD
i69|D5Dfi0\4Dj?m6:}6O\Dd
9iD69hDm O55jA\-md
\j5+H59?6+6mDfd9H50mDm
H1Hj

fTl\-Ym5%s%H5D?0%H6JOHds% %m0+\Df\HE656\"9mOHd|r\66j
5E}h%05\05%6065m}ODsOD9m}9O

01E5%\+H5YD\6%4\A%6iDm%5f15
D%Y%9+\66H6}\4jEm 5
m+HD96 m\

%6j.6jD}050695%h%50\6O5?\H:66mH\%m+HDh5OOfiHm1OH9Ds\9%5
}mDs\9E9 6965%69

"!$#&%'()+*+*-,/.10.2435687-0()9:*;,<'=?>;0A@CB:'DEFEG.H;0(IDJ'5@LK
':'1B5E-0./'EF9:*N0E-,O-0;35J.H'">-0BB:;B)'5EP0 0,2QR>TS:Q 0,/>-05,ffN,VUW0"B5+X :*.&9' ;,H,Y,ffE =Z0[+*Q
;,O-0[3\.'P>]\^-1,/.E 'E:.;B_E`0 .-0a*?E-,K"$.O(b'Y 0,.HOc,2SC,/.H( 'E:./E:;,.'
, 0[*9F.'\E ;0,ffE*S '()9:*87d.H;0(IDJ'5@), E-0/'T,Y,/ Ob=e0[+*;, '5ET./E:-0[*+*Sf ;KVg&O:-,Y
0F*N0H)E:(6>]I'=h,/9- N0[* 0,/ 'T'8B54E-0A./'E`9:*N0E-,I0H)9-'.HET./N0[*+*SiE ;,,0SKj4E-0a*k*SYl.mn,
B5+X :*..'I-,/I,/ Of9:*N0E-,oEG'.HOhB:'(P0[E-,K
p 3Eq.O;,/rB5+X :*./;,YD&GO-0[3s91,/;Bq0Et0[*.HE-0./3r099'T0 OuU
9H'a35NB:`0E:.1,
D&.Os0IE10[*v()'B:8*V'=w.H;0(IDJ'5@LKlg&O60AET.8, 0AEf.OEG.O(F,/8*3;,H;0,/'EG0>]'..O8 'Q
'1B5E-0.24'5E x '()(IE: 0./'Ef;,29-'E-,ff>:+*+./a,0,DJ8*+*v0,&0ET.2 9-0.Hy0E-BF0[3'NB_zZ'{H 'a35V=R'(f|
.;0(ID&'@<=Z0[+*4H;,K&% Oc0AEc0A99'T0 O60[*N,/'H;}:;,V0EI879:*+ .&9;,2ET.10A./'EI'=L0E:.1,~[.;0(
'T0a*n,\0E-Bs.;0A(9:*N0E-,l=R'.O-0A.N,\.O)3Ss>-0,n,y='5";0,2'E:E0>]'.".;0A(6D&'H@LK)<E:='5.Q
E-0.8*SY:.Oh0AET.[~,v'59-10.H'VO:10 OTSF,/O'DE\4Ef\9;,/E:.1,w4.8,V'DE)0 ./354.24;,K{g&O:-,Y
0[*.O'5OP.O0E:.lN,&9'35nB:;BcE:='5(P0./'Ef0>]'.V.1,.;0(b(P0.;,Y5.O8&9-0./ 9-0./'EFEF9-0Q
./ :*N0h0 .2435./;,n,oE'.{879:*+ .\zZ>.{80.O;YA4(b9:*k .<4Ef.HO ':'1B5E-0./'EF9:*N0E-,8|1Ky,&0H;,/:*.;Y
.O0E:.v(F0[E-,45E'10E:.w05,v.'DO: O6'59-10.H'1,.:*SET3'A*435J.H;0(IDJ'5@y0AE-B".HO{.;0(b(P0.;,
ET35'*3;BsEi.O(GKF'm4E-,2.10E Y&1[TRI8Nj0E-B[T5;"0AIE`H;0[*+4./Ss.;0(0 ./354.24;,
ET35'*3Ef.OE:./ '5()9-0E:SL]DO:+*dI8y0AE-Br:-I8ET35'*3"E'F.;0(ID&'@ KV.OH()'Y
EP,/'(b{.;0(.10,2@C,'E:*S6,/>.H;0(P,V0ET3'A*435;B YT0BB5E".H'h.OB5+X :*./SI'=-8*SE\'E()9:*+ .
;

fi {:

;2T1A/-ff-8PH6H;)PH;&:;jr;A1/aH6s)I:PA/N

):+NHI;/:1/rH6H;8/H6H6H;b6]1- HN:T/N[
8/5/;)<-/1-8l8-ffN:"H;8//-rIR/[;+N:P5;;8VRGZH65c2
;1[8N:+{5?HoA1;1&VvlTkHRR+lCRNb1:R8Z<J851
8VH-/]Tff/F:+h<Z81l[8vZf/-H)12C"4A4:V- HP
\;8// -fo4No)-H1:hb;/:yA-f;2]68I:;s8
/54/f-AJH;/:1&&:Nh5+d8:/FH;/:1/FN<h/];HkL\bIThA1:;8H
\T24H ckf 1H:;8;o)T245;Fr;8/i
H&)-H1:/-8-8I1AT&&f8:+NH4H;T[N&-F:N-Hy88[G8)
I):1-s8:15-/;/-5-ff:k+/;I1<I;j--2;sGH)1[V):8
;I&b:4; Z)-/-8< -b8:kNH;/:1/b ;ATan-
:N-l&8+J8)c4H)T8-s;/]-ff:++424;bj-:;V:1I 18;
j8rrb:P/Nf:F[Z/-;H+LG8:15-245`:N-;5rs ):/;
;I& [+;
V)V-fff "h] Pv5
1aL;I&\/;&-[<-f]T/;cf+1A\{f;5L[v
HT/)1-;vA:4:&;v<:s6[ZV;5:1"o)/;H)TH-:;
j-f54H;8/r):):;[jNsf51vIj-F-/;`5"G2-;H+L/
G:G:;ffvo ;8/-i1ae1AG-A :5P[Z/-;H+LI;5/:
8;/;/N//N {;A6&HL v:{/T]; -1A/-[LH;IJ5"):8N&8:N
-5T2nak) 5 ;/s24;

H/-8s /-Hq)C:8NbP[-F- :+
8:45;r-_-:1/:C mZr:8:rT
]&"-[ 8-/;js
--R[-R
Hf{G ;5v;vC;5h[Z ;ff

$-d ;5?;5;:1A45
1G:8[+4; P["/];HkLA/-;8//i-&;&
fi:FT:/-_un

/ -f5J;bs;8/


:/P8f:+N
fi/:{::/-\[)-
-1ak8N<
]T/8
J+fT8 \ :/h n:[?;5ff

T/];$ HT/h 1A- ;:8
&j-;
wnA-IjNIH24 -i5J;q;8/
$j;8/
j/1H;\




):+N/-I )5/;

ff"/+;\)1A/-[ P:;ff:;HNff-

qjC8;Hf/ -8)-A;)H-:++/;f5N:;:
fi:

THT/-A-s-;
wNs/;\T

N<N;/:;d4r:1akVi;8/-
f-

"!$#&%('*),+.-0/1+2-43.+.-5)6'"+"798:*3;'*<1=

&>fi/:THT/- 8)&s` 5;&;5vV;$;v ;HF"[Z{[ff
:
C
8-/;oGI;@?Afi:):1[?/1A[+4;jN]{-R[-R-A;ACBDfiA4:/b4:-
; 8/f ;A)I-1<Efi/T/G8bI;fHP8):/F-;A8/v<:k
I-[+)-8+54b-VI&h:m4[F
Gfi/T&8)IbTlFIN{:8-;FH
fi:



-8ffN/:T[lff

1:&;I
B?ff

6H:
JT<
Jr/1A- 8):/f

; 8/v$n:5;Gff

B"(
K
J.
Ll1E
LsNfH84-8PHN-/M
h:;H8/-;j-8"]

-:;I;HP:fIff

/:NfHPI-[+f-8+0
L I- [N/&ff
K B".
J.

NoN rH68-5/-"A/Nff-;(

P5QHRTSSUWVYX[Z\ZV]Z>^_VK`baFZ>cdUWc_X[SNSe ^;VKSfVKg5VhUWi_X[UFj@fNaTklcff`W`bVKmUWSe>noX[SaWV5Q

p5q

firts;uTvwx(y{z"|5}ff~6_|1}rH}ffvTu>sw

ffHTWY[MK>;KW_5E4WdKT>ffb_4;54$5$ 5dWffKM>ffW;4ff4GW_[Wff]4b
_EK1KW_[N>bWff5
ffHT_bY4K>;KWA>ffW_[Nh_KK1TW;4ffW0>ffb_4Eff4b; 5bffK5ff_1WdN]5
4ff"1.WbKK54.bffKE>ffb_4_]NK1Fb_42Wff]t5bd5E["Y4E54d9T ] "9T"
ffff]ffffKb {NThW4&K>;K"9NMffK"W;45dt[*bffE1N4ffEff1Y

_]NK1KDN>ffbWKbN o4b4_ [bW{_K1KW_[N{Wbff5Ao 5(D@_4][


5l]]>K5Y[ Kd5
ffffb54W]N945KbY{b;5bffK1Y2ff_1WdN]54ff 1 WW]N]54;YK4dW

G

o4WK{_4T1MNbWYhW>;ffWdNdW54bT;KNl;Y1 >ffW_[_;K

dEKd;5{.ffb{K.ffMG;K5Kbff45]4b.9>;ffK5CYffH
]K4K9ff]ff*{ffEff.Y;K45hK.K594.4Y4ff;5d9>_lNTGK.1
.4ff5]9.9ff];4ff5(..dK;4;ff K]4;5 Effb41ffFffK.H(TK5d;K5K5
94.4EK5ff]0@ffEE50ff];4ff494; ff_FW>MYff>MW_H(Y; 4K> 6
MK594.4HK5d;K5E@K9ff;ff ffYEff;1.E2N4ff5K2,1ffH E4ff45
ff; ]@.4ff9K.G.dEK4K.]5{Wff6.hK4dK;4ff5(2.ff];4;
ffMKK4_



.t25ff9

dE]T9dKd5(T



].1".l

MoEKff9]94_K.1ff{K;

"5Y;K.2K2

EK EK59{K5E.d KYK.EF]K5Yd



0ff9K4_MK

.E;;64Nff9;4K

H

]Y1K.1T2N>GK9K4K.ffh



6M@ff4ff.5M

ff ;6hff9K94;E4.K5HK.HK594.4tlY1*K5.dt]K.FK5
ffd54_.]_.;d"55KKlNMWffTAff" ffK]9ffd(.Y.ffffff.6;4



K



.YHW1]K54;K5




ff5ff

; 4]Kd90.;4EK4K]59Kff.ffl1ffff



..;d;YEK590K5HKMWff;bK.ff"

fiff

ff9]94_hDff

ff.]W1K54.1ff;5{ff4@K

WGff>.9;ffK0ff0.;4>Eff;.1ff9ff9;4K5EK

YEK590K5HK5Y;K.F.2ff K>]4K.ff@]>4_ff494;5



AG4_K4_]




;ff9K94;@ffEM



K

.Y{;6dff1>K5

5Y;NDKdK{].1T.,.d9K94;Y4{

!"$#

.

245KdYMff{1K.K5

%

'&)(

.d9K94;YM ffK

"*,+$+.- /

Td4"

{ffEEE]o4KhK

;Y

4Dff];4d

.];6



94.4Y{.



;]0.].ff9



]ffK{K.1t2W

].ff5d>K@5Y;94;

102354687:9;2=<?>=@$ABAB9C35AB0,D!3E2

oNEff ]

F

t]ffKW

HG

Eff4

K{K;KffK">.4Y6lK4_>E5dK;4ff494;ff_1E>MY>M dW*H">;4dK5
ff9]94_@K5

KJ

IG

94.4

ff ;K5hKKdK



QP



!Gfi* LG MG

$c





M5Y;N;D

fiN

ff dW ;"K52ff.

[Z\X=X=S^] fiX _ ` ba
ec

5"5]]4W44

WT;5b5bffK1F44_h_1[N d15ff

`

YffG\ffKK0]5

h;NMYEK590K5

FRTS VUfiS$WYX

5H ffW]t

d]YK5



1" ( "K

(T d$Y5E]



_

_4"5" ffW[W5[

4FK1KY[(ffTl5MWW

F`
fd
_
"RgS VUfiS$W%X

h ic
[j8kl!mn] nS,opUWYS qfkVl!mn]
1Z\X=XrS] fiX
c

s8tvugwyx{z}|Y~rELYL^|QK:B%|KLBu1x{L/C$=H~5H|QtLv%=r=$,:|%555Hgugwx{LCL5Bfi=,.
Q==rt
tv,ugwyx|QL~5L,L,~|YL55LH=|%H:|Y,~5,fizfizfiKK$,=!L,L,L5y5~ELKKF5YKL%zfiL
,~5EL,EL=$t
W

dKW

Wff

ff

"5b

ff

Kff5bKT5bffKff >dW_[ff_]N.GW_["9_[Fbff
1051ffWbff

ff2WKb_1_

ff;_4bff

(TDW5bffK5

((W

(T>
1





(TDW1bffK5E

$O

[W[



5WM5bffKWhW_[

fifi"V
$Ev5$$,pI^\5\$Cpr
,rVCV1$fi%VC\%.%=VvY%$V,B[gv%C=VC,b%%VC\%$%=p

v= V=$vV%BV%IV1= Y^F=[=%YY, $=.H
V
%$;/%v'%Vv=1%85V='rBEv%.%= v.%rV
vv.$r=.v%rVr\%gV5$r=,
VQI ,=$$C/%[
ggpYff

$%B$V$ fi
$
g V,%vg5%B% .,v ^%='!=:$,/%v CB$%V$,fi
v$YV^Vi$\%%= vQ\V5$ rg%, %,8
%% .%$!
'!=.,B%v
% V =
C$$YV.,fi v[Y%%
p$Kv;fi ,%%$I.;{$$
%%.$i vF%Yrv \% ,%%$ r
$%ff
; =.v%rv%, ) vr
."%
Ve. $%rv$ v %
%Y$$
gB% ?v.;%,f%, vr v
=$vV,!$Ci=$" !v $!%I%[,=V;Q gf1$# $ ;\.,=V;Q,f
$B$V%=5v,
$F.$C$v\ $/%, ) vr iv Qv%1$Q %v$,
%v% vi.viC%Qg5$5%%g$' &fi
(*),+.-0/21435 687:9;1=<*>?@/25"A23B

p=$Yr$\%IHV\Y$v8yY =.v=[DC!EGFIHfJKLCg$\v$, $HV
%\%$
NONP %\%R
QTS\=vL
NNPU%%QQVCV,D
NONW"rpvY,$fiX
VrfY%vVM
%=,\$ /$=V%Q.v%%vV$, v5 4F$, ZYIE$5!FVCY
C\ Cg%1$V [L.
, v5 !5CO
i5Vi$=$ \f.,/v.$CVv"$V [L] !5 v5E iE.CF.%,=%,IY^F=
rg=Cv.r%$ [L.=$v\$\%rFI$%.* [LV$=Q.
^Gv5 v5E E$CgV !v,.Ci
B V %v$VCV
v..;Vv^[%
rI &$1$=$v8vYv.= / VCQ.?$=Q.v
%vvV. .Y:rYgr%, %,%, $F%, %vQe$ $%$,r$_ &
%\%
Q`S\=v=

NNPar
\b
Cg=%:
cedVE CvV EG FH fX
F$[h
g E=5E$ C! EG FIHf L L =v/:F!
%iV !vV$ff
Xfiv%5 %{=f% ' &gv$[IL = \ X%
V %%,Vr%v$'F%i$Y $Qv,=gIHV1$=Q.j
CeVV% ,fi
kVCIvYvV, %v[!==iv $Y Y= V%Y,Y!j
lnmYVo

lDm ;
'!,Yp !$ i$=$vr
q*sFFVCY F ,=%, vV Qv,Yt !v, =.v%rVr
=$vQY%,\v5$ v=Bu i":
XL
'H* vMw
* i* kXx* k * l V$%,g/$%.o
yLz[L\VC 7
g r
k x %
V $=Q. igQ
kDmv%,YvM
lDmfi
{% |v$} XL KHf~ vw k x
kDmfi
lDm;t %\5^i=$v.$v\%[%C !v,=
,X
}t,%J
Ypv8Z , hIJ
"tt' ' Z#$' G , \: %n
Z2$0 $p pt p,
!en
F
$ 5 , ZJ0% ,% [ }!
}.0
$X
}t[%J
V%D
0 J
OZptDV' ' ,L Z}X[ $prt VFE,
$L
$yG '

"}
=$C $ rt V
G 0\
F tJ
, TG 0:y0
[p Z5
$ ' 8p,Vt J
$ *",u LK ;ZG]Zt$"
Z : $2 =$C
:Vt ^ "rK
Yp8u 0V' ' ,L Z0$YpF_ $ } \prQp V RZ0 K
$p JV
$%%J
:
Zu 8@
=$C ] $%"%J
V%p
F. $ b C%
2G0KGX'4_]ZL_f0p'u*n0__J;b,~J}K,==
K_D;,';t4'K}f_J:]0GL0K_"'GG


fiu"} =r* Z X }J

} ff
fiff ! fi#"%$'& "
ff!
fi#ff()+* #,
-/.'021.436570#8'9:;36<>=.'0?57@A3BDC EF50#B=7?G8 0#B7HI5DEFJ402=7.'0K0< =DEF50MLN0JA?POQ3R=0#36S2TUBVEF< =0<=)EW?X<4BY36<48
J40I:EF0IOffBYL.'0<>0<'Z 36Z0#8GEW<>=70#36SL[?X5\^]`_ff<>=. E;B0<48 0#3ba?5bcd3P<fe19g50C'570#BD0<=IBh3`:EFSEF=DEF<'ZfH3XBD0i
j B j 3b::F@c'L.'0<k0<'Z36ZX0#8EF<M3=0#36Sl3HI=DEFaXEW=D@c'3=70#36Sm?< :F@Y.43XB[3VC4365=DE;3b:1.43650#8'9d:n3P<2op9/19Nq(] -N.'0
9N19rEnBs3MBD<436C4BD.'?X=?6O[=.'0=0#3PS2TUBtSY0<=I3b:uB)=(36=0sEF<A3kC4365=)EnH j :;365B EF= j 36=DEF?<REF<v=.'0IEF5s=0#36SLN?5\wc
36<48RO j 5=.'05HI?XSYS j < EnH3P=DEF?<A36<48xC :;36<'< EF<'ZRE;B?6Oy=0< j BD0#8z=?{O j :|'::=.'0KHI?<48XEF=DEF?<4Bs?6O36<ve19
op3b:F=.'? j Z.}c~EF<G8 @ <436SE;HY8 ?XSK3bEF<4Bcw=.'0=0#36SSK3b@M<'0a053HI= j 3b::W@ROy?5S36<e19/q(]~v0sO?'H j B?<
=.'50050I:F0a636<=3P50<43BtEF<xL. E;H.vC43P5=DE;3b:EF=p@RSK3b@M0IE;BD=VEF<G3M9/19]^e EF5(BD=bcw=.'050#H7EFC40KRSK3b@MJ~0
?< :F@vC43657=DE;3b::W@BDC40#H7E|40#8w]x057=(3bEF< :F@c}EF<>8 @<43PSE;HY0< aEF5?X<'SY0<=IBcB j H7.>3B=.'0Y?<'0#BV?6ONEF<=0570#BD=
EF<>? j 5YLN?5\wc50#H7EFC40#BkHI? j :;8>J~02HI?<4B E;8 050#8>=7?0aX?6:Fa0K?6a05=DEFSY0cN3Bs=0#36SkB570#3HI=DEFa0I:F@f8 0#H7E;8 0
=.'0k<'0I=YBD=70CAJ43B)0#8J4?=.?<=.'0MHI?<=70I=Y36<48z=.'0MH j 550< =BpEW= j 36=DEF?<}]ve'?X5EF<4BD=(36<4HI0cuEF<>=.'0
==I3H\8 ?SK3bEF<}c=.'0M.'0I:EnHI?XC'=052HI?SYC436< @vSK3b@50#3HI==?v0<'0S@a0. E;H7:F0#BMBD00<>0<'5? j =0c=. j B
0a?6:FaXEF<'ZM=.'0IEF550#H7EFC40] HHI?5I8XEW<'ZR=?R19=7.'0?5@cw=0#36SSY0SJ405S j BD=3655)EWaX0h36=S j = j 3b:%J40I:EF0IO
EF<2=.'0IEF5<'0I=BD=0CwoDBIq}D][e?50#3H7.B)=0CM}EF<2=.'0s50#H7EFC40cw=.'0s50I:F0a36< =B j J'Z5? j CMS j BD=/O?57S3
1.43650#8'9d:;36<}]
10#HI?X<48wc=.'0R=0#36S2TUB=(3BD\3b::F?'H36=DEF?<SK3b@>J40> 4D(I~#+Ic%0]Z4]FcN=.'0x36Z0< =K?5kZ5? j C=?
C405)O?57SC4365=)EnH j :;365=(3XBD\xSK3b@<'?X=J40M8 0=05SEW<'0#8w]`_ff<>=. E;BBpEW= j 36=DEF?<}c%=0#3PSSY0SJ405(BVEF<=70<48
=.436=t=.'0500I E;BD=BD?SY0VEW<48XEFaXE;8 j 3b:[?5B j J'Z5? j CR=?K8 ?k=.'0=I3BD\w] SY?<'ZK3XHI=DEF?<4BHI?X<4B E;8 050#8x3B
350#B j :W=?6O%=.'0EF<=70<48XEW<'ZM=7.436=#cXEF<48XEWaXE;8 j 3b:BVSK3b@Ya?6: j < =005=7?YC405DOy?5S=.'0 j <'50#HI?<4H7E:F0#8x=(3B)\^c
?5C~05(B j 38 06b?5(8 05?=7.'05(BN=?Y=I36\0?aX05[=7.'0=(3B)\^]
-/. EW5I8wcwEF<48XEFaE;8 j 3b:;B{?5B j J'Z5? j C4BSK3b@2<'?X=.43#aX0K36==(3EW<'0#8x36C'C'57?C'5DE;36=0YS j = j 3:J40I:EF0IOBsOy?5
Oy?5SEF<'Z>36<re19c:F0#38XEF<'Z=7?AHI?SYS j < E;H36=DEF?<LNEF=. EF<=.'02=70#36S2]?SYS j < E;H36=DEF?<SK3b@>3b:;BD?
365DE;BD0M8 j 0M=?v36Z0< =(BTN7EF<=70<=DEF?<=.436=I236==)EW= j 8 0KJ~?=.>=?6L365(8'B=.'0IEF5Y=70#36SZ? 3b:/36<48=7?L365I8'B
=0#36S{SK36=0#BT3HI=)EWaXEF=DEF0#B]%e'?5EW<4B)=(36<4HI0c63N=0#36SS{0ShJ~05#TUBEF<=70<=DEF?<s=.436=wEF=(B=0#36S8 ?3P<3HI=DEF?<}Dc
36<48sEF=(BuJ40I:EF0IOd=7.436=HI?SYS j < E;H36=DEF?<k?6OB)?SY0C43657=DE;H j :n3P5%EF< O?X5SK36=DEF?<{LNE:+:}0<436J :F0=.'0=0#3PS=?8 ?
}Dc6LNE::':W0#3X8sEF==?HI?SYS j < E;H36=0N=.43P=}EF< Oy?5SK36=)EW?X<h=7?=.'0=0#36Sop3B:F?<'Z3BB j H.YHI?S{S j < E;H36=)EW?X<
8 ? 0#B<'?=HI?< 'E;HI=LNEF=.2C'570aEF? j BHI?SYSEF=S{0<=(Bq(]
}Fl^vb~[w4}6R4 wv^b^ ^6n{}sM
_ff<1- c p?6EF< =EF<=0< =DEF?<4B3650 j BD0#8z3BJ j E:n8XEF<'ZvJ :F?'H\'B?PO[=0#36SLN?5\w]{10a05(3b:[38 a636< =(36Z0#B
3HHI5 j 0x8 j 0x=?v=. E;B j BD0]e EF5(BD=#cN=.'0xHI?SYSEF=S{0<=(BhEW<3kD?6EF< =YEF< =0<=)EW?X<rJ~0Z6EF<=?vC'5?6aXEn8 0x3
C'5DEF<4H7EFC :F0#8>Oy5(36S{0L[?X5\MOy?550#3BD?X< EW<'Zv36J~? j =YHI??X5(8XEF<436=DEF?<>36<48>HI?SYS j < E;H36=DEF?<zEF<>=0#36SLN?5\w]
-N. j Bc6=. E;B Oy5(36SY0LN?5\J40ZPEW<4Bu=?38'8 50#BB=0#3PShLN?57\Off3bE: j 50#BB j H7.Y3B =.'?BD0EF<Ye EWZ j 50']%10#HI?<48wc
=.'0%D?6EF< =[HI?SYSEW=7SY0<=IB EW<sD?6EF<=uEW< =0< =DEF?<4B%C'57?aXE;8 0Z j En8'3P<4HI0Oy?5%SY?< EF=?X5DEF<'Zh36<48Sk3bEF<=0<43P<4HI0
?6O3M=70#36S3HI=)EWaXEF=D@c}Eff]0]nc36Z0< =(BsBD.'? j :;8vS{?< EF=?5hHI?X<48XEW=)EW?X<4B=.436=H3 j B)0K=.'0{=0#36S3XHI=DEFaEF=D@v=?
J403XH. EF0a0#8k?5 j <43H7. EF0a36J :F0?5uEW5750I:F0a36< =#cw36<48YSk3bEF<=(3EW<M=7.'0=0#3PS3XHI=DEFaEF=D@K36=:F0#3BD= j < =DE:?<'0
?6ON=.'0#BD0YHI?<48XEF=DEF?<4B3P5DE;BD0#B]-N. EF5(8wc3Vp?PEW< =EF<=70<=DEF?<G:W0#3X8'B=?M36<x0IC :E;H7EF=Y50C'50#B)0<=(3P=DEF?<x?6O[3
=0#36Sl3HI=DEFaXEW=D@c'36<48{=. j BOff3H7E:+EF=(3P=0#BN50#3B)?< EF<'Zh36J~? j =N=0#36SLN?5\w]w_ff<MC4365=)EnH j :;365bc3XBBD.'?6L<:;36=705#c
36Z0< =(BH36<K570#3BD?<K3PJ4? j ==.'0570I:n3P=DEF?<4BD. EFCMJ40=DLN00<K=7.'0IEW5N=0#3PS3HI=DEFaXEF=p@k36<48K3P<EF<48XEWaXE;8 j 3b:ffTUBt?5
B j J'=0#3PS2TUBHI?< =5DEFJ j =DEF?<4Bt=?sEF=#]
t?6LN0a05#cw3MB EF<'Z6:F0p?PEW< =EF<=70<=DEF?<GO?53k. EFZ.':F0a0I:N=0#36SZ? 3b:ufE;BEF<4B j H7EF0< =h=7?KC'5?6aXE;8 0
3b::[?PO/=7.'0#BD0K38 a636<=I36Z0#B]M- ?2Z j 365I36<=700HI?X.'050<=s=0#36SLN?5\wc~O? j 5h38'8XEF=DEF?<43b:NE;BB j 0#BsS j BD=J~0
38'8 50#B7BD0#8w]Kt050c}=7.'0K1.43P50#8'9:;36<4Bs=.'0?57@2.'0I:FC4BVEW<36<43b:F@BpEnBs?6O1- TUB36C'C'5? 3H.}c}3P<48REF<
?<'0H3B)0c41-t 8XEF50#HI=D:F@MJ4?X55?6LBOy5?S1.436570#8'9:;36<4B] \0@k?J4BD05a636=DEF?<kE;BN=.43P=[36<43b:F?ZX? j B
#

fiw'

R46D;b46#';64N%' ;'Y'>D464D'X(6'k#6RUY (b/)(6 ''hX;
6 FNF DF4
/'4ID;D'NF 6F#IX'4IFY7#6[X#6Y4Ih4)%''(D'I{Y
D6F'DFz46RFfD7;IY6N'IF 6FF DFxy' F'FI#6u 4 #w%
' F'
X4D#bNF''%D47YI4DIbF#b#6gY4II ;s''(D'bF746DF
D6F'DFx46744PQ64II%#7x'#wDk'K'X#/;K 76I'N'k46#'dnP
'ff
2' #D#D47I'74Ihfi

2D' F'M~
4M7'#6Y4I
(W DF4t46
66(' GX'XW)WX}%46#'d;64KP4'6#th'74bd~IWItWKI{Y27#7W~

46)n P446#'dnP4yF4XWX; 4bD4
%Fv'kIYYx#7F~74'I6DF'2
#I'(pWX F(6(7fi

K{4D'hIX'4I
t%A 6''77Y'46IbWI;46%P46#'d;64 '6[X#bF' ;'X PW F7'
DF4(P'46z46#';64YN46tn%uQ 4)# 6FF )WX4k' nXF'x F7
WI6(7 n+
M' ;M'k'YIb67DF4 P^F4XFXn 4d#PmY4I'64Y4)'46
#6Y4IY''()'GzIYYD6F'DF46}ff46D;I ;6#Y{DF'##6)+F#/F
fi
46; kbF44PWXM#IDFs nP44#7F~
MK
YPWXhDMfi

MD ')W'k '#I'
DF}tff%4t'#7F46F#'/kD 7 ! F# '#I'DFx"

M7' DF#62
uQ !X F#467'DFs#6PX#
pw64{y 6F F )WX4{ #I'VF#
'#I')'4DY6
DX' 6FuF DF46NyY#wPF#XF'h7 F(6(7fi

%
$'DF'
's 464pWXP ; WI6(7"

/kDMF 6F#
xYD''#6'x46D''#64D
6FtF DFM{4Dy 746D}uy%
26kF4XWX; 4b;F 6F# WR'h)} F
4D%ymPF DFk 746[D7} KX'(bff't#D FDF'F7DF{ WI6(7"

YX6F#
fi
46;b
} 44XF'MM' F46DF4N7'#6l4I' (
#IX4w'
&7) ([P4+
*I64,
.-fiX;I47%'N(X 0 /wF'6{'6'F yK6)WXY#6
Y4I4DKbF (bFv64'#6{K6#~IDFFDF# 46D;I ;6D
x'xKD71
2W 6F#

ARD''#62PvF4XF; 4bff3
&) (KP44
*(64' #7 ;s( 5 /AF46#';64
D'6RFG)4
66RW#IDF4
6'8 7'~ !X W)W'R46#6Y4( '6
24PQ{#7F4
n)(x46 FG#6YKP0 px4Dy F(YI)WX4''{''2 (b;YP'M#7F4
6F;6D
t% ! F#s4PFfXDK2)4
N;s4)7Y#xfi

GRD''#69
ffX 4D6
F4XF; 4b%#6lY4: (kbF W'{#6lY4(I'D''#P2U 6F F DF;
ff
'Y7IW66 h7#6Y4# F7DF<
M4)7'K)}KN ;VF7DFz(7F'R'#
'VW 6F2 IbW# ;6#IX W)WX}%4FVFA''XF4sN3
p64=
>
-fiI
ff4)#wk7#6{h~4D
x4K6 FY7kW y746F(V#6Yk6#/W 43
QP''
K z'F74?
v '#I'27'2D@
/ nF WkbVIX4D(bF ;Y'#I#76A
4#64)
'7N;D#PmY4I%K
4'4P W7Y F'I' [)(646}'t#6XIDFF)

4n%46'IFY#P IDFXW)
4sffbFr6467#v r'XFDF}NDYkF yKPDF64X'Y'
44 4
kI;6DF4) WM6YX'#6Y4II)WX4;%4DIy 4FY{ FDF'4 %X;I4D#
Fv#IDF B48 7'
F({;D';'64bF'67'
I''7#I47W#'
kDtFx46#'dnP4t%yK
6FW DF>v7 nP''kx#62 6F F DFyKv)@
tn{Dx~
'47 F6 F;
N ;6' F'AK
RF#z'Y#6 k4(D64b
fi(K'k64Dk6'F FD;b''
7 F6 FC
RY'M's47 F +FDF#'K64) ;z4Y7'K64D4Ik6 F'{6
MD''(XDM2kD''#6F4XFXn 4u7'ffbF'Y6N'IF6 F4XF; 4bXQD''7#6
FA~DyF'x'KD''IDwK f)4>MD#7A7#6Y4YI(V2 W'k'M6'
'')nP26 KD''#PyY~DyF'v'M7IW66 K(XD^zQ{x#D F#N66 Y6
6F' %F()I+ D'X#DX'%F4XF; 4b;tD''#PK%~Dym7''4 F'#{()^

E

fiFHGfiI%J'K'L<MONPQR'SUT"PQVF,QJ'W%IXG'K'Y
Z=[\]^'_`)abficAd'ae^'fhg.\Adfiia jkg5lfiinmoipc)q#rsgqtl?aXcAd'au_Aa`)^fimc=]0[v]cAd'a _w\ g0^h`xa`%l?a`yipzfia`,mpg\ff{s]0[vg`ff`yi|f'rta ffic}
_Aa ~fimpg0f'ffiif'|#r^h`)cwcAd'a fg.z'zfi_Aa`A`=cAdfiip`]cAd'a _e\ g5^h`)a[^'_AcAd'a _ez.ip`A\^h`A`Ci].fifa\c)i]fhfi
hfhgm<ip`A`)^'aiU`|a f'a _gkmnig0cxi].f]0[="w>X38`=\]rtr^'ffiip\ g0c)i]f;\ g0~hg0lfiiomoicxia`uj.ipgtgdfiq"l'_xiUz g0~'
~'_A]"g.\Ad cAdhg0ce\]rlfiif'a`cAd'a~'_Aa`ff\_)i~'c)i]fh`X]0[>cAd'aC]0ifficwifficAa ffic)i]fh`eg5~'~'_A]"g\ffd=icAd;`)]rtag`)~?a\c`
]0[>dhg0_Aaz'mpg0fh` >{.a q+].lh`)a _Ajkg5c)i]fslhg.`)azt].f#Ae_ff]"`)eu_g0^h` b< <iU`,cAdhg5c%cAd'ae\].rtr^'ffiiU\ g5
c)i]f ifOC]0ifficuif"cAa ffic)i]fh`X\]^fimpz ~h].cAa f"cxiUgkmnmq;lhaOg0_A_)ijaz g0cwif@dhg5_Aaz'mpg0fh`uj.ipg#g"i]rO`ezfiahffiif'|
h?p.4" O']_uifh`)cg5fh\ab\].fh`yipzfia _cAdhg0cgOcffag0rrta rlha _dhg`u]l'cgif'az~'_)ijkg0cffaiffi[]_ffrsg0
c)i]f4g0l?]^'cecffd'a+g\ffdfiia ja rta fficX]0[%cAd'acffag0r8`u\^'_A_Aa fficecffag0rg.\c)i]fv0fO)]0if"cuifficAa f"cxi].fh` b<cAdfiip`
cAag0rra r+l?a _=iomom`xa {1cff]g0cAcgif4r^'cA^hgkm%lhamoia[wifVcAd'aOg\Adfiia ja ra f"c]0[Hv0bmagz.if'|1cff]\]rt
r^'ffiip\ g0c)i]f#yfV\]fficA_g`)cb?ifdhg0_Aaz'mpg0fh` b>cAd'acAag0rra r+l?a _8`X\]rr+^'ffiip\ g0cxi].fV=]^fimpz3g0_)ip`)a
lha\ g5^h`)awiic hh0X" cAd'aXcffag0rzfi]`x]rtaXg\c)i]f#vuwdfiip\ffdO[]5mnm]0e`=0b g5fhz ioi,cAd'aXcAag0r
\ g0f'f']czfi]#X=icAd']^'cgkmnm%cffag0rra r+l?a _`ulhaif'|4gwg0_AaX]0[wg\Adfiia ja ra f"cX]0[%0=dfi^h` b?[^'_ffcAd'a _
h_`)cX~'_xifh\ffi~fima`_Aag.`)]ffiif'|hblhg.`)az;]f;ifficAa _A_Aampg0cxi].fh`)dfii~h`+g5rt]f'|g\c)i]fh`:b<ip`X_Aa.^fii_Aaz;cA]zfia _xij.a
_Aama jkg5f"ct\]rtr^'ffiip\ g0c)i]fifdhg5_Aaz'mpg0fh` },l'^'cifVcAdfiip`ifh`)cg0fh\ab?)]0if"cifficAa f"cxi].fh`~'_ff]kj.ipzfiat[]_
`)^h\ffd1\]rr+^'ffiip\ g0cxi].f#=icAd']^'cucAd'aX_Aag`)].ffiif'|?
yft|a f'a _gkmb5io[cffd'aHcffag0r8`cAa _ffrifhg0c)i]f]0[].f'aeg\c)i]ft>ip`a`A`)a ffic)ipgm'[]._>cAd'a=cAag0rcA]X~?a _)[]._Ar
`)]raX[]0mom]0=if'|;g\c)i]f b<cAd'a~'_Aa`ff\_)i~'c)i]f;if#)]0if"cif"cAa ffic)i]fh`cff]g0cffcgifr^'cA^hgmlhamoia[wif
cAa _Arifhg5c)i]f]0[%cffag0rg\c)i]fh`ip`Xgzfia.^hg0cAa[]._w_Aama jkg0fficX\]rtr^'ffiip\ g0c)i]fe]0=a ja _bfiif1`x]rta
\ g`)a`:begz'z.ic)i]fhgmt\]rtr^'ffiip\ g0c)i]flhg.`)az]f`)~ha\ffio\iffi[]_ArOg0c)i]f'zfia ~ha fhzfia fh\q_Aampg0c)i]fh`)dfii~h`
g0rt].f'|g.\c)i]fh`iU`gmp`)]4a`A`)a ffic)ipgmV]_ifh`)cg0fh\ab,cAd'a`A\]^'c`Xif@cAd'a#cAcg\ff{4zfi]rsgif@f']c]ffimq
iffi[]._Argkmnm>\]rt~hg0ffiq#rta rlha _`]0[%\]rt~fima c)i]f;]0[>cAd'ai_`ff\]^'c)if'|g.\c)ijic)q;C`)]tcffd'a\]rt~hg0ffiq\ g0f
rt]0ja[]_ffg5_z?b?l'^'cgmp`)]#cAd'a~'_Aa\ffip`)as\]fi]_z.ifhg0cAa`u]5[Ha f'a rq#m]'\ g0c)i]f4cA]Oa fhg0lfimatcAd'at\]r~hg0f"q
cA]O] \ \^'~fiq#|]fi] z;g0cffcg\ff{if'|t~?]"`yic)i]fh`iffi[]_Arsg0cxi].f'zfia ~ha fhzfia fh\q?^h\ffd\].rtr^'ffiiU\ g5c)i]f4\]^fimpz
gmp`)];lha#~?]cAa ffic)ipgmomqzfia _)ijaz[_A]rcAd'a#g"i]rO`]5[ hh@" ifdhg0_Aaz'mUg5fh` b%l'^'ctg0ccAd'a
\]"`)c]0[[^'_AcAd'a _w_Aag.`)]ffiif'|h
">Xzfi]fia`f']c_ffamq]fcffd'a>h_`)cff~'_)ifh\ffi~fima`_Aag`)]ffiif'|[_ff]rifficAa ffic)i]fcAdhg5c[]_<ic`\]rtr^'
ffiip\ g0c)i]fbfi_Aamq.if'|]ftcAd'au~'_Aa`A\_)i~'c)i]fh`,]0[')]0if"c,ifficAa f"cxi].fh`>ifh`)cffagz<>w]0=a ja _b"w>Xa ~fim]0ic`
a'~fimnip\ffictzfia\ffmpg0_g0c)i]f;]0[>iffi[]_Arsg5c)i]f'zfia ~ha fhzfia fh\q4_ffamUg5c)i]fh`)dfii~h`g0r]f'|g.\c)i]fh` b?[]_g.z'z.icxi].fhgm
\]rtr^'ffiip\ g0c)i]f==dfi^h` b'wd'a f;\]rtr^'ffiip\ g0c)if'|OcAd'aXcAa _Arifhg0cxi].f]0[%gcAag0rg\c)i]f#)b<"w
\ffd'a\A{'`[]_%g0ffiqXiffi[a _A_Aaz]_%zfia\ffmpg0_Aaziffi[]_ArOg0c)i]f'zfia ~ha fhzfia fh\q#_ffamUg5c)i]fh`)dfii~h`,=icAdsg0ffiqX[]0mom]kif'|
g\c)i]f3<k;=d'aiffi[]_ffrsg0c)i]f3_Aama jkg0ffic[]._<ip`tgmp`)];\]rtr^'ffiip\ g0cAaz3wd'a f@g0cAcgkiffiif'|;r^'cA^hgm
lhamoia[wif;cAd'acAa _Arifhg0cxi].f1]5[H)XX`egO_Aa`x^fimcb<lhg`)az ]f;cAd'at`)~ha\ffio\iffi[]_Arsg5c)i]f'zfia ~ha fhzfia fh\q
_Aampg0c)i]fh`xdfii~@`)~?a\ffinhaz<b>z.ioa _Aa fficXcCqfi~ha`u]5[%iffi[]._Arsg0c)i]f4g0_ffa+\]rtr^'ffiip\ g0cAaz<b2wd'a f4cAa _ffrifhg0c)if'|
#=d"^h`:bvcffd'as`A\]^'c`\ g0fV\]rr+^'ffiip\ g0cffascAd'am]'\ g0c)i]f3]0[wa f'a rq4^'ffiic`Xd'a f\]rr+^'ffiip\ g0cxif'|
cAd'a\]rt~fima c)i]f;]0[>cAd'ai_`A\].^'c)if'|t#|0ija fcffd'aXiffi[]._Arsg0c)i]f'zfia ~?a fhzfia fh\q;_Aampg0c)i]fh`)dfii~4=icAd cAd'a
~fimpg0f'ffiif'|s]5[2g5cAcg\ff{if'|~h]fi`yic)i]fh` >[vf']t`)^h\Ad#_ffamUg5c)i]fh`)dfii~Oip`w`)~ha\ffiohaz<b?]_>io[>]cAd'a _,_Aampg0c)i]fh`)dfii~h`
g0_Aa`x~ha\ffiohaz<b<cAd'a`A\]^'c`==]^fimpz\]rtr^'ffiip\ g0cAaz.ioa _Aa fficwiffi[]_Arsg5c)i]f
">Xcffd"^h`O`)cg0_ffc`=icAd4)]0if"cif"cffa f"c)i]fh`:b=l'^'cscAd'a fl'^fiiomUz'`^'~dfiia _g0_\Adfiip\ gm`)cA_A^h\cff^'_Aa`
cAdhg0c~hg0_gmomamwcAd'a dhg0_Aaz'mpg0fh`cAd'a ]._Aqb~hg0_Ac)ip\^fimpg0_)mqb>~hg0_ffc)ipgmedhg0_ffaz'mpg0fh` ;=d'aO_Aa`)^fimct\]^fimpz
lhat\]fh`CiUzfia _ffaz4gOd"qfil'_)ipz rt]'zfiam%]0[%cAag0r=]_A{<b'cAdhg0culh]._A_A]0e`[_A].rcAd'at`)cff_Aa f'|cAdh`]0[%lh].cAdOC]0iffic
if"cffa f"c)i]fh`[]_ArOgmoig5c)i]fs]5[\]rtricAra f"c`if#l'^fiinmpz.if'|#g0fhztrOgif"cgkiffiif'|X)]0iffic%ifficAa ffic)i]fh`%g0fhz
dhg0_Aaz'mpg0fh`Czfia cgiomaz;cA_ffag0cArta fficw]0[%cAag5r8`ug0cAc)icA^hzfia`ifV\]rt~fima1cg`){'` bg.`w=amomg.`w^'f'_Aa\].f'
\ffiomaz4cg.`){ `X=dfiip`uip`u]0[\].^'_`)af']cXcAd'a]ffimq~?]"`A`yilfimaOd"qfil'_)ipz<X`urta ffic)i]f'az;ag0_xmnia _b[^'_ffcAd'a _
a'~fim]._g0c)i]fif cAd'a`)~hg\a]0[vcAag5r+=]_ff{trt]'zfiamU`ip`e\ffmag0_xmq#a`ff`)a f"cxiUgkm


fi<'%fi
>O>s;
"w38hypU3 ')'4fi 5Afip uA)tfip0h:tt=A5AfiAff'A
fi)'@)@X=''0.)hu5w"w>XAp0AAuA0= # 0h0fioo)
=' 'k. u#"wU
fiff
fi fiyA)=A0 fip0h
' t0 fifi h
4"w)A5h 0A,= ')A' th)0"xU5A

fiff "!#$!%!#" !
20? 0A.X'fioUff)& @''AA#ff08( ')0"tx.) >'fio& #A'tff fip0*
)ffh..pfih
? 0A +wfipA 'Affw00 fi8,0wx.) ( ,ff'Xfi 0ff- /
.2'A1
0'h 5A
)'0w
243u)hA5
28>'"5 3e0A A09h 0A:%wfio;A' O0Ah..pfih+.h 0ff
20x.)w)hff.6
fi798"8:$!-;< fi79>=? @AXB
=? "$!-;C=A-"8:1D fi8:(E F$" fi!G@
fiH-
Ie5Aw'0
yo& ; 'ffA)4A0.h 0ff <X)'0wJ
.2.'AK
0'<=AVx.)X0>h..Ufihk
)''A5su 'ffA)4ufffinpfiA 30=A')h 0A:L
C20h 0As0 =AM
)9NO+O0A
"fip o& ''A #)''A0O,Afipufis:
Q
Q

R

[ EXECUTEMISSION ]

R

[ Flyflightplan ]

............

Q

R

[ Engage ]

............



[ Waitwhile
battlepositionscouted ]

[Flycontrol
]
route
Q P

[ Travelling
Overwatch ]

[ Travelling ]

High
level

Low Contour
NOE
level

P

High
level

............

P

[Travelling
] [Travelling
Lead
Cover ]
*

Low Contour
NOE
level

............

&
Scout
]
[ Mask
Observe ]
* [ forward *

Employ
weapons

P

R

Unmask

*

Mask

............

waitfor
scouting
............

Employ
missile
............

popup

Initialize Maintain Select Gotonew
masklocation Dip
hover
position Mask

2'ffT0UwAOfisVUWff)#0>t .:Xhh 5Awfi 0AYsffZ
fiff[
fi fi
.

X==AOh..Ufihk%h 5A fiA5.h 0ffwp)Ohyp)w0 U( %'Ah.);Afi \]o^
0'fiop 0)3Afi\>0hJooXA Ah0)Afi K' A' 0h 5AUOA5h 5Au
0Oh.pfih=h 0A=puY "h5p o_ ;fi A'< ,yh0AxUfip0hw' ;015 "a
`."
0Oh 0A, 'x.'A'w? 0A.>pw0''0A=A#0b
)'')'5 "
+'wfipff#s9
hOY "h0U kn& 4fi A'AOhs5h..Ufihkx''A0<A0 c
,=A'*
) 'x'
0 fi> +peh0A)pfip0uA0u)''A0A'Xh 0A=pufi A' AhA0 h 5A
,wA'
) 'x'40. "> +pA's0 fiT
`.>xnA>A' 30;h.pfihe.h 0ffXA)fi O=fih
'Affp)A0 ')'#tff0 h 5A=p'etfio ?''e 0?c
dhfifi_ 4fi ff'
0='')#)t .2'A1
0Afih,ooh)A0ff=A'Y Xh'0)O0v? 0A%ffh0,Ue fifip <
A'Xwff sfis
f s0s5AfiA0
A0 h 5A gBW"o<A0t h >h)HCfi0' .hy& s)a
gBW
AO)0fiop)Vh
')0""A fi)J
&')0"ufiA fi) <
gBW=ooHhtfi 'ff1.1
2:gBWi3"jia
,b
.2'A
0'fi0=A'efi'x% 'ff'eA5As,6
')0fi>"ff ")Oa
2 'ff kpAy 3"jl ,y) A.pe0
Afip ')0",fiA "x.'A'uA0 s9 ff
')0",fiA "x.b
2 '"0 3 j ? ,x ApX0 2 '"0 3 j
h.pfihwA0 +? XoH)Xh..Ufihk.h 0ffA# tfiF -k=0?h <Afih.A'
h.pfih,fiA fi)h ,e "xfffi 0ffY #0n ')0fi0hh..pfih%fiA fi)h=pAfih,.At
w' ;00 fi=h0A)pffh0AA0= <
op

fiqsrYtuvwyxGzV{|fi}~-{9|Zq(|fiutcrv

-6?c%fibfi-cG9&->O_%&>cF6&O><^ficFY:"F&fiJF&>_% &
Y%Ofi#>F >F%*
F><FY&Ffi%>fi>>Fa"m1FfiY
F%>fi
KY
F6LF*aT%9#
:_
KF#ficKfiyfi4%&#&bV
F%% 1Yfi
9&V F>?&%&%Y6
Yfi> &%FiFn("F% &Lfifi?6
F("?%%9:&
&Y&"9:_G_1&Yfi&fiTF#fi?(F*fi%KfiKL#>&TsF*9%-e_Y&
%9OO"FY&L
fiKLY"F&fi/%F
"mficF*cY_&fiY
F%KfiVa-6?cF/9"G9&Y>9&bF>(fiB%F"_%&fiVc
"6i
fi
1%FCKfifi%%G-%mfiF[CT#BG9&->O_%&>F6*
fiYF?
F>FfiVF%FYbF>FmficF&1%F&%Fa&VKV
fi
"%


yF[>Ffi- cfi"
&fiG"(&K#-Gfi6CE :nF&fi%m<&fiY&

c %>Ffi>-_C%F yF*F&-&YY&fi%BKE :K&(-%
>B
fi%fi% &KT1F[MFGfiY&G%aKE :%C&c
fiY
E(FlmeF&Y?&Y-_
:Bi"
-%?FLL&Y&L*m-6?c Y&LCF:_F&bCE :nF&fi%**>Y&

%/fifi-F% aF%Gfi>K-_ &fi
&fic#fi6FLs n fi
>9:&F&fiF?fi%>fi>
&ficY"F%
LYBFfi%>fi>
&ficF[Y"F%>
:?Y>F&fiGFlFF%#9fisF[>F-F%
:nF&fi%

::^("
&fi%fiKF[
F6KY

Y_J JF "F*Ffi#>Ffi

>JY&F %>Ffi>KF%F

>LF/Tfi%F&fiFL-6iJfiCfi>9aKEY
aFFLs n-6?c9"
&- F&fifi-

fiK_K-
<&MFLfiy?K Y_fi&%Y"FY&MF%FY::&&cF%
KfifiZaF>Y&&bY"LY&Tfi/CEY
B_Y_FfiY>Y&
K
fiY"#fi
Y"9:&J_ J
F_ &_FfiYL%%9fi&fi
J% y-6iKY

9&Y>9&fiKbY 9&$&%Y%%YYafi#>F&fi%9aKEYY& fi4#&&G^ F1Y&
L
fiY"Y*FfiY>%%9 _ ><&FLfiyKfifi"FGfi>O&F_ %KFa
F%FY::&&1
fiY"5%F&*K%h_Yfi
FC&/F -6F>Y&

G^F:&F&%
&fi%GF "
%Cfifi%

KFL-6i&Y>Ofi
&fi%&
"
%aF[fi#>Ffim
E
&fi&b-m?cZ]fi
&fi%LY
&%-6?cJ6F%Y:&&
fiKKfiY& &MF%Y"FY&%a>O&%%Yfi
YfiK

&-6?c

F#F>&

a%% :/L
l(YyKE9nmVYy&
K
E
TL[fi%
FfiF ->T%%
6>Y"&Bfimae_Ym_YY&fiV-%-m

L $L % $
ff
&>
fi ! "#%$!&'$()*#$!$+, &!-&!./&'102&'3$!&4%5$!.6879(:;&!- <=#4%&! >/68 ?@A#
B CD#$'&4E5$'.#$F6G79(:H IKJ(LM>F6NPO B &$!&4%5$!.*C5&!.5 B &!5Q5E*5&R'#<S&(!TA"#%$!&
U /VW= 4X5 B &!$ZY5[5 B &!.*&!%\C5&/W B &!5]&'.#^_'"+#5` aA#b $-Q#$'$4%, a. B R[&'W B T^c&!W B R
! "#%$!&&'Q0d#$'&4E5$'.Q B &eJ[6879(:;Jf (>/6g= B h#$!&+5$!.687i9(:H
j 7k5&[W B &!5=lmY5nRY5@#$!&+5$!.6879(:oJf (>/6g#$!&+5$!._LM>/6pNfOe
&Y"cY:&
maL
"L # yfi
F%F ->9fiF"G Y_GF?c-#c6%
fi6CT#
q _(
r <6%F_m%-&&fi _s
=t _ 3Yu >K%F"
Y"FhFCT#
FfiG%_

&*&fi&fiL%>
FY:Y_GF&-C&-Y&fi
E

L"&fi Kv a&L
E
&fi]T-:&
aL
$T A% #fi
F Hcw fiYsfi>9
cCT#6
&
>6cFfi%>fi?fi(
E
&fiVE_(%>

1Y:&


fiE
FlY
_#%
&F

&YY%
G&bfi
_

x

fiz8{@|(}=~
=+@ h Z23fh d= 8]@#=TX=_H##TXS*@+Q#D3f
=G=n1# Xm# %e)#@(=+@ (#/Af+H@=# #+ 8M%*E[3@
=+fAP# c/##@ = /_/=##@ = c@#=@+# #@XP
p#'D@A!e# +X@DP#=a@_# ipHf_@+f+P*
'==H# + #_@#=T_+S*#(=@+F#/##[ ==)=f#f@
@=# + S)Z2e!+ 8(@##=+S)H# id# =k=+f##@
# @ + Xc#S# +aP#=
#3 =f+=@ffh4=-S#=+d3f(8c# p#-=ka#a#
@@X+@ff@m# X+X#c!a@#AFp!/=f*# +#P# Q#a+
Af@/++fA]a@=f+c!A@# /]@3+=-)@#H#@HmX=F#@#@ i#a@
+/A@+# 8SG]@=## mX# p)@a##a+@-#
@#@#8/#D D# p#A8=+=_##X++hmAkc+ 8
!M/+i#mX_#@_p#= 8/@=T=D*##SAQe
= @+T#D+#k=Acm#im@ a/## Xp# a#a+
+[/2+#Hf+=*2*# X+X#e#@Dm # aki@=f
ST!M)da@=f+p# 1/=fcp#m@#=@+i#@#2#@# k
@@X+@m#@H +X#@c#@k#a+@c#@H# \
HS@ k X+A[=@+@_# a/#8Xff=-mAmpi#P=-D+Ap4=
SS+%]+iHS@k@=+#a# [+*=ff_+@@# XkQ/=8D=3mA_p
#P@c-4X==#=+_=@_@HS+#a=8+#HM@ @#af#4@f/
/E(-@hSX@++Hm+@@ k8+#D*Mm+S!X=+#K]@ff@#a
+d+d3k c# X#Hfa#P4 8(S)Z S*/E3A#
#Aa@#Aec=#@-#TXS/+@@# # XkMpA#S/#m+=!=
+fmAm=caa@=f# @mh
@@_@@S@+HX(#@a@=f+D #eS)Z@ #@n-=#c+@
==#f+=c/#S/@2+@EQ@k=P/#TXSc=#m2P
@## n##@H@##=/F+fm+#3i@#S@+F//@)=#mX+@!==
#f+=mAp+p _P=TffpZ *##a++[ /+
+@@pS+mc=kipQ=k+ H+i@a@@-#@a#@#*)=i@#c@
+!)# = )#X)#=f!3+ #@H# k)@##=+S/=#=+ =K@=#=f@f
#aH@#=TX=/=PFf/+=/_#@-# \+S@ka@=PX+_#
f* @# 8# +=+@o #@S@+hPX+@D##a)#@*)A)EXSK8E
# H'@+[SH+ h#@a=f+o =#mX+@!==
#f+=_k-/@) A/#a@##@/[MaX+Xm# +[#@
@8eZ-a# =A@#@-/@_a@=f+P@X# 8
@kAaK%!=32) )EXSKA i@ S+K@QkEXS
=P #Hf==+ -#@+ XQ+=@=nm) ip###X#m =
@=#=f@ d=Q#T=_@8k/==_=#m*#@e=S *@*T=c@@
-)[3@X#HF= #Q)3-#@a_/ S+f@/fH=@#c#@
=n#m+@!=p=k#f+=[F/=f=n#m+i#@GQ@+kc# +_
#@-@*= /# a#Q=Q@@#@PX#/@a@#@=#c+@


fi ff
fffi ffff ff
ff

!#"$!#%$!#%$&(')&(*+,"$*-%ff!#%./0%1.32/5476984:2/0*%;"ff<3*>=-/!4?8ff-/0.:/0*%$8@A&(*+7+ABff%/5&#8>.C/D*-%FE$!(G/0H/I@J/K.L'MN84
!(Gff"@8O/D%ff!?!8><C@J/0!#<P/0%RQ!&(.:/0*%RSffTUSVTXW
Y[ZK\^])_a`cbd#_fe>bg`fhji`ck;l7monqpi`[`br`h
st%ff!u+v8>w:*<v4C*Bff<x&(!y*z6{.3!8>+}|~*<3u698/I@0Bff<3!4#M84}*Bff.C@J/0%ff!/0%)Q!&(.:/0*%1ffM/548>!#%.x4#/D%$8zH/J@I/0.:'1.3*
+,*%/0.3*-<{.3!8>+"!#<:6r*<3+v8>%$&(!TQt698&/I@J/0.x8z.3!4}4:B$&32+,*%/0.3*<:/0%ff?H'u!(Gff"@D*z/D.C/D%ff/D.(4!(Gff"@J/5&/0.
<3!#"ff<3!4C!#%.x8z.:/0*%y*>6.3!8>+*"$!#<x8z.3*<x4#T9%y"$8z<3.:/5&(B@58><MaQt8@I@D*>|48>%!(Gff"@I/&/0.}4:"$!&/If&#8>.:/0*%u*>6
+,*%/0.3*-<:/0%ff&(*-%$-/D.C/D*-%$4~.3*A!#.!#<3+}/0%ff!8-&32/0!#=!#+,!#%.MBff%$8&2/0!#=O8>H/I@I/5.:'*</0<3<!(@D!#=>8>%$&('*>6.3!8>+*"ff
!#<x8>.*<x4#Tq9%u8ff-/0.:/0*%MQt698&/I@I/D.(8>.3!4P!(Go"@I/5&/0.A4:"!&/Jf&#8z.:/0*%u*>6.2ff!<3!(@58>.:/0*%$4:2/0"uH$!#.:|~!#!#%y8
.3!8>+*"$!#<(8>.3*< 8>%$A/D%$-/0=-/5B$8@54#$*-< 4:BffHff.3!8>+y4 &(*%.3<:/0HffBff.:/0*%$4.3*/0.T~QPB$4:!4.32ff!4C!4:"$!&/I$
&#8>.:/0*%$4.3*/0%6!#<~.32ff!8&2/D!#=-!#+,!#%.~*<Bff%$8&2/D!#=>8>H/I@I/5.:'*>6[8.3!8>+*"!#<x8>.3*-<T[~2ff!4C!4:"!&/If&#8>.:/0*%$4
8><3!H$8-4:!*%.2ff!{%ff*.:/0*%?*>6 8:IT<3*z@D!/548>%y8zH$4:.3<x8&(.t4:"!&/If&#8>.:/0*%R*>6.32ff!{4:!#.*>6 8&(.:/0=-/D.C/D!4
8>%7/0%$-/D=-/5B$8@[*<t8N4:BffHff.3!8>+Bff%$!#<3.x8z!4q/0%y4:!#<3=-/5&(!*z6[.32ff!t.3!8z+yU4*>=!#<(8@I@c8&(.:/0=-/0.L'T~2B$4M8N<3*>@0!
&(*%$4:.<x8/0%$4{8.3!8>++7!#+AH!#<A-/9*<{8y4CBffHff.3!8>+t.3*4:*-+,!v4:BffH*"$!#<x8z.3*<#L4t*"$#t*z6.32ff!.3!8>+
*"!#<x8>.3*<}Is5~TAV*</0%$4:.x8>%$&(!Mq4:Bff"ff"$*4:!v84:BffHff.3!8z+)/548434/0%ff!.32ff!,<3*>@0!}*>6t8?(q/0%R.32ff!
t.3.(8&3,*+8/0%T~2/54~<*>@0!{&(*%$4:.3<x8O/D%$4.32ff!4CBffHff.3!8>+.3*}!(Gff!&(Bff.3!{.32ff!4:BffH*"$!#<x8z.3*<#L4.*4&(*Bff.
.32ff!H$8>..:@0!"$*4/0.:/0*%/0%u4:!#<3=-/&(!N*>6[.32ff!*>=!#<(8@I@c.!8>+*"$!#<x8z.3*<KKLqKI#CrrI#o>#Kr5V9#x-r(
L4:!#!{a/0Bff<!AxT
84C!j*%F.32ff!?%ff*.:/0*%*>6{<*>@0!4#M .2ff<3!#!y"ff<:/0+}/0.:/0=!u<3*z@D!#r<!(@8z.:/0*%$4:2/0"$4ur/rA:x,5r5-
r/I/r~tL(,#K$rK}8>%$r/I/J/r~-JLCo$$t&#8z%v&(Bff<3<3!#%.:@0',H$!4:"!&/J$!/0%yQtjT~2ff!4:!
"ff<:/0+}/0.:/0=!j<3*>@0!#r<3!(@58>.:/0*%$4C2/D"$4
&#8@I@0!^:I#:}$Kr(5F(ff#r:K$K}
/0+,"@0'1.32ff!?6r*>@I@0*O|/D%ff
<3!(@58>.:/0*%$4C2/D"$4H!#.:|!#!#%y8.3!8>+*"!#<x8>.3*-<Ds[8>%$7/0.x44:BffH*"$!#<x8z.3*<x4#
~~ L:#30(r5#X~5y0
N[L:05X~5y0





P#Ir33#a 3 K

ff




2ff!4:!y"ff<:/0+}/0.:/0=!u<3*z@D!#r+7*%/0.3*<:/0%ffF&(*%$4:.<x8/0%.(4}+v8'H!R&(*+}H/D%ff!MP.3*4:"!&/I6';+,*<!y&(*+,
"@0!(GR<3!(@58>.:/0*%$4:2/0"$4#Tff*</0%$4:.x8z%$&(!M6r*<.32ff<3!#!,8>!#%.x4-/9M[w{8>%$uM|~/0.32<3*>@0!4*" Ma*" 8>%$
*"$ Mff8}&(*+}H/0%$8>.:/0*%
:s
<3*>@0!<!(@8z.:/0*%$4:2/0"&#8>%H$!{4C"$!&/I$!u84~3*"$# *"$ *"$ -xT
Qt?rH$84:!j8>!#%.x4}&#8>%j%ff*>|/0%6!#<7.32$8>.}.32ff!<3*>@0!v%ff*-%ffr"$!#<:6r*<3+v8z%$&(!*>6 *-"$ -+v8>!4
Bff%$8&32/0!#=>8>H@0! ~HffBff.{.32ff!<3*>@0!%ff*%ffr"$!#<:6r*<3+8>%$&(!,*>6w:B$4:.{*%ff!*>6-/*-<Aw/54{%ff*-.A&(<:/0.:/5&#8@t.3*
TQ>/0+}/I@58><:@0'Mq6r*<.:|~*8z!#%.(4-/8>%$Rw#MH$*-.328>%js ~9&(*+}H/0%$8>.:/0*%"@0B$4<3*>@0!#9!#"$!#%$!#%$&('
+v8'yH!v4:"!&/J$!j84N3*"$# *-"$ *"$#
*"$ O3(T ~*>@0!,+,*-%/D.*<:/0%ff&(*%$4C.3<x8/0%.x4+v8'
H$!}4:"$!&/I$!/0%y.3!#<+v4~*>6q/0%$-/D=-/5B$8@54#<*>@0!4#Mff*<t4:BffHff.3!8z+yU4~<3*z@D!4T
2ff!A+7!&32$8>%/54:+46r*<.<x8&/0%ff.3!8>+7+v8>.3!4#<3*>@0!}"$!#<C6*<+v8>%$&(!,*<P/0%6!#<<:/0%ffy.32ff!(/0<{<*>@0!,%ff*%ff
"$!#<C6*<+v8>%$&(!N/54"$8><3.C@D'R*+8/0%!#"!#%$!#%.T,4+,!#%.C/D*-%ff!?/0%Q!&(.:/0*%SffTSffM/0%4:*+,!,*+8/0%$4#M
8>%u8>!#%.t%ff!#!?%ff*.t%ff*O| /0.x4P.3!8>+,+v8z.3!U4~!#.x8/I@0!?"@8z%*-<.3<(8&3.32$8>./D%u!#.x8/I@9MHffBff.+8'<3!(@0'
*%2/02ffK@0!#=!(@*H$4:!#<3=>8>.:/0*%$4#Tff*</0%$4:.x8>%$&(!Mo/D%.2ff!t.3.x8&,*+v8/0%M/I6 8}2ff!(@I/5&(*"ff.3!#<P/4P!4:.3<3*>'!M
.3!8>+ +,!#+}H$!#<x4/0%6!#<}<3*>@0!%ff*%ffr"$!#<C6*<+v8>%$&(!76*<.2ff!8 !&(.3!.3!8>++,!#+}H$!#<T9%R*-.32ff!#<A&#84C!4#M
4:B$&2 8-4{.2ff! ~*-H$* Bff"Q*ff&#&(!#<*-+v8/0%M%ff*R4:B$&22/02ffK@0!#=!(@t/0%$-/5&#8>.:/0*% /54A8=>8/I@8zH@D!T9%$4:.!8M









fffi



fi

fi






fi


"!
#$&%('*),+-/.10),02,- 3),45-6'789:-<;=?>"@5AB(8C7ED,-6F7EGH-6'ff),D&),45I64 J*JK0'L:I7),-5M/L:),+*'4H'BN;ff=?>O@<ABP8C7ED,-QF7EGH-6'ff),D63C7RG -6'-62PL:I
I64HJ*JK0'ffL:I7E)PL:4H'S9T7E'G 0C7EG -UJV76WX8-K'-QI6-6D,DY7E2,WH$RZ[+L\9:-VG -Q'-62Y7)PL:'G'7),02Y769"9T7E'G 0C7EGH-]L:D?I602,2,-6'ff)P9:W4 0),DPL:F-V),+D,I64H^-/4.;ff=?>O@<A_3H;=?>"@5A`F4ff-6D"'4 )^2,-6IY9:0F-D,0IY+*7/^4HD,DPL:8L\9:L:)PWH$@a9:),-62,'C7E)PL:bH-c9:W 3C7E'K72,)PL\dIcLT769I64HJ*Je0'ffL:I7E)PL:4H'
9T7'GH07G - 3D,0IY+7ED5f(; L:F'-6263"gih hEjk/JV76WX8-50D,-6F$


fim/n"oKprq
stuffvrwHxXv"uffuy`wz{z}|"wHs~1vz1uuff6,z[sv& u~vr,zsw6~1zv~(s{stuffvwwEHsE~1v"tcrsvu ztvr~1w6~1zv/
QRsS|&u5}"Rr &u\t1~(xsr(suffstuffvrwX~1vw"u[*z}|&z"K"xc~1r(swi~z}vy"sx6r~1v"ts"usywz
u u ~1us&sxx Kz}S"vr~ffsw6~1zv{[s|usv"zw"uffx6z}"H uSz?~1vr,z[sw6~1zvufftsHy}~1v"tz1uSv"zv"
&uffiNzE[sv& u5a~1Hx6wrsx5y}~(x &xx6uy|u zOV51usy"x~1v&y}~}~(yr&s(xVwEzsv"v"z"v& uVzuffYE&sv"tux
wzw"uSwus{?sv&ywr&xz}w"uffwusuffS|uffHx~1v&y}~Eu w61~1vr,uffz1uff,uff6Nz}[sv& uS~1vr,z[sw6~1zv
u zv&y/&s}xUy}~(x &xEx6uy~vu wi~z}v"1}"V[s_1usy~1v&y}~1~(yr&s(xwzy}~Eu w61{ zS"vr~(ffswu
w"u ~1Xz1uv"zv",&uffiNzE[sv& u5y"y}~1w6~1zv&s1?s_,uffyrz[sC~v"P~1v&yruffuffv&yruffvw_u&svr~xi[x*,ze~1vrNuffE
6~1v"tSz1uX&uff6,z[sv& usEuV"z~(yruy~1vV5*r&xffrz1uXv"zv",&uff6,zsv& uV~(x~1vrNuffEuy~?v"z
~1v&y}~1~(yr&s*zxi"|"wus~xXx6uE~T&uyNzX&uffiNzE[sv& uzsz1u6sxe~1v~wEuff"&a~1t"uSrH*xiz&
~]s5~1v&y}~1~(yr&s(xS]~wEr~vs[x6"|"wEussuNz"v&y~1v&ffs&s|r1uzK&uffiNzES~1v"tw"u ~1z1uxffRV
~1vrNuff xVw"uuffvrw6~1uSx6"|"wusffsv"v"zwV&uffiNzE~1wHx*z1u
i}|&sx6uySz}vw"u*z1uff,zvr~1wz}6~1v"t z}v&x6wHs~1vrwHx5sv&ySwE"uVz1uVuff6Nz}[sv& u*~1vr,z[sw6~1zv[s|z"w
wus[swuxffr5~vr,uffHxewusz&uff swzX5(wz_|&uX"v&sEr~uffs|r1u"~1we~1v}zuxVuff&s~1(,z
uffr(sv"vr~1v"t&effsx6w6~1v"t{Euff&s~1sx_swusz}&uffHswEzstuffvrwHxs"wEz[sw6~(ffs1uffv&x6"uw"uSuffvwi~Eu
wus:x z}S~1wuffvrwXNz}w"u ~1_uffr(sv"vr~1v"tcw"uSuffvw6~1uSwus~xsCu wEuy~(~(x"v&s}r~1uffr
s|r1uH""Ew"uffzEu?stuffvrwHx~1vr,zwEus[swEuxXv"zwzvr1s|z"wzxxc~1|r1uuff&s~1Eux6r1wHxffR|""w
s(x6zuff&s~1X"v&sr~1uffs|r~T~PwQz~1u 1uffCsv& ]"us w6~1zv&xwHs}uffv~1vx6uff}~ uSzV\uff&sC~E yruff&uffv&y
zvw"u zvrwu w [\Euff&s~1(Vsx~1vz}uyyr"uwz(Kxyrz[s~1v"Yx6uE~"v&sEr~uffs|r~~(w6
zv&y}~1w6~1zv&xffyrz}[s~1v"Yx6&uE~SEuff&s~1X~xw6~1tt}uffuy/ v zvrwHsxiw}~T\uff&s~1P]s}xe~1vz}uy{yr"uSwz
z1uff,z}vr~wEz6~1v"t zv&x6wEHs~1vw_Ys~1"uxffV51usy"xusEst}uffvwSwz&Hx6wsv&sCrffuw"usC~T1"u
*"uSsv&s1xQ~x[suff}us<sHP,( 6eff(r6*sxc~1v"t1uEz1uYs~"Euffs&xc~1v"tw"u"v&s}r~1uffr
s|r~~1wQz](Vr~(E[s[z"ff "*~1vsvXXY zS|r~v&sw6~1zv~Usvr[stuffvrwVzVx6"|"wEusYs~x
~1v~1wHxz1uVz}[sv]Y zS|r~v&sw6~1zvV"uffvswEusuffS|&uff x[sEuz1uffYyruff&uffv&yruffvrwzvs`xc~1v"
t1uS~1v&y}~1~(yr&szsxc~1v"t1u{x6"|"wEus{[OzX~1v&x6wHsv& uRV"uffvstuffvrwHxsuS&}~1v"t~vNzE[sw6~1zv}~(s
\w s}u T~1v"t(*Y zS|r~1v&sw6~1zv/HRuffuffEzv"u~xz1uffYyruff&uffv&yruffvrwzvw"uS1usy"u ~( z"wuff{*r&xff
x6"zr(yw"uX1usy{ Hs}x6&s 6~1w6~(ffs5z1uXYs~1"uz"ff "Hxff
]"us w6~1zvwHs}uffv~vffsx6uxz<s i~wi~ffsC<zuXYs~1"u_~(xVwusEu zvr&t"Hswi~z}v"wz[yruffwuffES~1v"u
swusuffS|&uff/zx6"|"wus{/wzx6"|&x6w6~1w"wu_,zXw"u 6~1w6~(ffs*z1uXxXuffvw6~1zv"uyusiT~1uffawr~(x
xc~1w&swi~z}v z}ux6zv&y"xXwzw"u "v"Eu zv&E~uyffsx6u~1v&suy"<(sv&xffy}~(x &xx6uy~vu w6~1zv":"
*"ux6wEuff&xVwHsuffv~1v`V5~vwr~(xffs}x6ususxUNz1zxff
]iEX16ff( Y6K ffi i6N,NPff
fiff
ffff ! #"$ff#%&('fi)"+*+"+ff"+
%,-ff % %.#%,ff ! /0 '1ff-%,2!ff /-&("+ff 3ff
42"+
/ '1ff
%.5ff ! 67"+ff"8*(%,*+ :
9;ff !"$'!0
2
'1ff*+<3
*+"+ %'>=1%?"$'A@B
) 7"CD-EF'!%&(*$ G=10, :
H(. %,2! IJ0 '1ff%
2ff G/-ff ff ff
2
%.Kff
"+ff"8*L%*$ M.B"+*$2! 5N''%ff( '=1"8=ff O.P%,2!ff"+ff
2ff"+%,'
Q
RKS6 TK ffE,(6 U&6ffN V?(i,11 W6X,EP7 HM' /';0, '1ff5=A ff
/"+' M)%
"$!*$ '=1"8=ff
XP YI
"$' *+2=1"+'0-"$ff
*Z.[I!"+ff\ !
EFO.P%,\7%,'1]"8 ff
\&("+ff ;'=1"8=ff ,^ \ 7_A"+
ff"+'0/ %//"+ff
'1ffff
%ff ff
K
`a.
ff
/ %,/"+ff- '1ff\ *+ G,=1<;
"$ff
"8*bIff '=1"8=ff
"+# *+"+/"+'ff =c.P%d %,'
"8=1 [ff"+%,'
e%

"$'!ff[' ,I"Z.ff -'=A"f=!ff g"$\-)ff
"8 "+)'1ff\"+';-ff Gh%,) ff%\&( "8
"+5'i#j\kO@l7%,"+'ff"+%,'mI
"$ff
J
)%,'!"+"+*+"$ff
"+ Jff
%ff
\ff
n *$
,=A</ "+ff"8*op Nq, '"Z.m"+ff)%

# *+ q,'Fff()"+*+"+ff"+ GI
"$ff''!%,ff(ff[E, M%q, ff M%*$ M"+'?42
ff"+%,&
' rA"$"+*f*+<,IGff ! sN'=1"8=ff M"$2!*$ G=%,2!ffJ"Z.t*+*%,ff
(ff G
/ g%,*+ @=1 ) '=A '1ff\%,'"+Hff

u#v*ff6QU w,iQ,,N(YPS6x#y('=A"f=!ff XP[YM'%ff#2*+ =%2ff#"+';ff
)zQ'{2!ff
"$ff
2ff
.P%,ff g%,*+ }|( "+~7%,2*8=/ '?'?"+'=A"$q1"8=12*q%,*+2'1ff N "+'0"+ff
*Z.[I1%,\-ff
n*+ ,=A (q,%*$2!'Fff

"$'!0
"$ff
K2ff
.P%,Kff ! 5
"$ff
"8*
%,*+ Kr1"+' -
)"$lP"+J#ff G%) N[ff
%,GI'=g"+' M%*$ 7@B
2ff
"+ff2ff
"$%'
"$)*+"+ "+ff(,
"+ q / '1ffGI'1</
%,*+ @b2
ff"+ff2!ff"+%,'"+~''%2' =6ff%/X

,

fi5\DDK{,DMD\DD

gsN$7lO1[N+bP [P b81 --+BN1PDOPNJ
$!\!JN>
,+$-!(,7+1$b1
#N$N,1(+1+1fA,(
Gn/(1+
!+(,8
,+\/8/ //+
1

3DNNz{8m,A;LA3b1+81D1m1DDG,DD,G1 8D
bG7f7F518lF$8D, mN-8{8}8DDfi#DN~[fmG3:GD 8D DD,1
D# m,N+m,KK1m;NDG8F1L1!(Pa a$7Nbb+1PbabG818,#1{c--
G8m1 8A?DNGD 8DAf#8DD!DGDG 8 P18+8DDGD
DD,A8D/N, A\D?Gm1{Pg8D1,:;L ,-ND?1m1++8 8,1ONGD 8Dm#D
8,/A5P DD,A6fD, m1g8?118D87DD,1 b/GD 8DmAm1D
DDmG,-PNm1D818ND?N, A\D,13:mg1\P DD,A DGfN
GDPG 8DG8; 8b+8bm1 8bm
8 8DGD,
nPDF fiff,GDN, #8P
DAf
8D, 18mG? mNfiDN18/
8D;A/GmD,fiN?ND8F~Gfiff#1
8m!8Pm,1 !m1NK1m
8mG7{fiff+PN8 ND,Dgb/G 8 PsG!DGGD
D#8, ;118mF~
Pbfi,G
sD\ 8\mFfDDG,D1m1\A8!,-8D#GNfiffA DD,11D}m1
D{,1/fi P Nm8 #++m8!, / ,1p!m1N,O! b1+81
1 P/mFf{DDG,D#8 Pfi fim1+8D8m!8PmP:7DD DD,1 1
1\mA PGP1G 8 PJN18,\DDND;N1;m8G;DP1 8fiDN-g1DA P+"
, N PG,fi#88

D;+8D{DD# +fi D,L,L%$'&P+# ,!" 3
8D18fimm1)(!
P/!P18,b Afm bAmG* m,Am ;,+.-'/10 ,+324G657(!5m -8D11D!D
16( 7m m1,+.-/10 !,+%89#18>Lmmfi+8D3GP 8183 DD,1:;8m , 1\1{8m!f!Pm=<J1m{ND/ DD,1sD1-8>AfiP7F~mFf
l+fDNfi>mP{P?# +&a$# ,D1/L B! 818@<\N G1P 8m1Af
P-
8m1 8L#8 Dz7Dm 8D 8:P1+Afb;G 8 P\187 m8
s8 G+
DmN8F18A1fmG-DNm8\1BCEDB zP8 G+DmNf118m/G!;8#+fDN#P\7D;,K
1mZG;8a+fDN PfiD1 8!,KD!{fm71mG-8DNFfGfN
+fDNfi8;+8,{D8DDfim GF? 7 8D G!;8alF$8D3N,1 mA,
O!m7D,Nm1,1n;mG#++DDJfiffD,GD# m;! P\G7f!m#8D!D~Gm7f7fD
,11,}b(z DDN,1H 1fm!8!PmI(!mGDNG;8a+8DLD8B
8m1++fJ:;m7BNDG8N18,M83D,AK)LC#Db!18DG 8!fJ

MONQPBRTSVUWKXAPZY,[\Y,]^@_a`7YbTcedfdhgjij_\]lkm^n_\cei
O! 1-G;DP1;{, A$P 1m:6fmA,1 L1GVo8DA
D?L;1,1 L1G8 >m1P !8D;,MP;G;DP1 8
8
+ 1/1D,p [q,G 8Grfi D1-;8 P+,G\77s
m8L8 +8;8D3
#DGbt(fG1,,NP
8DbD! P;G;DP1 8 G8,G 88J5g1O!
1!,L8Gm
PA 8?G?DP17f!6G 1m mDGmK#G+tD+vuF,+,aK@w
# ,+%xmgPy& @#fiwbaGw@$>Nfi# z${wba$ N,+a%xV| +8NDA1 P;ADDN:
, m!m ;D;Gm N8G#1\,8b# PFfmD8-PD!D,G,N1 + !fAA 81\D
D,G7fD7f!m1D} 1887f!mb15! m1 PGP1,Dq} 18 f 8m BG1;
#fi,sD{1mD1/G?DP17f!mDDG1D;G!;8;N1FffiDmFtLG+fG
~g8,NP
8DbND PfiG;DP1 8 G8,G 8!8>?O! 1N;D#{b1+81hD;
G Nbfit,G7f!;DDfi1~A88DDmFtLG+fG#G8F1gf}[Af#87f!m
@

fi1lj

@lV!l%Jfi;l)%\@'a@;l)%\@6fi@6VlV=@fiE;z,zJl
lV,J@*I"EB?B;l,QfiJfiIn6%@Jl%6Vl%{l@",zz,.=
;lJ;V,>"V@fiJ@,'=lzfiz6Vlvn@,fiJ?@'>fi@6Vl@lfiI.
a;l6@fiJ@TmJ;T@lfifi@6%'V,\"@qhl@,>y=mh@'fi@66z"
l4Ap.@7,lT%nKV%a@VV,JlGEjhsl@,"JG1
l;@%1@Al@ lee,,'lqVfi@z,J@"V,JlE=@,v
J@@fiz6) l@Q'A@,,.J?j7a@Evfi@fiz",nJ@e1l
%,fi%;Ifi j 7Ol@fiJ@v!T@JlVlVfivn"Vfi@6VlJ@e,v le
Rewards
(1

NC

)

Cost: 0

B

(F unknown) B Cmt

Decision node
Chance node

(F known)

C
Cost: Cc

B

1

(F known)

0

(F unknown) B Cmt

@l6Z'%\@'@fi@l"ze
?6@lEfil,%fi%lJ"J*7@lJ@Tzv!Ifij)?j>6B7@lJ@*';?% ?
6T.V)fil,%fi%lJ>@1{zfi@6Vl%sj6?>6z=@j
qI?jj
,ya@e,Jfi,fi@Vl;z @T.elq,zl;V"zz\
>@@j@7

l@"a@@ltz@6;.,B@lfiI@l@@\,fi)q7f\"z6 fill
Ifi@6@ l4"%zn, j A4am,.J,A;@%llQa@K@lm@l
lV{n '@lVzl@e\,fi4"l@l@v!4q7 j @eV;lTfi@l"zfiJ
Iqfi@4{,,zl@l\,nJ@@;fi=O,%6V,'Q%Q,fi%,fi
a,fi%@fiz6VlvnJ@6OlEfiJ",fi%@J%'>%fi%@J%fiBlJllfi";%n@fiJz>@=
%JJl@ze@T\l!n@7Z"fiaB*'%{V@,B,n,V,@l)fi@l"z
l%fi%@
Zm%fi%*lJT.""%nJ@v'.JQ,J%zEJfi%fiJ@J*lQav*zV
aV%,

l@fi=aGl*l@,nJG@ jJQfi@6V6?, ; l*m,.>a@
fil%filJlsEh;l@l;J)fi@V6A@Hl6%{mlsnn@)fiz6Vlvn%
sj6Ef?>6z=@j
Qj
at.1 ) l
fiffQ 1 l

lllEzl.%J@fi@6VlJ@A
@%,,zl,fi.JQl)V,
J@*fiJJzeJ"J@,j @B,Jfi,fi@,% 6VmqT.V,l,fi4"Q,;
lV JlzlT,J% ,
l"zal
f*mTl,z4n" l6fi 'l%
T.*l@m%fifil%
Blz)fi@6VlJl{fi@,"z"J @V;l6%v>"zs)a@
fi@6VlJ@vlfia@Vfil,%6,,
elVl,fi4"J@ 'l%
l>6J@f>@l!
#
",fis@VQ%lzl@,\Ga@ %6Tn%V
",n%z,@lV,fifiJ?qv,fi%1

$&%
'

fi(*)+-,/./02134
576/8:9;45<(=57,/>-+?)/./@

B

(1

)

NC

Cost: 0

C

Cost: Cc

(1

1

C0

B

(1



B

(Terminates)

) (Not Terminate) 0
(Terminates)

BCmt

(Not Terminate) 0

)

(1

Rewards
B

B

)

(Terminates)

B

(Not Terminate)

Cn

[Irrelevant]

EGFH7I/JLKMON-PRQ/SLKUT VK
VVK
WXFZY[F\7T]SLJXKUK?^_FSL`ab
c H;dFTe TfdgH7KUT;ShWi\7jkjlI/TFZWUd SLK
YmFonpP-qsrLtkuRv<P-qsrxwytku&eiFzb{K7be|Fonpa}~}7-=vrL*W=firiUzauL-T2u&b
*afF:YleFzb{K7be2dkSLK
dgj\7KUJ&d SL\J` d7YSLKUJLjlFT SLK
V2eSL`FZYK
7I SF\T!JXK
VI WiK
YSL\l ~}7-=v_W
YKUKUT/JLKUF\7I Y[7ba?eRFzb{K7beh`FH7`I/T WiKUJLS&dFTSxd \7I/SkSLKUJLjFT dgSF\7Te-T/\Wi\7jjfI/TFZWUd SF\T
JLK
YIS&YFok-TFZY`FH7`b_`/KUJXKi\7JXK7e-SL`/K]VK
WXFZY[F\7TSLJLKUKFZYI/JLSL`/KUJkKiQ/SLKUT VK
VSL\]FT WXI VK<dT/KU^
jkK
YLYXd H7KS;K SL`/JLK
SlSL\x\ FTSlFT;SXKUT;SF\7T ^`/KUJLK]-TFZYUKUJL\ eh/I/S KUT/Ki SiYd7WUWiJXI/K
Vd JLK
\ ^*KUJsrx_*u&b=_`FZYSL`/JXK
S_jkK
YLYLd HK?jdQFjFUK
YKiQ/ K
WiSLK
VI/SFooFSx^`/KUT!a?7eFbK7beF=TF:Y
`FH7`\7J_Wi\7jkjlI/TFZWUd SFT/HkSLKUJXjlFT SF\7Te/d?SLK
dgjjkKUjl KUJWi\7jjfI/TFZWUd SXK
Y*dsSL`/JLK
SbEO\7JhFT YSid WiK7e
d]SL`/JXK
SljkK
YLYLd HKkFZYI YK
VFod Tfid H7KUTSdFoZYFTFS&Yl\ ^TJL\ K7e-^`F:WX`FZYdSL`/JLK
SkSX\!SX`/Klx\ FTS
FT;SXKUT;SF\7Tb\ ^*KUKUJ
e*dYkKi\7JXK7e_SLKUJLjlFT SF\7TjkK
YXYLd H7K
Yd JLKI YK
V^`/KUTa7e_^`/KUJLK]SL`/KU
jdQFjlFUKKiQ/ K
WiSLK
VI/SFooFS7b
U
</

2;U/ Lh ~
c Yd= J&YSRYSLKUe;P c? \7T?I YK
YG7I doFS&d SFKr\ ^e`FH`e
jkK
VFI/ju2 J&dgjkKUSLKUJ dI/K
YUb=;P c?
K
YSFjdgSLK
YoF7KioF`/\;\/V\ _Zd7WX]\ hx\ FTSfWi\7jjlFSLjkKUTS&Y eF:dSLK
jSLJ&d7WX7FT/HrxdgjfK7e-
7u_
VT jlFZWUdoFTKUJLJFT/HdSLK
jYjKUT;S&d*YS&d SLKJL\7j\7 YKUJLd SF\T Y?\ _SLK
jjKUjfKUJ&YUd7WiSF\T YUb
E/\JLSLI/T SLKi7eJ&d SL`/KUJhSL` dgTkSLJ&d7WXFT/H?K
dWL`kSXK
jkjd SXKYKU J&d SLKi7ed Td H7KUTS-FWUd TkJXKi\7TFSiYh\ ^T
SLK
j\ KUJ&d SX\7JKiQ/K
WiI/SF\7T]\7J?SLK
dgjSLJ&d7WX7FT/H bzT JLSFZWiIZd J
eRYI// \;YKF-` d7Y?YKiK
WiSLK
VdSLK
j
\7KUJ&d SL\7J#\JKiQ/K
WiI/SF\7Te-d VyFSfT/KUK
V/YSL\K
YSFjd SXK \7J\ KUJ&d SX\7JlRedgT V]FS&YSLK
jb
\^e/FoF*YKiK
WiSLK
VdgSJ&dgT V\7jJX\7jdWX`/\ FZWiKk\ *K
do]/JLKiKUJid KWUd VFZV/d SLK
YUeGSL`/KUTFS&Y
SLK
jjd SLK
YsjdyVFonKUJlFTSL`FZYlYKiK
WiSF\7Tb<`;I YUeSL`/KUJLKF:YWXK
dgJd\ ^oF7KioF`/\;\/V\ dx\ FTS
Wi\7jkjFSXjkKUT;S=FK
YSFjd SLK
SL\K?`FH7`b-\^_KU7KUJe Fo-FZY=SL`/K\TWX`/\ FZWiKddFZd K7eSL`/KUT
VKUKUT V/Y\T!SX`/Kk/JLK
WiK
VFT/Ho- SL` dgSF_KiQK
WiI/SLK
Vy^_FSL`SL`/KlSLK
jsbkrxjd
K?I YSd
Y[FT/H KUSL\7TeFbK7be-?jd
K?d TkFT VFF:VI d\7KUJ&d SL\J-SL` S_FKiQK
WiI/SLK
Vd\T/K u&bh_`/KUJLK?d JLKSL`/JLKUK
WUd7YK
YSX\pWi\7T YxF:VKUJbkEGFJiYS
eOF?rLFZY?YI//SLK
dgj\ u_\7Jl?edo-jkKUjl KUJiY\ ^_KUJLK
\ FT;SKiQK
WiI/SFT/H]o= ZRbhE/I/JLSL`/KUJXjk\7JLK7e2o= Z]Wi\7IZV\7T K?SLKUJXjlFT SLK
VF:djfI/SXI KioFKi
jk\T/Hlb`;I YUeF:YoFKiSL\Kh\ FT;SkWi\7jkjFSXSLK
VSL\?KiQK
WiI/SFT/HSL`/K\7TT/KiQS_WL`/\ FZWiK?y
FZY_K
YSFjd SLK
V\^b_7K
Wi\7T V2eFo-eY\7jkKjkKUjl KUJ&Y*FT]^_KUJLKT/\7SR\ FT;S JLSFZWXF SFT/HFT
SLK
j\7 KUJ&dgSL\7JKiQK
WiI/SF\7T]K
JFKUJ
`/KUT WiK F:YK
YSFjd SLK
V`FH`b_`FJ&V2eFo-T/\\7 KUJ&dgSL\7J/JLK
WiK
VK

Re/K7b{H b:e FZY= J&YS_FT!dkYI//H\;dze/SL`/KUT FZYK
YSFjd SLK
V\ ^b
`FoKd H7KUTS&Y=I YI doFTKUJjd S&WX`FT/HK
YSFjd SLK
Y=\ eY\7jkKUSFjK
YUe/K
YSFjdgSLK
Y_V\fjF:Yjd S&WX`b
_`/KUJLKi\7JLK7e;P c? FTSLKUH7J&d SXK
YfY\7jkKKUJLJL\7JJLK
Wi\ 7KUJLJL\I/SFT/K
YUbE/\7JFT YS&dgT WiK7ehFod Td H7KUTSkF
&


fi2/-


gL
_Lk/
7ff/
fii-
L h&fiLih// ff/?X

fi&gLfi
Z L
fifiL ii 7
k

" ! fiR
& oZ# $x % i7klL
;&' &( fiL 7
fi&R fL
fifffiL

)fiL
*
& oZ# +i7lLk
&
&,- .i ;/ fi&7 g0 !1lZ# *
L
_Ll
% /
LL2 fi0 3)&4 ! fihk
LL2 7
5 ! fih
&g Z# 6iklLk
&
&178 9:<; !
fi&_# /
?:= *
):>
fiL
/ ! / ? iL k
LX 7

@g=ff /
Ai i&-B
; C /

fiD/
L6
UgD ffAA/ L
L

&
8Gl
XB
EGFzff /
fiL7 0 o# ff g>
!z ihZH
/I
ikk )C / H7 J789:<;7L= /k

K
;L U
fiffMU gN

! filL
kUl
fi&' - &PQ&GN !7R
!z ilZS
Z[ L fi 7

ff /
Z?T ZA
Z[ kLT 01i U L L
L

& U _
7
fi2
fiL

7 .C /
ZkT ZV
fiX W fiL L]k? 3 ! fiL k Z# fffiX
fii
ff 2 / :'=3
3 YE"&MZ
ff /)
fiL7 0 o# < !? <

; [ ?ff fiL
gfX!O
$xg3 ;L
RZl
L ]\N !?A
!z //

# XN ^ L
fiLl _ Mi
&a`ff /
fiff_Z)
fiL k L fi3 Vi ff fi& & fiXR
"R &P&m
b`dcH*eif _ Z?Z 7
fii .fiL fiL mXkff /X
/l
fi2 !L
gkUl
fi&' &f8H/X

fi&gkUL
fi&
Qg%hjiff"g%hHk
lgf?2 fiL7L# /
7 lC / H7 &

mnRopq"res%qQtuev4w
78 91:B;Z<
fifffiX
;# R
Uk
L b_ff x77 fi :A
i_ 7

!_ fi

fi&gL fi&
&gL

5 ]Uk2!Byz{lfiff

&Y9-L
ZT0ff/
Afiff
S/
i?ff/p3fiff/ |:*

0A:}@7kL Rfiff
*2fiLHfiL

):d
0G~&789:<; 7hU
ff/
fffiLUX

; /
fi#o
fij:L& /C"?84fi& = fiL lc_7 g%&H8 )\<fiL 7K
7k
!_ fiL /ff /kff fiXU6
7
&lg-2 3/O
\oZ&ff /k/ fiLU6
73 ' &.g= /R
yOoZ&
ff /kT ;S
/
/l
fi ! 7
&>

fiX

ffx73 &lg-2 3/O
{# / ?ff /O
;Lx
2fiZ ]ff /f[ U
!-/ /L
l
& 8H ' / ]ff /X
:L& /Cp2 .84fi& # fiL<
7
ff /lL

[ U
_T S2fiffk# / & ZT 0@O /f
/*s3 .c7 gj&Hg- /R
)k# / hff /
/l
fi_ !4
:
]ff /L
g fi/;
l
fii fiD/aFz &P&Off /L
gR
*z# //L

*3 K
fii fiD/Z?ff fiLU

7
fi& fiD/JD&jg-2 3/O
6= / Rff /_T
/
/l
fih !# //L
h_ 7 2 /_k &
7 ]
; TL
g

[ U
: L&/C

z
84&fi # fiL
\
c 7g%
_
\\

8
g[U
&fi
y*ez
{*ff\T
\\

2
:
L
g
&fi 2fiDff
{

{

;!;S/ /
#/ /X





8 )\8H/fi/;

fi&fiff ff/?fffiXUX7
&
789:<;M[ oKU

ff/
ffLfi UR 7 >Lfi 7K
7kl
7K
-! &>7
/
&fi To#&
,e b fiXK:2fi /7 //
R7 <0
fi3 ff/lL
&7#C/
fi#!fiLk"2/78R
\ 003 ff&fi L
'2 ff/ R 7 X 0


fi #/ i; :N]
ff/
[U
? ]
fffi/i ffLfi &X8H/ SLfi
!
ff Z_i A/ |
-// ffXfi UB 7 h . U&N


!78 91:B; [ f
// Bfi L
fi :
_
!
&fi T0%
fi#! Lfi 5Lfi
L 0oR L
g}_ fi/C) ; 0oZ#%i 7kS KU
+X
- 7_ 0
7_
Xfi -

?

k 0!
X
S* _fiffC6U 0o

&



fif%")LTMj%<
S"?TfTe"V"
R
b
T#x#ff
#bK</R
DT0%
ffffQ
#_ff6SV_<ffff
6)T

3=3)ff< 1Bl=|
Rff26SS#6#
/-0
R0K#ff)D#
jHff
ffR
x
_3/R

Qffx+/
#|M_
DffMIL}LO_0+AffN
G
T0(ff/
X6T
Hj
ffDTff< /D/2AD2#/I_6THXO3.#/
#K
S00Dff?
D/K#4Hffff52?/
(

5ffff
/RffSff#%_6T
ffH6T

ffDl-?Q
ffA)N6Vffb0Aff6'%SKff3_beD_#?D%ff
)ffff

Q

1Bl#G03_<ff6HTX=S2d#
ff-0O
ff}/T0
bff#
63 /
MT.#
/-0|2ff#K/ff|R_%A_.V#/|#/
#K

D/K#
"
ffff}_6T.
ff T>L/#GT< #ffff
bA
/T(
=/6

32#

Rff<HQ%A6T_%KT
%ff2S#f_R
ff=3_3)T#jff6j

Qblff
<ff=D/
DH#KHKX<ffS#RSf =3=3lffK<ff#K/_<LT
ff
-0RHjT#jff H
%2/ ff
eHQ%_XRQ
##%f
_
T0ff6j
#<ffS
Off#D/
DH#</XK)
=K##K
ff)ff26
j <
Rff=%
T0%ffff6IVffX2ff/XKffSHQ%R/ffR
<d/ ff
ff2#Tf
%
ff
Ad/#0/L ff00
% DQd_2.#XT

l<j"VaX
1BYB3ff
ffe_6T2lffe6TYff
ff00#bK}2ffT6/3aR#ff3x5
j%RVX2T)0L=DHffffff
X_0
ff
d6Tj%<M f2NK
=3_ %23O
NK#)ff.ff_DT SQ
AB/3)Q
.
R
A63] Kff]/Mfflff)ff

6ffA63aHAff
_3/aff_ 6TY?Q
ffDX_<H0_ < ff
003=ffD#VRb%/2

HR=XHRS
< < /3=
.ff=X6TjKj0K#ff+3a%R
fij%R
RR_#ffHQ

ff
#<H </3
ffffS6T
]bff
#AKR=V<M <#R6Tj ffD/QDMH
/)LG
ff
#.#_ffePLS
D_# _RSL
2#AffHH
ff #ffff
>6 #
ffT_3Ob
?_AffK6TdIjlDH#KTf#
_HH
ff
#
ff"
ffSHff13.=#KTff#_3R)/D/
T0(/Xff_
ff
jff.jKT


b bffR)ff
NffePLV#)/DQR
=3lffRff
=}2fff
ff
R_3/#.#ffTD'ff
3X2Affff2B
ff=3_
]3/ARffb#=L ff_#
b/D/4ff
#R6TG3Off3YffSffff)jR
)0K#D>ffRff_DTS
ff
Q
Dff#/0AQ
6T_0N#/D#6-0
jffe6T)ff
# ff#
#KT0
/Aff_
D/Q <Yj
=3/XffSHffR
2N0#X2ff<ff ffSQ
6T Tff
/D/

#_ff
fififi
Ij



5

1Bff
fi
fi



"!

< /
#
D=ff#

fi

<ff
/0N#2D
#%$&

2
ffD

ff


fi'(")+*,

-/.1032546798:8;48<%=>8@?BA+6CDFEHGJILK
MONPQHRTSUWVYXN[Z\]\_^_\1`bac\def^1S dbN[^1acUWN[^P`fNgRY\1`Whi`Wh"N+QjNPdbk"UWNdSl"SmNffU%PL^_^ noNffUblpSUWQqPre[NYPrgsUWNffkdWPt]\u^1v
\1`bawyx\re[Nzx M5{}|~ydNffr`b\1UWN`WNPtQRYSUfVeffPnP]\_^_\1`b\1NdPUWN]"UWSk"h`c`fS]oNPUi\1rN[ZNe[k"`b\1r"y`WNPQ
SnoNffU%P`WSU[d\1rPL^_^}Sl`fh"NgSQqP\rd"`Wh"NffUWNHPUWNcd\1r\_JeffPr`s\1Qjn"UWSmNffQjNffr`%d\1r `WNPQHRYSUWVHXN[Z\1]\_^u\1`baw
"SU\1rdb`%Pre[N\ry]Nffrefh"QqPUfVFUWk"rdiSl5|5`W`%PeWV/PL^1QjS db`HPL^_^5Sl5`Wh"Nj`WNPQHRYSUWVl@P\u^1k"UWNdlpUWSQSk"U
NPUb^_\1NffU\Qn^NffQNffr `%Pt`b\1SrFPUWNcPLmS\gNgwY+NffUf`%PL\1r^1aPL^_^9Sl}`Wh"NlPL\_^1k"UWNd\r O\1k"UWNcjPUfNcPg"gUWNdWdbNg
W` NffQqdPrgPUfNPg"gUWNdWdbNg]NeffPkdNPNffr`%dHQHkdb`Hr"SRP`f`%PL\1rQHk"`WkPL^5]N[^_\1N[lH\r`Wh"N
PeWh\1NffmNffQNffr `Ok"rPefh\NffmP]\_^_\`baSUs\1UWUfN[^NffmPre[aySlT`WNPtQSnNffU%Pt`WSU%dffwjMh kdff\1r \1`WNffQO`Wh"N
e[SQjQqPrgNffUYr"SR>P`W`%P\rdQHk"`WkPL^/]oN[^u\1N[lY`WhP`Y`Wh"Nsh"N[^u\e[Sn"`fNffUe[SQnPr ahPdYe[SQjn^1Nff`WNg\1`%d
Nffr" PNffQjNffr`HRY\1`Wh`Wh"NNffr"NffQHaJYR5h\_^1N\1ry\1`WNffQ}`Wh"N\UfUWN[^1NffmPre[aSln^Pr"r\1r"P]a nPdWd
UWSk"`WN\de[SQQk"r\effP`fNg`WSH`Wh"NHe[SQjnPraw
W` NffQqdPrgPUWNPg"gUWNdWdbNg]NeffPtkdbNFPNffr`%djr"SRPe[`HbS\1r `b^1a] ayU%d`qNffrdbk"U\r"`Wh"N
Ndb`%P]^_\dbh"QjNffr`YSl bS\1r `Ye[SQjQH\1`WQNffr `%d]N[lpSUWNsN[ZNe[k"`\r"H`Wh"N[\1UYUWS^1Ndffw}SU}\1rdb`%Ptre[NP`WNPQ
QjNffQH]NffUgSNdYr"S`5]oNff\1rN[Z"Ne[k"`b\1r"q`fh"NQH\dWd\1SrPd5dbSSrPd\1`n"UWS"e[NdWdbNdT\`[dYSU%gNffU%dp\1`WNffQ
%U[P`Wh"NffUt\`5Pe[`[dbS\1r `b^1ajR\`fhq`Wh"Ns`WNPQ PLlp`WNffU+`fh"N`WNPtQNdb`%Pt]^u\dbh"NdS\1r`Te[SQQH\1`WQjNffr`%d
`WSHN[ZNe[k"`WNi`Wh"NQH\dWd\1Sr/w
W` NffQqds"oPtrgPUWNHPg"gUWNdWdNg]NeffPtkdbNj`Wh"Ni`WNPQSnNffU%Pt`WSUH};b ;ufpp_ffffp;
[p%\ddnNef\_Ng`WS]NPr>|ssve[SQH]\rPt`b\1Sr>SlH`Wh"NFUWS^1NFStl`fh"Ndfe[Sk"`%dPtrg`Wh"N
r"Sr"vdWe[Sk"`%dwMYh kdk"rPeWh\1NffmPt]\u^_\1`baStl`WNPQSnNffU%P`fSU%d\dgNff`WNe[`fNgcd\1re[NN[\1`Wh"NffU`Wh"N
dWe[Sk"`%dSUY`Wh"Nr"Sr"vdfe[Sk"`%dYeffPr"r"S`5noNffUblpSUWQ3`Wh"N[\1U5UWS^1N"SUT`fh"NcdWe[Sk"`b\1r"vpUWSt^NcPdWd\1r"QjNffr`\d
k"rdbnNef\_Ngw rz\1`WNffQqdcPtrg r"SUWNffnP\U[dPUWNjnoS dWd\1]^1N]"k"`P``Wh"N^NPdb`c`Wh"Nje[SQnPr
\rlpNffU%dP ffe[SQjn^1Nff`WNffv;lPL\_^1k"UWNPtrgUWNff`Wk"Ufrd5`WSh"SQjNi]PdbNo\1rdb`WNPgStl+RP\`\r"\1rgN[r\1`WN[^1aw
rz\`fNffQ9`fh"Nqk"rPdfd\1r"NgyUWS^1NP PL\1rz^NPg"dH`WSk"rPeWh\1NffmPt]\u^_\`baY]"k"`HUWNffnPL\1Ui\dinS dWd\]^1N
]NeffPkdbNiSr"NSl}`Wh"NUWNffQqP\r\1r"dbk"]"`WNPQd5effPr`[PVNsSmNffU5`Wh"NUWS^1NSl}`Wh"NcdWe[Sk"`w
W` NffQ\dPg"gUWNdWdbNgzd\1re[Nj`Wh"NHUWN[^1NffmPr`SnoNffU%P`WSUH\dr"SRN[Z"n^_\ef\1`b^1agN[r"NgFPdsP
`WNPQSnNffU%Pt`WSUsRY\1`WhPrzYve[SQH]\1rP`b\1SrySlTQjNffQH]oNffU%dffoUWS^1NdffwHMYh kd]PdbNgSrFe[SQjQHk"v
r\effPt`b\1SrlpUWSQ3`WNPQQjNffQH]NffU%dff`WNPQQjNffQH]oNffU%dff"effPr\1rlpNffU5\1`%dk"rPeWh\1NffmP]\_^u\;`aw
W` NffQ\djPg"gUWNdWdNgF]oNeffPkdbN\1r`Wh"NNdb`%Pt]^u\dbh"ve[SQjQH\1`WQjNffr`%dHn"UWS`WSe[St^@`Wh"Nj^1NPgNffURY\_^u^
UWNffnNP`\1`%dQjNdWdWPN\_lPUWNdbnoSrdbNi\dsr"S`5h"NPU%gRY\1`Wh\1r `b\1QjNi^_\1QH\1`wcSRYNffmNffUL\1rNffr"NffU%PL^
P`W`%PL\1r\1r"QHk"`WkPL^}]N[^_\1N[l\1mNffr `Wh"NHnSdWd\1]\_^u\1`baFSlYk"re[NffUW`%PL\1re[SQjQHk"r\effPt`b\1SrFeWhPr"r"N[^d\d
Pjr"S`fSUb\1Skd^1ag\_e[k^1`HeWhPL^_^1Nffr"NbPL^1noNffUWr3~S dbNdff%Prg`Wh\dsUWNffQqP\rdPtr\dWdk"N
lSUlpk"`Wk"UWNRYSUWVw
|dYPlk"UW`fh"NffU+\_^_^1kdb`WU%Pt`b\1SrSl`WNPQHRYSUWViXN[Z \1]\_^_\1`a\1r x M5{}|~y RYNe[UWNP`WNgd\_ZmPUb\P`\Srd\1r
`Wh"NNffr m\1UWSr"QjNffr`%PL^e[Srg\`\SrdlPef\1r"`Wh"N|5`W`%PeWVe[SQjnPraSlh"N[^_\e[Sn"`WNffUn\_^S`%dffw}{+Pefhe[Srg\`\Sr
UWNk\1UWNg`Wh"NFn\_^1S``WNPQ`WSzXN[Z \1]^1a>QjS"g\_la\1`%de[SQjQHk"r\effP`b\1Sr>`WSyQqPL\1r`%PL\1re[Sh"NffUfNffre[N \1r
`WNPQHRYSUWVw9Mh"Nd\_ZmPUb\P`\SrdPUfN
wH+p;t+MYh\dY\d`Wh"N]PdbN[^_\1r"N[r"SUWQPL^je[Srg\1`b\1Sr/w
wH+p;jO|5^1`Wh"Sk"hjd\1QH\_^PtU+`WSe[Srg\`\SrRYNTPdfdbk"QjN}\1rqPg"g\`\Sr`fhP`e[NffUf`%PL\1rHU%Pg\1S
lUWNk"Nffref\1Nd[efhPr"r"N[^dHR5h\efhRYNffUWNjn"UfNffm\1Skd^1adbNffnPU%Pt`WNg9PUfNjr"SRe[SQjQSr/w rynPUW`b\e[v
k^PtU/QjNdfdWPNdsn"UWNffm\1Skd^1aFPdWdbk"QNg `WS]Nn"Ub\1mP`WN[^1agN[^_\1mNffUWNgz`WSSr^1a `Wh"Nje[SQjQPrgNffU
PNffr`+lpUWSQ\`[d5dbk"nNffU\SU%dffPUWNsr"SRPL^dbSjQqPgNcPLmPL\_^Pt]^NH`WS`Wh"NS`Wh"NffU5`fNPQQjNffQH]NffU[dffw
%

fiT+""/" L"+""

H+; ff
fi
fi"!#$&% fi' $()fi*!#+$,!-.fi' $/!#,'fi01#2'*3%54
6
87:9;fi< 6 +*3% "9"
=oH+;?>@"ff
fiA
."fi<?!#$&% fi' $ @)B70*'+*5 $A%% fi' $Cfi&fiDfi<*E*-F

G!#Hfi<*-"fi*3I&$,
JCK*3%LMHNL' fiOJP4+*-$&'' $Q ,
Lfi#.$*-&5.fifiR!<ST$Qfi*
*-$*-DJ
UH+;WV.1Xff*-*)Y70*;$&!#*.Z2 $W'fiR.<fi170 fifi<*;[&'*#
$*5.4\!#$&%LfiNL$C])^[fi_<'+*
H&,0` [,
fi'JE $%% fi' /
$ 0a0Z&b)c*-$Zfi# 53JK$fid!-!#Rfi*#
J"*3'fiNL5.fi*:fi*# _%'fiR$&!#*3ff
eH+;Cf.5gh$C%%LfiNL$QfiW!#$&% fi' $iU)\*-*)Bfi*!#KH&.$ZJP&'+*Kj&*#kZ [,
fiOJl $
*3!<,L$5fi*[&.fifiN
L*mH&ZOLfiNL/
$ ;a0*+!#+H&.$,J51H<8`%,*3%70 finfi*Hfi' $4 &2
fi' $/.fi
!#*-fiR2 $ES*-JK
c!-.fiNL$&-)&#.fi*-1fi&$!#$ZfiNL$,, $"fi<;j&J
*D%,*3!< $Ffi*-<*-fi'!4R.+*-70<S+ $TpZa1qB rs*-$&.[,
*3 .*-$,fiR1fi<+j&*#k, [,
LJ*3NH&$&%nfi5fi*

.[^8`*;!#$&% fi' $&ff0tuL*;vH,
fiR0fi<* $Z[&*-ff.4wK*3.*3o*#k@!<&.$*3%E.K$fi*3.x+*-[^*-R
4 *3!</4 fi*"ky!#$&%LfiNL$&ff +a0*+fifiR2
z$,[&*-;4 +*3.*3ffL$Pfi*-*fi*3."ff{ [&2
.$&!#*3%Y)
!-.fi' &m.$&%*3!<S
L*3< { .*"!#KH&.*3
% +|02
.$&!#*3%Q.*-$,fiRff4,

LJP*#kcH,
. fifi*"%,*3!< $Tfi*-J
4R.+*-70SY).$&%Efi<Z&}

&'fiRfi*5pZa1qB rT~}j&*#k,L[,
fi'J ;0.fi' &:.*-$,fiR12
712Jc1!#+$,!-fi*)
$' $fi*"%,*3!< $Qfi<*-Jn4#.+*-70
+0*3!<S
*3+*-$Zfi# !#+$,!-.fi*5`*-JE
fifi'
*h$,
LJn4
, ')B 0-[ 504ff!#R'*)fi<,
JW*3!<S
*3m.*-$,fiR:70,
%n
LS*#
LJT$fi;!#KD$,!-.fi<*".fi;2

h)B'
fi,;%,*#&$, fi' $P *#
2k*3%*-* K1

fi<*-*+fi*3.":70<SE70 fi%,*-$ZfiN!-8
o!#Z'fi Kc%,*#
-)}!.)\ )
.$&%P 0 a0*$Z[^*-;.41.*-$,fiR170*-*mk*3%n $Wfi, *#kH&*-NLK*-$Zfimfi543)'2

fi*-*Kfi*3."
{ !-.fiNL&-)Y[&2
.$&!#*3%T.$&%n*3!S
*3:{ !#,
%[^*+$Q'd%!#&<'*3% $Wfi<*D$*#kfi;'*3!#fi' $) fi:
%!#,
fi fi$fi<*;!-.fi' &fffi*3.70 fiE4fi*-oL$&!#<*3'* $nfi*3.x -*.%
t@c!#&OL$y&R'fi;$Qfi*"[&8
$&!#*3%Tfi*3.) fi71;[,
L*Efi</H^*-'4 fiRm $Q$&%,*-"2

dk
!#$&% fi' $&-)[,Jnj&*#kZ [,
J%,*3!#<*3 $: $&!#*3 $fi*+$,[&*-.4K*3.*3ff $T*3'H^$&'* Ea0*
&R'fi0'*-fi0.4w!#$&% fi' $&_O!#$&% fi' $&0(mfiK=G

&'fi#.fi* fi&.fi}fi*:[&2
.$&!#*3%5fi*3.!-.$"<*3%,&!#*
fiR1!#KD$,!-.fiNL$E $*3NH&$&'*mfi+fi*;OLfi<&.fi' $E4h!#*3%Y)*
) $&!#*3'*L$!#+$,!-.fi' $!#Z'fi
Xff870*-`*-2)$&%,*-d!#$&% fi' $&:U;$&%Ee),fi*d[&8
$&!#*3%5fi*3.x!-.$E2
' $&!#*3'*: fiR0!#KD$,!-.fiNL$
fi%%,*3fi*+$&!#*-fiR8L$,fi' *3ff t@ $&'fi#.$&!#*)70 fi!#$&%LfiNL$U)S,$.70
*3%,*+.41H&,m` [,
fi'J
.fi".fi'!-2

JQ
*3%5fi*3+*-[^*-R5fiW*#kH,
!< fi'
J!#+$,!-.fi*W!<, *-`*-+*-$,fi".4713J,H&L$,fiR
$Tfi*# fi* 5gh$C%%LfiNL$)B70 fiQ!#$&% fi' $Ce)fi*+fi*3&mfi!#+$,!-.fi*5fi*3'fi#.[,
N
!#+Lfi<+*-$Zfi#071*-$/%,*3!<% $Efi&2
fi:0fij&JK4<7oR%
ao*;!-.fi' &0fi*37102
'5.[,
*;fiH&*-N4<fi<* $$&%,*- 2

wk!#$&% fi' $&-)^[fi0 fi
*#
*3:$5.$ZJEK* +*3<.*31.$&%*-"2 $&ff $&'*-$& fi' `*Kfi"!#$&% fi' $& (.F=Kfi&.fi ',
%n*3',
fi
$Q4*-70*-DK*3.*3 ?g$&%,*-*3%Y)} fiR*#k&!&.$*E.4]2.Fh(4
%TK*E+*3<.*3mfi&.$Qfi*E[&8
$&!#*3%
fi*3.fimH&*-'4x.$5%,*-$,fi'!-2
zfiR'Smo$fi0$,
Jm71'fi*ff.4zH*3!< &1!#+$,!-fi' $E*3'#!#*3-)
[fi1!-.$E!#*3.fi*1NNSc}4}fi*dfi<*3. $EZ'fiNG
*:*-$Z` $+*-$,fiRff oOa0*:$*#kcfi1'[&'*3!#fiNL$"70

w%!#&
fi*ff'* .4z!#+$,!-.fi' $5*#!< *-$&!#J5 $"K* %,*-fiR2
Da0*:*3!<S
*3}fi*3.x%,,*30!#+$,!-.fi*
4*-7*-+*3<.*3-)}[fi fi4h2
fiWH^*-'4Lfi#[&!E< /
$ QqB`*-$T $Cfi<*5&R'fi$"8
ff!-'*)
fi,ff*#
G!#Hfi<*-_!#KH&.$ZJ5*-fiRff'fi&!<S"$Efi<* 7o2J5fifi* [&.fifiN
L*mH&ZOLfiNL$) $&!#*+*3* 70 fi
+*3% }[fi, +ffu$fiz!#+$,!-fi*3
% gh$,fi*-*3'fi' $.
J)fi*B$Z[^*-z.4+*3<.*3^ $&!#*3N*
$Wfi**3!<S
*3fi*3.$&%,*-!#$&% fi' $&;(.Fo
= Da0,ff [^*3!-.&'*"!#$&%LfiNL$(E2

.7d:fi**3!<S
*3
fi*3.fi+2`.%*-fifiNL$+'fi<&!S+[^*#4*d<*3!, $fi*:[&.fifi'
*:H&ZOLfiNL/
$ 1hg$+4h!#fi3)fi,1!#$&% fi' $E71
%,*3 $*3%fi<d*-fifi*}*3!S
*3fi*3.$&'fi&!<
p.L$&!#*fffi* *3!<S
L*3<Bfi*3.!-.$$87TH&*-N4<+* .4
R3

fiY ,

Number messages

350
300
250
200

"balanced-u"
"cautious-u"
"reckless-u"

150
100
50
0
1

2
3
4
5
Types uncertainties

6

u <;0 &.:L#+,-.' n0 / ' &8z&#-R2 ,' 3-
: K<3, R}&.' :&ZOLNL5+1+3<.3 1#&&.3Y 1,<&.#
'K+-+33 ."N'G1m#@<&.3Yu 32 3.K-D^-R;NR.&,3y ?K&.'
&, '
;uC.3oC ^.
KD,-.NL;#< -&#:z#NLN-8Z ;<3.#&.<'#,' 0 D-8L-m ;<3. -.#N
#+,-.' T.-3 -?-.&'"OL,G-Z+,-R.' T3.&-N<".&#Eu
3 .& -+:+3'0:#+,-.' +.-3 .Y3.0Y8.&mff&'#, 3
.0Z1B T0,3< --NK#+,-.' /N#L3#NL '5L 80-' 5 .-3Y@&.'#
,.' E "<-2 - 3. - }<;&3d#+&.m;R2z,&- .B+33
-m3."o Z<c,&#3.^8:&2.&#3Y-.NL&d.&3< 3o 0 E &#3OL
,D^-R:. .-,Rff&- 3.n0hm Z-<3'dh2 _#+&.''Y<;#2w#+#.' &2
3'R#3"2.2,LP33.I0-E-#&NR.,EOW . TZ:0 R . QA, W,
R K"2,L3 -+<&.;#,&KY+3N,L# '.1&# ..+',E<L-,'
L&NR.' <-"}. -2 -
u < 3 c#&'3ffEm1R","2 :3< <--''# 3#' '-&,L3:< &2
.&#353&-N<0#0 K-A+3<.3\<,o3.0<-,.' +&#,3LE',Z<-'
#-R<'3-doD-.' &ff3.#&&.3 3 " .E1+m+330&.n;&8&#3
3.+'&NR.,'2w#+,-.' .-3YBh&,-3YY^-&/.-,R-, D,.NL
0 C-.NL&+3#,l+^ET C32:' +03 35.-,RL,+-',P
#&&.;.Z5+3<.31.:2
u < c#&N3:+R&'&<_,52 &#+.Z8LW#K&.' E;^-'".&#.
-.' &b&&2.&#3.&n3<L3<13"00 &#3 EZ&-#:.\-Z#} /<;3.n:1&#
.Z8L1,3< <--''# 3#' 'C-&,L35<&2.&#3l3.IP&-'0#G:0 Q-
+3<.3ff ,3.m-,.' n&#,3 Q'Z,-'#-R<'3-E0+-.NL& 3.&#
.Z8LT &#RK/OL,G-Z5.-3P. 3 W .T+"K3.3m&?E&8&#3

fiff ffff !"#%$ &(')ffff*+')-,."#*ff/ fi0#ff1
fi324"35 fi1!
fi*"#*


!"6* 7981ff*(:ff
;<#

=6>?

fiNumber messages

@ACB/DFEFG)HJIKLNMFOQPRKSLT@LNDFU/B:AFEFV

500
450
400
350
300
250
200
150
100
50
0

"balanced"
"cautious"
"reckless"

2

3
4
5
6
7
Number agents team

8

WYX[ZN\F]
^`_acbdfe
e6gNhfii jCkml%gSX[nb/o^#p[^h#eX[qN^:h#kNl`l+\FnCX<hgeX[kNnr/st^h
imp[^o
oe
^glu^#vhfiwgnFZN^o1nFkxl`^o

gyZN^o
gnjzwF^nh#^xe
wge{Cp[kNe|kqN^]}pQgy{o~X[e
wze
wF^-v4gSvCX<or

e
^glrf^]
^N(^Nkmnjo}^qN^ngZm^nRe6oe
wF^oX[l+\Cp<geX[kNn~X[e

wF^hg\FeX[kN\oJe
^glh#kN\Cp<jnFkme%^
]
\FnX[n]fi^gSp/eX[l`^Nr+nCe
^]
^o}eX[nFZp[NX[nefiwF^`e
^oe9o
h#^ngy]X[kJkN]:efiwCXQo-^#v4{^]X[l`^nCee
wF^+]
^h
imp[^o
oxe
^gl
X<ozgCp[^e
k{^]kN]
lefiwF^l+X<o
oX[kNng{F{F]
kN{F]X<gefi^#p.^qN^ne
wFkm\FZNwe
wCX<oe
^gl^#vchfiwgnFZN^ox\oe_
l`^o
ofigZN^oCg]^~^]fe
wgnzefiwF^9gSp<gnh#^je
^glr/Ykzg`h#^]
e6gSX[n^#v4e
^nCeFefiwCXQot]
^o\Cp[efXpp[\oe
]6gye
^o3e
wF^
{kme
^nRe}XQg5p/kN]:X[l`{F]
kqmX[nFZefiwF^%jC^hfiX<oX[kNnFe
wF^kN]
^e}XQho^#p[^h#eX[qNX[eX[ne
wF^`g5pQgynh#^je
^glrJfk~^qN^]
~fwF^nze
wF^:efi^oefo
h#^ng]X[kxkm]efiwCXQot^#v4{^]X[l`^nRe3~fgNoh
wgynFZN^j)Fok+e
wgee
wF^:e
]6gyno{kN]fie6o/g]fi]X[qN^jp<ge
^
gexe
wF^`]
^njC^qNkm\o+{kX[nCee
wF^JgSp<gnh#^jefi^gl~fgNoxgCp[^%e
kh#kNnCeX[nR\F^Je
k{^]kN]
lefiwF^%l+X<o
oX.kmn
g{F{F]
km{F]X<ge
^#p[Nr(k~^qN^]NefiwF^:]
^h
imp[^o
oe
^gylnFk~{^]kN]
l`^jX[ng{F{F]
km{F]X<ge
^#p[NwCX[ZNwCpX[ZNwCeX[nFZze
wF^
]X<oiJX[nefiwF^:]
^h
imp[^o
o3g{F{F]
kRgNhfiwr

Number messages

300
250
200
150
"balanced-m"
"cautious-m"
"reckless-m"

100
50
0
3

4
5
6
7
Number agents team

8

WYX[ZN\F]fi^%_N_Nb1Y]6gno{kN]
e|jCkml%gSX[nb/o^#p[^h#eX[qN^+h#kNl`l+\FnCX<hgeX[kNnr
WYX[ZN\F]fi^ _-Xpp[\oe
]6gefi^oe
wF^:jmX^]X[nFZ%h#kml`l+\FnCXQhgyeX[kNnz{ge
e
^]fino1X[nze
wF^:hg\FeX[kN\ognjJg5pQgynh#^j
e
^glJokN]:e
wF^+dfe
e#gNh
ijCkml%gSX[n)e
kge
efi^l`{Fe|efik%\FnjC^]6o}e6gnje
wF^`jmX^]
^nh#^+X[ne
wF^#X[]xe
kNe6gSp1h#kNl`
6

fi)F/C

+FC<[N|Y[NFfi%C[N6(
F9
m[FCNfi y#<N6[NCSC<#tCF}.Fm
C
FN4SC<#)[+
Ff
6Nfi9CN%5.13Nfi/#QyN6y[NxQ`NFfi
F6#R#N

N#
N6[:C[NN6
NC[66fiRfC<
z#N<#/yfi[m[N<CS1NF
6fiN6#6)[6#C6m[`C.[CNfiy#<m6[NzxN<#3N6
cF|}Q [F
C[N6
F5m6SCN
fy#<m6[N[`
Ff
y6m[F:[Rfi9N#NFCS
m6fiN6
F:FNF[F3[mQy

F:CN
:#<N6[Nzt.fiFNFf#NFR}.F+
yuN6
N#1#F
#F
R
C</C[N|yNRS/FFfi
F3m[F`y


[%
F3:[F<y`[m<[N

F`m[FCNfi`FF
yN#[N[Nx
<#C<Y
F+[F9N[`3N<
FF`6y
%mF +N
Fx[`[m<[F
F#R[C.S<C[z

F}FF
F
N6SCN
:y#<N6[NJ<t[5[zFNxm+NyRC`6mfF
9mR6FRyN:
F
F+NTY[NF
STC[N#+
FJ4S6Sm93
N6Sf#N`+FC<[N`FNNmyF[N
S<#zfi%1Fm/[##NC
F9F[N
#
yFN:[6
m6S`
fiN[
FN:NF/m`+FCQy[Nz6#C6mf<f#Nfi
#<

+
FCm
|y#<N#[Nz(FN
N:
F%F}.m:
#R#fi[C FNC6FF9FN3N:
FS<#fi#C#fi[RxFF#
fiR}Q5[NFC.m9
F:F[NfiC
F3S<#z
yCCFNf#N FC<fi|fC[9fiF#.
#<m6[NF
4#F3`CN
C[N
25

Percentage messages

90



Degree Collaboration

80
70
60



50
40
30
20

"team"
"team-without-subteam"

10

"cautious"
"balanced"

20
15
10
5
0

0
0

5

10 15 20 25
Phase Number

C/3Nfi:#y<N6}.m

30

0

35

5

10 15 20 25
Phase Number

30

35

)f#SNf#N`+FC<[N

Y[NF
%SFf
6Nfi%CNJS[1

fiz#m`+FCQy[N
u-y)
fiff Q/
FSS[[N#}.fi<xF#NJ
F:#N
[RNy.m.#4m[Fz`4mN[FzNC6


+N
`yC[[(#N`[F`fiF:#m
1[R [
S[

}.m/F3NzS[


[N3<fiF
4Cfi[FzS
R
C[[3N<`fi<S[N`#Rm6m[[NzC<)N[
NF-.C[<S[`C[`C6[N [TfiF`f
6m
CN%S[
`[%fi`
+
#N
:NC<


mC[
[NC CNFm[[NS3#4m[F#N
FN+#`C[N"
!`

Ffi4C##
R

#[#[N%#m`+FCQy[NyC[[NF([C.}Q51.C.R6y[N#NC<NfiR<S[SNx

mC.fi9CFC
Ffi<Sm/N6
m61N<C1NFY.C[<S[`C[`R#[Nx[`
F/(
6Nfi
CN%5.%
$f
Nm
F9
&ffiuN6
m6Y['
R
fC<fi`NC<`mC.+f[m[N<CSN6y
N6
[`
F[C[<S[`C[`C6[N)#NNC<+Nfi+

NC[
36fi#N`+FC<[NN6y
N6
N6
N#/m
z
`[N5Y#m`+[
`C63fi
NFfz#m(

zJmF:
`[NS
fi+[[N
#N+[
`C61Y<1S[
NC (
N#SR
)F(6
&cC#FFfi
F
`NfiN
3
F
FC#|#[#[m[N
NFm[[NS/fiQ5N}fNC<z9F#
.#
J [
Fx#4
fi`9NNNfi#N+C.y[N
55.Fy+ *)N%
,.-
+S)N0 /1.
,1N+S65#mCQx

mC[
f|}6
/}fi<SNN#
N

2243

fi576(8.9:;=<?>@ACBDFEG@AH5%AC9I.86:J

K+LMNPORQCO4STVUWQCXZY([]\^S O_[]QC\^`baST]cRdSCe(f'XQCcgdhORi^S \SZi(j\^e(cRdelk4monpjcRORidqcRXrQCcRdCa^`_dqs^Stc4S ORduQCs^dqc4StORQCc4`
XvSf?Y^dhcgdwCj([]cRdee(dqs^dq\^ex[]\yzQC\P{|idqOgidqc|ORid}UWQxXXZj\([FUqStO_[]QC\Q~UqUWjc4`{[]ORiORiddq\GO[ficgdhORdS XQCc
QC\(T]fvSZ`_jYORdStXPm%UWQCjc4`_dCax[]O{QCj(Te'S ss^dS cORi^StO7ST TV`_j^Ugi`_sldUg[STVUqSC`_d`UWQCj(Te?Y^ddUWQC\QxXZ[]qde
[]\QCjc[]\([]O_[ST[]Xs(T]dqXdq\GOWS O_[]QC\#YGfex[F`gUWQxdqc_[]\yPyCdq\dqc4ST[]S O[fiQx\^` YjOORidq\G|dq\^UWQ~e(d`
scRdUg[`_dWT]f`j^URizyCdq\dqc4ST []S O_[]QC\^`ORQvSCQ [erORidhX?S \Gf?`_s^dUg[ST.UqSC`_d`qm
\HSCeex[]O_[]QC\^ST7s^Qt[fi\(OhQt7dqSTfij^StO_[]QC\[`dSC`_fPQtXrQ~ex[ Y([ []O+fQ oS yCdq\(OORdS XY^dqi^Sx[]QCc4`qmZ\
QCjc"dWNs^dqc_[]dq\^UWdCae(QCXvS[fi\rG\Q {T]de(yCdoSxUqwCj([]cRdeucRQCXdWNs^dqcRO4`[`\QCO.`_O4S O[FUc4S Ogidqc[fiO"j\^e(dqcgyCQGd`
Sh`+TfiQ {dqCQ T]jO_[]QC\m"\vORid|OROWSCURZe(QCXvS[]\axQCc"[]\^`_O4St\^UWdCaGcgdST]{7Qxc_TeXZ[ []O4S cRf?e(Q~UWORc[fi\dUWQC\(O_[]\Gjd`
ORQZdqCQ T]CdCa(cRdwxj([]c_[]\yXQex[ UqS O_[]QC\^`%[]\'QCjc|`_f(\GOgidqO_[Us([T]QCOORdS XY^dqi^Sx[fiQxc4`qm"\`_j^UgiP`[]ORj^S O[fiQx\^`qa
G|Stss^dS c4`OgQ0SCUg[ [fiOWS ORdv`_j^UgiXQex[UqStO_[]QC\^`h`_jyxyCd`_ORdezY(fPe(QCXvS[]\dWN~sldqcRO4`qS OTfidSx`_Oal[]O
[`|QtORdq\z\QCO|\dUWd`R`gS cRf'ORQvSxee'\dq{UWQGQCcWex[fi\^StO_[]QC\Ps(TS \^`qmnQCc[fi\^`O4S \^UWdCap[fi\ORidORO4SCUge(QxXvS[]\a
e(QCXvS[fi\'dWNs^dqcgO4`%dS c_T []dqc`_jyxyCd`_ORde?SuXQ~ex[ UqS O[fiQx\aORi^S OORididWT [FUWQxsORdqcUWQxXs^S \(fv`_iQCj(Te?dqSxe(d
dq\dqXZfHxdqi([FUgT]d`'`_dqdq\dq\cRQCjORdCa%c4S OgidqcORi^S \#^fx[]\yHQ CdqcmdqcRdCa|SCeex[]\ySP\dq{j\^SCUgi([]dqS Y([ T]
[]O_fUWQC\^ex[]O_[]QC\QxcoORidrORdS XQCs^dqc4StORQCc ^f([]yCiGOgs(TFSt\{Sx``_j(Ug[]dq\GO.G"ORidq\dq\^`_jcgde
ORi^S OORids([ T]QCOoS yCdq\(O4`%UWQGQCcWex[fi\^StORde?ORidORdqcRX[fi\^StO_[]QC\vQt7 ^f([fiyxiGORs(TS \|a(dqCdq\r[=_j^`_OQC\dStcRY([]
ORc4StcRfORdS XXdqXZYldqcoe(dqORdUWORde?ORiddq\dqXZf?Cdqi([UgT]d`qmKRUWQCjcW`_dCaORiddq SC`[]QC\'XvS \dqjxdqc4`qaYldW[fi\y
e(QCXvS[fi\0`s^dUg[ U a=i^SCe'OgQ}Yld}SCee(de=mfik
V^ltl
x
`Xdq\GO[fiQx\dehdStc_T [fidqcaCXQG`O[]Xs(T]dqXdq\(O4S O_[]QC\^`Q XZj(T]O_[]0S yCdq\(O.UWQ TS Y^Qxc4S O_[]QC\UWQC\(O_[]\GjdORQocgdWTfifuQC\
e(QCXvS[fi\0`s^dUg[ UZUWQGQCcWex[fi\^StO_[]QC\?[]\`_dqcRx[UWdQ VORdStX}{QCcgvK_ dq\\([]\yG`qaMx ^a^MCCL(k4m"zQCcRdcRdUWdq\GOTfifCa
iQ {dqCdqcaCSdq{dq\^UWQCjc4S []\ydWN^UWdqsO_[]QC\^`"i^SCddqXdqcgyCde?K+ dq\\([]\yG`ba^MCxLC%[URi? [e(\dqca=MC(CkWm
d^c4`O|Yc_[]dW^f'cRdqx[fidq{ORid`_dZ`_f`_ORdqXv`S \^eORidq\PUWQC\(ORc4SC`_OORidqX{[]ORiG|#m
tdq\\([fi\y(`q`KWMCCL(kl[]Xs(T]dqXdq\(O4S O_[]QC\?Q XZj(TfiO[fi0StyCdq\GOUWQ TS Y^QCcWS O_[]QC\Z[]\?ORidoe(QCXvS[fi\rQ dWT]dUWORc_[UW
[]O_fhORc4St\^`_s^QCcgO4S O_[]QC\ZXvS \^StyCdqXdq\(O[F`%ST`_QY^SC`_deQC\_Q []\GO[]\(ORdq\GO[fiQx\^`[]O"[`T[]CdWT]fQx\d|Q Ogid.^cW`_O
[]Xs(T]dqXdq\(O4S O_[]QC\^`[]\SUWQCXrs(TfidWNe(QxXvS[]\PY^SC`de?QC\PSZyCdq\dqc4STVXQe(dWTVQ "ORdS XZ{QCcR=mVdscRd`_dq\(O4`
Szc4S Xdq{QCcgHUqST T]deqClh_q~xqb ZY^SC`_de#QC\
S_Q []\(OvUWQCXXZ[]ORXrdq\GOOgQORid'ORdS Xz`+Q []\(O
yCQGST#S \^eS_Q []\(OcRdUg[]s^dvUWQCXrXZ[]ORXdq\(OORQS'UWQxXXQC\zcRdUg[]s^d'omu{Qex[`_O_[]\^UWOuO+f(s^d`Qt+Q []\(O
UWQCXX[fiOgXdq\GOW`" SuXQ~ex[ UqS O[fiQx\PORQZORid_Q []\GO[fi\(ORdq\(O_[]QC\^`%c4S Xdq{QCcgZS cRdUgTS[]Xdez\dUWd`R`RS cRf
Y^dUqStj^`_dex[ dqcRdq\(OSCUWO_[]QC\^`hStcRdZ[]\GxQCCde{|idq\P_Q []\(O}UWQCXX[fiOgXdq\GOW`hS cRd?e(cRQCss^de=mQ{dqCdqcaSC`
SrcRd`_j(T]Oa(_Q []\GOcRd`s^QC\^`[]Y([ []O+f{7Qxj(TFeS ssldS cORQvYldZT []XZ[]ORdeORQ'SO_{QCT]dqCdWT"i([]dqc4S c4UgiGfzQ 7S+Q []\(O
yCQGST7S \^eHS+Qt[fi\(OZs(TS \a"ST]ORiQCjyCi[]\^ex[fix[e(j^ST`'UWQCj(TedWNdUWjORd'UWQCXs(T]dWNSCUWO_[]C[]O_[]d`u[]\`_dqcRx[UWdvQ
ORid_Q []\GOs(TFSt\m7id_Q []\(O|cRd`_slQC\^`[]Y([ T[]O_fzcWS Xdq{QCcRu[`[]Xs(T]dqXdq\(ORde[]\PORidZ.|}`_f`_ORdqXPa
{|i([UgiS ssldS c4`ORQQ~UWj^`%QC\?SORdS XQtOgicRdqdoS yCdq\(O4`qm\P.|(aCORdS XZ{QCcRscgQ~UWdqde`%{[]ORi'S \
CCx^F7S yxdq\GOoe(dqOgdUWO_[]\yvORidu\dqde?QCc"_Q []\GOSCUWO_[]QC\p[fiO[`|Ogidq\'cRd`_s^Qx\^`[]Y(TfidQCcd`_O4S Y(T [`_i([]\yPS
ORdS XS \^e'dq\^`_jc[fi\y'XrdqX}Yldqc4`q^UWQxXXZ[]ORXdq\(O4`|SC`cRdwCj([]cRdezY(f'ORid_Q []\GOcRd`_slQC\^`[]Y([ T[]O_fXdqORiQe=m
i([ TfidZORidscgQ~UWde(jcRduQCc|d`_OWS Y(T [F`i([fi\yZ_Q []\(OoUWQCXXZ[]ORXrdq\GO4`7[fi\G|"[``[]XZ[ TFStcoORQ.|
[fi\^UgT]j^ex[]\y#ORidv`[]XZ[ TS c_[]O_fHQt7ORidgT]dSCe(dqc4[fi\G|ORQzORidWQxcRyGS \([]qdqc4[fi\.|?
G|e(Q(d`Y^dq\dW^OcRQCXSCe(QCsO[fi\y' `qaC{i([FUgiPscgQx[e(d`[]OSCeex[]O_[]QC\^ST^dWN([]Y([ T[]O_fCm
G"[`ST`_Q?cRdWTS ORdeORQz|o=.K+7[FUgi [Fe(\dqca"MC(CkWa~SrscRQCOgQCO_fGsldhORQ(Q T]C[]OS
s(T []deZORQ|Yj([ TeS|UWQ TS YlQCc4S O_[]Cd%[]\(ORdqc_0SCUWd7S yxdq\GO=QCcVStss(T[UqS O[fiQx\^`"`_j^URiSC`S[]cRORc4SCdWTGS cRcWS \yCdqXdq\(O4`qm
|o%h`QCc_[]y []\^`"S cgd"[]\ORidCi^S cRdeTS \^`OgidqQCcRfCm|T]ORiQxjyCiZORid||o=%#[]Xs(T]dqXdq\
O4S O[fiQx\e(Q(d`\QxOdWN~s(T [Ug[]O_T]fHcRdSx`_QC\zcgQCXOgidPll'GC.S OgO_[]ORj^e(du[fi\Ci^S cRdeTS \^`[]\(ORcRQe(j^UWde
[]\KRocgQG`_oc4S j^`qa=MxC(k4a[]O|e(QGd`7[fi\^UWQxcRs^QCcWS ORdex[F`gUWQCjc4`_dyCdq\dqcWS O_[]QC\'S \^eZ[]\(ORdqcRscRdqOWS O_[]QC\'ST]yCQC


fi=.(

_]Rvg^ "C_] ]^ R%]v_gZRC_x(fi=R^
ff fifig _]R(qC] Cq("C
l "!$#%&('*),+.-0/0 g1 ]4 RR2

x3 Wx4_4
lq 57qqZ(v P^qo 'g6
F7 3^
](R8 1]Cq( Cq(9 :C9 ;Cq4 $!<#%&('6)6+.-=/tRR> z]H_ g](Rq4 W_]C&
_ gHCv](R9 ?
^ Wu /Z_qxqGg@ ?]Ggq4 W_]C'(_Rx3
:<+A'6BCWCGg4C_4D
5figE
!$#%"('6),+F-GH%> gEIG: > (q@ Dff@fifiJot K)6HL'.$+LMNO q(]G9
ff@fifi7P] _9 ;CqW o]R
QlCR4tGS
5| ~T VU]4_@ *:$+A'6B (W >CY
X+ ](?]GRq(_]C^N
Z5fig C
] [^q W /:C^ R@ \]Ft^8 4 gqvR^tR^
:C^ g@ \ QQRG7 R#]_
!$#%&('*),+.-xR
X_ ]G%R Q^x^ (W P QQgG g /A),HL'.<+LMA\" R` W bfi

WxGRWC_A
5]Rc
X+tfi(R QlC^ (1 ]
:$+d',Be W] 5oR
5C3 f^C_@ Cg
(q9 QfX_ ]GC( ih@Q P(]q4 8 R(]9 c:C@ WC ( :$+d',B ^C
R%
qjQ^ (1 ] /C"g ]9 ?C(]RC_]R
WC^_g4]GW" ZR ]_ ^__]Rfix]?R9 Q^]_]ZR W_ ;x ?
_]9 (C%R8 ]9 ; (]vgoCgq. 5} _RqvT k(] ( (:<+A'6B^C RRqR
Qg@ 3 q ]9 ? Q?]'R
lq
(^9 d:$+A'6B^C](RR ( W@g@ R(> mx
^CgRPg@ ( WvRt2
5C 'e ;xqR 9
(@ g]C ?RqCgq_> SWCZ(> q _]C_8 ]@ W_ ;C] .C*
578 1|CR

(e n5]R?(]q4 g /|R v
_ g v9 "xR8 ]9 ; (Z] v 1]q3 ?03 q ]Pg v9 o:$+A'6B _1 1fi^R4 RrRq^_P7 WRGR
(Cvfi^T =Ch_qqz]RZCRq 57' _RqvT ,U]^ 1 4 RqR^ p
(1 >x]S
WjW lC4 fix
Cq"CR7 Q}j / 8 (__]R
(Cv] ?q]9 ;C8 ~RqCA
l@ Ssrfi(G_D
WC Q fi u:$+A'6B^C
QR QlG_@ _]CGgq%
WC Q ]v
;x x1 wxq _]C^Rv_ QQlCR|g
57x3 Z]PRhtCqG g(fig@ WRR
]4_8 1/3 5figv8 Q ` g]R CGe F% rR 4 R9 ( ? 9WCR
Q^ xfiR
WCrZ]Rq(49
(qRqRfi(]p
/0 WRxhqRf
5C >H QQl ZRp
^?R?_]CGgRu /%W1Fj ^C4t_]C&
" ` N
(q9 Q
_R@ ( uG^ ` yX+tfi(|C( (fiqW gP_x `z/ ;Cx_]CGgq%
WC Q ]
{ vx.
QR9 ;x]C^F
57x3 R
^ uff@fifiJ (k5$
QR_q(R@ ? Z](]_ ]R
Q]qq(4 _]C? /Vg R
?
5C3 # (8 | _^
^C@ C}
X+ ](](Rq(_]C^9 ~^
57x3 ] bo> gPCRx 57x3 ^/C
:$+d',BY Y(8 w^(fi#R Qlq4 Rx49 " #8 ^x4 _]C#RW]8 QRR ;Cqg9 K| 59 ;Cq@
:$+d',B5|CF
Rq6
(9 ;C8 ] Ql@
l@ q ^_u /n |_9 ;CqW kQR ]qv]PR^t$
5C3 rfip
WC(_]G@ N(9 ?
;C8 ] Qq( /VRt2
5C 2qQ^ (1 ]_]]'RD
'|RW 3(Cv]&
( "RD
QR_q W /9 5V(xv]^
_ gC<
4t^ Q^Cg@ p o]C(1 wxq (3 qefi9 ? Qz]Pg lq9 D: ] Wf:$+A'6B^Cg'8 ~Rq
?_ ^_4tG_ 1?R9 ;C_%R^t. ]q$
5C3 ( ]%F
^_RuRR <
:$+A'6B C%Z_9 Q^ 4 go _Rq


4 gqoR^tt8 Rq^]C /7R^to bp5C3 (c:$+A'6B _S
QR ;C> (S
WC W9Qg^ 7 ;t W
]HS
] RqZ ^ ~+FZ Ql@ g1wxq _]C /RD
X+ ](q(4 7 Rfig (h]c
(W >Z Qz]?R


{Y
Q^ R` W &;xF 8 Q ` g]vt^ ]C RS
Q^ RFe %:C^ R@ \] ^
3)RG lRIG4 ^9 Fff@fifi =R(
R` ]Z^C Q^8 1]@ Cog}g@ mC(]Rqq(D
/C|R ?o _ g vRR
(1 > Qr(fiqW g' /
X_ ]G](Rq(_]C^9 (^8 ]8 /0 ^CCRqR q
lq49 (](RqGfix^9 X_ ]G]GRq(_]C^y
/x|R
rWR@ Wx
gW]@ ^qx_@ t$( ^ _
fi@ zR?CqqW b lt_]C /nWCZ(> q _]Cp
^C_@ C
] /xRv _]C ?Z(9 Qlq (q 8
.
/ 1] 5]h 5KQR_q(4"6
(q41 ]@ fWCR
Q^ __xR
^q 5qqS
:$+d',B uR| ]qF
57x3

^ &ff fifiJ@("]zRqRvj /RW]6
qQ^ (1 ]_]9 6R
lq ]p
5]R&
&:<+A'6B] ] (htP8 Q> g]
@ g^ (_Rz_4 _}
X+ ](R
WCZ]Rq(4c
^C_@ CE
\dg'*)9 "5|(> RK5|Cu^ (Rg_@ ]
QR9 ;x]C^6
5C3 _' ]q@ Cq(4D
5C >z]R
Q > gfia b zq W'_Cq_]] WCgR@ W "C ?
_zR8 G_gq Wj /$X+ ](z
WxZ]Rq(49 '<_ ]
]qS
5C3 ( .rC(]RC_] R9 Q^]
5|C(]C Ql@ g b lq@ ( {
Q^ R_> W @ %R?@ R^t(F
QR ;C> (@ /x}rC(]RC_]p
5|Cc
^C_@
CE
WC
Q^ _] 7 R(]9 ;Cqq(S
WC x]_]C^j / Qlq4 Rx49 R(Z@ g^ (_
5|Cc
Rqv
x3 W;Cqg@
Rf
^c
]Z]R@ R?C(]RCfi' zR9 Q^] /&X_^_C4
Qg9 ?Z(qRqRZ]@ # Q^@ g _hg ]2
QlqR
Qlq4 RC %UgRqRCg RZR ]9 ?0_ ^_fig_]C^
5|C$
(8 w^@ p;xv'a Q^@ g .QR W@(RZ8 ~@ Wg@
_9 Q^ W R8 4] x ;C> (^ 9 { v
WC(R4C@ :<+A'6B^C"+fix(W wxqtG xqq4 lq@ ZC(]RCfiZ
R9 Q^]L
;xF]4%8 Q> g]R ]9 ?C(]RCfiR
WC^R4](49 (R^ %q^ ]ox(figC_]Z /Z gvxR Rq
@

fin.(f&@` F.6

ej9SjkZ 13@9(`z9u@> 1`af>d<29a6^ 1k.36@N39iR3ab
8 4872ab794393R$A6@jW>@*jbD9}3v@R 1
Z 1b@939A3jR38RR@> &9$38@3@9FL>>FAR938R4889
86S393fL]f39j3@R3@3R9Lk39eb $L@ &9 8 &R1>9
~37`7~7 c811_97@_3^8R3R939 3>F393
R$A6YD39 4799 19@3
3@jv9&3@@63978>9 y87R3R99
cL81<74eW93@o9NZK393f6%88>9 %88939d39n73K
@ (& >@3L>3Dk8R>9f>f1D973R99na@3@v
9>><9e ab7S 82>9ab7z8aAu989D998 x3u$@3>$
>L<A6"1@f3LL3cb8.@>f3939>Fi9n7363AE8>9
ejF893 @973in8@8487R`9j
AL81 7A989R9FS8R
>9&6<>u1b7
$d,Y76@196n73z7>p7,@ AL3^8R8p3@RZ@
9@9yR@3j`av$7>fL99 194a3@v9A" 1&<A6G>L@
fL3v9 1@f89R9 (3@L7,q$]811>z39D833A7v 9 1
`c3438u4A36397<n73x
<A6_>ke`a$38>3@*3$887bj6iR9L(4Liqu$137n1uqL,y
Di9n(@39 @ 8@N$@u@198$Liqu$137LW7qj3,y,yD@9k(@3a9@
@7 (<bk97>$397@8jW>uab7&3@L877c8R9L3( >
3ab743$Lveb99986Lc@196L3fgy,Yi8@$7gR39G.8
u9K9*f8>39R393398K4Ni3^7>33@97R9n73
Di9
@39@ @ K$93$a7g9f@}8N38R7> 47 >
N>6jy8&cD3@}94Z(S937>9Dv S3@89RD7b7>
>D.71 9969LR8>zj3> k>Yy,L v9eW@pu@9RL6.
7RR2pR9666@8@33aW^ 1yj986Zj3> 1gjb7 iL 937>8
,}8RRY37 ZL
y,_>RN`2>E87E8ab79$}
v f43@f3R87bj3@Li$7`j84N8@8Nb77> n89<y,
9
987RR367W&939Lu@Lk@LFL81|bv6L,oD@9$(@39
37`@D998 &9994877pRb@TxS9D]<`
f@f8@
v@a$3487f9@F *c973R9@366L,}3R9v1>93
f839S4L, 3N
6.c998 xR8&k3@j2Lx$d,9jv37>46@
9ab7v8&3
3@aR.jb@7.RL(3$877vu@1@SL, j98&L>@81`a
*$39
3$y3281@8R7 &^RL6xR`j338,82>9ab7
7`f@>i399>4@LLL>9uL,_98R1@D7R6A3497S3@
NK$d,Ykjp3$d,C8>}3>v77bab7 L811bYK887bj&
.9a`eW(L6N6L6K27ya93D$87fS3@L3ci3887bj
bN99 FgL7>vf893 19@p887bj39d,D3@@u39fZ 1k3R863
3@u11babSK8RbR984j%3@L3NK1`7KE8738>9
DRN43p99 487~L,N,y,`f798@Ki
$d,Yf986987v38>ab7%f$A6S6L6}`<f39@3
g@SF3RL3(RL93>S1>R38>abY9L99K$d,Cjp3S$6%
87YiR9Lnj38@E @7 Y$6%0 >N8@K799 $3
,87ab7SR8b7v7vab7.jk1$jR2j989A$L99@jbL81`
3@86R^j]4e`cf8R39TRZcL>^@j43*7b7>
@

fi


fiff ffff
! fi"#%$'&()(*+$-,fi"(*./0*fi$$1-23/4 5 fiff !2-*.ff'! fi12678 +ff (*9&"
: "12281! fi126;<-
-22*=12> /"($1?5?*.($+/4@281
#;*=5/ fi(58/7A*.ff fi4BC*.($EDF<GIHJLK
'2-*.ffN21?*fi6fi/4'OPFQ*.ff'&(fi9R-SfiS+TU?9VWKXfiK/9Y/ : 121Z4[2-*.ff]\^_5 .//5/ fi(V9fi28!
`712-23/afi-2
: 2-*.ffb fi7(1?*=2 fi1?<8(*fic&(d
`e7#/ ./2-$K f< .ga+1-9%2Z"- : -5
*.&#h;Z84B_5 ./i
+ff ff'/2ff ?9

fiff ff'"%*.5/ fij9Qff + fi15/4k*.($l127(*Y/1m*.1 fii*fi$$12-5-$K0F!8 : fi1ff0*Y#g*.7712 *fi28E2 @-*.ff n
! fi126/oODfi fi&p124E-Kq*r#WK;9gRYSfiS.sU21
*.( : fi12ff0c2-*=fft7#%*.(u/2 k57(*=1?*.2B12 .#/nv7#%*.( : +1i
`n

"5/ fiC&>w/($+a+%$"(*Y#x9y!/28A1Z4=;$+#/>Aff'&p-$$-$z
fiff ff'"%*.5/ fi(KwDFGIHJ{7"127( 5
#/>L*Yafi .%$
5"(8]21
*.( : fi12ff0*.Z +(9(5 0*=4fi
*.@|(
`/&#/>k1-*fi5 fi!/28AOvvU!
`e7#h%/i2-*=ff}4fi *Y#%
~-7#%*.(*.($
OvhvU5
#/-
5/afi@
fiff ff'"%*.5/ fiOP5E2 &('/ff 7p fi12?*=c/C71?*fi
5%
.U?K zO2ff'>21?*fiP);
fi9Qc"12n
: fi9bA8fi9cR-SfiSR.U
9q$-%3/ fio8 fi12>E% *.77#h/-$ : +1iff -2*.4fiB715/ fi15/5/-*.5/ fio
fi1?$+/(*.Z +
&(*fi5-$l fiE28 *.4fi?\p12-
"1?3/afi ff e$
#h/4E : -*fi8E fi281?V\j*fi
5/ fi(KDFGIHJ{*.77#h-'$-%3/ fi
28 fi1> : fi1
fiffffm"%*.Z +k5
#/-
5/a+5>E*.($@8(*.(
ff?V9(&"!/A*'afi1>$+hj12
fi2
`!
71?*fi
Z;*r#( fi7(1?*=5/ fi(*Y#h/-*.5/ fiB : 4fi1
*Y#9$ fiff0*rn/($7p($-2-*.ff'! fi126ff $
#(&(*fi5-$ fic_P ./
/5/ fi(VK
IBI.IIfiyfiC}jfi
F -*.ff'g +126'%!&(-
+ff'/4B(
1-*fi3/4.#/>k
15/5%*Y#E*'ar*=15/P>B : ff'"#Zn*=4fi<a+/12 fiff ?91
*.4fin

/4 : 12 fiffafi/122"(*r#afi/12 +ff
: +1 21?*Y//4o*.($-$"(*.5/ fij9!2 E/2122nv&(*+5-$ : fi12ffB*.5/ fi
/4fi1?*.5/ fij92 '7p fi25%*Y#jffm"#/5/nv12 +&( fi5%[57(*fi
cff'%23/ fi(cOPFQ*.ff'&(c*Y#K/9R-S+Sfi<*. ')*r#WK;9RYSfiSfi
/ff 2
#F
h`e
/1?*9QR-SfiS=s(h##h%*.ff0Z fiE*Y#K/9R-SfiSfiT</?*. B*Y#K/9jR-SfiSe(fc*->+-5n! fi28@c*Y#K/9
R-SfiS+fi!
h#h#>fi9R-SfiSfiTU
K 712afi/ fi"(/ff 7#/ff
*.5/ fi(y : ff'"#/5/n*.4figZ>e5ff09Y/(#/"($+4B fi"1I .j9
2-*.ff'! fi126[8(*fiy : 2 &(@&(*+5-$B fi 712n$
(-$9$ fiff0*rnZ7(-h7#%*.( : fi1!
fi1
$+(*=5/ fijKg<n
: fi122"(*.
#>fi98-5i7#%*.([*.12/|(
`/&#@*.($28"(c 0ffB*.?8 : fi18m"(
1?*Y/Z-c :
fiff 7#/
`9
$>(*.ff'%Ba+/12 fiff ?KwH'*@1-5"#/-9*.4fi?\Q
fi812i2-*=ffm! fi16k*.z,fi"%6fi#/>z$+%25 .#/afiB/2
ff'%2
fi1?$+/(*.2-$[ff'%5&p8(*Yafi/ fi1-Ky"12281ff fi12fi9Y28g
fi1?$+/(*.Z +m7#%*.(I*= fiq&p!12"(5-$u/m +281
$ fiff0*r(VK!Dfi"(2812"(5c%y/ff 7p fi12?*.!8 .ga+1-9&( fi28@ *-a+/ff 7#/ff ?*.5/ fi
j fi12*.($B : fi1?


fi(3%5(
>]*fi
12 2<*.77#h;*=5/ fi(K
J fiZa.*.2-$w&>28
15/5%*Y#g-$ : fi12-*.ff'! fi126|(
`/&h#h/P>C*.($12"(2*.&h#h/P>fi9Q28%*.15%#8(*fi
712-52-$dDFGHJC9*B4fi1?*Y#Iff $
# : 2-*.ff'! fi126K!8#/DFGIHJC\c$afi
#/ fi7ff c;$1Za+
&>i71?*fi
Z;*r#(-$I : 2-*.ff'! fi126*.77#h;*=5/ fi(9+/?
fi1%Q&(*fiZ-$' fi'715/(/7#-$B8 fi15/-I : -*.ff n
! fi126KIDFGHJ%! fic : _P"(5* : z/ff 7#/ff 2-$]5>52ffB8(*.8(*Yafi&p4fi"@2 [&15%$4fi28c4*.7
&(5!k
=##%*.&p fi1?*.Z +k8 fi15/-*.($@71
*fi
5%
fiKDFGHJ
fiff'&-c5afi1
*Y#6+>0 .afi
# : -*=2"12-
OvvU"(5' : _5 ./</5/ fi(*+* &"h#%$+/4k&#/ 26 : fi1* 2-*=ff]\_P ./ff?*r#*.5/2"($ OPafi-2,+"
*Y#K/9!R-SfiSfiy fi8bafi-,fi"fi9RYSfiSR&U< 28@*.12Z;#/h##/"(51?*.2-'8(*. DFGHJ&"h#;$"7
*'8/1?*.1
28%*Y#g512"(
2"12 : _5 ./!/25/ fi(*.($/($+a+%$"(*Y#/25/ fi(9*.(*Y#/ fi4fi fi"()2 28[7(*.12n
5%*Y#iDfi8(*=12-$ #%*.(wO21 5@c1?*."(V9R-S+SfiTU?<OvhvU/24+1?*.5/ fi : .afi
#2-8%,fi"- : fi1
`7#%/
-5?*=&#%58ffB : _5 ./25/ fi(wO2Dfiff'/28o fi8j9cR-SfiS+TU?!OvhhvUm71Z(/7#/-$
fiffffm"%*.Z +
&(*fi5-$l fiL
fiff ffff
c/]_5 ./c25/ fi(!OWapU"(Z :
`e7#h%/ 12 .#/nvff + fi15/4k
fi(Z21?*Y/?
*fi[!
#h#*fi[127(*Y/1 ff 8 e$'&(*+5-$C fiE_5 ./[/5/ fi(VcOa(Ui*.77#h%*.5/ fi : $-;P +nv28 fi125%
2-8%,fi"- : fi1!
fiff ff'"%*.5/ fi@5
#/-
5/afi/5>*=($ 8(*.(
ff?V9)8@8
fi2
`ey : 28y_P ./
/5/ fi( : 1?*.ff ! fi16KBFj E*-a.*Yh# : 28 7( .!1i : *wff $
#<Z"(28z*fi'DF<GIHJL9j* : "($*.ff ?*Y#
8(*.4fi<E*.4fig*.1
28/2-
2"1-y%!-255%*Y#*.1?8/2-
2"12-!ff'"(5!712 .a+%$
`7#h;/i5"77p fi12 : fi1
12712-Z?*=5/ fiL : *.($C12-*fiZ fi/4k)8z2-*.ff4fi *Y#%9yO1-*fi
5/afi.U2-*.ff7#%*.( *.($d2-*.ff5
*.2-K
DFGHJ8(*fic&(C*.77#h-$C*.($ar*r#"(*=2-$/A2812
fiff7#
`L$ fiffB*Y/(KiF!! B : 28 $ fiffB*Y/(9
-2

figBj-fi;YLyfi

2
fi2@.(j?=(5(fi-(.2[(fi5-wfik2-Y/v!fi5%E3/';=5/fiE+/2fi vfi?Y//(j.(
2+qh/fig=fiI-.0(-+g(=25%/(.2-[%.2+2Y/55%!
e
;Z-I!/2'(2-I.
fi2!52Z;=fi
j3@2
0fiBY/je)fi(yjfi%Yfi.fi-.;y.o(
fi
/fi <xfi!(.5%(=5/fi@/]cxfi2(
fi'/05Z-<.!P3/'%.2-pg5
2+2(. ?
(=/].<Pce
!
fi?5fi!<I;mW.[v2fik
+ /20e
.-.'g+2Q.(C5fi?Y0=P+c;Z
5-'0Y/ofipCx+'x2@!fi2z]+E%25@%/fi-Z5/.5/zCm2?+
5/fi(
!/2C/-.2/(C3Z;r
ep5/ ? )+/o5!
h-+fii5@vfi2.c
e%.(.Z+
(fi5-/-.2/o5@/?
hc
h/-c-.25g.p
h'-fi+2/ 2fi-Y(.0.fi?

fi%z.2+0.5 B2fi5/B2-.'!fi2k+
5/fi/5/-y?.2[2(.zY/--fi5fi/L.pfii]
fi(- Yh/fiyv2fiCfiBY/(p( 2-fiZfi/l=(fi[2-.'!fi2.+?</-.
3/2(.Z+5(- B
fi
+(=5/fiA2/-
fi<(Z?.(
fiE2[vfi20.Z+@/-fii
?fiZ-j.
fi2Q.fi/-.2(Q3/2(.5/fi5p- !2/-j?.fiI.fijfivfi20.Z+/-fi'.(
fim%.fiq
!
hv
fi
5%
-B2-. 'pg
fi%'2(I55/i
fi[-=2- -x+

2fi5/ [fi
5/fi/5/-
<WYhI(fi@fiCI2/-<y/(
fi?=@(.5%/(.2-E3/2(.Z+(c+/5/fi(Yh/fi
C'.!/-fi/(3/fiE2-=2/o.2fio
fi%o
+ / @
22'/((
5/fi
/-.2/@.2fi-yvfi'/5/.fi
fi?+/(.5/fid2fijqYfifi?
pYh/22-
5/fi0.([2-
.fic;Ir;Zifi[2fi%x+jv22!!fi2-(=25%
%.5/['fi/2+
?y!/2B2
h;=
fim%.Z+j!.fi
.fi0
/./?.fi?fifi/BPQ.'(
)5fi]-fiff
fiQ.'(fijYfifiI2'/v-. 0.-fi/fi/fi
fiY%.(B/25/fi(!vfi

fi (=5%5fiB!/2 . fiY%g=([/25/fi(
< j2(
-/@fir;y.(25/fi(y0Y/(+%.2

fi?+/(.5/fiwWYh/2-jP(
'2-= 0.2-y.v2E.22Bfi!%5%Yfi2
%.-@?fiZe
.!fi-
./fiC2 .fi2-+.5(L.L=2fij/'(fi](@.2
vh/A(Y%.(
-d!/2=L.fi?
fi2y2fi5/fi
5/+Z-VI/5%Yj2-5/?y.j2%y.2fi0.2(+22-P..'q=mpfi
-fiefi?
5%2/CC
fim%.Z+L.(.hh/5/-'/Lw5/(/-WfiZ+E%fii.+2
fi fi%<xfix2!fi2Ifi(@5%2-
fi '%.5/fi@0Y[x+2 2(+3%!.q'/5/.fi

.h%.(+?.5/fifi+5%.5/fi25g.22=jg.2p22fip-fifi
I25/fi<Ib2
h-<fiB2
2-. fi!52-. -+B2-5./+@+%2.fi
(.25%
%.5/B]-%+@

fi
5/fij
h/c-+?5/B/ 2-.'!fi2u;[/?5
h='/2-55/'fi (=/fi-55/=5/fij
(.h/o.fi?'2dfifi5%.2@
B%.(B!/2fiB/-fi@!fi%oY%5E/ r+AC
(
hh/5fi
A@fip]2(=+2-23/z5(2%25-g+;C/5/0=2
/z/-fi<I r.

/ 2.fi-
(
/h%5w2-.'!fi2
ff!#"%$'&()$'*$+-,ff.

!%<2-5-.?]fi!5pfi22-Efi)(.2.
fi2?fi
cfi+fiff
=5fi /xfi 10p2-i);
.2Z;/;Q.
2(-+?3/fi.(!2+/fi(q
+x2(
y(.(yPQ.'(fifiYfir
(2(..fi
jQ.fi4
3c?.?jj.(5
)h.(5
0I.!5/+vfic2
/m
fi
.(A5pfi2vfi
2[g+2 2pfi22-E2%c.25%/fi1
<%2
(23/fi(<!/2E!%]./(Yfi
/(-w/ 2.fi[2
6 (Yh5E.!2 .25%/fi r;Z]2(.2fic2-. 'p?c!fi2+fiE2 !fipA7 jfi2cvfi
2
/]5pfi2B.i2]!fiL2pfi22-/ ;@=25%/fi8
cfi0r
ep25%5Evfi ;B!fiLfi
2.+;-d9
Y+%Cfih/..o.(:
32]fi+25fiA=<
;!
3(./I.(
LY@fi [.1

= fi=;
+j
> >@?

fiACB DEGF

HII1J'KLMON8HQPSR5J TffUCM%VWJ+LYXZ\[]H^

X_I1J'` MOab` U'TffM%c-K

dSe fSg+hifkj+lGmffn%o7m lGfplGf hqo7risut+f lt+f7vumxw4yOmxvvumzw{h|qe f1lGf hqo7risug |isumff}~mxy)d1pg rqmxffslGf lsu}|qeGshxrq|isovufff
%|sht+hif l5m}5f7f o7j |sm}mxy1eGsufkr@xr7oqeGsokv1mffg'fkr@x|qmffr7hkCmffrrf ffo7|isufffgGvx}+hk1vv1mffg+fkr7x|qmffr@hsu}Q|qe f
eGsufkr@xr@oeG#f7 f o7j |qfs}g+xr7vvf7v%x}+le fk}+o7f]|qe f#su}g+xr@vvuf7vo7mff}+hi|qrj+o7| dSe fo7mfffk}|7hSsu}|qe f
g+hifkj+lGmo7mlGfxrfpfk}+ovmGhif lsu}5ff~ffSdSe f|qfkrq]su} mxvumffff~sh<+r@hi|plGf hqo7risut+f l9t+f7vumxw+|m\ovxrisy|qe f
g+hifkj+lGmffn%o7m lGfff

z7 GOk+@7Offqi
mffg+fkr@|qmffr

{\ CffS!uuuu}CffplGfk} mff|qf h|qe ff7f o7j |isumff}mxyQ|qf x

tG|qf !xsufffk}|qe fo7mff}G|qf7 |bmy|qe fo7j rqrqfk}G|su}|qfk}G|isumff}eGsfkr7xr@oe\ x}+l


wSsu|qeg+xr@xfk|qfkr@hSCffG!uuG})

d)fkrq~hS CSox+C'xrfvvf7!o7|ivu#ffhsu}5fff o7|isumff}


)

lGfk} mff|f hS|qe fp|qf xhimxsu}|Ssu}G|qfk}G|isumff}#|qmf7f o7j |qf

C

4kk x)x@-









lGfk} mff|qf h|qe fh|@x|qj+hmxy|qe f1imxsu}|su}|fk}|isumff}

@SO

-

+we fk|qe fkr

s|<sh]j |qj+vvut+f7vsufkfff l|qmt'fffoeGsufkfff lC j }+ffoeGsufkzxtGvufmffr<srrqf7vufkzx}G|

4k 7 oeGsufkfffkfk}G|qn%o7mff}+lsu|isumff}+h
fk}|So7mff}+lsu|isumff}+hSmxy)|qe f{|qf xmffg+fkr7x|qmffr

@G7blGfk} mff|f h1|qe+|1|qe fpy%ffo7|hx|ishW+f hS|qe f]ffoeGsfkfkn


hWsu]svxrivuwSsu|qe~rqf hig'f o7|b|mj }+ffoeGsufkzxtGsvs|i#x}+l

srrqf7vufkzx}+o7o7mff}+lsu|isumff}+hk

Yff]]'7ffOk |qfkrq]su}+x|qfknig

4

gCl x|qfkn%hi|@|qf

@7kp_lGfk} m|qf hSo7mff]j }Gsokx|isumff}~|qm|qe f|qf x|qm|qfkrq]sun



}+x|qf]himxsu}G|o7mff]su|qfk}|1|m


+lGj f|qm|qe f{y%ffo7|Syq

%kCQqkk k' p@@lGfk} mff|f hp|qe f]j gl |isu} myb|qe f]|qf xh|@x|qf]mxy{wSsu|qe

|qe f{yo7|Sy

4

gCl x|qfkn%hi|@|qj+h @-

]lGfk} mff|qf h]|qe fj gCl x|isu} Qmxy|e f|qf xmffg'fkr@x|qmr


wSsu|qe:s|7ho7j rqrqfk}G|

hi|@x|qj+hmxyffoeGsufkfffkfk}G| j }+ffoeGsufkzxtGsvs|i#mffr<srrqf7vufkzx}+o7ff

4~+'+x

Q+x u-

sh|qe f{su}+lsuffslGj+vbxfk}|1mrb|f xf7 f o7j |isu} \mffg'fkr@x|qmr

<lGfk} mff|fp|qe fffo7|isumff}+hmxy|qe fmffg+fkr7x|qmffr

Csh{]|qf hi|Smxyw1e fk|qe fkr1|e fxfffk}G|

QkC57'

4k u

)sh|qf hi|1mxyw1e fk|qe fkr{|qe fxfffk}G|

Q +'+kqkk x)kqCC+'%
mffr1hij |qf x

z7 GOki












sh]|qf xmrj+h|bm} fpsu}+lsuffslGj+v%

lGfk} m|qf h1hif7vyq


<lGfk} m|qf h1oe+x} fffs}|qe fprqmxvufpg'fkriymrq\x}+o7fpokxg+xtGsvsu|my

xfk}|



7Offqi

s}+lsuslGj+vmffg+fkr7x|qmffr


hif7vyq1~ff

uuu}CfflGfk} mff|qf h|qe ff7 f o7j |isumff}

myx}

thif7vyq xsufffk}#|e fo7mff}|f7|1my_|qe fo7j rrqfk}|<s}G|qfk}G|isumff}#eGsufkr@r@oqeG\

x}+l~wSsu|qe#g+r@xfk|qfkr7hCffG uuG})

!mffrf7 g+mGhWsu|qmffrq5g j rg+mhif h k f o7j |qfknO|qf nOmffg+fkr7x|qmffr@x}+lk f o7j |qfknsu}+lsuffslGjzvnOmg+f r7x|qmffr@
xrqflGf7+} f l5hhifkg+r@x|qf]g rqm o7f lGj rqf hkpW}5rqf vsu|iffd1p
|iwSm+


fiff

lGmf h{} mff|pls)fkrqfk}|s|qft+fk|iwSfkfk}|qe f

fi
"!#$% &'()

*&+#,-/.102+3$,4657398;:+<=74
>"5?
@A
BDCFE$GHBDIfiJBDK6L;IFMNOBQPRKSGUTVPDWYX2Z\[]Z_^`Z_afibc
Z\bedZfgffZ b
hi6j

c
f&kFlHmongprq6moksutv
wyx\kFk]x\k{zDmHn|
h}fw
v
df&n~s#w(2zkDkfizDmHkBDGUK$FD1CDT6LyL]GYL(BFOGo|
mo|Oz|

v
w;lHkFk]xOkfizDmHn|$hfc~|$kDq6h#qVmHn|
hf7w$v
f&kFlHmDq6nlHD|$ngh\mUYnh\mHkFh\mong|$hXt
#f&nk&WYQfifiVWRX_"Ze{\OjQfifiVWRX_"Z#{e\j7F{{VWRX_Z\F66\
e\Sjoj&|

Wq
jn~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfiojQ{YWYh#q
zonkF
qVnngm$HzD|
h\nmHn|
hlQWYXjFZ
Hj



QfiWHokFkF
q6hzDkDHzD|
h#Ongmon|
hlQWYXjFZ$HjHj

v
wynlnlmok]zFqVlHkkQHk;~Yq
zDm~ngl2~|
h#mo|lRqVmHnl~mHkmHkFopnh#qVmHn|
hrzD|
h#Ongmon|
hr|6~X2f2k
zFq6lokkFok~7nl|
hgq;mHHkfiqVmmH|XWlHkFk(x\kfizmHn|
h}fc{jnlq6hq6|
$|
l{f7w$v


nf&kFlHmongprq6moktv$wlokFk]lokfizDmong|$h}fw
v
nnf&n~w22z;o|
|
lHkY|$#kFDq6mo|
TVL]LyE\CDK{GHBDWmHkFopnh#qVmHkDDWYXjFZ\FZu[j&nmHn

Hn|
onmt
v
wyx\kFk]x\k{zDmHn|
h}(qVh#(fgc{w
v
nnnYfn~h|y|
mHkFn$kFong|$Hnm(|
kFDq6mH|$fiZngh#q6Dq6kF
@AVBDCQE$GUBIH#Vfi6EK6IRTDNBFPDK{GHT6PDW{T6LyL]E\CDKSGUBWmokFHpnghq6mHkDWYXjQZeQZ7[jFZfiBF FZuX^`Zafibc
Z
bedZfffiSjFt
nfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFt
fq6mokDYlomRqVmHlQWRX_

jFt


W#jn~efiDF{{FD{u#WujFZ{kFok[

nf
q6#qVmHko|
kDp|$hnmH|
onhzD|
hlomHDq6nh\mHlfitv
w(x\kQkxOkfizDmHn|$h#fdfw
v
nnf&n~\H|$gkYp|
hnmH|$Hnhz|
hlomHRqVnhem~q6nHk{lHzH;mH#qVmWYQfiWYhq
zonkF
q6ngnm$Uz|
h#\nmong|$hlFWXjFZ
{RjmHkFhq6mHkYlomRq6molFWDX jQt


WYzQjn~HkfizkFn
k]zD|$pp(hnzQq6mHn|6hy|6~mHkQHpnh#qVmHkDDWYXjqVh#~Yq
zDm

n~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfioj



Q{YWYh#q
zonkF
qVnngm$HzD|
h\nmHn|
hlQWYXjFZ

HjQfiWHokFkF
q6hzDkDHzD|
h#Ongmon|
hlQWYXjFZ$HjHj

nfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFt
nnfq6mokDYlomRqVmHlQWRX_

jFt



Wjq6mokDYlomRqVmHk6Wfi\9DF{{#W[jFZ6{6WX7jojFt
v
w;kDkfizDmok`\|$pqVnghOYlo#kfiznzq
zmHn|
hlmo|]p|\n~]mokfiq6plHmDq6mok|V~[w
v

c
cfi

fi

6

ffofififfQ6#\VH ff

{oOHFr
FD6H$






ffHQg{D#ffH {
!"$#&%'($H*) $+-,.#&%'($HooF#6D6F
/0214357681:96814;2<=9?>:@A1B?;C68>2B +DE GF'HI'JE JK6
$2 !"
$#&%'($ H ) $#L%E($ o4MN
+ 2HQ#VR6F

/G0214356P1:96814;fi<Q9?>4@1B?;6P>fiB #&%'($ GF'HI'JE JK6
V $H

W
HD6\PffX
R TS UHff RV\H6oo
4

Y&
Z []F\ $#L%E($ ouoF#6D6F

/G0214356P1:9P^`_Eafi^]bX^a25;ficd9?>:@A1B?;C68>2B fe 1c g GF'HIUJE
V $H

W
HD6\PffX
R TS UHff RV\H6oo
4

&

&2



ih7j&k#mlnffHD6o VF\popj7h
V #6otDs $e2\HF\H$ ud fv]wG
q &HFr
x &Z y6Z 4u fvw*zm(*E{|*}~*[

2$ d, 1@;fi^`B hjQ
G

ff $PHff QF6njh

/0214357681:96814;2<=9?>:@A1B?;C68>2B P 18@;fi^`B +D'H&fi
Qfiffo4YV`#

2gS
hjn
F#Vg7ff :O Vfi;gy\FRVeO fiDH$&oEd
2Hff :Y V`$ #

2 gD#fiffrffHfi(2ff#VRfiVFHQ
H
F#Vg
V m# yH$4$
V

H(
W D$Hff oR6\T\Y g$6H$12
ff gFfioff &o $o\r
V 6Hff fiD
#

2 g(

D$#\H
UffX*jh
Foff &

/0214357681:96814;2<=9?>:@A1B?;C68>2B X >2<n@'c1:681:9f;2^`cK5B41 +D'HIfC FfiUHff 4 6` #$o
fi K6
hjQS
Q#6
ff PHff Q* #$Hg
fi D7
V Fo4 Y6 H&H ffr Pff# fi
ff \ fiH
oEdDjh


=hy
j Q#HDfiA Hy4 fi4 o4 Hfi2V&
FRVH
Tjh
7
]
*D7fitQ'*`G
/0143 576P149P^`_'afi^`b^afi5;2cd9 *@A1B?;C68>2B $Hff Q4'HIfXJE7JU J
6

& Hff Dfi Hff fi
ff V#O\Y # V#\HQeo



$ZXy6Z #p{|*}~' Z yVZ $Ezm(*E{|*}~*[Z yZ6' fifi[~(6H




Z UX}Z4
Z $Y
V Qe8U
#\og$Fff g
ZX}Z:&
Z
#$Hg
fi H D$#\H
UFff $

Z HoF
6D4H
#Ogo
Qff $ g H
g
ZX}Z:


6o4$off RVH(Z # Hff FF g
X

fi'n*]E7Nn&

Tfir4$r?2P$


Efir4$r?2Pfi EP 'fi'fiP
4X4rI72A$rEX:Kn:PrmUPfirnP4fir
$K* rAP ' 4fiP7= 2P7E7PX

P4EP
Q
fiff ffff fi4$ ! #
"$& %E

i7 EmnP4fir p '
& 7
*m*E ,*+ - .0/
( K )fi+

K$2
14365#ffP


fiff ffff fi47 5#8ff9 P ? $&fiEfir4$2`Er 2K
;
: E2 4`fiTI?fi7=
<X:P?
>'4 &A @2P4fi]$'r fiUn =fiP'X4
Er 2&47EP BEfirPX2nDEfi4fim P P&r E2 7
r&

fiff ffff fi4 CDEFG
fi 8HAffIJr ? $IfC' fiUP4fi`E7r fiK
L
K : EfiPPK*E7PUfi47p r4$fiPP rPEfi'
<X:PM
>E4 &


Emr4Xr:A4P:$E`E2K' 4fiP7
NPO;O?QSR;TFU8VXWPYLZ#[]\MN_^

Za`cbdO;efiQgf_hFefiQSi

jlknm=opJq'r smutv smwolx mwoytz{Amwx]{Sms}|J~8|Jss}|J~6knmx mwoytzrnz||Jaj?a=rnt|Jz9x mwxzk zolpJtzysm
pJAx]mwoo
mzpssknmsrmAy|x mknmps|tzknqx mwoytz{AmwxzurnrAmAxz_MAjlknm=tv s}mwocpoF~lzkknm
ps|t
z}knqzMrnrSmAxzJpJtmF{Apomwx|mnmwyvnz|'|JAk zmtptyk zypsA|rAmtpJ|to|tDtmwpyzmlr s9pAo
6k zs}mknmopq'r smtv s}mwou{Sms|+~ptmx mwoyt
z}{Smwxzo7zq'r szGAmwxz8knm8|tqnknm'pyvApstv smwo=pJtm
mAy|nx mwxzg|pJtwnpJAxpJtmpwJpzspJ{ smpo?pJ| sznmMrnrSmAxzG
?lG * l $ FLa $u

*M$ l $? ;

BP4r n77 4firp47p&UfiP7D7fi
Kfi PfirTP?2P=474finD' 4PE2
4fiP8E
P=r 7 p47EP2QPX2 7E 4fir
4lS
< TPX:P'
>'

Kfi
aU P2PTP4fiP=47?finQ4
;
$4 fi4PU nfir 7 p47EP;@
fiDrXfi ' ?2Pu4c
;
$4 7n4rP P&rEfi=' X
;
47p&UfiP7D7 fi' n2PX7= U ?2PX
B;;



fi0n;

fifi? w7fi?w=fiwwJAa7w=fiw;fi=7
fiufififi=4lSD





?lG=Ml?FLauM?ll'MM
afilafi0fi= lw?w

w+ fiwfilfifi?J;L8w;



ff








fi











w;]M ;M w
w J7G F
u7dw fiwu4c9





=}fiD+






w;]a;7fiJfi M=7 ? Gw

=wfi

waaw;fi

fifi? w7fi?w=fiwwJAa7w=fiw;fi=7
fiufififi=4lSD

!

?lG=MlG l?a7Ma a====M ll=
afilfi77
0wa
w=Gfiw
wwM=w=fi D+ Jfiu lwfi=}7w
7G

a;? w7fi?w=fiwwJnfi
w=7;7=fi
fiufififi=4lS




" $#&%
(

+*

)

ff



'


#&% D7fifi,.-0/,

" afi77210354
=

fi7GM7=wG;0w6'=}fi?
7986:;-0<.7
>=
A@
+*

?lG=Ml Mlln=uM?ll
fiGaM 0 lw=7w J7G=fiL fi=

fi

fiw

a;? w7fi?w=fiwwJnfi
w=7;7=fi
fiufififi=4lS

?

ff

)





CB " $ #$%=a


fi7GM7=wG;0w6'=}filw;a
7986:;-0<.7

fi7GM7=
wG;w=fiwLwaa&10354


fi;a ;=w=fiawJ fi=fiafi=7
fiufififi=4lS



E

CF

G=

HLMll

?lG=MlG=uMM L G u
afi? Jaaw wG u0fiG wfifi
w7fiJfiaJwwJ
=7wA ?fifiw






I@



? '



LN

J'
)

GK L

fiOPRQSUTUV.WYX[Z\5]U^`_Z\aO?\5SUbQ2PUTUc
dfe
g h!j5kfkIlnmoqp!rsmto$smoflnmofsrmvuxwCy;z|{9sm}r~}lnmGgfh!r2s>mRAofsrm

g
sRsln2lk&Rlnk0rkfsm5kfr~loIr2l!5lh!j5oIlfjrlkAoIrk?r
g
m5rrof5lkEl2lnk ps>
A~Ir2lnk|rkIEsm5kIr~lCofr2l!5lhJj5oflIj5rRlnkofrkr
g
sUhnAmm5ro
Rlnk0rkfkfr~l

$j5kfkIlnmoqp!rs>mo[smoflmtoIsrm9uxwyqz { s&j5mRhI5sln}A~>l5j5loIrEh!kIsofshnA~;kfr~>lAs~j5kIl
rA sRs>mGRlnk0rkfsm5r
UnU;
CnUR[Ga`U[E255RCUi6nRnUna65ARUR|UJU>fI
6`RJ`R5qRA.U&G;5.U;|5[C50;5Gn[A
!AE0 |5;;0>E5;A[5UJUAn
A!|.|RA$AnY5
|RAC2CC5Gn[U? 5UnAvU5
?UC6UCC` AUC|5G&
5 qUUn&;A55IGR|!56v5Rnn6fC 5|Rff
2 fi5

5qR[5!A25fi05!5Cffq!505
RU n$U[ nAn5
$55R 5!U|RAnJ nJU!5a6>|;5J"
R`6URU;iIiR|R!|R55RAUC&6;5C!UAC|5C;0
5Rn [!225E|92 C05;|5E5A 5U!U5An
A!|.`R;An
Anv65
5UA[$#&;2&%.5('U5qU 5UR 5!)nvJ+*6R25!5[
I,!|Rff

fi;5|5$-U5|;.
A!;2592 05.0>;
5UA[$#&;2/%.('5U5.U.5UA.$[6C510q?255A[326
55RnR?5!4+ R|I5H+R|! En5J" 56na65AA9[[
nA[U65 7%q805RU:9R;5AI!5ff%;|A!|CUI|
<105A3=G`>%.n!A 55R?<I5RU 6G &56!5t5!nUvA.I@C!
|R2ff
E fiG;505;5A5
A!25CBR>`CAD?EEA
<U!A5
F%.!ACG5UG#
nJ`tD6R|URUHR5!5 +AC5(05
`Jn!UUn9R|URU1IJIJI !5UA505 5CD?EAKB55LENM|$O P5R
nR55URQ745535J!!52n5!;5CR|URU+5 RvR5YAUfC 5|R
ff
E fiG25055R5
A!2592 |0>;S0UT6
GRn5AD`5$#&.U$<U!A5; AU5V<G$=G.5 $R|I5nUA5nA!|UUn5
n+55!UYGRJf65AA5!5A?fW!506ff
2;505;5$- 505

E592 05;;0>5
!5U.5R `656!U!U!nAYA
22G5YXA0[U PZR
[\[

fi]?^8_J`!a
bdc1e3fffghKikj;hAlnmkcoYpfhJqjRrs6ttu!vjwJeYxyxzoY{$ecoY|ff};~!xzoYfec e!x; Gc(ep8Go |}"efjU z
Uzyy hYhut78j
bdc1e3fffghdikj.8jh.lqY}z!8c6hwdjjr s6tt!v jxzoYfec@}f1 ep8cfffj/wJe8hAj.j;hk@ec(3oYh
8j;hdlAeYxyxzo1Vhkj.rPL8fjyvh U Uz 8 / z U h8j$sY3!8jJCPRc(6f(fh
woY{8cff}z!h8Cj
ox;c(h8jj;hl@e!fff6fh?jArs6tt7vjmk8eYx;6!oY, ee38eYx;6!};Go}zfff|(cff};{8p8|(6
3~};c(e8!|6j8! ff 3 h?rP!v h7N3t773j
o66fffe|(h8ikj;hiLc(eY.f|(eh8j;hl&bkhj8j?rstt!vjACp!x"|}oN3|k eYxyxoN{ecoN|ff};e};};c(6 |16
}"8c(eY~}zf(oY|}"ej3ff ff. 3 U U 6ff 3yU $V U6
6R 1Nj
}xyxhKj;h?wJ8h8jh?bdcoN|(h$8j;h?e3fff!{!x;e3eChVAj;h?lAoY{h?j?rs6tt7vj3|( xyxy};!|oY!|fUec
|(8:f3!|(8|ff}z{oY|(|x" xz?@o eoY3WeYdc(e| oYc(};8Go};c co|6jff6 ff@ !
6U 6kVyz U 8 ffU z U6 6j
Y8!};83fhkjrs6ttY8vjwJe};|(!|foY e3~3|ff};ef@|(8Uep88oY|}"eeY e!ec};oY|ff};e};
p!x;|ff};oY3|df7fff|1fj+3+ 6+ 6 +6 6hKNj
Y8!};83fh+jkrs6tt7vjwJe!|(c(eNxxy};8 e!e$coY|ff};~,8c1e{!x;fffeYx;~};8};};!pfff|(cff}zoxp!x;|ff};oY!|
fff7f|(fLpf};8ffeY};!|};3|(!|ff};efj U 6 Uzyy 6h6Yj
moY};8Yo8h?bj!j;h8l/KoN{$h8Gj$rstt!vjAqe81}zox eoYcff}zfffeUecLo}x;p8c(+e!};|(ec}"8oYc16 e~!
c(C}"p!x;|ff};oY!|fff|(|}"8!fjff6 ff !U 6ff U z
Uzyy hYj?r(q|(p!!|doY{f|(co |v j
m};83hj;h.7Pp88{$c(hkGjh..oYehj;hkqe8!{c($hd.jh.L}z!oYc?hbj;h.l,c(8c6h.j.r s6tt!v j
AxzoY886|(6oYo |}"~};|ffj,wofff|( xyUcoY1!}hwdj;hAl,c(8c6hL.jLrPJ8fjyvhJ U 6 RV6z
V U U3ff U Yj?q8c}"8c6hVj
m};|oY8eh j;hf(o8o8h8Gjh7mkp8!};e!fff!}h?j;h8e78oh8j;h$l&df(ooh7j?rs6tt!vjAe{e8 p88c(e{e|
ecffxzG p8}"!};|ff}zoY|}"~jff6 (1 3 UU
6j
m};|oY8eh jhKAoY{hKj;hAq|1e8hKAj;h x"e!fffehKj;he88o8h j;hdf(o.o8hj;hKlf(o8ohGjAr s6tt!v j
8c1e{e8 p8fff!3|(8|}oN3| f K1oxyx;8jff ff 3 U6 U 8
6ff U z U6 Nj
o};c?h.jJ.j;hLYe86fhjJj;hJl}; xzfffhdAjJjJr s6ttY8v jwJe!ec};oY|(6{$o~};eceN e8p8|(c
8coY|(6WUec 6f };|oo};c(fffe!oYc6j ff ff 3
! ff @ +
V3U
. 6ffU
ff
3zffLffVff UU jR.cffxzoY!e
h x"ecff}z8o8fff|ff};|(p8|1
eckqY};p!xzoY|ff};e,oYco};!};8fih ff!};~cf};|ffeYwJ!|(co x x;ecff}z8o8j
?~6f p8h j8j;hwJe8hAj?j;hl.p886fh8jr s6tt!v j.,o |ff};8|(e|(8cjdff6 ff
3+U ff U 6 U6 6jC!x;eoYc(?hwoxy}(j;kkd8c(6f(fj
?e8(!{oYp8@hmj.jLrs6ttY8v
j zy 1ffU 6 Vy 8 U6 3@ U U U !6U!Pff
3 6jj j!|(86fP}fh oYc(~YoYc
ff!}"~cf};|ffj


fi!!"$#&%(')+*!,.-'/)01)+!23!!4

57698:<;!=?>@>A(B3C$5DC9A!EF=?>G>9=HAJI3C$50C.ALKMEF=N!OPHQSROPTL=?>@>@6AVULC$B3C$WX/Y+Z+[\C1]J^!_>.Oa`LOP8S69b+`!QcTLO+dS=Nfe+=`!=H?O/>9Q
6hgOa8S69b+`(iVjlk!`6@monp69`!erqp69=stCvuxw+y{z|~}?w+?}L|}pAL$WXa\A!!!Z+!C
v=s=?>@>AjC$W?XY+Y+\?CtJ}L| ?(z?+?|~{S&p}L|c|~p}LC FOPH<qPOPHNv`69qfiC$VH<=ddA$ROPT!HS6~Ne+=+A!5O+d<d{C
J69=`8<=?>ArEC.AKB=?6G^!=?69HO!A&ECWXY+Ya!\C

J|~?cw+?w+@|ca(zpazz}@a|}D+@wP?C

69`LN!:?H<=d85:/HO/sQ6@>@>A$>9k!=I16~Ne+=U+k!698A$LjC
JbP>@>~O+:fiAL5DC$W?XY+Y+\?C B
;!=3kLdS=dbPm_>~OP`Ld{C3?c| y|w+}cG|@+/}Ly?AL!{AL[+Z!C
IOa_!k!8ApULC9APKE3OPHHA+RFCI3CpWXYpY+\CpRbb+_L=HOa8S69q+=T=;LOqp69b+HJ69`bN!dO/mC+B=:;(CH<=_(C/<UBQSRI
QY+PQp!A
`LdS8S698<k!8=Fmob+HFd69k>~OP86hbp`xOP`LN78<HO/69`69`!eLALv`69q+=Hd698SnbPm
R=`8HO/> >9b+HS6~N!O!C
IOPbAVjC1ULC9A1$kL:O+dA1jC.A5fb+HS>9=n+AC9A
U+=?>9q+=d8<H<=?>A5DC9A1K5k!HHO/n+AC1WXY+Y+\CjFe+=`8<Qcb+HS69=`8<=N
OPH:;6h8=:?8<k!H<=Fmcb+HO/69H<Q:?b+TLOP8d69k>~OP8S69b+`(CB=:;(CLH<=_(C!B=:<;!`6~:O/>vb+8<=3!A!B
;!=3jFkLdS8<H?O/>@6.Oa`
jH<86Gfi:6~O/>J`8<=?>@>G69e+=`L:?=`LdS8S698<k!8=+C

=?6@>@>9n+AtlC
ULCFWX/Y+Y+[\C/G|/w@f+c|+}w+wp}LDfi/y|w+
p}C;(CC8;!=d6~dA3U:;!bba>bPm
Rb+_!k!8<=HFU:69=`L:?=+AJROPH`!=eP69=5f=?>@>hbp`xv`6hqp=Hd698Sn+C
I16~:;(A3RC9AVKUP6.N`!=H/AFRC
WXYpY+\CR(j3]1tiV;!=`OPe+=`8d:?bP>@>~OPTLbpHOP8<=fs
698<;_L=b+_>9=+C`
Sy??+|}az}c?}Lw+c|+}Lwp 1+}S}y+}3c+}L++p
+/}L~
+/}L! aC

bd=`T>9bb+AJCpULC9A+(O/69HN$A+C+]C9AP=s
=?>@>A+jC9A!A+K5:/ROPHS>API3CWXY+YXP\CPj_!H=?>G6969`LOPHnOa`LO/>9nd6~dJbPm
8<;!=dSbOPHOPH?:<;698<=:?8<k!H=OpdVOFTLO+d6~dJmcb+HVe+=`!=HO>!6h`8<=?>@>@69e+=`L:?=+C 3?c| y|w+}c@|Gp}Ly?A/(!W?XQ\A
+Z+Y/p+!C
U+=`(AULCWXYpY+[\CpSy??+|}aSzpfi|}fiPvP|~l+}F+w?ficw+c|+}1/+@c|+}wp}L3(?w+?}!
|~}+CJj=HS6~:OP`j3d<dSb!:6~OP8S69b+`mcb+H
jFH<8S6@fi:6~O/>`8=?>G>@69e+=`L:?=+AJ5=`>9brVOaH<fiARjC
UP6~N`!=HARC!W?XY+YP!\?CjF`OPH<8S6@fi:6~O/>Np6~d<:?bpk!HdS=v>.Oa`!e+kLOPe+=
mcb+H:?bP>@>~OPTb+HOP8S69q+=F`!=e+b+86.Oa8S69b+`(C$`
Sy??P
|~}P3Stz3w+c|+}Lw++}S/}Ly?3+}3c| y/|~wpL?}Lc@|Gp}yFcaC
U+698<;(AJC.A KRb+;!=`(AVJCVWXYpY+[\CBbPsOaHN!d3dS=rOP`8S6~:dFmcb+HOP`0OPe+=`8:?bpk!`6.:Oa8S69b+`>~OP`!epkLOPe+=
TLO+dS=N&b+`dS_==:<;O+:?8dCJ`S/y?p|~}PStzwpc|~+}w+Vp}S}y3+}3?c| y|w+}cG|.
+}y&~FF3c+C
U+b+`!=`TL=H<eA]C.AB16~N;LOPHN$A3C9A
=H<`!=H/A]C.AEv6h`!`n+AC.Ak!`!epTL=H<eLAF5DC9AKIOPbLA
jCW?XY+YP!\?C
J>~OP`!`!=N8=OPO+:?8S69qp698n+C1B(=:;(C!H<=_(CLp[!AjkLdS8HO/>@6~OP`jF
`LdS8S698<k!8=+C
U+8<b+`!=+A
JC9AKV=?>hbdSbLA5DC1WXY+Y+[\CB(bPsOPHN!d:?bP>@>~OPTLbpHOP8S69q+=OP`LNO+Nqp=Hd<OPHS6~O/>
>9=OPH<`69`!eLiO:O+dS=
dS8<kLNnf69`0H<bpTLb+8S6~:&dSb!::?=HC&`U+=`(AULCW]N$Ch\A Ftpfi?|~}ffiPvP|~p}pw?ficw+c|+}!
/+@c|~+}fw+}L&(?w+?}L|}|}x@c|9Sw+/}LV/c/C
BJOPTL=+A 5DCJWX/Y+Y+\CI
=:?k!Hd6hqp=OPep=`8tOP`LNOPe+=`8<Qce+H<b+k!_8<H?O+:<p69`!e69`O&H<=O/>9Qc8S69=Nn`LOP6.:=`!Q
q+69H<b+`!=`8CD`S/y?p|~}PSzf}c?}Lw+c|+}Lwp1+}S}yp}ux@c|9Sw+/}L/c
cu++C
BJOPTL=+A(5DCJWXY+Yp[\C3B(H?O+:<p69`!eNn`LOa6~:8<=OPO+:?86hqp698Sn+Ct`Sy??+|}atSz&3w+c|~p}Lw+1+}
//}Ly?t+}3?c| y|w+}cG|@+/}Ly?~FF3c+C



fi$!

JPL+LD++
fiff <ff < L99+ ff!"ff#$<P&%' ($)*,+.-!/#0fi11fi243"56879/!:

;=< 1?>A@ ; 3=/5B@CEDF/5G:H1#-!15I01J/5LKJ- ; 3 M'03=@CNfi5 ; 1C=CO3P6415I01&Q"KK9KRNS+

JPL+!DL?+?)T9!8+F<aUVW,XYLa&"ffFZ![8p\4W !fiEK']B^

]_CO3"12ZKR- ; 3 M.0#3"@CBNfi5 ; 1C=CO3P6415I01J`8L8 G

JPL+3D9Ja8 I!(Rb


c 9Ja8!
f
e 9Jg f

h .9(
c # fi$
X ?!
9v
9Je'S
+ ffJ
j L
k 9fl
kff %P(mgVpnJ)`PO+8+fiop4 W< 4ff!\+U`9&~8!D\4 !fiqKJN
rs@64@8tH3=5I/1 mu$
v ?8

JPL+!D9lwe'SpIjJkLpnedi'kxy8 ff zp <#[!9+IXYLP&"ff38p

ff(L#)*z+.-!/011fi23=56
7{/!: ;=< 1'Nfi5 ; 1-5I@ ; 3=/5I@4C8|}/43"5 ; DF/5G:H1#-!15I01F/45fKJ- ; 3 M'03=@C8Nfi5 ; 1C=CP3O61#5I01
QN|D{KRNS+

JPL+3D9kff %P(9g9Jl~e'+fjJkLFpnOX4PO+Ofiq

`9Z~8X 8 YL%WW ff #d)`+.-!/011fi23=56
7A/: ;=< 1TF3 : ;=< D/5:1-!15B0fi1&/5DF/o]_ ; 1 15I1#-!@ ; 1fi2/4-017J@5B2Td1 < @3=/-!@C.1!]-1G7H1#5 ; @ ; 3=/
5

"X L8 ?9Jk+\+! <tD99lv+TxF/+n


X PU&
8IX< P? ff!"ffz
%d 89# 3&"`TXOL(ff ( <((ff "ff#.o<T(' !&9I! #O~8,9 P_ff~#
)*< OP+ I?ff z)*I!! +

bOPO~PU(D9'kYff8 !Fg.FlFff(p Fg1+4,i$!ff!Xff"`[ !4 <!"ff.
I?
Z!
[ 8p

\ !
fi{ {)`,+.-!/011fi23=56
7d/!: ;=< 19KKKJNdm@C=C8d]/873"/5+.CO@5L1G^
0 ; 3"/5o+.-!/GCP1#?7A@5B2TN7fi71G7

fi

fiJournal Artificial Intelligence Research 7 (1997) 283-317

Submitted 8/97; published 12/97

Bidirectional Heuristic Search Reconsidered
Hermann Kaindl
Gerhard Kainz

hermann.kaindl@siemens.at
gerhard.kainz@siemens.at


Siemens AG Osterreich,
PSE
Geusaugasse 17
A{1030 Vienna, Austria

Abstract

assessment bidirectional heuristic search incorrect since first
published quarter century ago. quite long time, search strategy
achieve expected results, major misunderstanding
reasons behind it. Although still wide-spread belief bidirectional heuristic
search aicted problem search frontiers passing other, demonstrate
conjecture wrong. Based finding, present new generic approach
bidirectional heuristic search new approach dynamically improving heuristic
values feasible bidirectional search only. approaches put perspective
traditional recently proposed approaches order facilitate
better overall understanding. Empirical results experiments new approaches
show bidirectional heuristic search performed eciently also
limited memory. results suggest bidirectional heuristic search appears
better solving certain dicult problems corresponding unidirectional search.
provides evidence usefulness search strategy long neglected.
summary, show bidirectional heuristic search viable consequently propose
reconsidered.

1. Background Introduction
problem represented state space graph, solutions problem
paths given start node goal/target node t. Finding solution
attempted searching graph. search guided heuristic information,
called heuristic search. work heuristic search problem solving deals
unidirectional approaches, start heading towards node (see, e.g.,
Pearl, 1984).
one goal node explicitly given search operators reversible,
bidirectional search possible, proceeds forward direction
backward direction (see, e.g., Nilsson, 1980). Strictly speaking,
even required operators inverses. necessary given node n
set parent nodes pi determined exist operators lead pi
n. Searching backwards means generating parent nodes successively goal node
(see, e.g., Russell & Norvig, 1995). words, backward search implements reasoning
operators backward direction.
illustrating example class problems bidirectional search
usefully applied, consider finding find shortest path two given places
using given map city. case one-way streets, bidirectional search implements
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKaindl & Kainz

reasoning like following: \in order arrive t, one-way street leading towards
may used". slightly adapted problem class, cost driving street may

different, depending driving direction. steep street top mountain
may serve example. Bidirectional search works also correctly case:
backward search implements reasoning backward direction takes account
cost driving forward direction. formally, k1(m; n) = k2(n; m) cost
optimal path n. k2 used notational convenience only.1 bidirectional
search algorithms dealt paper work correctly conditions
require operators reversible cost path either
direction.
Bidirectional search shown ecient unidirectional counterpart
heuristic knowledge unavailable, inverse result originally found
experiments bidirectional heuristic search Pohl (1971). Since kind search
work expected, consensus conjecture bidirectional heuristic
search aicted problem search frontiers passing without intersecting.
situation metaphorically compared Pohl missiles pass other,
illustrated figure reprinted Nilsson (1980, Fig. 2.11). Nilsson conjectured
case bidirectional search may expand twice many nodes would
unidirectional one.
original algorithm BHPA proposed Pohl (1971) may actually show
inecient performance, missile metaphor wrong misleading. demonstrate
bidirectional heuristic search actually aicted problem search frontiers
passing other. performance BHPA much worse originally expected
two different reasons:
1. BHPA's search frontiers typically go other.
2. major effort spent search frontiers already met: finding
better solutions one found first meeting search frontiers
optimal one; finally proving indeed better solution possible.
first reason specific BHPA incidentally resolved technical improvements introduced related algorithm BS* Kwa (1989). second
issue, however, also major obstacle eciency BS* actually bidirectional search algorithm performs heuristic front-to-end evaluations, i.e., evaluations
estimate minimal cost path evaluated node search front
t. Note, kind evaluations also performed typical unidirectional search.
common belief missile metaphor, however, so-called wave-shaping
algorithms developed de Champeaux (1983), de Champeaux Sint (1977),
Politowski Pohl (1984), idea steer search \wave-fronts" together.
contrast BHPA BS*, algorithms perform front-to-front evaluations, i.e., evaluations estimate minimal cost path evaluated node one search
front nodes opposing front. fact, algorithms achieve large reductions
number nodes searched compared algorithms perform front-to-end evaluations. However, either excessively computationally demanding,
1. notation explained Appendix.

284

fiBidirectional Heuristic Search Reconsidered

restriction solution quality. Still, reductions number nodes
searched using front-to-front evaluations come from? all, algorithms performing
front-to-end evaluations suffer problem search frontiers passing
other.
order answer important question, let us shortly focus common property
heuristic evaluation functions estimate minimal cost path applying
heuristic knowledge static information encoded state information node
evaluated. static evaluation functions typically evaluate error, i.e.,
difference minimal cost path heuristic estimate cases
greater zero. approach improve accuracy given static evaluation function
perform search utilize results. Since involves dynamic changes, call
dynamic evaluation function. Dynamic evaluations bounded look-ahead search
studied various contexts Kaindl Scheucher (1992).
static evaluation errors typically smaller paths smaller cost, also
observed Pearl (1984). Front-to-front evaluations therefore typically accurate
front-to-end evaluations. addition, costs paths nodes
opposing search frontier (or s, respectively) known, overall evaluations
front-to-front algorithms much accurate front-to-end evaluations. Since
former utilize results search opposing direction, may view
approach dynamically improving heuristic values static evaluation function. Due
asset, wave-shaping algorithms achieve large reductions terms nodes generated
since perform front-to-front evaluations. However, quite expensive terms
running time (per node examined), calls finding appropriate balance.
fact, Dillenburg Nelson (1994) well Manzini (1995) developed recent nontraditional approach bidirectional search called perimeter search achieves exactly
this.
devised new computationally much cheaper approach dynamic improvements call difference approach. utilizes differences known costs
heuristic estimates given evaluation function improve heuristic estimates
function. difference approach applied bidirectional heuristic search
algorithms perform heuristic front-to-end evaluations. exemplified two new
methods dynamic improvements heuristic evaluations search.
also devised new approach bidirectional heuristic search performs heuristic
front-to-end evaluations, dynamic improvements heuristic evaluations
search embedded eciently effectively. approach generic sense
encompasses whole class (non-traditional) bidirectional search algorithms.
show paper, instantiated case availability sucient
memory well case limited memory.
results experiments suggest bidirectional heuristic search improve
unidirectional heuristic search respect generated nodes running time
(for certain problems finding optimal solutions). Since missile metaphor wrong,
bidirectional heuristic search using approach without time-consuming
front-to-front evaluations. So, bidirectional heuristic search viable propose
reconsidered.
285

fiKaindl & Kainz

paper organized following manner. First, discuss previous work
present new theoretical empirical results existing approaches bidirectional
heuristic search. describe new generic approach non-traditional bidirectional
search two instantiations. Thereafter propose new approach dynamically
improving heuristic values based differences known costs heuristic
estimates. presentation experimental results applying approaches,
discuss context various approaches bidirectional heuristic search
previously proposed.

2. Previous Work

order make paper self-contained, sketch essentials previous work
heuristic search algorithms focus bidirectional heuristic search, without going
detail necessary understand new results previous work
new approaches.

2.1 Unidirectional Heuristic Search Algorithms

Many unidirectional search algorithms presented, would prohibitive
review here. Rather, focus unidirectional algorithms form
basis bidirectional search discussed paper. First, review traditional
best-first search algorithm A* (Hart, Nilsson, & Raphael, 1968). Then, shortly explain
linear-space algorithm IDA* (iterative-deepening-A*) proposed Korf (1985). Finally,
review algorithm called Trans (Reinefeld & Marsland, 1994) implements form
enhanced iterative-deepening search.
A* maintains set Open so-called open nodes generated
yet expanded, i.e., frontier nodes. Much best-first search algorithm, always
selects node Open minimum estimated cost, one considers \best".
node expanded moved Open Closed. A* specifically estimates
cost node n evaluation function form f (n) = g (n)+ h(n), g (n)
(sum) cost path found n, h(n) heuristic estimate cost
reaching goal n, i.e., cost optimal path goal t. h(n)
never overestimates cost (it said admissible) solution exists, A*
guaranteed return optimal (minimum-cost) solution (it also said admissible).
certain conditions, A* optimal admissible unidirectional heuristic search
algorithms using information, sense never expands nodes
(Dechter & Pearl, 1985). emphasize optimality result
A* compares unidirectional competitors, bidirectional approach may well
improve performance A*. major limitation A* memory requirement,
proportional number nodes stored therefore practical cases
exponential.
IDA* designed address memory problem, using heuristic
evaluation function f (n) A*. IDA* performs iterations depth-first searches. Consequently, linear-space requirements only. Although performing depth-first searches
iteratively deeper deeper heavily used computer chess programs
context alpha-beta minimax search since sixties still use (see Kaindl, 1990),
286

fiBidirectional Heuristic Search Reconsidered

B1
k1(A,B1)



k1(A,B2) B2
h1(B2)

g1(A)

h1(B1)

k1(A,B3)
h1(A)

B3


h1(B3)

H1(A) = max( h1(A), min( k1(A,Bi) + h1(Bi) ) )





Figure 1: illustration back-up idea.
application approach problem-solving searches marked breakthrough
solving dicult problems. IDA*'s depth-first searches guided threshold
initially set estimated cost s; threshold succeeding iteration
minimum f -value exceeded threshold previous iteration.
IDA* shows best performance trees, one major problems
pure form cannot deal duplicate nodes sense transpositions. transposition
arises, several paths lead node, search space represented
directed acyclic graph (DAG). disadvantage IDA* relates advantage
requiring linear space.
Fortunately, computers memory available needed IDA*.
memory utilized recognizing duplicate nodes two ways, using finite state machine (Taylor & Korf, 1993), transposition table implemented hash table (Reinefeld
& Marsland, 1994). Due general applicability wider variety domains,
since bidirectional algorithms partly make use it, focus latter technique.
algorithm Trans proposed Reinefeld Marsland (1994) uses transposition
table IDA*. Since size table deliberately parameterized,
approach utilizing limited memory. Analogously earlier applications transposition
tables computer chess programs, Trans utilizes table actually two purposes:

recognizing transpositions;
caching best heuristic values acquired dynamically.
Since latter use dicult understand, explain underlying idea
depth. back-up idea illustrated Fig. 1. normal search
nodes Bi statically evaluated stored, values still used backing
node stored | case Trans transposition table.
dynamic value minimum estimated costs best paths found
nodes Bi . Unless static evaluator consistent, useful store maximum
dynamic static value node. cached node re-searched,
improved value often used instead value assigned directly static
evaluation function.
Apart use Trans, back-up idea actually widely applied many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi,
1989), RTA* (Korf, 1990), SMA* (Russell, 1992) (Ghosh, Mahanti, & Nau, 1994).
287

fiKaindl & Kainz

advantages little overhead steady (though often modest) improvement
increasing memory size. addition, idea also works goal condition instead
goal node specified, i.e., require goal node explicitly given. However,
applicable re-searched cached nodes, cannot see could make
sense context traditional best-first search like A*.

2.2 Traditional Approach Bidirectional Heuristic Search
First, look older approach bidirectional heuristic search forward
backward searches alternate. call traditional approach. encompasses
algorithms performing front-to-end others performing front-to-front evaluations.
2.2.1 Front-to-end Evaluations

Since first proposed algorithm bidirectional heuristic search called BHPA (Pohl, 1971)
performed front-to-end evaluations, let us begin approach. employs heuristic
evaluation functions hd (n) estimate cost optimal path evaluated
node n s, respectively, depending search direction d. precisely, h1 (n)
estimates cost optimal path n forward search, h2 (n)
n backward search. Note, always optimal path
found (i.e., s) therefore also cost path estimated
evaluation function fd uses hd heuristic component. viewpoint
backward search targets node s, however, may seem cost frontier
estimated heuristically, precisely cost frontier.
issue matters cost path either direction.
view BHPA search essentially two A*-type searches opposite directions,
i.e., traditional best-first searches.2 performed quasi-simultaneously, i.e.,
sequential machine one node expanded another, search direction changed
(at least) time time. decision searching forward backward direction
made anew node expansion according cardinality criterion (Pohl, 1971):

jOpen1j jOpen2j 1 else 2
Whenever search frontiers meet node n, solution found. cost
g1(n) + g2(n), i.e., cost path found forward search n, plus
cost path found backward search n t. Even two parts
solution forward backward search optimal, however, concatenated
solution path necessarily optimal. Therefore, algorithm requires special
termination condition guaranteeing optimal solutions. termination condition
2. precisely, BHPA viewed consist two HPA searches (Pohl, 1970) opposing directions.
long heuristic function used consistent values weighted equally gd -values,
relevant difference check whether Open become empty. admissible consistent
heuristic functions, option move nodes back Closed Open important, new better
gd -value found. heuristic function consistent hd (m) hd (n) + kd (m; n) nodes n.
implies hd admissible, i.e., heuristic function never overestimates real cost.

288

fiBidirectional Heuristic Search Reconsidered

BHPA follows:

Lmin max[ min f1(x); min f2 (x)]
x2Open1

x2Open2

(1)

condition essentially means cost Lmin best (least costly) complete
path found far larger estimate computed fd -values
search frontiers. heuristic used estimates admissible, path
must already optimal solution order satisfy termination condition. Since
understanding condition important paper, elaborate depth
below.
Implicitly also condition successful termination improved algorithm
BS* (Kwa, 1989), removes nodes n whose fd -values Lmin terminates
Open1 Open2 empty. technique removing nodes called trimming
BS*, newly generated nodes placed sets open nodes all,
called screening. techniques improve BHPA \just" respect
saving memory, BS* additionally includes improvements reduce number nodes
generated. major improvements following:

nipping: node selected expansion already Closed opposite search tree, put Closed current search tree without
expansion;
pruning: situation, descendants node Open opposite
search tree removed.

BHPA BS* admissible fd consistent. However, BHPA's results
clearly less ecient A* finding optimal solutions, also BS* never
shown really ecient A*.
Koll Kaindl (1993) first conjecture missile metaphor misleading explanation provided (preliminary) evidence finding. Based
realizing fulfilling termination condition (1) key issue, developed
ecient "-admissible search algorithms, typically find solutions known error
bound faster generate fewer nodes corresponding derivative A* guarantees error bound. algorithms provided, however, improvements
finding optimal solutions, require exponential space like BHPA, BS* A*.
Based approach, Kaindl Khorsand (1994) showed bidirectional
heuristic search using limited memory possible using unidirectional search
algorithm cope limited memory | SMA* (Russell, 1992). However,
runtime eciency insucient.
2.2.2 Front-to-front Evaluations

Since long time consensus belief search frontiers would
pass other, research focused algorithms would force \wavefronts" meet
\wave-shaping" techniques: BHFFA (de Champeaux & Sint, 1977), BHFFA2
(de Champeaux, 1983), d-node retargeting (Politowski & Pohl, 1984) generalized
algorithm (encompassing BHPA BHFFA2) (Davis, Pollack, & Sudkamp, 1984).
289

fiKaindl & Kainz


h(A,B1)

g1(A)
B1

h1(A)

k2(t,B1)
h(A,B2)




h(A,B3)

B2 k2(t,B2)
k2(t,B3)

H1(A) = max( h1(A), min( h(A,Bi) + k2(t,Bi) ) )


B3

Figure 2: illustration front-to-front idea.
algorithms perform front-to-front evaluations show bidirectional heuristic
search ecient terms number nodes generated.
Since basic idea front-to-front evaluations important understanding
paper, illustrate using Fig. 2. evaluation node nodes Bi
opposite search front available storage, costs optimal paths
every Bi estimated. Adding known costs paths Bi goal node
t, normally accurate dynamic estimates gained static front-to-end
evaluator directly estimates cost t.
However, algorithms performing front-to-front evaluations either excessively computationally demanding, restriction solution quality.
compute heuristic estimates nodes one search frontier nodes
other, order estimate paths going nodes opposite frontier
vice versa. So, effort evaluations needed single node selection
expansion may even seem proportional cross product numbers nodes
frontiers. use appropriate data structures, effort reduced become proportional number descendants expanded node times
size opposite search frontier.3 Still, excessively computationally demanding frontiers may contain order millions nodes. keeping effort
practical non-trivial problems, algorithm may either restrict computation
certain (small) number nodes promising values keep search direction
focused single target node opposing frontier several steps retargeting
it. approaches typically terminate non-optimal solutions therefore obviously
lose admissibility, i.e, guarantee finding optimal solutions.

2.3 Non-traditional Approach Bidirectional Heuristic Search

So, traditional approaches succeed improve unidirectional search
finding guaranteeing optimal solutions. particular, algorithms based
traditional best-first search exponential storage requirements. may seem
bidirectional search needs store nodes least one frontier search
opposing side recognize meeting frontier (typically implemented
hashing scheme). Instead storing frontiers forward backward
searches alternate, possible search one direction first storing nodes,
3. According personal communication Dennis de Champeaux.

290

fiBidirectional Heuristic Search Reconsidered

search direction. call non-traditional approach bidirectional
heuristic search.
approach perimeter search (Dillenburg & Nelson, 1994; Manzini, 1995).
perimeter search, breadth-first search generates stores nodes around
predetermined (and fixed) perimeter depth. final frontier breadth-first search
called perimeter. search finished nodes stored, forward search
starts s, targeting perimeter nodes. Depending given problem
available storage, forward search performed A* IDA* fashion.
former implemented PS* (Dillenburg & Nelson, 1994), latter IDPS*
(Dillenburg & Nelson, 1994) BIDA* (Manzini, 1995). perimeter depth,
IDPS* BIDA* search exactly nodes. However, BIDA* temporarily removes
perimeter nodes cannot affect computation evaluation function
consequently reduces number heuristic front-to-front evaluations compared
IDPS*. Due improvement, BIDA* far ecient terms running time
IDPS*.
BIDA* achieves good results (sliding-tile) Fifteen Puzzle domain. investigate case contrast traditional approaches bidirectional
heuristic search. particular, show results experiments varying perimeter
depth, i.e., varying perimeter size storage use.

3. New Results Previous Approaches

Still, seems previous approaches bidirectional heuristic search understood properly. Therefore, present new results propose
new approaches.

3.1 Theoretical Results

present new theoretical results bounds number nodes expanded
traditional bidirectional heuristic search front-to-end evaluations. Since runtime
performance proportional number nodes expanded, bounds
potential eciency. assume availability consistent heuristic evaluation function
hd directions.
First make explicit principally known result form lemma, since need
particular result proving new results. addition, understanding important
understanding results. Note, however, termination condition bidirectional search significantly different termination conditions unidirectional search
like A* given Pearl (1984).

Lemma 3.1 (a sucient condition successful termination BHPA BS*):

solution path t, BHPA BS* terminate successfully (i.e.,
finding path) iff following conditions satisfied:
(i) least one search frontiers BHPA BS* minimum f -value must
raised least value optimal solution C , is, minx2Opend fd (x)
C ;
(ii) optimal solution must found, is, Lmin = C .
291

fiKaindl & Kainz

Proof: need concerned whether algorithms indeed find optimal

solutions, since corresponding proofs given Pohl (1971) Kwa (1989), respectively. focus exactly termination condition Formula (1)
fulfilled | BHPA explicit termination condition, BS* implicit
explained above. minimum f -values Opend first values f1 (s) f2 (t),
respectively. Since fd consistent exceed C . minimum f -values Opend
increases gradually nodes f -values < C least one search frontier
expanded (or nipped pruned BS*). Since maximum minimum f -values
Opend used, one least one must become C . search,
Lmin C always holds, optimal solution found, Lmin = C .
2
order establish bounds number node expansions, let us first focus
upper bound number nodes expanded BHPA.

Theorem 3.1 number node expansions BHPA bounded
#(BHPA) < #(A )1 + #(A)2

Proof: worst case, BHPA may perform A*-type searches
directions completely, exception least one node expansion. Even Lmin =
C achieved last node expansion one direction, immediately thereafter
termination condition fulfilled according Lemma 1. Therefore, opposite direction
least one node expansion saved.
2
sense, bound may look quite weak, actually Nilsson (1980) conjectured bidirectional heuristic search may expand twice many nodes would
corresponding unidirectional one. conjecture based assumption originally
published Pohl (1971) search frontiers may pass without intersecting.
recently, however, empirical evidence found Koll Kaindl (1993)
assumption invalid, i.e., frontiers typically meet rather early even without
using wave-shaping techniques. So, question may arise whether
conditions result Theorem 3.1 reasonable useful. order show conditions, define strong symmetry property search spaces. Although may seem
completely unrealistic assumption, dicult imagine search space
property. Searches optimal solutions TSP (traveling salesman problem)
instances need generate nodes represent visiting neighboring cities
start city. Since city also final city visited, reverse search
opposing direction needs generate nodes exactly cities, etc. So, least
straight-forward implementation bidirectional search TSP works symmetric
space. symmetric TSP instances (where arc costs independent
direction) usual heuristic evaluations functions TSP (like minimum
spanning tree heuristic), turns perfectly A*-symmetric search space.
Definition 3.1 Let f11 = h1(s); f12; : : :; f1k,1; f1k = C different f -values expanded

nodes forward direction analogously f21 = h2 (t); f22; : : :; f2k,1; f2k = C
backward direction. search space perfectly A*-symmetric iff A* expands
number nodes f -value forward direction backward direction,
is, #j (A)1 = #j (A )2 j = 1 : : :k.
2
292

fiBidirectional Heuristic Search Reconsidered

Theorem 3.2 search space perfectly A*-symmetric f -values distinct
direction,

#(BHPA) = 2 #(A) , 1 3

Proof: perfectly A*-symmetric search space, numbers nodes expanded
directions A*-type searches within BHPA strictly last 2
f -values, termination possible point; since distinct
direction, amounts 2 nodes remaining 2 f -values:
#(A )1 , 2 = #(A)2 , 2
Depending Lmin = C achieved, 1 3 nodes must expanded
fulfill termination condition. Summing proves theorem.
2
Since practice f -values normally distinct (in direction), show
consequence realistic assumption | occurrence many different f -values.
meant sense number nodes f -value small compared
number nodes expanded.

Corollary 3.1 search space perfectly symmetric many different f values,

#(BHPA) 2 #(A)

Proof: Since several nodes f -value, expansion
3 nodes may saved optimal solution already found.
number nodes f -value small compared number nodes expanded,
however, #(BHPA).
2
So, strong assumption symmetry BHPA expands close twice many
nodes A*. possible conjecture Nilsson (1980) supported although
original assumption appears valid?
point search frontiers BHPA meet early, i.e., pass
without intersecting, go other! So, possibly large
region search space explored twice (as illustrated Fig. 3).
BS* avoids double exploration (see Fig. 3). Unfortunately, appears
dicult quantify size region. So, cannot determine tighter upper bound
number nodes expanded BS* without assumptions.
Fig. 3 also illustrates search frontiers BS* typically \ragged".
means meetings occur \middle" well near (as observed
experiments).
let us look lower bounds number nodes expanded BHPA.
need assumption symmetry show general results.
Theorem 3.3 numbers nodes expanded BHPA bounded
min(X1; X2) + 1 #(BHPA)
293

fiKaindl & Kainz

A*





BHPA





region search space explored twice

BS*





nipping

pruning

Figure 3: illustration traditional bidirectional heuristic search front-to-end evaluations.
Xd = #d (A ) , #kd (A) number nodes would expand search
direction minus number nodes value fdk = C .
Proof: lower bound represents case earliest termination according Lemma
1. (At least 1 node expanded direction.)
2
Corollary 3.2 f -values distinct direction, number nodes
expanded BHPA bounded
min(#1 (A); #2(A)) #(BHPA)
Proof: Xd = #d (A) , 1 since 1 node n fd(n) = C .
2
Corollary 3.3 maximal improvement BHPA given
#(A) , min(X1; X2) , 1:
Proof: min(X1; X2) + 1 minimum number nodes expanded BHPA.
2
essence, shown certain conditions traditional bidirectional heuristic search front-to-end evaluations exemplified BHPA expand close twice
many nodes A*. original conjecture result based
apparently wrong assumption, found another | even obvious | effect
(partly) responsible.
addition, shown BHPA cannot much ecient A*
respect node expansions even best case. variant BS* without pruning
technique, lower bound number nodes expanded applies. general,
major problem traditional bidirectional heuristic search front-to-end evaluations
cost satisfying termination condition.
294

fiBidirectional Heuristic Search Reconsidered

3.2 Empirical Results

order provide evidence missile metaphor misleading, present new
empirical data performance BS*. Since perimeter search seems become
ecient increasing perimeter depth (Manzini, 1995), investigated
behavior experiments two different domains. present new empirical results
experiments provide explanation perimeter search works well
Fifteen Puzzle domain.
3.2.1 BS*

BS* classical best-first search algorithm requires exponential memory. So,
aware BS* implementation yet able solve dicult problem instances
Fifteen Puzzle, given domain-specific knowledge puzzle
Manhattan distance heuristic. experiments, BS* able solve 59 100
instances used Korf (1985), available 256 Mbytes main storage (on
Convex C3220).
gathered data runs BS* provide empirical evidence
missile metaphor misleading (in addition data already given Koll Kaindl
(1993)). average, BS* found first solution generation 7.2 percent
total number nodes generated. quality solution average 6.3
percent worse optimal solution. continuing searches, BS* found
optimal solutions generation 22.4 percent total number nodes generated
(again average). is, search effort BS* spent verify optimality.
means search frontiers BS* meet relatively early without use
wave-shaping techniques, even optimal solutions found rather quickly. However,
even BS* already found optimal solution problem instance,
\know" solution optimal. So, must continue search generate
remaining nodes order prove fact better solution available.
Relatively overall higher effort, BHPA would find first solution even \earlier"
BS*. course, BHPA needs exactly number nodes BS*
search frontiers meet. first meeting, however, would generate
nodes BS* search frontiers go other. search frontiers
would, however, pass illustrated missile metaphor, solutions could
found early.
3.2.2 Perimeter Search

Perimeter search achieved good results Fifteen Puzzle domain, solve
Fifteen Puzzle problem instance relatively fast limited memory. However,
approach bidirectional heuristic search also seems understood suciently yet.
So, made experiments increasing perimeter depth two different domains.
results may seem quite surprising. cannot yet explain theoretically,
important right, try explain intuitively.
experiments, feasible use complete set 100 Fifteen Puzzle
problem instances used Korf (1985). Fig. 4 shows domain BIDA* works
well, especially terms number nodes generated. data normalized
295

fiResults relative Korfs IDA* %

Kaindl & Kainz

50

Nodes generated

45

Running time

40

35.3

42.0

34.2

35

32.7

30.7

29.7

30

28.0

27.8

29.1

27.4

25
20
15
10
5

4.1

3.2

2.5

1.9

1.5

1.1

0.9

0.7

0.5

0.4

0
10

11

12

13

14

15

16

17

18

19

BIDA* Perimeter Depth

Figure 4: Comparison BIDA* different perimeter depths Fifteen Puzzle (100
instances) | time optimum.
respective search effort IDA* (in Korf's implementation), since first
algorithm able solve random instances Fifteen Puzzle.4 Also running times
good.5
Consistently (Manzini, 1995, Table 1), Fig. 4 shows steady decrease
number nodes generated required running time increasing perimeter depth
reaches 16. perimeter depth, however, BIDA* achieves minimum running
time. exact perimeter depth optimum occurs may depend several
factors machine used eciency implementation. new
important finding is, however, optimum actually exists BIDA*.
optimum perimeter depth shown exist PS* Dillenburg Nelson (1994),
data presented Manzini (1995) suggested increasing perimeter depth
number evaluations performed BIDA* even decreases. larger perimeter depths,
however, savings terms node generation obviously outweighed larger cost
front-to-front evaluations. Note, data presented Manzini (1995)
show optimum amount memory required storing perimeter
depths greater 14 exhausted resources available experiments reported
there.
4. give idea overall diculty given problem set, note IDA* generates 363
million nodes average, needs slightly less half hour Convex C3220.
5. BIDA*'s result worse data reported Manzini (1995). primarily due use
different machine different implementation based ecient code IDA*
puzzle provided us Korf using. implementation overhead especially
wave shaping shows clearly even using runtime optimizations described Manzini
(1995). access implementation Manzini, E-mail communication
given hints it, agreement overall effect relative
running times due different implementations IDA*.

296

fiBidirectional Heuristic Search Reconsidered

Knowing existence optimum helps us better understand improvement perimeter search traditional approach bidirectional heuristic search
based front-to-front evaluations exemplified, e.g., BHFFA. advantage improved evaluation accuracy balanced large overhead time consumption
node evaluations. BIDA* tuned towards optimum, algorithm like
BHFFA typically balance regard. BHFFA reason
find optimal solutions quite easy problems, perimeter search comparably much cheaper
per node searched, since much smaller frontier \targeted".
Although performance perimeter search cannot improved deliberately
using memory, optimum running time BIDA* Fifteen Puzzle
problems good. So, wanted see whether results also
achieved another domain used experimenting algorithms.
made experiments finding optimal solutions set maze problems.6
problems, BIDA* based IDA* inecient due high number iterations. So,
used PS* (Dillenburg & Nelson, 1994) implements common underlying idea
| perimeter search | based A*. A* works well maze problems,
seems runtime optimization BIDA* cannot practically used A*-based
algorithm due excessive storage requirements, since every node Open information
every perimeter node would stored may affect computation
front-to-front evaluations. fact, Manzini (1995) states technique
applied depth-first search algorithm.
Based experiments, perimeter search approach appears work satisfactorily illustrated Fig. 5 | neither terms generated nodes terms
running time. data normalized respective search effort A*, since seems
ecient algorithm problem instances fit memory (see also
optimality result A* unidirectional competitors Dechter & Pearl, 1985).7
Even comparably larger perimeter depths (50, 100, : : : , 250), numbers generated
nodes marginally improve (up 93.9 percent number nodes generated A*
shown figure), running time becomes quite high (up 358.7 percent).
running time reduced perimeter depths smaller 25,
real savings number nodes generated therefore improvement A*
observed.
considering different performances perimeter search domains, question arises, works well Fifteen Puzzle satisfactorily maze. Let us consider reason good results first, closer look
case perimeter depth 1. minimal perimeter around node Fifteen
6. use domain inspired use Rao et al. (1991). Problem instances
domain model task navigation presence obstacles. 100 instances drawn randomly
using approach behind Xwindows demo package Xmaze. heuristic evaluator, use
Manhattan distance like Rao et al. (1991).
experiments, made following adaptations. order allow transpositions,
\install" wall three percent cases. leads roughly \density" transpositions
Fifteen Puzzle. Moreover, use much larger mazes | 2000 2000, order focus
dicult instances these, use instances h1 (s) 2000.
7. give idea overall diculty given problem set, note A* generates 2.7
million nodes average, needs less two minutes Convex C3220.

297

fiKaindl & Kainz

358.7
350

Nodes generated

Results relative A* %

303.0

Running time

300

244.0

250
185.1

200
150
100

139.0
119.8
99.3

98.7

97.4

96.2

95.0

93.9

50
0
25

50

100

150

200

250

PS* Perimeter Depth

Figure 5: Comparison PS* different perimeter depths maze problems (100
instances).
Puzzle contains two nodes. Still, perimeter approach saves half node
generations IDA*.
major improvement explained quite simply looking approach
improving heuristic evaluation function. Perimeter search \discovers"
search analogous improvement Manhattan distance heuristic presented
Korf Taylor (1996, p. 1203) name \last moves heuristic" (more precisely
part dealing exactly last move).8 precisely, cases dynamic
values increase h1 (n) two units, i.e., twice (unit) cost either arcs
two perimeter nodes.9 improved evaluations, many node generations
saved even using perimeter nodes.
Still, question remains improvements observed maze domain.
domains arcs unit costs, found major differences help us
explain phenomenon. Fifteen Puzzle problems relatively short (optimal) solutions,
due unit costs arcs overall cost solution also relatively small (53.1
average). comparison, maze problems (in mazes size used) relatively
long (optimal) solutions relatively high cost solution (5262 average).
8. heuristic based last move solution, must return blank goal position.
order allow blank position, tiles next blank goal position must
certain places. Manhattan distance accommodate corresponding path
therefore increased two units.
9. also relates property Manhattan distance heuristic itself. cases, increase
cost known arc (with cost 1) added increase heuristic estimate
evaluated node perimeter node (also 1) compared estimate t. remaining cases,
heuristic estimate evaluated node perimeter node reduces (by 1) compared
estimate t, cancels cost known arc.

298

fiBidirectional Heuristic Search Reconsidered

differences also ected differences heuristic values (although used
domains less heuristic). given set Fifteen Puzzle problem
instances, h1 (s) = 37:1 average much smaller h1 (s) = 2361 given set
problem instances maze domain. data heuristic values
\Think-A-Dot" problems used Dillenburg Nelson (1994), note mean
path length given 18.4, i.e., even much smaller Fifteen Puzzle.
Let us assume Fifteen Puzzle maze domain
number perimeter nodes twice cost arc (i.e., two units) added.
means resulting dynamic evaluation improves static evaluation
absolute amount, quite different relative amount: 5.4 percent Fifteen
Puzzle compared 0.08 percent maze domain. So, dynamic improvement
heuristic effect much higher Fifteen Puzzle, leads much larger savings
terms node generations effort front-to-front evaluations.
summary, Fifteen Puzzle perimeter nodes improve static
evaluation, since twice (unit) costs arcs even cases simply
added. large effect domain heuristic values typically smaller
40. maze instances size experimented with, heuristic values
two orders magnitude larger, therefore many perimeter nodes would
required achieve much effect. These, however, make perimeter search expensive
terms running time probably also storage requirement.
considerations, clear effect front-to-front evaluations
much steering frontiers together, rather improve heuristic evaluations
dynamically. particular, example two perimeter nodes illustrates
\wave shaping" real effect, rather improvement evaluation accuracy.

4. Generic Approach Non-Traditional Bidirectional Search
developed new generic approach bidirectional heuristic search integrates various
search algorithms typically leads hybrid combinations. Since approach
allow changing search direction once, viewed non-traditional
form bidirectional search.
major steps generic approach are:10
1. Assign search direction even nearly available memory
traditional best-first search.
2. Perform traditional best-first search assigned direction using given memory.
3. Unless best-first search already found optimal solution, perform search
reverse direction. Use memory structure built previous best-first
search, possibly together additional memory still available, compute
use front-to-end evaluations.
would dicult perceive even general approach subsumes
perimeter search. expensive front-to-front evaluations, however, wanted
10. approach different one proposed earlier (Kaindl, Kainz, Leeb, & Smetana, 1995).

299

fiKaindl & Kainz

transpositions

linear-space search



best-first search


Figure 6: specialization generic approach.
devise approach avoids need find balance cost
evaluations beneficial effect.
useful specialization generic approach uses memory sides
search space illustrated Fig. 6. traditional best-first search uses assigned
memory usual, e.g., A*, linear-space search uses much memory still
available transposition table (Reinefeld & Marsland, 1994). former first orders
sequence node generations finds transpositions. latter uses memory
finding transpositions another part search space, caching accurate
heuristic evaluations closer t.
limited memory available, approach exible. instance,
memory transposition table assigned, approach combines linear-space search
conventional best-first search bidirectional style. may look quite similar
BIDA*, note approach contrast performs front-to-end evaluations.
memory best-first search used find solutions earlier meeting frontier
(rather t).
sucient memory available even solving dicult problem instances
domain, also search reverse direction may performed traditional bestfirst search like A*. all, A* certain conditions certain sense optimal
respect node expansions (Dechter & Pearl, 1985).

4.1 Instantiating Limited Memory
First show generic approach instantiated limited memory
available. course, instantiation make use available domain-specific
information. particular, combine unidirectional search algorithms
best suit properties domain (see, e.g., Rao et al., 1991; Zhang & Korf, 1993).
example, domains IDA* choice, others depth-first branch-and-bound
(Lawler & Wood, 1966) much better. case limited memory, either
preferred A*.
present experimental results Fifteen Puzzle, domain
characterized distinct cost values. condition, reasonable
select IDA* linear-space search algorithm, since dicult problem instances
Fifteen Puzzle require much memory using A*, Manhattan distance
heuristic used. Since A* makes good use consistent heuristics like one (Dechter &
Pearl, 1985), select part best-first search.
300

fiBidirectional Heuristic Search Reconsidered

Based key idea bidirectional search, let A* IDA* search opposite
directions steps 2 3 generic approach, respectively. instantiation
generic approach leads BAI (Bidirectional A* { IDA*).
Optionally, may also give IDA* search part available memory
transposition table. Fig. 6 illustrates instantiation. call variant BAI due
use table BAI-Trans.
A* cannot find solution using given memory, IDA* searches reverse
direction towards frontier prior search. Since consider case finding
optimal solutions, search cannot always terminate immediately solution found.
better solution may exist, algorithm must find optimal one subsequently
prove optimal.
technically, IDA* part must changed slightly. Instead find
goal node, solution found whenever depth-first search meets frontier
opposing A* search. cost solution smaller cost best solution
found far (or first solution found) value stored. course, cost
best solution found far may sub-optimal, algorithm yet know
already optimal. However, stored value exceed non-overestimating
threshold IDA* part, depth-first search exited successfully optimal
solution.
addition necessary changes, IDA* part advantage start
increased initial threshold based admissible estimate optimal solution cost
determined A* part. Since assume consistent heuristic h, minimum
f = g + h nodes Open always admissible estimate. Therefore, estimate
higher usual initial threshold IDA*, used instead.
Moreover, necessary IDA* part search space already
explored A*. technically, depth-first search invoked IDA* meets
closed node opposing A* search frontier, branch cut (meeting open
node general insucient). call nipping according analogous method
described Kwa (1989).
ecient implementation Fifteen Puzzle even effort hashing every
node causes overhead cannot ignored. Therefore, implemented BAI
way avoids hashing nodes | based heuristic estimate |
knows frontier opposing A* search still reach.
According step 1 generic approach, search directions must assigned
A* IDA* part, respectively. traditional bidirectional search, Pohl (1971)
proposed used cardinality criterion problem determining frontier
select node expansion: continue searching frontier fewer open
nodes. utilized node expansion traditional bidirectional search
algorithms, BAI decide issue beginning whole search.
search space suciently symmetric, initial search direction
determined random. search space least slightly asymmetric
specific knowledge determining search direction available, seems reasonable
make shallow probes search space sides use idea behind
cardinality criterion. Since BAI incorporates IDA*, using algorithm also probing
consistent overall approach. example Fifteen Puzzle, first
301

fiKaindl & Kainz

iterations IDA* searched sides, direction fewer generated
nodes assigned IDA* part overall search, since especially dicult problems
search much deeper A* part.
Let us shortly discuss behavior BAI. best case, would seem
A*. fact, BAI even better pure A*. BAI assigns search direction
dynamically, lead better results systematically going one direction.
worst case, BAI perform part A*, without savings IDA* part
(except effect nipping).
key question BAI saves effort without enough memory available
completing A* search. Primarily, save one IDA*'s iterations. Due
better initial threshold, early iterations saved. Since earlier
iterations comparably cheap, helps much less saving last iteration.
search also terminated complete iteration IDA* cost best
solution already found larger new increased threshold. Therefore, large
savings possible BAI terminates earlier pure IDA*.

4.2 Instantiating Sucient Memory
let us sketch generic approach instantiated case sucient
memory available sense even solving dicult problem instances
domain, traditional best-first search terminate successfully given memory.
case interest order see whether bidirectional search better A*,
sense optimal unidirectional algorithms.
sucient memory available, instead IDA* (or depth-first branch-and-bound)
reverse search employ A*. fact, easy construct algorithm analogously BAI described above, using A* instead IDA*. instantiation
generic approach leads BAA (Bidirectional A* { A*). algorithm changes
search direction contrast BS*. better utilization approach
dynamically improving heuristic values based differences, introduce slight
variation algorithm below.

5. Approach Dynamically Improving Heuristic Values based
Differences
new approach dynamic improvements heuristic evaluations search based
differences known costs heuristic estimates. differences utilized
two concrete methods presented below. basic idea common methods
many nodes search, actual cost path
already known. Since static heuristic values normally gained rather cheaply,
differences computed signify error made evaluation compared
cost known path. differences utilized improve heuristic estimates
search.
order able compute differences, search must bidirectional.
focus context non-traditional approach bidirectional heuristic search
described above. Actually, application also possible context traditional bidirec302

fiBidirectional Heuristic Search Reconsidered


B1
h1(A)

g1(A)

Search
frontier



g2*(B1)

Diff1*(B1)
h1(B1)


B2 Diff1*(B2)

Diff1*(Bi) = g2*(Bi) - h1(Bi)

Diff1*(B3)

Mindiff1 = min( Diff1*(Bi) )

B3



H1(A) = h1(A) + Mindiff1

Figure 7: illustration Add idea.
tional search like BS*. involves, however, intricacies beyond scope
paper. So, interested reader referred (Kainz, 1996).

5.1 Add Method

first method instantiates approach adding constant derived differences heuristic values static evaluation function. Therefore, call Add
method.
Note, adding constant evaluations change order node
expansions unidirectional search algorithm like A*. So, benefit approach
may immediately obvious. However, bidirectional search algorithms using frontto-end evaluations, estimates compared cost best solution found far
(which necessarily already optimal one), better estimates available
comparisons improves eciency due earlier termination. explain
detail apply approach context non-traditional approach
bidirectional heuristic search.
See Fig. 7 key idea method. assume consistency static heuristic
evaluator hd . Around goal node t, search examined part graph stored
optimal paths nodes Bi closed fringe t. node Bi , heuristic
value h1 (Bi ) computed subtracted optimal path cost g2(Bi ) = g2(Bi ) =
h1 (Bi ), resulting Diff1 (Bi ). actually error made heuristic evaluation
node Bi . minimum Diff1(Bi ) nodes Bi fringe computed |
call Mindiff1 .
point Add method consistent heuristic value h1 (A)
node outside stored graph underestimates h1 (A) least Mindiff1 . prove
precisely below, first need show result Diff1.

Lemma 5.1 heuristic h1 consistent, optimal path node n
intermediary node

Diff1(m) Diff1(n)
holds, i.e., Diff1 decrease optimal path decreasing distance goal
node t.
303

fiKaindl & Kainz

Proof: heuristic h1 consistent,
h1 (n) h1 (m) + k1 (n; m)
simply obtain

g2(m) , h1 (m) g2(m) + k1(n; m) , h1 (n)
Since n one optimal path t, know

g2(n) = g2(m) + k1 (n; m)
substitutions obtain

g2(m) , h1 (m) g2(n) , h1 (n)
equivalently
Diff1(m) Diff1(n)

2

proves lemma.

Theorem 5.1 heuristic h1 consistent, possible compute admissible

heuristic H1 node outside search frontier around

H1(A) = h1(A) + Mindiff1 h1 (A)

Proof: path exists node t, also optimal path must exist,
let go frontier node Bj . (If path exists, h1 (A) infinite
theorem holds.) Lemma 1 definition Mindiff1 know
Mindiff1 Diff1(Bj ) Diff1 (A)

Since Diff1 error made heuristic h1 , write

h1 (A) + Diff1(A) = h1 (A)
substitution obtain

h1(A) + Mindiff1 h1 (A)

2

proves theorem.

Corollary 5.1 H1(A) also admissible estimate frontier node.
Proof: replace Bj proof Theorem 3.1 without changing validity.
2

304

fiBidirectional Heuristic Search Reconsidered

Theorem 5.2 heuristic h1 consistent, H1 consistent.
Proof: heuristic h1 consistent,
h1 (n) h1 (m) + k1 (n; m)
Adding constant Mindiff1 sides leads

h1 (n) + Mindiff1 h1 (m) + Mindiff1 + k1(n; m)
means

H1(n) H1(m) + k1(n; m)
proves theorem.
2
let us sketch Add method utilized context nontraditional approach bidirectional heuristic search. using BAA, example,
first A* search must used compute value Mindiff1 (we assume starts
node t). Optimal paths nodes within search frontier guaranteed
frontier nodes themselves. suboptimal path found frontier node,
however, known optimal path leads another frontier node
optimal path t. So, change fmin, since costs suboptimal paths
cannot uence minimum. Mindiff1 reverse A* search constant
added h1 . call resulting algorithm Add-BAA.
course, larger value Mindiff1 preferred given amount search.
So, search starting around better guided expanding always one
nodes n minimal Diff1 (n). call variant Add-BDA.11
also necessary check, whether node evaluated outside fringe
graph around t. simply achieved Add-BAA Add-BDA hashing,
done anyway. node fringe first A* search matched,
solution already found, first node path inside stored graph around
matched, path need pursued further, since optimal continuation
already known. So, evaluator H1 actually used, consistent, therefore
A* re-open nodes (Pearl, 1984). search terminates selects
node n expansion f1 (n) = g1 (n) + H1 (n) smaller cost
best solution found far, proven way optimal one.
details method theoretical properties refer interested
reader (Kainz, 1994).

5.2 Max Method

second method computes estimate based differences uses
maximum static estimate. Therefore, call Max method.
See Fig. 8 key idea method. assume consistency static heuristic
evaluator hd , path cost g1(A) known. know
evaluation node A: h2 (A) g1(A). difference Diff2 (A) = g1 (A) , h2 (A).
use difference construction admissible estimate F1 (A) cost
11. Earlier called Add-A* (Kainz & Kaindl, 1996).

305

fiKaindl & Kainz



k1(A,B1)

g1(A)
h1(A)

Diff2(A)
h2(A)

B1

h2(B1)

g*
2(B1)

h2(B2)



h2(B3)

Diff2(A) = g1(A) - h2(A)
fmin2 = min( g*2 (Bi) + h2(Bi) )

*
B2 g2(B2)


g*2(B3)

B3



H1(A) = max( h1(A), fmin2 - h2(A) )
F1(A) = max( f1(A), fmin2 + Diff2(A) )

Figure 8: illustration Max idea.
optimal path constrained go A. Note, g1(A) = g1(A)
necessary, call difference used Diff2(A) instead Diff2 (A).
addition, assume search performed reverse direction.
search, assume nodes Bi closed fringe optimal paths
known, cost g2(Bi ). Therefore, possible compute
fmin2 = min
(g (B ) + h2 (Bi ))
2

Based assumptions, construct dynamic evaluation function
follows.
Theorem 5.3 heuristic h1 consistent, possible compute admissible
heuristic h01 node outside search frontier around
h01(A) = fmin2 , h2(A) h1 (A)
Proof: Every path must go frontier node Bj . cost Cj
path bounded follows:
Cj k1(A; Bj ) + g2(Bj )
h1 consistent, possible estimate optimal cost path two nodes

k1(A; Bj ) h2 (Bj ) , h2 (A)
Therefore, write
Cj h2(Bj ) , h2 (A) + g2(Bj )
Since fmin2 = min
(g (B ) + h2 (Bi )), also write
2

Cj fmin2 , h2 (A)
valid cost path including optimal one,

conclude

proves theorem.

h1(A) fmin2 , h2 (A)
306

2

fiBidirectional Heuristic Search Reconsidered

Corollary 5.2 h01(A) also admissible estimate frontier node.
Proof: replace Bj proof Theorem 3.3 without changing validity.
2

dynamic evaluation function necessarily better nodes static
function, useful combine functions:

H1(A) = max(h1(A); fmin2 , h2 (A))
Since admissible resulting function also admissible. value fmin2
changes search, however, H1 consistent.
Since formula computing H1 originally derived difference Diff2 (A) =
g1(A) , h2 (A) included, also derive overall evaluation function

F1 (A) = max(f1(A); fmin2 + Diff2 (A))
let us sketch Max method utilized context nontraditional approach bidirectional heuristic search. using BAI, example,
A* search starting first must used compute value fmin2 (we assume
starts node t). Again, like Add method, necessary optimal
paths frontier nodes known. getting values fmin2 large
possible given amount search, usual strategy selecting node minimal
f2 appropriate here.
subsequent IDA* search within BAI must perform hashing graph stored
around order check, whether node evaluated outside fringe
graph around t. latter case new solution found. call resulting algorithm
Max-BAI. transposition table (Reinefeld & Marsland, 1994) used addition
BAI-Trans, call Max-BAI-Trans.
interestingly, IDA* also utilize Max method without additional storage
requirements. Let us sketch basic approach linear-space application
method here. IDA* normally searches one direction only, let alternate
search direction iteration solution found. Actually, procedure
outside generic approach bidirectional search presented above. include
since linear-space approach special interest. fmini computed one iteration
used subsequent iteration, must search alternate direction
use value. example, iteration searching s, adapted IDA*
computes hmax1 = max(h1 (Bi )) nodes Bi . value used estimate
subsequent iteration checking, whether node evaluated \outside":
h1 (A) > hmax1 true, node cannot \inside" H1(A) safely used.
check substitutes hashing stored graph. Since static heuristic function normally
underestimates, however, nodes heuristic H1 used although would
theoretically correct use it. call resulting algorithm based idea
Max-IDA*.
details method theoretical properties refer interested
reader (Kainz, 1996).
307

fiKaindl & Kainz

Results relative Korf's IDA* %

100.0 100.0

Nodes generated

100

Running time
76.1

80

67.1

66.7 66.7
54.4

60

50.8

40

30.1

27.6

27.4

24.5
15.4

13.9

20

4.3

0.9
0
MaxIDA*

IDA*

IDA*Probing

IDPS*
Depth=2

Trans

BIDA*
Depth=16

BAITrans

Max-BAITrans

Figure 9: Comparison Fifteen Puzzle (100 instances).

6. Results Experiments New Approaches

order provide empirical evidence effectiveness eciency
new approaches, made experiments two different domains: Fifteen Puzzle mazes.

6.1 Fifteen Puzzle

First let us look specific experimental results finding optimal solutions
set Fifteen Puzzle problems, complete set 100 instances used Korf
(1985). compare algorithms achieve previously best results domain
new algorithms. compared algorithms use domain-specific knowledge
puzzle Manhattan distance heuristic.12 main storage available
Convex C3220 used 256 Mbytes.
Fig. 9 shows comparison several algorithms terms average number node
generations running times. data normalized respective search
effort IDA* (in Korf's implementation). already noted above, IDA* needs average
slightly less half hour machine used find optimal solution
one problem instance. So, even slight improvements mean notable savings time.
IDA*, Max-IDA* IDA*-Probing linear-space algorithms use additional
storage, performance cannot compete algorithms use 256
Mbytes. Max-IDA* generates 54.4 percent number nodes generated IDA*
due dynamic improvements heuristic evaluations according difference
approach. Since these, however, imply overhead per node searched, needs 76.1
percent IDA*'s running time. IDA*-Probing variant IDA* uses
probing idea selecting search direction. Although search space sliding-tile
puzzle appears quite symmetric, interesting see much gained
selecting search direction dynamically. Since IDA*-Probing overhead
running time, even faster Max-IDA*. order see well probing via three
iterations already indicates better search direction, compared result
12. much improved heuristic functions, much ecient searches result (Culberson & Schaeffer,
1996) even solving Twenty-Four Puzzle instances become feasible (Korf & Taylor, 1996).

308

fiBidirectional Heuristic Search Reconsidered

perfect oracle. Using would still generate 64 percent IDA*'s nodes, i.e., IDA*Probing overhead generated nodes determining search direction
less 0.1 percent overall 3 percent worse this. Systematically searching
backward direction, however, significantly better systematically searching
forward direction due high standard deviations, although saves 17 percent.
IDPS* uses nodes additional storage perimeter. Due
related overhead front-to-front evaluations, needs running time
IDA*-Probing, although generates much fewer nodes.13
Trans (using 256 Mbytes memory) achieves savings half running time
compared IDA*. saves even much node generations amount memory,
effort hashing slows down.14
Another technique prune duplicate nodes proposed Taylor Korf (1993),
using finite state machine. results included Fig. 9, since lack data
running time (no data given Taylor Korf (1993), reimplement technique). IDA* employing pruning technique generated 100.7 million
nodes set instances reported Taylor Korf (1993), means
27.7 percent number nodes generated pure IDA*. finite state machine
achieved result contained 55,441 states, requiring modest amount storage.
course, finite state machine must built pre-processing stage first.
use search involves small constant overhead running time. So,
sliding-tile puzzles, approach seems better transposition tables
eliminating duplicates. actually appears represent successful approach yet
solving Fifteen Puzzle problems using unidirectional search.
principle, provided available storage BIDA* (Manzini, 1995),
ecient algorithm perimeter approach. given 256 Mbytes storage,
BIDA* store maximum 1 million perimeter nodes. would correspond
perimeter depth 19, BIDA* generates 0.4 percent number nodes
generated IDA*, needs 42 percent IDA*'s running time. So, shown Fig.
4 use memory savings number nodes generated,
optimum running time smaller perimeter size (16), show
Fig. 9. Also reduced perimeter, BIDA* achieves best result terms nodes
13. results reported Dillenburg Nelson (1994) based runs using different sample set
Fifteen Puzzle, different perimeter depth. Using perimeter depth (4), results
Korf's set re-implementation even better terms number node generations,
much slower terms running time (even slower IDA*). personal communication
John Dillenburg turned implementation IDA* slower Korf's one (which
using) factor 60 per generated node. implementation overhead especially
wave shaping show clearly ecient one. Since smaller perimeter
depth means fewer stored nodes therefore less overhead wave shaping, perimeter depth
2 results better running time, consequently show data figure.
14. data figure gained using re-implementation Trans based ecient code provided
Jonathan Shaeffer. Note different way presenting results: absolute data figure vs.
relative problem diculty Reinefeld Marsland (1994). re-implement Trans, since
data performance Trans amount memory used available, since
integrate technique algorithms. Actually, Trans+Move best algorithm
described Reinefeld Marsland (1994), absolute results less one percent better
Trans. Therefore, re-implement Trans+Move cannot include
figure.

309

fiKaindl & Kainz

generated | 0.9 percent number nodes generated IDA*. BIDA*'s
overhead computing front-to-front evaluations smaller IDPS*, BIDA*
needs 27.4 percent IDA*'s running time.15
algorithms BAI-Trans Max-BAI-Trans store maximum 5 million nodes
implementation algorithms given 256 Mbytes storage. BAI-Trans
generates clearly nodes (13.9 percent IDA*) BIDA*, since overhead
per node much smaller, running time even slightly better (24.5 percent). Max-BAITrans | additionally utilizing new difference approach | achieves fastest searches,
needing 15.4 percent time needed IDA*. achieving result, uses
4 million nodes Max method (and BAI) 1 million nodes Trans. order
see uence Trans, compare result Max-BAI (not shown
Fig. 9 order clutter it) uses 4 million nodes Max method
(and BAI). Needing 19.2 percent time used IDA*, slightly slower
Max-BAI-Trans, shows comparably modest uence Trans.
summary, new approach bidirectional heuristic search enhanced Max
method achieves fastest searches finding optimal solutions Fifteen Puzzle
using Manhattan distance heuristic knowledge source. superiority Max-BAI-Trans terms running time previous algorithms statistically
significant. example, probability improvement running time
BIDA* due chance uctuation smaller 0.15 percent according test
compares means paired samples absolute running times, even much
smaller according test data relative diculty instance
well according sign test.16 using less ecient implementations IDA*
basis, difference would become smaller, since approach less overhead per
node searched therefore \gains" less compared pure IDA*. However, prefer
compare algorithms using ecient implementation available.
details results see (Kainz, 1996).

6.2 Mazes

order get better understanding usefulness new approach, made
also experiments second domain | finding shortest paths maze.
maze problems described Subsection 3.2. addition 2000 2000
mazes, also made experiments much smaller 1000 1000 mazes, order see
whether size uences relative performance various algorithms. compare
known algorithms achieve best results domain (as far found)
algorithms Add-BAA Add-BDA. traditional shortest-path algorithm Dijkstra
(1959) corresponds A* without using heuristic knowledge, need explicitly
include experiments. Also experiments, compared algorithms use
domain-specific knowledge Manhattan distance heuristic, main
storage available Convex C3220 used 256 Mbytes.
15. noted already Subsection 3.2, BIDA*'s result worse data reported Manzini
(1995), primarily due using different machine different implementation based
ecient code IDA* puzzle provided us Korf using.
16. details statistic tests used refer interested reader (Kaindl, Leeb, & Smetana,
1994; Kaindl & Smetana, 1994).

310

fiBidirectional Heuristic Search Reconsidered

Results relative A* %

160

Nodes generated

144.2

Running time

140
120

119.8
103.5

99.3

100 100

99.3
87.5

100

70.7 71.7

80
60
40
20
0
BS*

PS*
Depth=25

A*

Add-BAA

Add-BDA

Figure 10: Comparison maze problems (100 instances).
Fig. 10 shows comparison several algorithms terms average number
node generations running times. data normalized respective search
effort A*. already noted above, A* needs average less two minutes
machine used find optimal solution one problem instance.
BS* generates slightly nodes solving problems A* (103.5 percent),
running time even worse. may seem implementation BS*
could optimized, clear overhead compared A*. So,
BS* certainly improve A* here.
PS* (Dillenburg & Nelson, 1994) | using perimeter search, i.e., front-to-front
method | generates 99.3 percent number nodes A*, needs 119.8 percent
time used A*. data correspond perimeter depth 25,
best results shown Fig. 5 terms running time (see also discussion
Subsection 3.2). So, also PS* cannot really improve A* here.
algorithms Add-BAA Add-BDA generate clearly fewer nodes A* (87.5
70.7 percent, respectively). better performance Add-BDA ects higher
Mindiff1 value achieved guiding first two best-first searches
expanding always one nodes n minimal Diff1(n). precisely, Add-BDA
achieved Mindiff1 = 1174 (from reverse search 750k nodes), Add-BAA achieved
Mindiff1 = 811 (from reverse search even 1000k nodes). performance AddBAA terms running time is, however, still much A* (at least
implementation derived BS*). Add-BDA achieves fastest searches, needing
71.7 percent time needed A*. So, application approach dynamically
improving heuristic values feasible little overhead.
superiority Add-BDA previous algorithms statistically significant.
example, probability improvement terms running time A* due
chance uctuation smaller 0.005 percent according three statistic tests
made analogously Fifteen Puzzle data. significance result
holds improvement respect number node generations. Add-BDA
A* well algorithms compared generate child nodes
node expansions, superiority Add-BDA algorithms statistically
311

fiKaindl & Kainz

Table 1: Overview approaches bidirectional heuristic search.
front-to-front
front-to-end
traditional
BHFFA, BHFFA2 BHPA, BS*
non-traditional PS*, IDPS*, BIDA* Max-BAI-Trans, Add-BDA
significant also respect. particularly interesting, since optimality result
A* unidirectional algorithms stated sense A* never expands node
could skipped (unidirectional) algorithm (Dechter & Pearl, 1985).
Since relative results 1000 1000 mazes similar, show
explicitly (see, however, Kainz, 1996). provide empirical evidence
performance algorithms peculiar certain size mazes.

7. Discussion
presentation new approach bidirectional heuristic search experimental results, let us put perspective. Table 1 provides overview existing
approaches according way evaluating way organizing change(s)
search direction. algorithms instantiate new generic approach fall
category non-traditional bidirectional heuristic search algorithms (that change search
direction once) perform front-to-end evaluations. approach allows
coping limited memory (e.g., Max-BAI Max-BAI-Trans), also useful
case sucient memory (e.g., Add-BDA).
Due avoiding expensive front-to-front evaluations, approach dynamically improving heuristic evaluations less effective perimeter search saving node generations (at least Fifteen Puzzle domain). However, less overhead therefore
ecient per node searched terms running time.
viewpoint Table 1, approach somehow \completes" picture bidirectional heuristic search. (Note, however, non-traditional approach found
independently work perimeter search.) Still, ample opportunity
research bidirectional search, especially looking perspectives. Another issue is, e.g., whether linear-space search involved not. propose
paper Max-IDA*, algorithm alternates search direction every
iteration order able use information previous iteration improving
heuristic evaluations dynamically. Yet another perspective whether algorithm
designed find optimal solutions not. paper, focused admissible
search algorithms. discussed above, however, also exist "-admissible bidirectional
search algorithms guarantee solutions known error bound, well others
find solutions without guarantee quality (e.g., d-node retargeting).
contrasting traditional non-traditional approaches bidirectional
heuristic search, may appear strange less exible approach delivers
better results. \better" change search direction once?
dicult provide generally convincing answer question, let us summarize
observations:
312

fiBidirectional Heuristic Search Reconsidered

Traditional bidirectional search typically requires exponential space. Kaindl

Khorsand (1994) showed search possible using limited memory,
complexity algorithms runtime eciency insucient.

perimeter depths perimeter search successful, perimeters

much smaller frontiers traditional front-to-front algorithms.
parameterizing perimeter depth possible balance effort front-tofront evaluations effect improving heuristic evaluations dynamically.

runtime optimizations BIDA* IDPS* feasible perimeter
stays constant (at least iteration).

Mindiff value Add method becomes higher search computing

generates nodes. So, context traditional bidirectional search
initially small.

Applying Max idea becomes much complex, e.g., BS* search
frontiers change (Kainz, 1996).

general, one major problems heuristic search use available
limited memory effectively. Pure unidirectional approaches utilizing limited memory led
less convincing results (Chakrabarti et al., 1989; Sen & Bagchi, 1989; Russell, 1992;
Ghosh et al., 1994; Reinefeld & Marsland, 1994) non-traditional approaches
bidirectional search shown Table 1. particular, generic approach allows
exible effective use available memory. is, however, partly due integration
various unidirectional strategies. Future work may investigate direct use unidirectional approaches utilizing limited memory instantiations generic approach
bidirectional search.
addition, bidirectional search allows use memory dynamically improving
heuristic evaluations ways infeasible strictly unidirectional search.
demonstrated front-to-front approach well difference method.
following simple idea implicitly behind approaches may illustrate this. Given
breadth-first (uniform-cost) search depth d, node outside frontier must
least + 1 steps away start s. reverse search towards may use
fact compute estimate node outside frontier least + 1.
idea cannot used strictly unidirectional search. Note, however, approaches
discussed much complex useful simple idea. Since take
known costs heuristic estimates well differences account,
provide much better estimates especially nodes far outside already given
opposite search frontier.
sense, also possible view difference approach learning, since also
differences predicted actual outcomes important. Usual machine
learning research, however, strives using results one problem instance solving
subsequent instances, attempt. in-depth discussion relationship
outside scope paper. Note, however, also approaches using front-tofront evaluations could considered viewpoint.
313

fiKaindl & Kainz

8. Conclusion

Based new insights previous approaches bidirectional heuristic search, propose paper

new generic approach non-traditional bidirectional search front-to-end evaluations,

new approach dynamically improving heuristic values context.
showed successfully instantiate generic approach important
case available memory limited. memory also utilized eciently
improving heuristic values. certain problems sucient memory available,
proposed instantiation form algorithm challenges A*,
certain sense optimal unidirectional search algorithms. optimality result A*
unidirectional competitors Dechter Pearl (1985) imply bidirectional
search cannot ecient, experiments found empirical evidence
new algorithm ecient A* terms node expansions
running time. also showed approach ecient terms running time
bidirectional unidirectional search approach using information
two different domains. results statistically significant.
traditional bidirectional search yet achieve improvements admissible unidirectional search, non-traditional way performing opposing searches
sequence | exemplified perimeter search approach | seems
great potential. sense, show bidirectional heuristic search viable
consequently propose search strategy reconsidered.

Acknowledgements

years, several people cooperated first author research heuristic
search particular bidirectional search: Aliasghar Khorsand, Andreas Koll, Angelika
Leeb, Harald Smetana Roland Steiner. work served basis work
presented paper. experiments Convex C3220 computing
center TU Vienna available. implementations based ecient
code IDA* A* puzzle made available Richard Korf ecient hashing
schema Jonathan Shaeffer. Finally, acknowledge useful comments earlier drafts
Andreas Auer, Dennis de Champeaux, Stefan Kramer, Giovanni Manzini, Ira Pohl
Roland Steiner. Parts paper already appeared Proc. Fourteenth International
Joint Conference Artificial Intelligence (IJCAI-95) Proc. Thirteenth National
Conference Artificial Intelligence (AAAI-96).

Appendix. Glossary Notation
s;


C

Start node goal/target node, respectively.
Current search direction index; search forward
direction = 1, backward direction = 2.
Cost optimal path t.
314

fiBidirectional Heuristic Search Reconsidered

kd (m; n)
gd(n)
hd (n)
gd(n); hd(n)
fd (n)
fdj
Hd(n)
Fd (n)
Lmin
Opend
Closedd
jOpendj

#(a)
#d (a)
#jd (a)

Cost optimal path n = 1, n = 2.
Cost optimal path n = 1, n = 2.
Cost optimal path n = 1, n = 2.
Estimates gd(n) hd (n), respectively.
Static evaluation function: gd (n) + hd (n).
One f -values expanded nodes search direction d.
Dynamic estimate hd (n).
Dynamic evaluation function: gd (n) + Hd (n).
Cost best (least costly) complete path found far t.
set open nodes search direction d.
set closed nodes search direction d.
Number nodes Opend .
Number nodes expanded algorithm a.
Number nodes expanded algorithm search direction d.
Number nodes value fdj expanded algorithm
search direction d.

References

Chakrabarti, P., Ghose, S., Acharya, A., & DeSarkar, S. (1989). Heuristic search restricted memory. Artificial Intelligence, 41 (2), 197{221.
Culberson, J., & Schaeffer, J. (1996). Searching pattern databases. McCalla, G.
(Ed.), Advances Artificial Intelligence, pp. 402{416. Springer-Verlag, Berlin.
Davis, H., Pollack, R., & Sudkamp, T. (1984). Towards better understanding bidirectional search. Proc. Fourth National Conference Artificial Intelligence (AAAI84), pp. 68{72. Menlo Park, CA: AAAI Press / MIT Press.
de Champeaux, D. (1983). Bidirectional heuristic search again. J. ACM, 30 (1), 22{32.
de Champeaux, D., & Sint, L. (1977). improved bidirectional heuristic search algorithm.
J. ACM, 24 (2), 177{191.
Dechter, R., & Pearl, J. (1985). Generalized best-first strategies optimality A.
J. ACM, 32 (3), 505{536.
Dijkstra, E. (1959). note two problems connexion graphs. Numerische
Mathematik 1, pp. 269{271.
Dillenburg, J., & Nelson, P. (1994). Perimeter search. Artificial Intelligence, 65 (1), 165{178.
Ghosh, S., Mahanti, A., & Nau, D. (1994). ITS: ecient limited-memory heuristic
tree search algorithm. Proc. Twelfth National Conference Artificial Intelligence
(AAAI-94), pp. 1353{1358. Menlo Park, CA: AAAI Press / MIT Press.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics (SSC),
SSC-4 (2), 100{107.
315

fiKaindl & Kainz

Kaindl, H. (1990). Tree searching algorithms. Marsland, T., & Schaeffer, J. (Eds.),
Computers, Chess, Cognition, pp. 133{158. Springer-Verlag, New York.
Kaindl, H., Kainz, G., Leeb, A., & Smetana, H. (1995). use limited memory
heuristic search. Proc. Fourteenth International Joint Conference Artificial Intelligence (IJCAI-95), pp. 236{242. San Francisco, CA: Morgan Kaufmann Publishers.
Kaindl, H., & Khorsand, A. (1994). Memory-bounded bidirectional search. Proc. Twelfth
National Conference Artificial Intelligence (AAAI-94), pp. 1359{1364. Menlo Park,
CA: AAAI Press / MIT Press.
Kaindl, H., Leeb, A., & Smetana, H. (1994). Improvements linear-space search algorithms. Proc. Eleventh European Conference Artificial Intelligence (ECAI-94),
pp. 155{159. Chichester, England: Wiley.
Kaindl, H., & Scheucher, A. (1992). Reasons effects bounded look-ahead search.
IEEE Transactions Systems, Man, Cybernetics (SMC), 22 (5), 992{1007.
Kaindl, H., & Smetana, H. (1994). Experimental comparison heuristic search algorithms.
AAAI-94 Workshop Experimental Evaluation Reasoning Search Methods,
pp. 11{14.
Kainz, G. (1994). Heuristische Suche Graphen mit der Differenz-Methode. Diplomarbeit,
Technische Universitat Wien, Vienna, Austria.
Kainz, G. (1996). Neue Algorithmen fur die bidirektionale heuristische Suche. Doctoral
dissertation, Technische Universitat Wien, Vienna, Austria.
Kainz, G., & Kaindl, H. (1996). Dynamic improvements heuristic evaluations
search. Proc. Thirteenth National Conference Artificial Intelligence (AAAI-96),
pp. 311{317. Menlo Park, CA: AAAI Press / MIT Press.
Koll, A., & Kaindl, H. (1993). Bidirectional best-first search bounded error: Summary
results. Proc. Thirteenth International Joint Conference Artificial Intelligence
(IJCAI-93), pp. 217{223. San Francisco, CA: Morgan Kaufmann Publishers.
Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27 (1), 97{109.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2{3), 189{212.
Korf, R., & Taylor, L. (1996). Finding optimal solutions Twenty-Four Puzzle. Proc.
Thirteenth National Conference Artificial Intelligence (AAAI-96), pp. 1202{1207.
Menlo Park, CA: AAAI Press / MIT Press.
Kwa, J. (1989). BS : Admissible Bidirectional Staged Heuristic Search Algorithm.
Artificial Intelligence, 38 (2), 95{109.
Lawler, E., & Wood, D. (1966). Branch-and-bound methods: survey. Operations Research,
14 (4), 699{719.
316

fiBidirectional Heuristic Search Reconsidered

Manzini, G. (1995). BIDA*: improved perimeter search algorithm. Artificial Intelligence,
75 (2), 347{360.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga, Palo Alto, CA.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.
Addison-Wesley, Reading, MA.
Pohl, I. (1970). First results effect error heuristic search. Meltzer, B., &
Michie, D. (Eds.), Machine Intelligence 5, pp. 219{236. Edinburgh University Press,
Edinburgh.
Pohl, I. (1971). Bi-directional search. Machine Intelligence 6, pp. 127{140 Edinburgh.
Edinburgh University Press.
Politowski, G., & Pohl, I. (1984). D-node retargeting bidirectional heuristic search.
Proc. Fourth National Conference Artificial Intelligence (AAAI-84), pp. 274{277.
Menlo Park, CA: AAAI Press / MIT Press.
Rao, V., Kumar, V., & Korf, R. (1991). Depth-first vs best-first search. Proc. Ninth
National Conference Artificial Intelligence (AAAI-91), pp. 434{440. Menlo Park,
CA: AAAI Press / MIT Press.
Reinefeld, A., & Marsland, T. (1994). Enhanced iterative-deepening search. IEEE Transactions Pattern Analysis Machine Intelligence (PAMI), 16 (12), 701{709.
Russell, S. (1992). Ecient memory-bounded search methods. Proc. Tenth European
Conference Artificial Intelligence (ECAI-92), pp. 1{5. Chichester, England: Wiley.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,
Englewood Cliffs, NJ.
Sen, A., & Bagchi, A. (1989). Fast recursive formulations best-first search allow
controlled use memory. Proc. Eleventh International Joint Conference Artificial Intelligence (IJCAI-89), pp. 297{302. San Francisco, CA: Morgan Kaufmann
Publishers.
Taylor, L., & Korf, R. (1993). Pruning duplicate nodes depth-first search. Proc.
Eleventh National Conference Artificial Intelligence (AAAI-93), pp. 756{761.
Menlo Park, CA: AAAI Press / MIT Press.
Zhang, W., & Korf, R. (1993). Depth-first vs. best-first search: new results. Proc.
Eleventh National Conference Artificial Intelligence (AAAI-93), pp. 769{775.
Menlo Park, CA: AAAI Press / MIT Press.

317

fiJournal Artificial Intelligence Research 7 (1997) 249-281

Submitted 7/1997; published 12/1997

Gravity Fails: Local Search Topology

Jeremy Frank

frank@tiziano.arc.nasa.gov

Caelum Research Corp.
NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

Peter Cheeseman

cheesem@ptolemy.arc.nasa.gov

RIACS
NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

John Stutz

stutz@ptolemy.arc.nasa.gov

NASA Ames Research Center
Mail Stop N269-1
Moffett Field, CA 94035-1000

Abstract

Local search algorithms combinatorial search problems frequently encounter sequence states impossible improve value objective function;
moves regions, called plateau moves, dominate time spent local search.
analyze characterize plateaus three different classes randomly generated
Boolean Satisfiability problems. identify several interesting features plateaus
impact performance local search algorithms. show local minima tend
small occasionally may large. also show local minima escaped
without unsatisfying large number clauses, systematically searching
escape route may computationally expensive local minimum large. show
plateaus exits, called benches, tend much larger minima,
benches exit states local search use escape. show
solutions (i.e., global minima) randomly generated problem instances form clusters,
behave similarly local minima. revisit several enhancements local search algorithms explain performance light results. Finally discuss strategies
creating next generation local search algorithms.

1. Introduction
Local search algorithms heavily studied alternative complete search
NP -Hard problems. typical local search algorithm, gradient descent
greedy search, employs objective function rank states, picks \neighboring"
state maximizing improvement objective function. compelling (if inexact)
analogy dropping marble smooth surface observing roll downhill
local valley. typical greedy objective function acts like gravity, pulling current
state downhill. procedure result algorithm becoming trapped local
minimum. Local search algorithms tend find solutions satisfiable decision problems
quickly complete search algorithms. However, algorithms may terminate

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiFrank, Cheeseman, & Stutz

procedure GSAT(,MaxFlips, MaxTries)

# problem instance solved
# current variable assignment
i=1 MaxTries
= N -bit string selected uniformly random
j = 1 MaxFlips
solved problem(A; )

return
else

PossFlips = neighbors minimizing number unsatisfied clauses
= one element Poss ips selected uniformly random

end else
end
end
return FAIL
end

Figure 1: GSAT Algorithm Sketch
either without finding solution one exists guaranteeing problem instance
solution.
GSAT local search procedure Boolean Satisfiability problems (Selman,
Levesque, & Mitchell, 1992) proven effective quickly finding solutions
satisfiable problem instances. sketch GSAT appears Figure 1. figure,
refers problem instance GSAT solve. GSAT's search space space
complete assignments values variables. GSAT algorithm typically given fixed
number tries (denoted figure MaxTries) fixed number moves per try
(denoted MaxFlips) solve problem instance. move, GSAT examines
states reachable changing value single variable, selects moves minimize
number unsatisfied clauses. GSAT typically encounters sequence states
best move available state leaves number unsatisfied clauses unchanged.
moves referred plateau moves sideways moves, studied (Gent & Walsh,
1993a) (Hampson & Kibler, 1995). Plateau moves dominate time GSAT spends search (Gent & Walsh, 1993a). believed combinatorial search problems
discrete objective functions plateaus cause plateau moves local search,
unlikely search problems real-valued objective functions plateaus.
GSAT encounters plateau, randomly searches either runs ips finds
neighboring state fewer unsatisfied clauses, thereby exiting plateau. Returning
marble analogy, gravity plateaus, hence marble simply rolls
random finds exit runs momentum. Numerous variants GSAT
developed avoid random plateau search improve GSAT performance (Gent &
Walsh, 1993b; Selman & Kautz, 1993; Gent & Walsh, 1995).
nature plateau behavior local search algorithms well understood.
researchers suggest algorithms like GSAT become trapped local minima, i.e., parts
250

fiWhen Gravity Fails: Local Search Topology

search space escape better part search space.
true, local minima detection avoidance important problem local search
algorithm development. researchers suggested local search could become
trapped \ at" regions search space exits better states, call
benches. may happen benches large, contain exits
random plateau search small probability finding exit. Rather designing
algorithms testing problem classes, undertook empirical examination
nature plateaus variety 3-SAT problems.
paper presents several surprising discoveries concerning topological structures
leading plateau behavior impact local search. define plateaus feature
search space break plateaus two classes: local minima benches. Plateaus
defined maximally connected region local search space
objective function constant. Local minima plateaus surrounded regions
search space objective function takes values exceeding plateau,
result purely greedy local search cannot escape finding state
local minimum. Benches defined plateaus exits regions search space
lower values objective function. results show local minima
common benches number unsatisfied clauses close 1, local minima
also occur frequently higher numbers unsatisfied clauses. local minima tend
small, size exhibits high variability; often largest local minima exceeds 10,000
states problem instance containing 100 variables. Also surprising behavior
solutions: solutions grouped together global minima highly variable size.
results also show benches tended much larger local minima.
benches large number exits, small fraction exits,
result local search spend large amount time trying escape them. Plateau
characteristics dependent many features problem instance; found differences
plateau characteristics based ratio clauses variables, solvability problem
instances, problem classes. results plateau characteristics allowed us reinterpret success many modifications local search, including history lists (Gent &
Walsh, 1993b), random walk (Kautz & Selman, 1996) tabu search (Glover, 1989).
paper organized follows: Section 2 present definitions used throughout rest paper. Next Sections 3 4 present empirical analysis
properties plateaus several problem spaces. Section 5 present analysis
previous results light findings. suggest apply work
creation new local search algorithms Section 6, finally Section 7 conclude
discuss ideas future work.

2. Definitions
section define terms used throughout paper. restrict discussion Boolean Satisfiability problems conjunctive normal form three distinct
literals per clause, abbreviated 3-SAT, many concepts presented translate
discrete combinatorial search problems. first present informal definitions,
provide formal definitions end section.
251

fiFrank, Cheeseman, & Stutz

way visualizing local search space 3-SAT mapping full variable
assignment node N dimensional hypercube, N number variables
problem instance. two assignments differ one variable assignment
adjacent nodes hypercube. problem instance defines function nodes
hypercube, mapping node number unsatisfied clauses instance
assignment values corresponding node. refer number unsatisfied
clauses assignment level assignment. plateau maximal connected
region assignment space states level, level
plateau level states plateau. Even single state plateau,
neighbors different level state itself. define border plateau
set nodes hypercube neighbors state plateau
different level plateau. plateau minimum states border
higher level plateau. plateau minimum,
state border lower level states plateau; states plateau
adjacent lower level states called exits. Plateaus exits called
benches. benches consist entirely exits; local search algorithm may explore
one state bench moving it. call benches contours.
3-SAT, plateau global minimum level 0, unsatisfiable problem instances
global minima levels higher 0.
Plateau
exits

Exits

Minima

Bench

Lowest Level

Global Minima

Higher Level

Local Minima

States Exits

Contour

Figure 2: Taxonomy Plateaus
summary: plateau part space \ at" perspective
objective function. states neighboring plateau different level
plateau. neighboring states higher level, plateau local global
minimum, otherwise bench. every state plateau neighbor state
lower level, bench contour. Figure 2 shows taxonomy different types plateaus.
illustration definitions using simple problem instance presented
Appendix A.
realize different ways defining topological structures local search
spaces. definition plateaus includes structures lead plateau behavior;
local search exhibit plateau behavior passes contour, example.
definitions show observed plateau behavior local search caused variety
structures local search topology. retrospect, clear definition benches
specifically excludes contours would better serve characterize plateau behavior
greedy algorithms. caution reader results benches contingent
upon current definition benches, least one reasonable alternate
252

fiWhen Gravity Fails: Local Search Topology

definition expected give somewhat different results. discussed
Section 7.
end section providing formal definitions ideas. Throughout
following definitions, let H N dimensional hypercube representing possible
assignments 3-SAT problem instance . Two vertices hypercube h1 ; h2
neighbors, i.e., edge them, correspond assignments differing
exactly 1 variable.

Definition 2.1 (Level) Let : H ! Z + function mapping assignments integers
(h) = z assignment corresponding h results z unsatisfied
clauses problem instance . z defined level assignment.
Definition 2.2 (Plateau) Let P connected subgraph H let z 2 Z + constant. P plateau P maximal connected subgraph H (p) = z
p 2 P . Further, z defined level plateau.
Definition 2.3 (Border) Let P plateau hypercube H . Let N (p) set

neighboring vertices vertex p hypercube. Let V (P ) function returns
vertex set graph P . Define B (P ) = ([p2P N (p)) , V (P ), i.e., set B (P ) contains b
b neighbor vertex p 2 P b P itself. B (P ) border
plateau.

Definition 2.4 (Minimum, Local Minimum, Global Minimum) Let P plateau
hypercube H . P minimum vertices B (P ) higher level
level P . Also, P local minimum P minimum another minimum

Q level Q smaller level P . P minimum
local minimum P global minimum.

Definition 2.5 (Bench, Exit, Contour) Let P plateau hypercube H . P
bench P minimum, hence exists b 2 B (P ) level
b smaller level P . Also, p exit bench p 2 P p
neighbor b 2 B (P ) level b smaller level P . Finally, P
contour every state P exit P .

3. Probabilistically Painting Plateaus

Armed definitions previous section examined landscape plateaus
randomly generated 3-SAT problem instances. generated problem instances
ratio number clauses C number variables N ranged
3.8 4.6 according Uniform3-SAT problem generation model (Selman et al., 1992;
Crawford & Auton, 1993); algorithm generating instances presented
Appendix B. Problems region straddle \phase transition" satisfiability,
satisfiability randomly generated problems exhibits rapid transition
respect ratio clauses variables, complete search GSAT require
longest time average find solutions (Cheeseman, Kanefsky, & Taylor, 1991;
Crawford & Auton, 1993; Clark, Frank, Gent, MacIntyre, Tomov, & Walsh, 1996). Problem
253

fiFrank, Cheeseman, & Stutz

instances NC < 4:3 referred \under-constrained" since lie
observed transition satisfiability, problem instances NC > 4:3 called \overconstrained." guaranteed problem instance used set experiments
satisfiable finding solution using complete search algorithm.
Local search seems diculty level assignment becomes
close 0; consequently, decided analyze plateaus levels. quite dicult
randomly sample plateaus fixed level problem instance; probability randomly
generating assignment one unsatisfied clause, instance, small problem
instances 100 variables. used GSAT find plateaus analyzed paper.
biases investigation plateaus found one local search method,
hopefully provides first picture plateau structure local search spaces. Due
clumsiness language, remind reader throughout text findings
dependent plateau sampling methodology. Further, GSAT employs
random starting points, bias results depends gradient following
procedure. sample plateaus first used GSAT find state pre-determined level.
is, generated initial state ran single try GSAT encountered
state specified number unsatisfied clauses. used Breadth-First Search
find states plateau found GSAT. Naturally Breadth-First Search records
state found redundant states double-counted. recorded
size plateau (i.e., number states plateau), number exits
plateau contained.

3.1 Characterizing Plateaus
first analyzed relative proportions benches minima satisfiable problem
instances plateaus whose level close 0. generated problem instances 100
variables 380-460 clauses increments 10 clauses. problem size generated
1000 problem instances guaranteed instance solution using complete search
algorithm. Using procedure described above, problem instance generated
found one plateau level 0 5 measured proportion plateaus
local minima benches. analysis provide idea number
benches local minima problem instances. Note plateaus level 0
global minima satisfiable problem instances.
Figure 3 shows proportion plateaus local minima graphed
number clauses problem instances. described above, used GSAT find
plateaus Breadth-First Search determine whether plateaus local minima
benches. see proportion plateaus minima grows
number clauses problem instance plateaus levels 2-5; hence
local minima identical levels over-constrained problems under-constrained
problems. rate growth diminishes plateau level decreases, roughly
plateaus level 1. 85% plateaus level 1 minima 100 variable
problem instances numbers clauses investigated.
Figures 4 shows data, except case graphed level
plateau. level grows proportion local minima declines problem
instances numbers clauses. However, plateaus level 5 may still local minima
254

fiWhen Gravity Fails: Local Search Topology

1
0.9

Proportion Plateaus Minima

0.8
0.7
0.6
0.5
0.4
0.3
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.2
0.1
0
380

390

400

410

420
430
Number Clauses

440

450

460

Figure 3: Proportion Plateaus Local Minima vs. Number Clauses Randomly Generated 100 Variable Problem Instances

1

Proportion Plateaus Minima

0.9

460 Clauses
450 Clauses
440 Clauses
430 Clauses
420 Clauses
410 Clauses
400 Clauses
390 Clauses
380 Clauses

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1

2

3

4

5

Plateau Level

Figure 4: Proportion Plateaus Local Minima vs. Plateau Level 100 Randomly
Generated Variable Problem Instances Varying Numbers Clauses

255

fiFrank, Cheeseman, & Stutz

even problems 100 variables 380 clauses. Hence local minima fact life
even under-constrained problems, become likely over-constrained problems.
Finally, note plateaus level 1 2 reordering proportion
local minima. example, problems 450 clauses lowest proportion local
minima level 1, highest proportion local minima level 2.
explanation result.
1
0.9

Proportion Plateaus Minima

0.8
0.7
0.6
0.5
0.4

Level 0 Plateaus
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.3
0.2
0.1
0
25

50

75

100
Problem Size

125

150

175

Figure 5: Proportion Plateaus Local Minima vs. Plateau Level Variable
Sized Randomly Generated Problem Instances C/N=4.3
also analyzed relative proportions benches minima changed problems
grew larger. found one plateau levels 1-5 1000 problem instances
25 175 variables increments 25, NC = 4:3. Figure 5 shows proportion
plateaus levels 1-5 local minima NC = 4:3 graphed problem
size. see that, level, proportion minima grows problem size,
bodes ill performance local search larger problem instances. see
proportion local minima higher level decreases less rapidly larger
problems. conjecture that, larger problems, proportion local minima decreases
significantly plateaus levels higher 5, cannot predict exact behavior
data hand.
cost detecting local minima proportional size local minima,
understanding size distribution local minima important. cost escaping
benches dependent size bench proportion states bench
exits, understanding properties also important. next two
sections analyze characteristics benches minima. so, generated
statistics plateaus found experiment used generate Figure 4.
instance, 60% plateaus level 2 problem instances 380 clauses local
256

fiWhen Gravity Fails: Local Search Topology

minima, 600 local minima 400 benches analyze characteristics
plateaus. cases 100 data points available analysis.

3.2 Minima Characteristics
300
100 variables, 430 clauses

250

Number Minima

200

150

100

50

0
0

100

200

300

400

500
600
Size Minima

700

800

900

1000

Figure 6: Histogram Sizes Level 1 Minima Randomly Generated Problem Instances
100 Variables, 430 Clauses. Note minima exceeded 1000 states.
section analyze size distribution local minima. Figure 6 shows
distribution size level 1 minima problem instances 100 variables
430 clauses. median minima size 48, yet tail shows minima larger
1000 states. fact, 35 900 minima larger 1000 states
many 10,000 states. examined distribution minima sizes levels
1 found similar results; main differences lengths tails
histograms. consequence discovery escaping local minima explicit local
minima detection normally easy, occasionally expensive. Figure 7
shows distribution sizes minima smaller 100 states. see
fewer minima size 0-5 size 5-10; detailed analysis reveals
three minima size 1, fifteen minima size 2.
Due long tails distribution minima size, median provides
stable summary statistic mean. therefore examined median size local
minima levels 0-5 different numbers clauses determine size local
minima varies. Figure 8 shows median size local minima plotted number
clauses problem instances. striking feature results
minima tend quite small. suggests possible devise local search algorithms
detect local minima using exhaustive search propel
fruitful part search space. distribution shown Figure 6 indicates
257

fiFrank, Cheeseman, & Stutz

100
100 variables, 430 clauses
90
80

Number Minima

70
60
50
40
30
20
10
0
0

5

10

15

20

25

30

35

40

45 50 55 60
Size Minima

65

70

75

80

85

90

95 100

Figure 7: Histogram Sizes Level 1 Minima Smaller 100 States Randomly
Generated Problem Instances 100 Variables, 430 Clauses

150
Level 0 Minima
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

125

Median Minima Size

100

75

50

25

0
380

390

400

410

420
430
Number Clauses

440

450

460

Figure 8: Median Size Minima vs. Problem Size 100 Variable Randomly Generated
Problem Instances Varying Numbers Clauses

258

fiWhen Gravity Fails: Local Search Topology

local minima large, explicit detection minima fixed size (the
median, instance) may successful addition local search. second feature
note median size level 0 minima (i.e., solutions) follows pattern
local minima, level 0 minima tend smaller local minima. last
feature note median size local minima decreases minima level 0-3
number clauses problem instances increases. median size local minima
level 4 5 increases problems 450-460 clauses. One possible explanation
sampled problem instances guaranteed solutions, means
added clauses must contribute larger minima benches higher levels.
true clear minima levels 0-3 increase size. Another
possible explanation small amount data plateaus levels 4 5 relative
amount available plateau sizes indicated Figure 4.
120
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

100

Median Minima Size

80

60

40

20

0
25

50

75

100
Problem Size

125

150

175

Figure 9: Median Size Minima vs. Plateau Level Variable Sized Randomly Generated
Problem Instances C/N=4.3
also examined median size local minima levels 1-5 number variables
problem instances increases. Figure 9 shows median minima size various
levels minima graphed problem size problem sizes 25 175 variables
C
N = 4:3. observe that, problem sizes grow large (beyond 100 variables), median
size minima lower levels appears smaller minima higher levels.
also observe fixed minima level, appears problem instance size
maximizes median minima size. explanation large number
minima level 1 problem instances 50 variables.
Recall global minima satisfiable problem instance plateau
states solutions. many global minima satisfiable problem instances?
one, solutions broken multiple global minima?
259

fiFrank, Cheeseman, & Stutz

single global minima, size global minima tell us anything
likely local search encounter particular solution? answer questions
used GSAT find 1000 global minima single problem instance 100 variables
430 clauses, determined minima distinct. found 436
1000 minima unique, global minima instance ranged size
1 2880 states. Furthermore, found vast majority minima small,
median size around 48. repeated experiment 20 problem
instances found solutions problem instances typically divided
separate global minima global minima vary widely size. Due space
considerations present data paper.
Assuming could detect local minima, dicult local search escape
minima order explore new part search space? local search local
minimum must temporarily move states higher level order find promising
part search space. Two sources computational complexity contribute cost
escaping minima: cost detecting minimum, cost finding path
better part search space. size minimum measure detection
cost; chose minimum increase level measure diculty escaping local
minima. understand idea, consider sequences neighboring states
minimum level increases, decreases. interested minimum
increase required level decreases again. determine generated 1000
problem instances 50 variables 215 clauses each, generated initial state,
ran GSAT 1000 ips. sucient reach local global minimum. 1 order
find minimum level required escape, used Breadth-First Search. begin
states local minimum. explore state border, queuing
states explored increasing order level. ensures states lower
level explored first. encounter state lower level neighbor,
found path local minimum; level state neighbor lower
level minimum level required escape local minimum. results indicate
local minima usually escaped increasing level 1, is,
unsatisfying one additional clause. However, obvious border state use
escape; Breadth-First Search may expand tens thousands states finding
escape route, may always effective escape strategy.
summary, data presented Figures 6 9 shows local minima tend
small much time, therefore may easily detectable escaped. Local
minima typically escaped unsatisfying single additional clause,
still clear escape local minima effectively. Further, size distribution global
minima behaves much like size distribution local minima. Instances tend
many global minima highly variable size, evidence local search
likely encounter small sized local minima global minima large ones.

3.3 Bench Characteristics
1. local minima ranged level 1 6; measure level required escape
benches global minima.

260

fiWhen Gravity Fails: Local Search Topology

80
100 variables, 430 clauses
70

Number Benches

60

50

40

30

20

10

0
0

1000

2000

3000

4000

5000
6000
Size Benches

7000

8000

9000

10000

Figure 10: Histogram Bench Sizes Level 1 Randomly Generated Problem Instances
100 Variables, 430 Clauses

Recall bench plateau exits states lower level. Two
important characteristics benches impact performance local search
size benches number exits. first analyzed distribution size
benches; Figure 10 shows distribution bench sizes level 1 problem instances
100 variables 430 clauses. found long tails, implying benches
small, large. distributions tend much atter
minima.
next analyzed median bench size varies number clauses
problem. appearance long tails distribution bench sizes indicates
median stable measure mean. Figure 11 shows median
size benches varies number clauses problems different levels benches.
interesting feature large median size benches compared
size local minima. Benches typically 10-30 times large local minima,
depending level number clauses problem instance. Problem instances
clauses tend smaller benches, under-constrained
instances median bench size begins growing rapidly bench level even small
range plateau levels analyzed here.
also examined bench size depends problem size. small problems, i.e., 2550 variables, benches tended much larger problems variables.
explanation clauses adequately distinguish
assignments examine states low enough levels. Problems 100
261

fiFrank, Cheeseman, & Stutz

7000
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

6000

Median Bench Size

5000

4000

3000

2000

1000

0
380

390

400

410

420
430
Number Clauses

440

450

460

Figure 11: Median Size Benches vs. Problem Size 100 Variable Randomly Generated
Problem Instances
variables benches 10,000 states; exclude benches
analysis. 2
Large benches may dicult escape number exits small, exits
clustered together. benches exits, others many exits.
used ratio exits benches bench size measure diculty
escaping benches. investigate whether exits benches close
together, may also impact diculty escaping benches.
Figure 12 shows distribution proportion exits bench size benches level
1 problems 100 variables 430 clauses. distribution proportions
indicates plateaus highly variable numbers exits. note benches
fact contours; Figure 12 contours show benches whose ratio exits bench
size 1. observed six benches ratio exits bench size least
0.95 Figure 12 fact contours. Figure 13 shows distribution proportion
exits benches level 5; proportionally contours (65 78 benches
rightmost column histogram contours), mean ratio exits bench
size increased. difference two plots indicates benches lower
levels tend fewer exits benches higher level, even exclude contours
measurements.
understand escape benches different levels, next present plots
mean proportion number exits bench size graphed problem size
2. Breadth-First Search stores enormous number states, terminated program
bench size exceeded 10,000 states. Since large benches used median statistic,
caused diculties analysis.

262

fiWhen Gravity Fails: Local Search Topology

15
100 Variables, 430 Clauses, Level 1 Benches

Number Occurences

10

5

0
0

0.1

0.2

0.3

0.4
0.5
0.6
Proportion Exits Bench Size

0.7

0.8

0.9

1

Figure 12: Exits Level 1 Benches Randomly Generated Problem Instances 100
Variable, 430 Clauses

80
100 Variables, 430 Clauses, Level 5 Benches

75
70
65
60

Number Occurences

55
50
45
40
35
30
25
20
15
10
5
0
0

0.1

0.2

0.3

0.4
0.5
0.6
Proportion Exits Bench Size

0.7

0.8

0.9

1

Figure 13: Exits Level 5 Benches Randomly Generated Problem Instances 100
Variables, 430 Clauses

263

fiFrank, Cheeseman, & Stutz

Figure 14. taken consideration histograms Figure 12, hope
create accurate picture benches tend look.
see Figure 14 proportion exits benches increases level
benches. problems 430 460 clauses mean number exits benches
level 1 increases sharply, indicating over-constrained solvable problems benches
level 1 less obstacle finding solutions. point inclusion
contours definition benches may artificially ate proportions,
cases considerably.
0.8
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

Mean Proportion Exits Bench Size

0.7

0.6

0.5

0.4

0.3

0.2
380

390

400

410

420
430
Number Clauses

440

450

460

Figure 14: Mean Proportion Exits Benches vs Problem Size Randomly Generated Problem Instances 100 Variables
analyzed benches determine whether relationship
number exits bench size, found relationship clause
sizes benches levels investigated. lack relationship unfortunate, since
tells us little escape large benches.
summary, data presented figures 10 14 shows benches occasionally
large, often many exits benches. result, occasionally
local search become trapped large bench little chance
escape. also found benches higher level exits benches
lower level. showed contours common benches level 5 may also occur
level 1. Finally, found obvious relationship bench size number
exits. conclude local minima often problem local search
benches since benches seem easy escape.
264

fiWhen Gravity Fails: Local Search Topology

4. Plateau Characteristics Across Problem Classes

previous section analyzed plateaus satisfiable 3-SAT problem instances
one problem instance class. little reason suspect plateaus behave similarly
across problem instance classes. may also differences satisfiable
unsatisfiable instances class. recent years numerous algorithm designers
begun testing algorithms random problem classes pre-specified desirable
properties. Among problem instances guaranteed solutions (Tsuji &
Gelder, 1993), problems structure hidden algorithm.
class \cluster" problems presented Kask Dechter (1995); problems
consist number satisfiability problems independent sets variables
number clauses connecting clusters. repeated experiments problem
distributions determine plateaus instances exhibit different properties
Uniform3-SAT class, might alter effectiveness local search. also
repeated experiments unsatisfiable instances Uniform3-SAT distribution. Due
space considerations repeat full analysis performed above, discuss
differences characteristics classes investigated.

4.1 Unsatisfiable Problems
1
Satisfiable Problems
Unsatisfiable Problems

Proportion Plateaus Minima

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1

2

3

4

5
6
Plateau Level

7

8

9

10

Figure 15: Proportion Plateaus Local Minima Randomly Generated Satisfiable Unsatisfiable Problems 100 Variables, 430 Clauses
major drawback local search inability distinguish satisfiable problem instances unsatisfiable problems. analyzed plateau structure unsatisfiable
problem instances Uniform3-SAT instance distribution determine whether
differences would allow local search determine problem instance unsatisfiable. repeated previous empirical studies collected data proportion
265

fiFrank, Cheeseman, & Stutz

size plateaus limited investigation problems 100 variables 430
clauses. first present data proportion plateaus local minima unsatisfiable problem instances 100 variables 430 clauses. generated 1000 unsatisfiable
instances using problem generation technique used previous set experiments guaranteed problem instances unsatisfiable using complete search
algorithm. used GSAT find states level 1-10, generated corresponding
plateaus. contrast data data satisfiable problem instances 100
variables 430 clauses Figure 15.
Figure 15 shows proportion plateaus local minima similar
satisfiable unsatisfiable problems plateau level decreases, except plateaus
levels 0 5 proportion shifted right ome level. possible interpretation
result comes noting frequently adding single randomly generated clause
turn random satisfiable instance unsatisfiable instance. Hence local search
may become trapped higher level local minima unsatisfiable problems
satisfiable problems.
70

60

Satisfiable Problems
Unsatisfiable Problems

Median Minima Size

50

40

30

20

10

0
0

1

2

3

4

5

Plateau Level

Figure 16: Median Size Local Minima Randomly Generated Satisfiable Unsatisfiable Problems 100 Variables, 430 Clauses
Next analyzed median size local minima unsatisfiable problem instances
minima levels 1 5. analyzed data plateaus found generate
Figure 15. Since number minima small minima levels 6-10, could
gather sucient data analysis reasonable amount time. However, Figure
16 shows, local minima unsatisfiable problems tend much smaller local minima satisfiable problems. Figure 17 shows median size benches unsatisfiable
problem instances. found median bench size unsatisfiable instances tended
smaller benches satisfiable problems. conjecture local search may
converge local minima faster unsatisfiable problems minima tend
266

fiWhen Gravity Fails: Local Search Topology

higher level; since minima benches smaller minima higher
levels, local search able descend faster average become stuck earlier.
Unfortunately, differences slight enough seems little hope using
results improve ability local search identify unsatisfiable problem instances.
1000
Satisfiable Problems
Unsatisfiable Problems

Median Bench Size

800

600

400

200

0
1

2

3
Plateau Level

4

5

Figure 17: Median Size Benches Randomly Generated Satisfiable Unsatisfiable
Problems 100 Variables, 430 Clauses

4.2 Instances Guaranteed Solutions

next present data problems guaranteed solutions described (Tsuji &
Gelder, 1993). generator HardSolvable3-SAT generator presented Appendix
B. Brie y, generator selects assignment guaranteed solution,
generation rejects clauses satisfied assignment set additional clauses enforce even distribution signs variable. before,
generated 1000 problem instances, 100 variables 380-460 clauses.
problem instance used GSAT find state 1-5 unsatisfied clauses, determined
whether corresponding plateau bench local minimum. Figure 18 shows
proportion plateaus minima graphed number clauses problem
instances 100 variables. proportion local minima problems similar
identical proportions local minima Uniform3-SAT class shown
Figure 3. One difference local minima appear prevalent over-constrained
problems HardSolvable3-SAT class Uniform3-SAT class. second
difference data plateaus level 1. proportion minima rises slightly
380 clauses 430 clauses, dips sharply; hence benches level 1
Figure 18 Figure 3. detailed analysis reasons differences beyond
scope paper, generation process seems eliminate clause combinations
267

fiFrank, Cheeseman, & Stutz

1
0.9

Proportion Plateaus Minima

0.8
0.7
0.6
0.5
0.4
0.3
Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.2
0.1
0
380

390

400

410

420
430
Number Clauses

440

450

460

Figure 18: Proportion Plateaus Local Minima vs. Number Clauses 100
Variable Problem Instances Guaranteed Solutions
make level 1 local minima expense making minima higher levels.
higher percentages local minima over-constrained problem instances indicate
local search may harder time solving problems.
analyzed median size local minima different levels HardSolvable3SAT class found results similar reported Uniform3-SAT class Figure
8. median minima size levels HardSolvable3-SAT class larger
Uniform3-SAT class under-constrained instances somewhat smaller
over-constrained instances. also found bench size distribution
HardSolvable3-SAT class matched Uniform3-SAT class. median bench size
somewhat smaller HardSolvable3-SAT instances Uniform3-SAT instances
number clauses problem instances grows. also found problems
guaranteed solutions higher proportion exits bench size
randomly generated problems. surprising problem class
similar previously investigated class since problem generation algorithms
similar.

4.3 Cluster Problem Instances
next present analysis plateaus cluster problem instances; generation
procedure Cluster3-SAT presented Appendix B. instances created generating 10 clusters 10 variables 34-40 clauses variables shared
clusters. clusters linked 20 connecting clauses linking
clause contains variables distinct clusters. total number clauses instances ranges 360 420. earlier experiments, guaranteed instance
268

fiWhen Gravity Fails: Local Search Topology

1
0.9

Proportion Plateaus Minima

0.8
0.7
0.6
0.5
0.4
0.3
0.2

Level 1 Plateaus
Level 2 Plateaus
Level 3 Plateaus
Level 4 Plateaus
Level 5 Plateaus

0.1
0
360

370

380

390
Number Clauses

400

410

420

Figure 19: Proportion Plateaus Local Minima vs. Number Clauses 100
Variable Cluster Problem Instances
solution using complete search. number clauses clusters, generated 1000 instances used GSAT find plateaus different levels. found
instances took considerably longer solve previous classes, similar
results reported Kask Dechter (1995) (CPU times shown paper).
Figure 19 shows proportion plateaus local minima graphed
total number clauses cluster problem instances 100 variables. proportion
plateaus local minima less dependent number clauses comparison
Figures 3 18. result tend proportionally fewer local minima overconstrained cluster problem instances comparison Uniform3-SAT instances. Figure 20
shows median local minima size plotted number clauses problem
instances. local minima problem instances larger minima
Uniform3-SAT instances analyzed factor 5-10, seen Figure 8.
unable collect data level 0 minima due excessive CPU requirements.
Figure 21 shows median bench sizes plotted number clauses
problem instances. compared median bench size Uniform3-SAT instances
Figure 11, see median size benches cluster problems dramatically
different. Cluster problem instances fewer clauses per cluster resulted enormous
benches, cases larger benches Uniform3-SAT instances factor 10.
increase size benches cluster problem instances randomly generated
instances accompanied decrease proportion exits bench size. Figure 22
shows mean proportion exits bench size versus total number clauses cluster
problem instances. comparison measure Uniform3-SAT instances, shown
Figure 14, see benches cluster problems fewer exits benches
Uniform3-SAT instances bench sizes 1 5. increase bench size coupled
269

fiFrank, Cheeseman, & Stutz

1500
Level 1 Minima
Level 2 Minima
Level 3 Minima
Level 4 Minima
Level 5 Minima

1250

Median Minima Size

1000

750

500

250

0
360

370

380

390
Number Clauses

400

410

420

Figure 20: Median Size Local Minima vs. Total Number Clauses 100 Variable
Cluster Problem Instances

10000
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

9000
8000

Median Bench Size

7000
6000
5000
4000
3000
2000
1000
0
360

370

380

390
Number Clauses

400

410

420

Figure 21: Size Benches vs. Total Number Clauses 100 Variable Cluster Problem
Instances

270

fiWhen Gravity Fails: Local Search Topology

decrease exits means local search likely much harder time
escaping benches cluster problems problem classes. counters
good news fewer minima problems.
0.8
Level 1 Benches
Level 2 Benches
Level 3 Benches
Level 4 Benches
Level 5 Benches

Mean Proportion Exits Bench Size

0.7

0.6

0.5

0.4

0.3

0.2
360

370

380

390
Number Clauses

400

410

420

Figure 22: Mean Proportion Exits Bench Size vs. Size Benches 100 Variable
Cluster Problem Instances

4.4 Summary

summary, see behavior plateaus unsatisfiable Uniform3-SAT problem
instances differs behavior satisfiable instances class. Unsatisfiable instances proportionally local minima, smaller minima smaller benches
satisfiable instances. Problems HardSolvable3-SAT class minima
Uniform3-SAT class, benches HardSolvable3-SAT class instances exits benches Uniform3-SAT instances. result expect
problems HardSolvable3-SAT class harder local search local search
algorithms frequently trapped local minima. Cluster problem instances
fewer local minima Uniform3-SAT instances, tend larger benches
fewer exits. expect problems harder local search
trouble escaping benches.

5. Previous Work

Numerous researchers studied local search techniques NP -Hard problems, addressing plateau behavior local minima escape them. However, research
largely centered analyzing performance algorithms less structure
problem. Hence, improvements algorithms credited mechanism without
271

fiFrank, Cheeseman, & Stutz

clear understanding properties problem make mechanism work.
section review previous analysis algorithms properties local
search spaces light new discoveries. discussion focuses GSAT
similar local search algorithms 3-SAT problem, discuss potential impact
work local search algorithms next section.

5.1 Analyzing Properties Problem Spaces

Clark et al. (1996) studied number solutions affected local search algorithm performance 3-SAT problems Constraint Satisfaction Problems. showed
number solutions number constraints play role determining
well GSAT works. work complements study adding understanding
local search affected problem instance structure. also add results
showing solutions tend occur disconnected subgraphs variable size.
Hampson Kibler (1995) studied plateaus affect local search's ability solve
3-SAT problem instances showed local search algorithm could modified
performing complete search plateau encountered. analyzed ratio
number exits benches versus size benches randomly generated problem
instances NC =4.25. found benches higher levels easier escape
average, consistent findings. However, failed mention high
variance proportion exits benches, also failed report existence local
minima. also report local search, augmented complete search plateaus,
generally performed worse original local search. believe large plateaus,
rare, contributed large CPU times reported paper.
Gent Walsh (1993a) investigated GSAT solved problem instances aggregating statistics GSAT performance. collected information number satisfied
clauses function GSAT's ip number, number best ips function ip
number, statistics averaged many runs problem instances. study
indicates GSAT satisfies average 99% clauses 2N ips instances
NC = 4:3. works 425 clauses instances 100 variables. evidence local minima hard-to-escape benches level 5 (i.e., 425 satisfied
clauses) consistent results. Gent Walsh also report number
ips GSAT spends benches escaping highly variable second half
search, number satisfied clauses high (Gent & Walsh, 1993a).
consistent finding benches either easy hard escape.

5.2 Revisiting Local Search Algorithms

GSAT encounters plateau randomly searches plateau. plateau
bench, GSAT escape; however may take long time bench
exits relative size, exits highly clustered one region bench.
GSAT encounters local minimum never escape; even made move
minimum state higher level, GSAT simply move back minimum,
every state minimum looks better every state leading away it.
point GSAT escape local minimum size 1 forced make
move. However, either GSAT return immediately minimum another
272

fiWhen Gravity Fails: Local Search Topology

adjacent neighbor; found minima size 1 since GSAT doesn't
exhibit cycling behavior minor consideration.
HSAT (Gent & Walsh, 1993b) augments GSAT heuristic designed break ties.
HSAT several ips equally good terms number satisfied clauses,
ips variable ipped longest ago. HSAT explore benches effectively
GSAT ensuring variables ipped \fairly"; long HSAT remains
bench ip variable keeps HSAT bench variables
ipped. Therefore, HSAT's improved performance may due ability escape
benches faster GSAT. However, HSAT still unable escape local minima.
Tabu search (Glover, 1989; Mazure, Sais, & Gregoire, 1997) augments local search
fixed length list previously made moves. algorithm allowed reverse move
tabu list. Local search augmented tabu lists may escape local minima.
memory structure either explicitly implicitly store states plateau
force local search make moves away part space. However, due
nature tabu list, possible local search one variants ignore
move reduces objective function simply Tabu list.
Tabu search frequently stores moves, states. result, different tabu search
implementations allow moves states fewer unsatisfied clauses ever detected
date, even required move tabu list, thus avoid problem.
result tabu search missing exits benches; whether results poor performance
unknown.
GSAT random walk (Gent & Walsh, 1995) ips randomly selected variable
probability p uses standard criteria select ips probability 1 , p. feature
allow GSAT escape either local minima benches, guarantee
next move simply bring GSAT back minima escaped
happen multiple, equivalently good moves available. Gent Walsh (1993a)
report that, number unsatisfied clauses small, number available
moves leading reduction level GSAT tends 1. However, effectiveness
random walk suggests random ip move GSAT place
proceed solution. Also, p large, two random walk steps follow
succession, improving chances escaping local minima. fact variant
results substantial improvements even used modifications GSAT
tie-breaking heuristics (Gent & Walsh, 1995) complements discovery Section 3
local minima tend shallow; random walk may effectively promote escape
local minima parts search space.
WalkSAT (Kautz & Selman, 1996) examine possible neighbors moving. Instead, WalkSAT randomly selects unsatisfied clause investigates states
reachable ipping variables selected clause. result neighborhood examined changes ip ip, reverse move may next neighborhood
examined. WalkSAT performs much search blind features uncovered.
WalkSAT escape local minima simply choosing neighborhood containing moves
back onto minima, may take series worse moves escape bench many
exits simply neighborhood contain them.
Simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) examines single neighbor current assignment. Moves leading improvements objective function
273

fiFrank, Cheeseman, & Stutz

always accepted, moves worsen objective function accepted probabilistically; probability based much worse move long search
progressed. Like WalkSAT, simulated annealing conducts much search blind
plateau features. Simulated annealing make backwards move bench minimum
even neighboring state results forward move; help escape minima
large benches, may sub-optimal strategy early search.

6. Next Generation Local Search Algorithms
identified analyzed number features local search topology may
uence success local search. results used improve local search
algorithms? One contribution study identify features local search space
worth investigating beginning construction local search algorithm
solve new problem. rapid exploration properties benches local minima
undertaken determine local search tactics likely work best
search problem class. instance, examination might reveal one problem
local minima prevalent uniformly small, indicating explicit local minima
detection avoidance likely effective tactic. Also, possible use results
Figure 3 determine adaptive schedule resetting probability
random walk optimizing size tabu list, done Mazure et. al. (1997).
also possible new classes local search algorithms could learn tactics work best
manner similar MultiTac (Minton, 1996). study provides first step towards
identifying features tracked self-modifying local search algorithms.
local search algorithm starts exhibiting plateau behavior, may small
minima, large minima, bench many exits, bench exits. (We ignore
case small bench, since hard escape cases.) problem
identify case search process stuck in, choose proper tactic
handle it. Standard tactics include continuing search normal, invoking special
detection procedure, randomly ipping one variable random walk, randomly ipping
small number variables Jump-SAT (Gent & Walsh, 1995) randomly generating
new values variables randomly restarting.
Small minima detected easily using algorithm Breadth-First Search,
done Hampson Kibler (1995). local search algorithm detected
escaped local minima, desirable prevent revisiting minima
escaped. Local search could proceed \filling in" local minima found
order prevent revisiting them. approximately tabu search works,
schemes used well. small size local minima indicates
memory requirements scheme small long small numbers minima
encountered. algorithm using mechanism could explore numerous local
minima close together solution space without restarting.
Large benches minima dicult recognize escape. question
becomes one determining utility continuing search versus changing tactics.
studies done provide algorithm designers information required implement
utility computation local search algorithm intelligently choose among
tactics. instance, knowing problem instance cluster problem indicative
274

fiWhen Gravity Fails: Local Search Topology

large benches exits likely inhibit local search local minima.
Hence explicit local minima detection good strategy problem class; jumping
random restart might better strategy.
point many enhancements like proposed
place local search algorithms solve 3-SAT problems, enhancements
applied problem classes Graph k-Coloring. expect extensions
successful improving performance local search algorithms solve problems.
One way approach new problems spend time gathering information topology
search space, done paper. second option, mentioned
above, use knowledge local search topology learn best tactics
solving instances. Detailed information appearance local minima, distribution
local minima size, bench size, prevalence exits benches used
construct good local search procedures explicitly take factors account.

7. Conclusions Future Work
presented analysis important properties plateau structures local search
spaces used local search algorithm designers construct better local search
algorithms. defined set topological structures local search spaces shown
affect local search. provided conclusive evidence existence local
minima search spaces, shown become prevalent number
unsatisfied clauses becomes close 0. also shown plateau behavior local
search caused local minima benches. results show local minima
benches vary widely size; often small, large local minima
benches may defy detection avoidance local search algorithms. also show
characteristics structures change different problem classes. analysis
made possible interpret previous work improving local search terms
search space structure, illuminating importance escaping benches early search
detecting local minima later search.
made suggestions previous section might used create new
versions local search better current crop algorithms. obvious
next step implement algorithms analyze performance, especially
comparison existing algorithms already attempt escape plateaus.
barely begun analyzing topology plateaus. empirical
evidence local minima low level (i.e., near 0) escaped unsatisfying
one additional clause, may true structured problem classes.
evidence benches may many exits always imply easy escape;
highly clustered exits may make benches hard escape. analysis topology
plateaus variety problem instances lead concrete results
uence local search algorithm development.
clear nature plateaus highly dependent problem class
tested. Extending form analysis problem classes might reveal differences
plateau structure motivate substantially different GSAT variants. Furthermore,
plateaus Graph Coloring Problem Traveling Salesperson Problem may manifest
different ways 3-SAT, local search algorithms
275

fiFrank, Cheeseman, & Stutz

problems explore plateaus differently. differences must studied order
determine best apply new understanding local search topology. also unclear
study extend problems Traveling Salesperson Problem
search space may much \smoother."
collected large amount data local search spaces,
much success modeling features defined. possible compute
probability individual state search space local minima bench
exits, dicult compute expected size bench minimum without
making horrendous independence assumptions. work modeling may result
better understanding local search topology.
mentioned Section 2, possible alter definition benches specifically
exclude contours type bench. rationale contours provide impediment
greedy local search, little impediment semi-greedy variations. One
possibility change definition plateau include states without neighbors
higher lower level. several predictable effects change. First,
know reported benches pure contour regions. would eliminated
consideration reporting proportions plateaus benches. Second, size
benches would exclude states, expect find smaller benches
exclusive bench definition. Third, measurements mean proportion states
benches exits would also change, excluding contours reduces mean.
Fourth, states provide potential means linking bench regions would disjoint
exclusive definition. Thus possible use exclusive definition
cause dramatic reduction average bench size, accompanied increase bench
numbers. might even eliminate large size tails bench size distributions
observed using inclusive definition. would significantly alter conclusions
regarding benches impede local greedy search, recommendations regarding
deal benches. Exploring impact revised definitions
explanation plateau behavior worth investigating.
Finally, analysis topological structures geared towards analyzing local search
algorithms greedy objective functions based number unsatisfied constraints.
Many local search algorithm designers experimenting new objective functions
modified continuously throughout search, clause weighting schemes (Selman &
Kautz, 1993). Work type may lead innovations design objective
functions. Since plateau behavior rooted objective function used, analysis
suitable analyzing methods, may provide insight conduct
similar study self-modifying algorithms type.

Acknowledgements
gratefully acknowledge comments JAIR reviewers editors; also acknowledge comments Phil Rogaway Chip Martel, U.C. Davis.
276

fiWhen Gravity Fails: Local Search Topology

Appendix A. Sample Problem

section illustrates terms defined Section 2. Consider following 4
variable, 14 clause 3-SAT problem instance:
(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^
(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^
(A _ B _ C )^ (A _ B _ D)^ (A _ B _ D)^
(A _ C _ D)^ (A _ B _ D)^ (A _ B _ D)^
(A _ C _ D)^ (A _ C _ D)
duration section abbreviate assignments values variables
following way: 0 False, 1 True, hence string 0s 1s length 4 encodes
assignment variables ABCD order.
problem instance global minimum comprised single solution 1111.
single state 0000 local minimum size 1 level 1, i.e., one unsatisfied clause.
border local minimum consists states 1000,0100,0010,0001; states 0001
1000 level 3 two states level 2.
following states constitute bench level 1: 1001, 1101 1011. 1101 exit
since ipping C results 1111, solution. Similarly, 1011 also exit since ipping B
results solution. neighbors 1001 bench 0001 1000;
level three, 1001 exit.
State Comment
Level Unsatisfied Clauses
1111 Solution
0
0000 Local Minimum
1
(A _ B _ C )
0010 Border Minimum 2
(A _ B _ C ); (A _ C _ D)
0100 Border Minimum 2
(A _ B _ C ); (A _ B _ D)
0001 Border Minimum 3
(A _ B _ C ); (A _ B _ D); (A _ C _ D)
1000 Border Minimum 2
(A _ B _ C ); (A _ B _ D)
1001 Bench
1
(A _ B _ C )
1011 Bench
1
(A _ B _ C )
1101 Bench
1
(A _ B _ C )
1111 Border Bench
0
0001 Border Bench
3
(A _ B _ C ); (A _ B _ D); (A _ C _ D)
1000 Border Bench
2
(A _ B _ C ); (A _ B _ D)
0010 Contour
2
(A _ B _ C ); (A _ C _ D)
1010 Contour
2
(A _ B _ D); (A _ B _ C )
0011 Contour
2
(A _ B _ C ); (A _ B _ D)
0000 Border Contour 1
(A _ B _ C )
1110 Border Contour 1
(A _ B _ D)
0111 Border Contour 1
(A _ B _ C )
Figure 23: Topological Structures Sample Problem Instance
states 0010, 1010 0011 form level 2 bench also contour. 0010
neighbor local minimum level 1, 1010 adjacent 1110 level 1,
0011 adjacent 0111 level 1.
277

fiFrank, Cheeseman, & Stutz

states 1000 1100 form bench level 3 contour. states
0110, 0001 also contours level 3 themselves. Since states unsatisfying
three clauses contours fact local maxima.
features summarized Figure 23.

Appendix B. Random Problem Generation
appendix contains pseudo-code random problem classes studied paper.
First present Uniform3-SAT class. Parameters generator C number
clauses N number variables. class procedure selects three literals
without replacement N assigns negative sign probability 21 .
procedure first presented Crawford Auton (1993) appears Figure 24.
procedure Uniform3-SAT(C ,N )
=;
(i=1 C )

Clause= 3 distinct variables selected uniformly 1..N
Negate variable Clause probability 12
= [ Clause

end
return
end

Figure 24: Random Problem Generation Algorithm Sketch
Next present Cluster3-SAT problem generator. parameters number
clauses C , number variables N per cluster, number clusters , number
linking clauses L. generator builds instances first creating independent subproblems C clauses N variables each, using Uniform3-SAT generation procedure
described above. variables sub-problems relabeled sub-problem
shares variables sub-problem; sub-problems linked generating
L linking clauses. linking clause contains variables three distinct sub-problems.
Kask Dechter generate problems using HardSolvable3-SAT procedure defined
described Kask Dechter (1995). procedure appears Figure 25.
Finally present HardSolvable3-SAT generator. parameters number
clauses C number variables N . Instances generated first selecting
assignment guaranteed solution. Clauses generated Uniform3-SAT,
however clause either zero two satisfied literals selected assignment
rejected. instance, clause (A _ B _ C ) would rejected assignment 110
since two satisfied literals assignment. preserves uniform balance
signs variable limit, resulting little information solution
present sign balances problem instance. method discussed Tsuji
Van Gelder (1993) algorithm given Figure 26.
278

fiWhen Gravity Fails: Local Search Topology

procedure Cluster3-SAT(C ,N ,M ,L)

# First generate sub-problems distinct variables
i=1
,i =Uniform3-SAT(,,C ,N )
Re-label literals ,i sub-problem shares variables
= [M
i=1 ,i
end

# Next generate linking clauses
= 1 L
Randomly select 3 distinct sub-problems ,a ; ,b ; ,c ,i
Clause= one variable randomly selected ,a ; ,b ; ,c
Negate variable Clause probability 21
= [ Clause

end
return
end

Figure 25: Cluster Problem Generation Algorithm Sketch

procedure HardSolvable3-SAT(C ,N )
=;

= randomly generated assignment variables
(i < C )

Clause= 3 distinct variables selected uniformly 1..N
Negate variable Clause probability 21
# Check make sure Clause allowed formula
(1 3 literals Clause true )
= [ Clause
i++

end
end
return
end

Figure 26: \Hard" Guaranteed Satisfiable Problem Generation Algorithm Sketch

279

fiFrank, Cheeseman, & Stutz

final note random problem instance generation order. None procedures
guarantees resulting problem instance contain variables. large
number variables small number clauses used parameters, resulting
problem may contain variables. However, ranges clauses variables used
work problem instances full range variables.

References
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
12th International Joint Conference Artificial Intelligence, 163{169.
Clark, D., Frank, J., Gent, I., MacIntyre, E., Tomov, N., & Walsh, T. (1996). Local
search number solutions. Proceedings 2d International Conference
Principles Practices Constraint Programming, 119{133.
Crawford, J., & Auton, L. (1993). Experimental results crossover point satisfiability problems. Proceedings 11th National Conference Artificial Intelligence,
21{27.
Gent, I., & Walsh, T. (1993a). empirical analysis search GSAT. Journal Artificial
Intelligence Research, 1, 47{59.
Gent, I., & Walsh, T. (1993b). Towards understanding hill-climbing procedures
SAT. Proceedings 11th National Conference Artificial Intelligence, 28{33.
Gent, I., & Walsh, T. (1995). Unsatisfied variables local search. Hallam, J. (Ed.),
Hybrid Problems, Hybrid Solutions, pp. 73{85. IOS Press.
Glover, F. (1989). Tabu search part I. ORSA Journal Computing, 1 (3), 190{206.
Hampson, D., & Kibler, S. (1995). Large plateaus plateau search boolean satisfiability problems: give searching start again. Johnson, D., & Trick,
M. (Eds.), DIMACS Series Discrete Mathematics Theoretical Computer Science: Cliques, Colors Satisfiability, Vol. 26, pp. 437{456. American Mathematical
Society.
Kask, K., & Dechter, R. (1995). GSAT local consistency. Proceedings 14th
International Conference Artificial Intelligence, 616{622.
Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic
stochastic search. Proceedings 13th National Conference Artificial Intelligence, 1194{1201.
Kirkpatrick, S., Gelatt, C., & Vecchi, M. (1983). Optimization simulated annealing.
Science, 220 (4598), 671{680.
Mazure, B., Sais, L., & Gregoire, E. (1997). Tabu search GSAT. Proceedings 14th
National Conference Artificial Intelligence, 281{286.
280

fiWhen Gravity Fails: Local Search Topology

Minton, S. (1996). Automatically configuring constraint satisfaction programs: case
study. Constraints, 1 (2), 7{43.
Selman, B., & Kautz, H. (1993). Domain independent versions GSAT: Solving large
structured satisfiability problems. 13th International Joint Conference Artificial
Intelligence, 290{295.
Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiability
problems. Proceedings 11th National Conference Artificial Intelligence, 440{
446.
Tsuji, Y., & Gelder, A. V. (1993). Incomplete thoughts incomplete satisfiability
procedures. Proceedings 2d DIMACS Challenge.

281

fiJournal Artificial Intelligence Research 7 (1997) 161-198

Submitted 5/97; published 11/97

Storing Indexing Plan Derivations
Explanation-based Analysis Retrieval Failures
Laurie H. Ihrig
Subbarao Kambhampati

Department Computer Science Engineering
Arizona State University
Tempe, AZ 85287-5406

ihrig@asu.edu
rao@asu.edu

Abstract

Case-Based Planning (CBP) provides way scaling domain-independent planning
solve large problems complex domains. replaces detailed lengthy search
solution retrieval adaptation previous planning experiences. general, CBP demonstrated improve performance generative (from-scratch)
planning. However, performance improvements provides dependent adequate
judgements problem similarity. particular, although CBP may substantially reduce planning effort overall, subject mis-retrieval problem. success CBP
depends retrieval errors relatively rare. paper describes design
implementation replay framework case-based planner dersnlp+ebl. dersnlp+ebl extends current CBP methodology incorporating explanation-based learning
techniques allow explain learn retrieval failures encounters.
techniques used refine judgements case similarity response feedback
wrong decision made. failure analysis used building case
library, addition repairing cases. Large problems split stored
single goal subproblems. Multi-goal problems stored smaller cases fail
merged full solution. empirical evaluation approach demonstrates
advantage learning experienced retrieval failure.

1. Introduction
Case-Based Planning improves eciency plan generation taking advantage previous problem-solving experiences. shown effective method scaling
domain-independent planning solve large problems complex domains (Kambhampati & Hendler, 1992; Veloso, 1994). CBP involves storing information particular
planning episodes problems successfully solved. information may include
goals achieved, world state conditions found relevant
achievement, final plan decisions taken arriving
plan. Whenever new problem encountered, judgment made similarity
previous experiences. Similar cases reused extended search
solution new problem. example, previous plan may transformed
skeletal plan refined new solution (Friedland & Iwasaki, 1985;
Kambhampati & Hendler, 1992; Hanks & Weld, 1995). Multiple cases, corresponding
small subproblem, may combined extended solving single larger problem
(Redmond, 1990; Ram & Francis, 1996). Alternatively, plan derivations may replayed
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiIhrig & Kambhampati

provide guidance new search process (Veloso, 1994; Ihrig & Kambhampati, 1994a).
CBP improves problem-solving problems solved less time comparison
generative planning.
One challenging tasks CBP determining cases store
match cases new problem-solving context. complex domain, unlikely
problem seen once. Moreover, every problem solved
stored, library large cost associated retrieval may overshadow
gains provides (Koehler, 1994; Francis & Ram, 1995). Ultimately, would
like retain library minimum number cases new problems
solved ecient retrieval adaptation cases stored (Smyth &
Keane, 1995). However, complex domains, planner's theory problem similarity
incomplete (Barletta & Mark, 1988). information relevant
features new situation determine stored case applicable. Sometimes
new problem contain extra goals and/or changed initial state conditions.
changes may mean solution cannot found consistent earlier
planning decisions made stored episode. planner cannot predict ahead time
previous choices wrong current situation, experience retrieval
error.
paper, introduce dersnlp+ebl (DERivational Systematic NonLinear Planner
+ Explanation-Based Learning), CBP system like priar (Kambhampati & Hendler,
1992) spa (Hanks & Weld, 1995) based sound complete domain-independent
planner. dersnlp+ebl deals mis-retrieval problem allowing planner
learn planning failures may anticipate future errors. Failure explanations
automatically generated search process used extending case
new problem-solving situation. used building case library
addition repairing cases.
Although earlier systems chef (Hammond, 1990) exploited EBL techniques, use restricted reasoning correctness plans generated
case-based planner. contrast, dersnlp+ebl starts sound complete plan
synthesis strategy. emphasis improving performance base-level
planner guidance retrieved cases. guidance considered succeed
leads planner search path leading solution new problem.
retrieval error occurs planner directed wrong path search
solution, is, path lead solution. dersnlp+ebl extends current
CBP methodology EBL techniques employed automatic generation reasons retrieval failure. Analytical failures occur leaf nodes
search tree explained terms subsets con icting plan constraints. leaf
node failure explanations regressed failing search paths form reason
retrieval failure.
dersnlp+ebl builds indexes case library based failure analysis.
failure reason used construction new repairing case. example, retrieved
case fails due presence extra interacting goal covered retrieved
episodes, explanation failure formed identifies subset new input
goals negatively interacting. failure reason used construct new case
solves goals alone. failure analysis also employed refining
162

fiStoring Indexing Plan Derivations

Retriever

Library

Cases Problem

Planning
Problem

Storer

Plan Derivation
Case Failure Reason

Case-Based Planner
Replay/Extension[Recovery]

Problem
Solution

Domain Operators

Figure 1: schematic diagram illustrating approach dersnlp+ebl.
indexing case library censor retrieval failing case whenever
interacting goals present again, direct retriever new repairing case
avoids failure.
dersnlp+ebl's failure-based storage strategy limits size case library. Library
size reduced splitting problems single goal subproblems, storing separately. Large problems solved retrieval adaptation multiple
instances smaller cases. Multi-goal problems stored retrieved
cases fail merged extended full solution. describe empirical studies
demonstrate substantial improvements performance novel approach
multi-case adaptation.
remainder paper organized follows: Section 2 describes dersnlp+ebl learns case failure improve case retrieval. also reports
preliminary experiments testing learning component. Section 3 provides ecient techniques used store, retrieve adapt multiple cases. describes experiments test
dersnlp+ebl's method plan merging. Section 4 describes evaluation full dersnlp+ebl system solving large problems drawn complex domain. Section 5
relates work previous case-based planners, including chef prodigy/analogy.
Section 6 provides summary.

2. Learning Case Failure
stated earlier, dersnlp+ebl based complete correct domain-independent
planning strategy. Like priar (Kambhampati & Hendler, 1992) spa (Hanks & Weld,
1995), implemented partial-order planner. aspect differs statespace systems prodigy/analogy (Veloso & Carbonell, 1993a; Veloso, 1994)
paris (Bergmann & Wilke, 1995). Like prodigy/analogy, employs case adaptation
strategy, derivational replay stores planning experience form successful plan
derivations. Previous decisions made earlier planning episodes become instructions
guide search process solving new problem. Derivational replay includes
following elements, illustrated Figure 1 (Veloso, 1994; Veloso & Carbonell, 1993a):
facility within underlying planner generate trace derivation plan,
163

fiIhrig & Kambhampati

null
plan

skeletal
plan
e1

final
plan

X
e2 X e3 X
- - - - - - - - - - - - - - - - - - - -depth limit
X

Figure 2: Multiple derivation traces (each sequence decisions shown figure
rectangles) used guide new search process. figure, solution
could reached backtracking skeletal plan, lies
outside new plan derivation (shown filled circles).
indexing storage derivation trace library previous cases, retrieval
multiple cases preparation solving new problem, finally, replay mechanism
planner employs retrieved plan derivations sequence instructions
guide new search process.
dersnlp+ebl's methodology depends aspects common molgen
(Friedland & Iwasaki, 1985) priar (Kambhampati & Hendler, 1992). requires
eager case adaptation strategy, skeletal plan constructed contains
constraints added advice retrieved cases, constraints.
separate failure resulting previous guidance subsequent
planning effort. eager case adaptation, planning decisions encapsulated
retrieved cases greedily adopted decisions extended solve
extra goals covered. Multiple retrieved plan derivations replayed sequence
produce skeletal plan contains recommended plan constraints.
planner returns from-scratch planning previous decisions
retrieved cases visited. skeletal plan refined achieve
goals left open. Previous work demonstrated effectiveness approach
plan-space replay well advantage state-space replay (Ihrig & Kambhampati,
1994a, 1994b).
Eager case adaptation also described extension-first. skeletal plan
first extended search solution, and, extension fails, plan
backtracked over, discarding plan constraints added advice previous
episodes. general approach case adaptation therefore involves three distinct phases:
case replay, case extension, and, extension fails, recovery. search process
employed extending skeletal plan, planner constructs explanation
plan's failure becomes reason case retrieval failure. Explanations formed
analytical failures occur leaf nodes directly skeletal plan (See
Figure 2). analytical failure explained set inconsistent plan constraints.
failure explanations immediately regressed search paths encountered.
regressed explanations collected root tree form reason
164

fiStoring Indexing Plan Derivations

l1

l1

OB1

ld

ld

lp

lp

l2

OB2

l2

(b) New Problem Extra
Goal

(a) Previous Plan

Figure 3: (a) plan accomplish transport single package, ob1, destination
airport ld . (b) new problem contains extra goal involves additional
transport ld second package, ob2.
retrieval error. dersnlp+ebl detects retrieval error occurred ways
refining skeletal plan tried, planner forced backtrack
plan. point failure reason fully constructed. Performing skeletal plan
extension separate process prior recovery allows planner identify retrieval
error terms failure skeletal plan, construct reason failure.
reason communicated Storer used augmenting library
new repairing case.
Consider simple example illustrated Figure 3 taken Logistics
Transportation domain shown Figure 4. goal package ob1 located
destination location ld. package initially location l1 . plane located
lp used transport package. Figure 3a illustrates previous plan
contains steps determine plane's route destination airport well steps
accomplish loading package right place along route. Eagerly
replaying earlier step addition decisions new problem extra
package transport produces skeletal plan may readily extended include
loading unloading extra package long package lies along
route. However, new package old route, planner may able
solve extra goal without backtracking previous step addition decisions.
(See Figure 3b).
case failure reason shown Figure 5. gives conditions future
replay case result failure. conditions refer presence
new problem set, C , negatively interacting goals, well initial state
conditions, contained E . summary information content failure reason is:
extra package transport destination location, package
destination location, inside plane, located plane's
route.
165

fiIhrig & Kambhampati

action
precond
add
delete

(LOAD-TRUCK ?O ?T ?L)
(AT-OB ?O ?L)
(AT-TR ?T ?L)
(INSIDE-TR ?O ?T)
(AT-OB ?O ?L)

action
precond
add
delete

(LOAD-PLANE ?O ?P ?L)
(AT-OB ?O ?L)
(AT-PL ?P ?L)
(INSIDE-PL ?O ?P)
(AT-OB ?O ?L)

action
precond
add
delete

(UNLOAD-TRUCK ?O ?T ?L)
(INSIDE-TR ?O ?T)
(AT-TR ?T ?L)
(AT-OB ?O ?L)
(INSIDE-TR ?O ?T)

action
precond
add
delete

(UNLOAD-PLANE ?O ?P ?Li)
(INSIDE-PL ?O ?A)
(AT-PL ?P ?Li)
(AT-OB ?O ?Li)
(INSIDE-PL ?O ?A)

action
precond
add
delete
equals

(DRIVE-TRUCK ?T ?Li ?Lg)
(AT-TR ?T ?Li)
(SAME-CITY ?Li ?Lg)
(AT-TR ?T ?Lg)
(AT-TR ?T ?Li)
(NOT (?Li ?Lg))

action
precond
add
delete
equals

(FLY-PLANE ?P ?Li ?Lg)
(IS-A AIRPORT ?Lg)
(AT-PL ?P ?Li))
(AT-PL ?P ?Lg)
(AT-PL ?P ?Li)
(NOT (?Li ?Lg))

Figure 4: specification Logistics Transportation Domain adapted experiments
Subsequent backtracking skeletal plan, planner continues search,
go find solution full problem one exists. new solution achieves
negatively interacting goals identified failure reason. Moreover, since
goals represent subset problem goals, new derivation may used construct
case covering goals alone. dersnlp+ebl stores new case directly beneath
failing case censor retrieval. ensure whenever failure reason
holds (for example, whenever extra package plane's route),
retriever directed away failing case toward case repairs failure.
position describe detail dersnlp+ebl's eager derivation
replay strategy, well learns reasons underlying case failure.

2.1 Eager Derivation Replay

derivation trace contains sequence instructions representing choices lie
along derivation path leading root search tree final plan leaf
node. trace fitted context new search process validating choice
new context, replaying decision valid. order understand validation
process, must first describe decision steps planner takes arriving
solution planning problem. planning problem 3-tuple hI; G; Ai,
complete description initial state, G description goal state,
set operators strips representation (Fikes & Nilsson, 1971). ground operator
sequence said solution planning problem executed initial
state, resulting state world satisfies goal.
dersnlp+ebl refinement planner solves planning problem navigating
space potential solutions, represented partly constructed plan1 . Syntactically,
1. formal development refinement search semantics partial plans, refer reader
work Kambhampati, Knoblock, Yang (1995).

166

fiStoring Indexing Plan Derivations

Case Failure Explanation:
C = f h(AT-OB OB1 ld); tG i; h(AT-OB OB2 ld); tG g
E = f htI ; (:AT-OB OB2 ld)i; htI ; (:INSIDE-PL OB2 ?PL )i;
htI ; (:AT-OB OB2 l1)i; htI ; (:AT-OB OB2 lp)i g

Figure 5: Example case failure reason
plan space P seen set constraints (see below). Semantically, partial
plan shorthand notation set ground operator sequences consistent
constraints. latter called candidate set partial plan, denoted
hhPii. particular, partial plan represented 6-tuple, hS ; O; B; L; E ; Ci,
1. set actions (step names) plan, mapped onto
operator domain theory. contains two dummy steps: tI whose effects
initial state conditions, tG whose preconditions input goals, G.
2. B set codesignation (binding) non-codesignation (prohibited binding) constraints variables appearing preconditions post-conditions
operators represented plan steps, .
3. partial ordering relation , representing ordering constraints
steps .
4. L set causal links form hs; p; s0 s; s0 2 .
5. E contains step effects, represented hs; ei, 2 .
6. C set open conditions partial plan, tuple hp; si
p precondition step link supporting p L.
Planning consists starting null plan (denoted P;) , whose candidate set
corresponds possible ground operator sequences, successively refining plan
adding constraints solution reached. planning decision represents choice
resolve existing aw plan, either open condition (unachieved
goal) threat causal link. understand choices validated
replay process useful think planning decision operator acting
partly-constructed plan. possible choices available dersnlp+ebl shown
Figure 6.
Planning decisions preconditions based existence aw
current active plan effects alter constraints eliminate
aw. example, precondition establishment choice specified terms
existence unachieved subgoal. effect addition causal link achieves
open condition. precondition resolution decision threat one step
clobbering existing causal link. threat resolved adding step ordering
either promotes demotes clobberer relative causal link.
167

fiIhrig & Kambhampati

Type : ESTABLISHMENT
Kind : NEW STEP
Preconditions
:
hp0 ; s0 2 C
Effects
:
00 = [ fsg 0
O0 = [ fs g 0
B 0 = B [ unify(p;0 p )
L = L [ fhs; p;s ig
E 0= E [ effects
(s)
C = C , fhp0 ; s0 ig
[ preconditions(s)

Type : ESTABLISHMENT
Kind : NEW LINK
Preconditions
:
hp0 ; s0 2 C
Effects
:
O00 = [ fs s0 g 0
B 0 = B [ unify(p;0 p )
L0 = L [ fhs;p;
ig
C = C , fhp0 ; s0 ig

Type : RESOLUTION
Kind : PROMOTION
Preconditions
:
0
0

hs; p ; 2 L
ht; :p 2 E
ft sg; fs tg 62
Effects :
= [ ft sg
0

0

0

Type : RESOLUTION
Kind : DEMOTION
Preconditions
:
0
0

hs; p ; 2 L
ht; :p 2 E
ft sg; fs tg 62
Effects :
= [ fs tg
0

0

0

0

Figure 6: Planning decisions based active plan hS ; O; B; L; E ; Ci effects alter constraints produce new current active plan
hS 0 ; O0 ; B0 ; L0 ; E 0 ; C 0 i.
decision replayed, first compared current active plan determine whether precondition holds new context. Invalid decisions, whose
preconditions don't match, skipped. Establishment decisions ignored goals
achieve present open conditions current active plan. Threat resolutions skipped threat present. Previous choices justified
current situation used guidance direct new search process. Replaying valid
decision involves selecting match decision children current active
plan, making child next plan refinement.
dersnlp+ebl's eager derivation replay strategy replays applicable decisions
trace sequence. replay strategy contrasted
prodigy/analogy (Veloso, 1994) replay alternated from-scratch planning
extra goals covered case. eager derivation replay previous decision
eagerly adopted justified current context. Since invalid instructions
skipped, skeletal plan end result replay comparable product
fitting phase plan reuse (Kambhampati & Hendler, 1992; Hanks & Weld, 1995).
contrast plan reuse, derivation replay alter underlying planning strategy.
Replay merely provides search control, directing search node visit next.
means dersnlp+ebl inherits properties snlp, including soundness,
completeness, systematicity.
sample trace snlp's decision process shown Figure 7. trace corresponds
simple problem logistics transportation domain (Veloso, 1994) adapted
snlp Figure 4. problem contains goal getting single package, ob1,
designated airport, ld . derivation trace contains choices made along
path root search tree final plan leaf node. Instructions contain
description decision taken basis justification new context.

2.2 Eager Case Extension Recovery
decisions trace skipped replay known
priori unjustified. guarantee skeletal plan left
168

fiStoring Indexing Plan Derivations

Goal : (AT-OB OB1 ld )
Initial : ((IS-A AIRPORT ld ) (IS-A AIRPORT li ))
(IS-A AIRPORT lp ) (AT-PL PL1 lp )
(AT-OB OB1 li ) ...
Name : G1
Name : G7
Type : START-NODE
Type : ESTABLISHMENT
Name : G2
Kind : NEW LINK
Type : ESTABLISHMENT
New Link: (0 (IS-A AIRPORT ld ) 2)
Kind : NEW STEP
Open Cond: ((IS-A AIRPORT ld ) 2)
New Step: (UNLOAD-PL OB1 ?P1 ld )
Name : G8
New Link: (1 (AT-OB OB1 ld ) GOAL)
Type : ESTABLISHMENT
Open Cond: ((AT-OB OB1 ld ) GOAL)
Kind : NEW STEP
Name : G3
New Step: (LOAD-PL OB1 PL1 ?A4)
Type : ESTABLISHMENT
New Link: (4 (INSIDE-PL OB1 PL1) 1)
Kind : NEW STEP
Open Cond: ((INSIDE-PL OB1 PL1) 1)
New Step: (FLY-PL ?P1 ?A2 ld )
Name : G9
New Link: (2 (AT-PL ?P1 ld ) 1)
Type : ESTABLISHMENT
Open Cond: ((AT-PL ?P1 ld ) 1)
Kind : NEW LINK
Name : G4
New Link: (3 (AT-PL PL1 li ) 4)
Type : ESTABLISHMENT
Open Cond: ((AT-PL PL1 ?A4) 4)
Kind : NEW STEP
Name : G10
New Step: (FLY-PL ?P1 ?A3 ?A2)
Type : RESOLUTION
New Link: (3 (AT-PL ?P1 ?A2) 2)
Kind : PROMOTION
Open Cond: ((AT-PL ?P1 ?A2) 2)
Unsafe-link : ((3 (AT-PL PL1 li ) 4)
Name : G5
Effect : 2 :(AT-PL PL1 li ))
Type : ESTABLISHMENT
Name : G11
Kind : NEW LINK
Type : ESTABLISHMENT
New Link: (0 (AT-PL PL1 lp ) 3)
Kind : NEW LINK
Open Cond: ((AT-PL ?P1 ?A3) 3)
New Link: (0 (AT-OB OB1 li ) 4)
Name : G6
Open Cond: ((AT-OB OB1 li ) 4)
Type : ESTABLISHMENT
Key Abbreviations:
Kind : NEW LINK
PL = PLANE
New Link: (0 (IS-A AIRPORT li ) 3)
OB = OBJECT
Open Cond: ((IS-A AIRPORT ?A2) 3)
Final Plan: (FLY-PL PL1 lp li ) Created 3
(LOAD-PL OB1 PL1 li ) Created 4
(FLY-PL PL1 li ld ) Created 2
(UNLOAD-PL OB1 PL1 ld ) Created 1
Ordering Steps: ((4 < 2) (3 < 4) (4 < 1) (3 < 2) (2 < 1))

Figure 7: Example solution trace dersnlp+ebl

169

fiIhrig & Kambhampati

2 DmS 1 :
(Affi precond : fIi; Pff g add : fgig delete : fIj jj < ig)
(Afii precond : fIi Pfi g add : fgig delete : fIj jj < ig)
(Aff precond : fg add : fgff g delete : fPfi g [ fgij8ig)

Figure 8: specification Barrett Weld's Transformed Dm 1Domain
ultimately refined solution current problem. Without actually completing
search way predicting whether constraints left skeletal
plan consistent complete solution. Whenever skeletal plan complete
(whenever extra goals unsatisfied initial state conditions) planner must
undergo planning effort extend plan possibility effort
may fail, necessitating recovery phase.
dersnlp+ebl, skeletal plan extended first, prior recovery. plan
backtracked search process fails refine full solution new
problem. strategy requires depth limit placed search tree2 . Otherwise
skeletal plan extension may continue indefinitely, planning algorithm becomes incomplete. eager extension strategy not, however, linked particular search method.
example, may used best-first, depth-first iterative deepening search.
different search methods used exploration subtree skeletal plan,
prior backtracking plan. skeletal plan found fail, recovery
phase initiated merely involves exploring siblings replayed path. Like
extension, recovery linked particular search strategy.

2.3 Analyzing Failure Case Extension

order skeletal plan successfully extended achieve conditions left open,
sequence decisions adopted guidance previous trace must
concatenated choices arrive solution. occur, replayed
path must decision-sequencable respect new problem, defined
follows:

Definition 1 (Decision-Sequencable Search Path) search path contains sequence decisions decision-sequencable respect new problem, hI 0 ; G0 ; Ai ,
exist two decision sequences E E 0 E E 0 (where \"
decision sequencing operator) produce plan correct hI 0 ; G0 ; Ai.
One primary reasons replayed path may decision sequencable goal
interactions occur input goals new problem. particular, extra
goals achieved case may interact covered, making retrieved
case inapplicable. long recognized relative diculty problem-solving
linked level interaction various input goals problem (Korf,
1987; Joslin & Roach, 1990; Barrett & Weld, 1994; Veloso & Blythe, 1994; Kambhampati,
2. practice, limit actually bound placed number steps contained plan.

170

fiStoring Indexing Plan Derivations

Ihrig, & Srivastava, 1996a). Goal interaction formalized Korf (1987) terms
problem search space. Barrett Weld (1994) extend Korf's analysis plan
space. plan-space planner, order goals achieved crucial.
Goals laboriously serializable state-space planner (in exist goal
orderings goals may solved sequence) may trivially serializable
plan-space planner (meaning goals solved order).
However, goals always trivially serializable plan-space planner (Veloso &
Blythe, 1994). example, consider 2Dm 1 domain (Barrett & Weld, 1994) shown
Figure 8. Notice gff one set problem goals, true initially,
goal, gi , present set must achieved operator Affi,
Afii . means time case replayed previously solved goal, gi ,
action Afii , gff extra goal covered case, replay fail.
CBP, however, much concerned general properties
domain, properties particular search paths stored
case library. required input goals every problem trivially serializable
CBP beneficial planning performance. were, would
domains CBP effective. Trivial serializability requirement since
necessary every plan every subset input goals consistent
solution full problem. particular plans retrieved
library concerned with.
Even goals problem trivially serializable, replay may decision
sequencable, depending cases actually retrieved library.
2 Dm 1 domain, single-goal cases retrieved solve gi action Afii ,
decision-sequencable new multi-goal problem contains
goal gff . However stored cases solved Affi , replay cases
sequencable. fact, aim dersnlp+ebl's learning component achieve
indexing within case library new problems encountered
planner may solved sequenced replay cases retrieved library.
next section describes dersnlp+ebl able work towards objective
learning component learns replay failures.

2.4 Constructing Reasons Retrieval Failure
dersnlp+ebl constructs explanations retrieval failures use explanationbased learning techniques allow planner explain failures individual plans
planner's search space. leaf node plan represents analytical failure
contains set inconsistent constraints prevent plan refined
solution. analytical failure explained terms constraints (Kambhampati, Katukam, & Qu, 1996b). Leaf node failure explanations identify minimal set
constraints plan together inconsistent. dersnlp+ebl forms explanations
analytical failures occur subtree directly skeletal plan.
regressed failing search paths collected root tree
form reason retrieval failure (See Figure 9a). regressed explanation terms
new problem specification. contains subset interacting goals, well initial
state conditions relevant goals.

171

fiIhrig & Kambhampati

null
plan

e11

< (AT-OB OB2 ld), tG >
<tI , (AT-OB OB2 ld ) >

e1f-1
df-1
e1f
df
e1

null
plan

< (AT-OB OB2 ld), tG >
<tI , (AT-OB OB2 ld) >

skeletal
plan

df-1
df

skeletal
plan

X

X
e2

X

e3

X

< tI , (AT-OB OB2 ld ), tG >
< tI , (AT-OB OB2 ld) >

(a) Regression Process

(b) Detailed Example

Figure 9: path failure explanation root tree computed e11 = d,1 1 (d,2 1
(d,f 1(e1 )) ).
Since plan failure explained subset constraints, failure explanations
represented manner plan itself. Recall dersnlp+ebl represents
plans 6-tuple, hS ; O; B; L; E ; Ci (See Section 2). explanation failure
occurring leaf node contains constraints contribute inconsistency.
inconsistencies appear new constraints added con ict existing
constraints. discussed Section 2, dersnlp+ebl makes two types decisions, establishment resolution. type decision may result plan failure. establishment
decision represents choice method achieving open condition, either
new/existing step, adding causal link initial state. attempt
made achieve condition linking initial state effect, condition
satisfied initial state, plan contains contradiction. explanation
failure constructed identifies two con icting constraints:

h;; ;; ;; fhtI ; p; sig; fhtI ; :pig; ;i

precondition resolution decision threat causal link. dersnlp+ebl
uses two methods resolving threat, promotion demotion, adds step
ordering plan. either decision adds ordering con icts existing
ordering, explanation failure identifies con ict:

h;; fs s0 ; s0 sg; ;; ;; ;; ;i

con icting constraints failure explanation regressed final
decision, results sorted according type form new regressed explanation.
process illustrated graphically Figure 9b. example, new link
initial state results failure. explanation, e1 is:
h;; ;; ;; fhtI ; (AT,OB OB 2 ld ); tG ig; fhtI ; :(AT,OB OB 2 ld)ig; ;i
172

fiStoring Indexing Plan Derivations

e1 regressed final decision, df , obtain new explanation, initial
state effect regresses itself. However, since link explanation added
decision, df , link regresses open condition precondition adding
link. new explanation, ef1 , therefore

h;; ;; ;; ;; fhtI ; :(AT,OB OB 2 ld)ig; fh(AT,OB OB 2 ld ); tG igi

regression process continues failing path reaches root search
tree. paths subtree underneath skeletal plan failed,
failure reason root tree provides reason failure retrieved
cases. represents combined explanation path failures. case failure
reason contains aspects new problem responsible failure.
may contain subset problem goals. Also, initial state effects
present leaf node explanation, also present reason case failure3 .

2.5 Empirical Evaluation Utility Case Failure Analysis

preliminary study conducted aim demonstrating advantage storing
retrieving cases basis experienced retrieval failure. Domains chosen
randomly generated problems contained negatively interacting goals, planning
performance tested dersnlp+ebl solving multi-goal problems scratch
replay single cases covering smaller subset goals. Replay performance
tested without case failure information.
2.5.1 Domains

Experiments run problems drawn two domains. first artificial
domain, 2 DmS 1, originally described (Barrett & Weld, 1994) shown Figure 8.
Testing done problems randomly generated domain
restriction always contain goal gff . Logistics Transportation domain
(Veloso, 1994) adopted second set experiments. Eight packages one
airplane randomly distributed four cities. Problem goals represented task
getting one packages single destination airport4. fly operator augmented delete condition prevented planes visiting airport
once. meant replay failed extra package transported
previous route taken plane.
2.5.2 Retrieval Strategy

Cases initially retrieved basis static similarity metric takes
account goals covered case well relevant initial state
conditions (Kambhampati, 1994; Veloso, 1994). Prior studies show reasonably
3. dersnlp+ebl's EBL component explains analytical failures. Depth limit failures ignored.
means failure explanations formed sound case depth limit failure,
retriever may reject case applicable. Rejecting applicable case may lead
storage duplicate cases larger library size. However, empirical work shown
practical importance reasons outlined Section 3.2.2.
4. comprehensive evaluation unbiased problem set see Section 4.

173

fiIhrig & Kambhampati

effective metric. learning mode, cases also retrieved basis. However,
mode, failure reasons attached case used censor retrieval.
time case retrieved learning mode, failure conditions also
tested. failure reason satisfied new problem specification, retrieval
mechanism returned case replay. If, hand, failure reason found
true new problem context, case repaired failure retrieved.
Following retrieval, problem solved replay retrieved case well
planning scratch.
2.5.3 Experimental Setup

experiment consisted three phases, phase corresponding increase
problem size. Goals randomly selected problem, and, case
logistics domain, initial state also randomly varied problems. initial
training session took place start phase n, 30 n-goal problems solved
scratch, derivation trace stored library. Following training,
testing session consisted generating problems manner additional
goal. time new (n +1) goal problem tried, attempt made retrieve
similar n-goal problem library. testing session, case
similar new problem found previously failed, problem
solved learning, static from-scratch modes, became part 30-problem
set. method, able evaluate improvements provided failurebased retrieval retrieval static metric alone ineffective, failure
conditions available.
2.5.4 Experimental Results

results experiments shown Tables 1 2. table entry represents
cumulative results obtained sequence 30 problems corresponding one phase
experiment. first row Table 1 shows percentage problems correctly solved
within time limit (550 seconds). average solution length shown parentheses
logistics domain (solution length omitted 2 DmS 1 since problems
generated within phase solution length). second third rows
Table 1 contain respectively total number search nodes visited 30 test
problems, total CPU time (including case retrieval time).
results also summarized Figure 10. dersnlp+ebl learning mode
able solve many multi-goal problems two modes
substantially less time. Case retrieval based case failure resulted performance
improvements increased problem size. Comparable improvements
found retrieval based static similarity metric alone.
surprising since cases retrieved experienced least one earlier failure.
meant testing done cases likelihood failing retrieval
based static metric.
Table 2 records three different measures ect effectiveness replay. first
percentage sequenced replay. Recall replay trace considered
sequenced skeletal plan refined reach solution new problem.
174

fiStoring Indexing Plan Derivations

2 DmS 1

Static

Scratch

Learning

Logistics
Static

Scratch

100%
90
1

100%
240
4

100%
300
2

100% (6.0)
1773
30

100% (6.0)
1773
34

100% (6.0)
2735
56

% Solved
nodes
time(sec)

100%
120
2

100%
810
15

100%
990
8

100% (8.2)
6924
146

100% (8.2)
13842
290

100% (8.2)
20677
402

% Solved
nodes
time(sec)

100%
150
3

100%
2340
41

100%
2533
21

100% (10.3)
290
32

100% (10.3)
38456
916

100% (10.3)
127237
2967

Phase

Learning

%Solved
nodes
time(sec)

(1) Two Goal

(2) Three Goal

(3) Four Goal

Table 1: Performance statistics 2 DmS 1 Logistics Transportation Domain (Average
solution length shown parentheses next %Solved logistics domain
only)

(a) 2Dm 1

(b) Logistics

Figure 10: Replay performance 2 DmS 1and Logistics Transportation domain.
175

fiIhrig & Kambhampati

2 DmS 1

Logistics
Learning
Static

Phase

Learning

Static

% Seq
% Der
% Rep

100%
60%
100%

0%
0%
0%

53%
48%
85%

53%
48%
85%

% Seq
% Der
% Rep

100%
70%
100%

0%
0%
0%

80%
63%
89%

47%
50%
72%

% Seq
% Der
% Rep

100%
94%
100%

0%
0%
0%

100%
79%
100%

70%
62%
81%

Two Goal

Three Goal

Four Goal

Table 2: Measures effectiveness replay.
results point greater eciency replay learning mode. 2 Dm 1 domain,
replay entirely sequenced mode. transportation domain, retrieval based
failure always result sequenced replay, often static
mode.
greater effectiveness replay learning mode also indicated two
measures contained subsequent two rows Table 2. respectively, percentage plan refinements final derivation path formed guidance
replay (% Der), percentage total number plans created replay remain final derivation path (% Rep). case-based planner learning
mode showed much greater improvements according measures, demonstrating relative effectiveness guiding retrieval learning component based
replay failures. results indicate dersnlp+ebl's integration CBP EBL
promising approach extra interacting goals hinder success replay.
Section 4 report thorough evaluation dersnlp+ebl's learning component. conducted purpose investigating learning case failure
benefit planner solving random problems complex domain. evaluation implemented full case-based planning system along novel case storage
adaptation strategies. next section, describe storage strategy
developed evaluation.

3. Improving Case Storage Adaptation
aim case-based planning eciently solve large problems complex domains.
complex domain means great variety problems encountered. problem size
(measured terms number goals, n) large, unlikely n-goal
problem seen before. therefore advantage able store cases
covering smaller subsets goals, retrieve adapt multiple cases solving single
large problem.
176

fiStoring Indexing Plan Derivations

implementing strategy, decisions made goal combinations store. previous work within state-space planning Veloso (1994) developed
approach reducing size library first transforming totally ordered plan
partially ordered graph, separating connected components graph, storing
subplans individually. Goals interact respective plans must
interleaved order form complete solution stored together single case.
replay based plan-space planner snlp, component subplan may
subdivided, since planner ability first piece plans together, later add step
orderings interleave subplans (Kambhampati & Chen, 1993; Ihrig & Kambhampati,
1994a). Replay smaller cases sequenced long individual subplans
may interleaved addition step orderings form full solution. plan-space
planner therefore greater capability reducing size problems stored
library, and, consequence, number cases stored.
dersnlp+ebl's storage strategy makes use plan-space planners' ability piece
small plans together, add step orderings interleave plans. earlier approaches, priar (Kambhampati & Hendler, 1992), prodigy/analogy (Veloso,
1994) caplan (Munoz-Avilla & Weberskirch, 1996), cases stored cover
smaller subsets original set input goals achieved successful problem-solving
episode. dersnlp+ebl differs earlier approaches division goal
subsets based structure final plan alone, sequence events
making problem-solving episode. new repairing case stored cases
retrieved library solving new problem fail extended new
solution. storer constructs new case based failure explanation obtained extension phase well new successful plan derivation obtained
recovery.
failure explanation identifies set negatively interacting goals responsible
failure. goals form subset input goals achieved new
solution. repairing case stored, new plan derivation stripped
decisions irrelevant achievement interacting goals. new case
covers negatively interacting goals.
Note define negative interaction based failure skeletal plan.
interaction occurs set input goals cannot solved refining skeletal plan,
causing planner backtrack plan. Moreover, cannot determine
whether two goals negatively interacting merely analyzing final solution.
include information planning failures encountered generating
solution. particular, final solution tell us whether additional goal
achieved extending replayed path, backtracking path. Approaches
case storage determine goal interaction final plan alone (Veloso, 1994;
Munoz-Avilla & Weberskirch, 1996) therefore ignore retrieval failures
encountered planning episode.
Retrieval failures provide important guidance library may improved
avoid similar failures. dersnlp+ebl, used dynamically improve storage
library addition new goal combinations. Multi-goal problems
stored retrieved cases corresponding single-goal subproblems fail merged
177

fiIhrig & Kambhampati

Case Failure Explanation:

C = fhgff; tG i; hg8 ; tG ig
E = fhtI ; i8 i; htI ; Pfi ig
Figure 11: Example case failure reason
extended new solution. Repairing cases constructed achieve negatively
interacting goals responsible identified failure explanation.

3.1 Example Negative Interaction
Figure 11 provides example explanation failure encountered solving
problem Barrett Weld's 2Dm 1 domain shown figure 8. problem contains
three goals, gff , g6 g8 , attempted replay case solves
two goals, gff g6 , second case, achieves g8 . latter,
goal achieved action Afi8 represents incorrect operator choice
input goals problem include goal gff .
failure explanation shown Figure 11 identifies subset interacting goals, made
g8 gff . Note interaction evident final plan shown Figure 12.
plan, three input goals problem achieved connected
component. base storage solely plan graph represented successful plan,
three input goals stored single case. Moreover, new problem
representing novel combination goals stored library, causing library
size increase exponentially problem size. example, suppose domain includes
goals, fgi j1 < < ng gff . number problems size three
number 3-goal subsets n + 1 goals. dersnlp+ebl's strategy storing cases
based explanations retrieval failure result maximum 2n + 1 cases stored.
goal fgi j1 < < ng appears two cases, one representing single-goal problem
one representing two goal problem also achieves gff .
Storing negatively interacting goals multi-goal problems may therefore result
substantial reduction size case library. also represents tradeoff,
replayed cases must extended from-scratch planning solve con icts
individual plans recommended separate cases. Moreover, complex domains,
may goals interact positively may solved common
steps (Ihrig & Kambhampati, 1996; Munoz-Avilla & Weberskirch, 1997). goals
stored separate cases, replay may result unnecessary redundancy plan.
dersnlp+ebl, positive interactions handled replay process itself,
merges subplans provided multiple cases. Section 3.3 describe
merging accomplished. next section provides detail case storage
strategy implemented empirical study.
178

fiStoring Indexing Plan Derivations

tI

1:

2:

3:

tG

Figure 12: Solution example problem.

3.2 Building Case Library
following deliberative strategy adopted building case library. new
problem contains n goals, first goal attempted, and, solved, case covering
goal alone stored library. Problem-solving continues increasing problem size
one goal time. example, problem attempted contained goal set,
G = hg1 ; g2 ; :::; gi solved decision sequence Di second decision
sequence, Di+1 , stored whenever Di cannot replayed extended achieve next
goal gi+1 . Whenever replayed derivation path fails, recovery phase successful
producing new solution, explanation case retrieval failure used identify
subset negatively interacting input goals, N = hgj :::gj +m i, responsible
failure. replayed path fails extended, backtracked reach solution
new problem, new successful derivation passed storer along
failure explanation. explanation used delete derivation decisions
relevant set negatively interacting goals, N . reduced derivation
stored library repairing case. Alternatively, whenever next goal
set solved simple extension previous decision sequence, case
stored includes goal.
storage strategy entails two important properties. (1) new case corresponds
either new single-goal problem multi-goal problem containing negatively interacting
goals. (2) plan derivations arising single problem-solving episode
different decision sequence stored library prefix another stored case.
case added library new problem solved extending
retrieved case. New cases stored previous decisions need
backtracked search new solution.
dersnlp+ebl's strategy restricting multi-goal cases goals
negatively interacting serves ameliorate mis-retrieval problem. experience
planner problem-solving, interactions discovered,
less likely planner backtrack replayed paths. aim
eventually library minimal number cases problems
encountered may achieved successfully merging multiple instances stored cases.
approach therefore retain cases based competence well performance
(Smyth & Keane, 1995).
3.2.1 Example dersnlp+ebl's Storage Strategy

example multi-goal problem stored, consider problem contained
Figure 13 three packages, ob1, ob2 ob3, transported
destination location, ld . Initially goal set contains goal transporting ob1 alone,
represented (at-ob ob1 ld ), successful derivation stored Case A.
second goal added set. Since problem attempted achieves first
179

fiIhrig & Kambhampati

OB1



OB3

B
B

ld

B
lp

OB2

l2

Figure 13: logistics transportation example illustrating multi-case storage. figure
shows two plans produced two stored derivations. Case achieves goal
single packages, ob1, transported destination airport, ld . Case
B achieves goal ob1 ob2 located airport.
goal decision sequence backtracked order solve
additional goal, second derivation, Case B , stored. new derivation solves
mutually interacting goals, (at-ob ob1 ld ) (at-ob ob2 ld ). Problem-solving
continues addition third goal. goal solved simple extension
previous decision sequence. case stored includes goal. means
two cases stored library: Case corresponding single-goal problem
Case B corresponding multi-goal problem containing two negatively interacting goals.
Multi-goal problems stored problem goals mutually interacting,
is, individual derivations cannot sequenced extended solve
full problem.
dersnlp+ebl's storage strategy, size library limited amount
interaction domain. example, negative interaction, single
goal cases stored. logistics transportation domain, potential
problem goals interact negatively. However, since also significant percentage
non-interacting goals, strategy reduces size library comparison one
multi-goal problems successfully solved stored. storage
strategy also represents tradeoff since effort must expended merging retrieved
cases full solution (See Section 3.3).
3.2.2 Indexing Basis Replay Failure

Multi-goal cases stored library censor retrieval corresponding
single-goal subproblems. library organization differs earlier work stores
cases common fashion single level, first indexing case goals,
success conditions relevant goals (Veloso, 1994; Munoz-Avilla &
Weberskirch, 1996). contrast, dersnlp+ebl indexes cases discrimination
net similar one depicted Figure 14. figure shows one fragment case
library includes cases solve single input goal. Individual planning
episodes achieve goal represented one level lower net. labeled
180

fiStoring Indexing Plan Derivations

G0
input goals:

initial conditions:

(AT-OB OB1 ld )
(AT-PL PL1 lp)

(AT-OB OB1 l1)

G1

G2

derivation 1
r1

failure reasons:

(AT-PL PL1 lq)

derivation 2
r2

G3

G4

derivation 3

derivation 4

Figure 14: Library fragment indexing stored cases solve single input goal, (at-ob
ob1 ld ).
relevant initial state conditions, otherwise known footprinted initial state (Veloso,
1994). Together, goal initial state conditions make static success conditions
cases first retrieved. one cases retrieved replay replay
fails, derivation corresponding extra interacting goals added library
indexed directly failing case. future retrievals case, failure
conditions checked see whether extra goals responsible failure present
conditions. so, retrieval process returns repairing case
achieves con icting goals. case failure reason thus used direct retrieval away
case repeat known failure, towards case avoids it.
One might question hierarchical organization instances failures due
interacting goals alone. store cases single level first indexing
case goals, conditions relevant goals? answer
lies need censor cases failure conditions satisfied. type error
found retrieving multiple cases. example, consider new problem
contains three goals, g1 , g2 g3 . Suppose goal g2 negatively interacts
g1 g3 . case retrieved library achieves g1 g2 ,
one goal, g3 , left open. However, case retrieved solves g3 alone,
fail presence g2 . type retrieval error handled prioritizing
cases. repairing case stored subclass case failed. Failing cases
annotated failure reason directs retriever case avoids
failure.
Prioritizing cases basis negatively interacting goals alone sucient
capture retrieval failures may encountered. cases retrieved
basis partial match relevant initial state conditions, retrieval errors may
occur unmatched conditions (Veloso, 1994). example, failure might
occur logistics transportation example extra package plane's
route, similar failure occur package moved plane's route. strategy
adopted deal types failure information annotate case
181

fiIhrig & Kambhampati

OB1

OB3



l1
ld

B B
B

B

B
lp

OB2

B

l2

Figure 15: logistics transportation example illustrating multi-case retrieval.
failure reason (whether extra goal unmatched initial state condition)
use failure reasons prioritize cases. EBL techniques employed
construction failure explanations may used types failures.
dersnlp+ebl's method storing multi-goal cases goals negatively interacting limits size case library. aspects dersnlp+ebl's storage strategy
also serve lower library size. planner always uses current library solving new
problems. New derivations stored applicable case,
retrieved cases fail. strategy avoids storage duplicate cases, may
entirely effective since soundness failure explanations guaranteed. failure
explanations sound, pointers repairing cases may eventually lead duplicate
case, causing library continue grow indefinitely. However, easily checked
putting depth limit number repairing cases discrimination net. Also,
failures due interacting goals result unchecked growth library
since number interacting goals limited maximum problem size.
3.2.3 Detailed Example Case Retrieval

example case retrieval illustrated Figure 15. figure contains three subplans
corresponding two separate cases stored library. Case achieves goal
single package, ob1, located destination ld . Case B achieves goal
ob1 ob2 located ld.
Assume new problem attempted replay contains three
goals, (at-ob ob1 ld), (at-ob ob2 ld ), (at-ob ob3 ld ). second goal negatively
interacts goals. retriever first attempt find case
solves first goal alone. Case solves goal. However, case annotated
failure reason satisfied new problem situation, therefore censored
favor repairing case, Case B . retriever returns Case B ,
one open goal covered, is, (at-ob ob3 ld ). seek case solves
goal alone, find Case A. However, A's failure reason satisfied
new problem state rejected favor second copy B (which
call Case B 0), solves problem transporting ob3 ob2.
two instances Case B retrieved solve three goal problem,
Case B Case B 0 . Together cover new problem goals. dersnlp+ebl replays
182

fiStoring Indexing Plan Derivations

Figure 16: New linking opportunities indicated increase number siblings
step addition decision.
copies B sequence obtain solution full problem, thereby merging
respective subplans. Notice, however, union plans contain redundant
steps. example, plans plane location l1 . Section 3.3 describes
dersnlp+ebl deals positive goal interactions.

3.3 Multi-case Merging

say two plans mergeable respect problem, hI 0; G0 ; Ai, exists
solution problem contains combined constraints.

Definition 2 (Mergeability) plan P1 achieving goal g1 mergeable plan P2
goal g2 respect problem, hI 0 ; G0 ; Ai , plan P 0 correct
hI 0; G0 ; Ai hhP 0ii hhP1ii\hhP2 ii. (Thus syntactically, P 0 contains constraints
P1 P2 ).

Multi-case replay accomplishes plan merging, may result lower quality plans
care taken avoid redundant step additions (Ihrig & Kambhampati, 1996; MunozAvilla & Weberskirch, 1997). occur goals covered separate cases positively
interact may solved common steps. Replaying case sequence
results unneeded steps plan5 .
multi-case replay, open condition justification adding new step,
steps may added already exist plan due earlier replay another
case. first retrieved derivation replayed, none replayed step additions
result redundancy. However, subsequent goals solved replay
additional cases, step additions may unnecessary opportunities
linking open conditions achieve earlier established steps. planner
way determining priori steps may represented single step
plan6 .
dersnlp+ebl's replay framework handles redundant step additions skipping
step addition establishments whenever open condition may achieved new link.
thus strengthens increases justification replaying step addition decisions
open condition longer basis validating decision. justification replay strengthened add condition new linking opportunities
5. analogous decrease plan quality occurs state-space plan reuse, sequencing macro-operators
results state loops (Minton, 1990a).
6. Consider, example, domain plane may transport two packages one trip, not,
depending capacity.

183

fiIhrig & Kambhampati

dersnlp+ebl

dersnlp+ebl-ij

87%(6) 67%(5)
2465
5796

87%(7) 67% (5)
2198
5810

replay
%Solved
time(sec)

scratch

replay

scratch

Table 3: Percentage problems solved, total CPU time seconds 30 problems
problems Logistics Transportation Domain. Average solution length
shown parentheses next %Solved.
present. may detected increase number siblings prescribed
step addition choice (See Figure 16). siblings stored step addition decision
recorded annotations derivation trace. new links available
contained within siblings, step addition decision skipped. replay,
alternative new links explored normal course plan refinement.
means step may eventually added new links fail.
Increasing justification step addition decisions improves quality plans
terms number steps contain. example, Case B B 0 would normally
produce subplans shown Figure 15. cases replayed sequence
solving single problem, plans merged plane moves city
once. Plan merging increasing justification replay accomplishes
retracting redundant action sequences, may cause planning failure. thus
deals action-merging interactions defined (Yang, Nau, & Hendler, 1992).
next section describe empirical study testing effectiveness merging
strategy.
3.3.1 Empirical Test dersnlp+ebl's Plan Merging Strategy

preliminary study conducted test effectiveness dersnlp+ebl's method
plan merging replay. experiment compared dersnlp+ebl
without increasing justification replay. experimental setup consisted training
dersnlp+ebl set 20 randomly generated 4-goal training problems, testing
different set 30 4-goal test problems. initial state problem contained 12
locations (6 post oces 6 airports) 12 transport devices (6 planes 6 trucks).
training phase, planner solved problems stored successful plan derivations
case library. testing phase, planner retrieved multiple stored plan
derivations used guidance solving test problems. dersnlp+ebl
tested 30 problems replay from-scratch modes. Replay either
(dersnlp+ebl) without (dersnlp+ebl-ij) increased justification. results
shown Table 3.
Although overall performance poorer, quality plans terms number
steps improved dersnlp+ebl's strategy increasing justification step addition. result suggests dersnlp+ebl's method plan merging serves reduce
184

fiStoring Indexing Plan Derivations

redundancy plans produced multi-case replay. Recently, Munoz-Avilla
Weberskirch (1997) tested non-redundant merging strategy process planning domain found similar improvements plan size. next section describes
evaluation full dersnlp+ebl system.

4. Experimental Evaluation Complete System

experiments reported section tested full dersnlp+ebl system using
dynamic multi-case storage retrieval strategy described Section 3. aim
evaluate replay system complex domain. hypothesis performance
would improve problem solving experience negative interactions discovered
stored. addition, predicted dersnlp+ebl's method storage would result
low library size low retrieval costs.
Logistics Transportation domain (Veloso, 1994) become somewhat benchmark CBP literature. scaled version therefore chosen purpose.
tested large multi-goal problems drawn domain shown Figure 4 scaled
first 6 15 cities. size domain unusual current literature.

4.1 Experimental Setup

experiment run phases, phase corresponding increase problem
size. Thirty test problems size randomly generated. Since possible
obtain truly random distribution within nonartificial domain, following strategy
adopted problem generation. First, initial state constructed fixing
number objects type contained domain description. example, first
experiment, six cities (12 locations within cities), six planes, six trucks.
initial state problem constructed first including filter conditions (nonachievable conditions). defined layout cities. example, condition (is-a
airport ap1) identified ap1 airport. condition (same-city ap1 po1) indicated
ap1 po1 located city. Second, achievable (non-filter) conditions present add clauses domain operators varied
problem choosing object constants randomly available restriction
two initial state conditions inconsistent. example, plane package
assigned single randomly-chosen location. Goals chosen among
achievable conditions manner. Although attempt made create interacting goals, goal interaction common multi-goal problems.
limit imposed number steps plan. meant multi-goal problems often could solved concatenating subplans individual subgoals.
instances, planner could take advantage linking opportunities achieve multiple
goals common steps. also meant often planner backtrack
derivation one goal order solve additional goal.
first experiment used 6-city domain run 6 phases. size
test problems (which ranged 1 6 goals) increased phase. Prior
phase n experiment, case library emptied planner retrained
randomly generated problems size n. Training problems solved attempting
single-goal subproblems scratch, storing trace derivation solution
185

fiIhrig & Kambhampati

Phase

0

20

%Solved
time(sec)

100%(3)
15

% Solved
time(sec)

Logistics (Best-first

CPU limit: 500sec)
80
100

40

60

100%(3)
14(.1)

100%(3)
13(.1)

100%(3)
4(.0)

100%(3)
5(.10)

100%(3)
3(.13)

100%(3)
3(.13)

90%(4)
1548

93%(4)
1069(.2)

100%(5)
22(1.0)

100%(5)
23(.2)

100%(5)
25(.28)

100%(5)
15(.28)

100%(5)
11(.26)

% Solved
time(sec)

53%(5)
7038

87%(7)
93%(7)
93%(7)
93%(7) 100%(8)
2214(.55) 1209(.49) 1203(.54) 1222(.52) 250(.54)

100%(8)
134(.58)

% Solved
time(sec)

43%(5)
8525

100%(8)
563(.99)

100%(8)
395(.79)

100%(8)
452(.91)

100%(9)
24(.97)

100%(9)
22(.89)

100%(9)
22(.88)

% Solved
time(sec)

0%
15000

70%(11)
5269(2)

90%(11)
2450(1)

93%(11)
1425(2)

93%(11)
1479(1)

93%(11) 100%(12)
1501(1) 375(1)

% Solved
time(sec)

0%
15000

50%(12)
7748(3)

70%(13)
4578(5)

87%(14)
2191(5)

93%(14)
1299(3)

93%(14)
1319(3)

One Goal

Two Goal

Three Goal

Four Goal

Five Goal

Six Goal

120

93%(14)
1244(3)

Table 4: Performance statistics Logistics Transportation Domain. Average solution
length shown parentheses next %Solved. Case retrieval time shown
parentheses next CPU time.
problem one already present library, successively adding extra
goal. Multi-goal problems stored retrieved cases used solving problem
failed. Whenever problem could solved sequenced replay previous cases,
negatively interacting goals contained failure reason identified new
case achieving goals alone stored library. phase experiment,
planner tested 30 randomly generated test problems varying
amounts training. problems solved from-scratch mode replay
multiple cases retrieved library constructed training.
second experiment tested planner complex 15 city domain employed stable case library formed dersnlp+ebl trained 120 (6 city, 6 goal)
logistics transportation problems. library smaller problems used
planner tested larger (15 city) problems ranging 6 10 goals.

4.2 Experimental Results

first experiment 6 city domain dersnlp+ebl showed substantial improvements multi-case replay evident results Table 4. Moreover, replay
performance improved problem-solving experience. plans produced
showed slight increase number steps solutions obtained
from-scratch mode. results plotted Figure 17 graphs cumulative
CPU time test problems six experiments. figure illustrates CPU
time decreased number training problems solved. insert shows total CPU
186

fiStoring Indexing Plan Derivations

Figure 17: Replay performance Logistics Transportation Domain increasing
amounts training. Thirty problems tested problem size (1
6 goals). amount time needed solve test problems size
(including case retrieval time) shown problems solved scratch
(level 0) replay increasing levels training (after solving 20 ...
120 randomly generated problems). insert shows amount time taken
solve test problems increasing amounts training. time limit
500 seconds placed problem solving.

187

fiIhrig & Kambhampati

Figure 18: Replay performance Logistics Transportation Domain scaled 15
cities. case library formed 120 training problems (6 cities, 6 goals)
solved. library used solving test sets containing larger
problems (15 cities, 6 10 goals). None problems solved within
time limit (500 sec) from-scratch mode. replay mode, average solution
length shown parentheses next problem size.

Figure 19: Replay performance logistics transportation. percentage test problems solved within time limit (500 sec) plotted number training
problems solved. Percentage solved shown problems increasing size (1,
3, 5 goals).

188

fiStoring Indexing Plan Derivations

Figure 20: Figure shows size case library increased number training
problems solved. Library size increases training problem size (1, 3, 5
goals). 5' shows number single-goal subproblems contained 5-goal
training problems.
time (including case retrieval time) test problems six experiments.
evident insert, planning performance improves increased experience random
problems. However, relatively little experience (20 problems solved) enough show
significant performance improvements.
Replay raised problem-solving horizon, illustrated Figure 19. effective
larger problem size, from-scratch planning tends exceed time limit imposed
problem-solving. Figure 20 shows increase size library increasing
amounts training. figure also indicates library size determined
amount interaction domain, opposed number training problems solved.
rate case library grows tapers higher planner trained
larger problems7 .
second experiment, library formed course training 6-goal problems
used solve larger problems (6 10 goals) complex domain (15 cities) (See
Figure 18). None larger problems solved from-scratch mode within time
limit 500 sec 8 . planner continued maximum time problems, indicated
figure linear increase CPU time. performance substantially better
replay, however. Since library size relatively small, improvements planning
performance offset cost retrieving adapting previous cases. finding
suggests replay strategy employed experiments represents effective
method improving planning performance complex domains.
7. opportunity interaction larger problems. example, 6-goal problem could
contain 6 goals mutually interact, whereas 5-goal problem maximum 5 interacting goals.
8. dersnlp+ebl from-scratch mode used best-first strategy. replay, best-first strategy biased
subtree replayed path explored first, siblings path.

189

fiIhrig & Kambhampati

action (Put-On ?X ?Y ?Z)
precond (On ?X ?Z)
(Clear ?X)
(Clear ?Y)
add
(On ?X ?Y)
(Clear ?Z)
delete (On ?X ?Z)
(Clear ?Y)

action (New-Tower ?X ?Z)
precond (On ?X ?Z)
(Clear ?X)
add
delete

(On ?X Table)
(Clear ?Z)
(on ?X ?Z)

Figure 21: specification Blocks World Domain adapted experiments.

4.3 Empirical Comparison dersnlp+ebl Rule-Based EBL
Case-based planning explanation-based learning offer two differing approaches improving performance planner. Prior research (Kambhampati, 1992) analyzed
tradeoffs. hybrid learning approach dersnlp+ebl designed alleviate
drawbacks associated pure case-based planning, rule-based EBL. Prior
work, EBL used construct generalized search control rules may
applied new problem-solving situation. rules matched choice
point search process (DeJong & Mooney, 1986; Minton, 1990b; Mostow & Bhatnagar,
1987; Kambhampati et al., 1996b). approach known exhibit utility problem since
rule base grows rapidly increasing problem-solving experience even small
number rules may result high total match cost (Minton, 1990b; Tambe, Newell, &
Rosenbloom, 1990; Kambhampati, 1992; Francis & Ram, 1995). contrast, empirical
results discussed (see Table 4) indicate dersnlp+ebl low case retrieval
match cost.
demonstrate dersnlp+ebl reduces match cost, conducted empirical study
compared performance ucpop+ebl, rule-based search control learning
framework (Kambhampati et al., 1996b). framework constructs reasons planning
failures manner similar dersnlp+ebl. However, approach similar
Minton (1990b) employs explanations construction search control
rules matched node search tree. planners tested
set problems ranging 2 6 goals randomly generated blocks
domain shown Figure 21. Testing performed set thirty problems
increasing amounts training.
illustrated Figure 22, dersnlp+ebl improved performance 10 training problems solved. ucpop+ebl failed improve significantly. reason evident
ucpop+ebl's match time (ucpop-match) also graphed Figure 22. ucpop+ebl,
time spent matching rules increases training, wiping improvements
may gained use rules. rules matched
choice point search tree, small number rules sucient substantially increase
total match cost.
190

fiStoring Indexing Plan Derivations

Figure 22: Total CPU Time 30 blocks world problems increased amounts training.
also possible improve performance rule-based EBL reducing number
rules use utility monitoring strategies (Gratch & DeJong, 1992),
using sophisticated match algorithm (Doorenbos, 1995). example, Doorenbos
(1995) employs improved rule matcher based Rete algorithm. dersnlp+ebl,
hand, aims alleviating utility problem reducing number times rules
matched. Similar rule-based EBL, learning component employed generate
rules. However, rules generated govern retrieval cases stored
library. compiled indexing structure. dersnlp+ebl exhibits low
match cost applying retrieval rules one point search process. Specifically,
retrieves cases start problem-solving. case represents sequence
choices (a derivation path) thus providing global control opposed local. results
shown Table 4 indicate cost retrieving cases significantly lower comparison
time spent problem-solving.

5. Related Work Discussion
dersnlp+ebl's storage strategy relies capability case-based planner replay
multiple cases, covering small subset goals, add step orderings interleave respective plans. strategy differs earlier approaches priar
(Kambhampati & Hendler, 1992), prodigy/analogy (Veloso, 1994), paris (Bergmann
& Wilke, 1995), caplan (Munoz-Avilla & Weberskirch, 1996), division
goal subsets based structure final plan alone, sequence
events making problem-solving episode. Retrieval failures treated opportunity planner stores new repairing case. aspect similar
Hammond's chef (Hammond, 1990) also learns improve retrieval strategy
based failures. Despite surface similarity, important differences

191

fiIhrig & Kambhampati

Transformational
PRIAR
SPA
MPA
Plan-Space

State-Space
DERSNLP

PRODIGY/ANALOGY
PARIS

Derivational

Figure 23: different approaches case-based planning case adaptation accomplished underlying generative planner.
approach. dersnlp+ebl learns case extension failures, whereas chef concentrates
learning execution failures. Specifically, chef assumes incomplete domain model,
consisting stored cases, domain-specific modification theory patches. Given
new problem, chef retrieves previous case, modifies retrieved plan using domain
specific modification rules generate candidate solution current problem.
correctness solution tested respect external causal simulator
domain. solution found incorrect, explanation incorrectness (supplied
simulator) used modify case-library censor retrieval case
similar situations future. effect improves correctness chef's domain
theory. contrast, dersnlp+ebl assumes complete knowledge domain, form
domain operators. also access sound complete plan synthesis strategy.
aim case-based reasoning dersnlp+ebl improve performance
base-level planner. end, dersnlp+ebl analyzes case extension failures predict
case cannot extended solve new problem.
Fox Leake (1995) taken approach similar chef, use introspective reasoning explain failures find repairing cases. Similar chef, introspective
reasoning used revise indexing case library (Fox & Leake, 1995; Ram & Cox,
1994). approaches employ domain-specific techniques improve storage retrieval case library (Munoz-Avilla & Weberskirch, 1996; Smyth & Keane, 1995).
dersnlp+ebl differs automatically generates new indices well defined
domain-independent methodology (Kambhampati et al., 1996b) incorporated
underlying planning strategy.
Since EBL employed explaining case failure well success, dersnlp+ebl complements extends earlier approaches case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Hendler, Stoffel, & Mulvehill, 1996; Veloso, 1994; Bergmann
& Wilke, 1995; Munoz-Avilla & Weberskirch, 1996; Ram & Francis, 1996). Although
192

fiStoring Indexing Plan Derivations

exhibits low retrieval match cost, CBP system, eciency may degrade larger domain size. dersnlp+ebl's approach compatible others aimed
improving match cost (Doorenbos, 1995; Ram & Francis, 1996; Hendler et al., 1996).
example, mpa (Ram & Francis, 1996) built around retrieval engine performs
asynchronous memory retrieval. caper (Hendler et al., 1996) uses structure matching
algorithm parallelizes process plan's success conditions represented
retrieval probe matched large knowledge base world facts. process
expands binary predicates match success conditions larger structure containing implicitly specified relations knowledge base. structure acts filter,
eliminating matches fail line probe.
dersnlp+ebl similar case-based systems employ complete correct
domain-independent planner generate cases stored (Hanks & Weld, 1995; Kambhampati & Hendler, 1992; Koehler, 1994; Veloso, 1994; Ram & Francis, 1996). surveying
literature, possible distinguish approaches two orthogonal scales
shown Figure 23. horizontal direction, CBP frameworks ranked
underlying planning strategy falls continuum whose end extremes represent
state-space vs plan-space dichotomy. Towards state-space end spectrum
prodigy/analogy, employs means-ends analysis (MEA) planner, nolimit,
extend previous case. nolimit classed state-space planner since applies
actions plan based current world state thereby advances world state.
priar framework (Kambhampati & Hendler, 1992; Kambhampati, 1994) based
within nonlin (Tate, 1977). nonlin creates plans hierarchical task reduction.
also partial-order (plan-space) planner constructs plans protecting underlying causal structure. Like dersnlp+ebl, extends case normal course
plan refinement defined underlying plan-space strategy. However, dersnlp+ebl
implemented within partial-order, causal-link planner, snlp (McAllester & Rosenblitt,
1991; Barrett & Weld, 1994). aspect similar spa system developed
Hanks Weld (1995).
different CBP systems may also distinguished according case adaptation strategy. roughly categorized either transformational derivational
(Carbonell, 1983; Veloso & Carbonell, 1993b), according whether transform previous plan replay previous plan derivation. transformational strategies priar
spa, final plan product planning episode stored case
library. case retrieved plan fitted adapt new problem-solving situation retracting irrelevant redundant subparts. Early CBP systems (Carbonell,
1983; Hammond, 1990) also employ transformational techniques adapt previous solution. Causal-link planners snlp ready-made plan reuse since causal
structure employed plan adaptation part plan itself. priar spa
use plan's causal structure fitting plan new problem context,
extending fitted plan solve new problem. priar differs spa
employs extension-first strategy. skeletal plan first refined addition
plan constraints undertaking retraction constraints. spa,
hand, alternates retraction plan constraints addition
new constraints. mpa (Ram & Francis, 1996) extends spa's transformational strategy
accomplish multi-case retrieval adaptation.
193

fiIhrig & Kambhampati

mentioned earlier, derivational analogy case-based planning technique
introduced Carbonell (Veloso & Carbonell, 1993b). model developed
Veloso prodigy/analogy (Veloso, 1994), employed case fitting strategy called
derivational replay. Case fitting based replay similar fitting plan reuse,
based plan's underlying causal structure. justification planning
decision stored derivation trace ects causal dependencies plan
steps. justified choices replayed solving new problem. Replay thus serves
purpose retraction plan reuse. Replay may advantage multi-case
reuse since allows planner readily merge small subplans solve large problems.
dersnlp contrasted prodigy/analogy employs case fitting
methodology called eager derivation replay (Ihrig & Kambhampati, 1994a, 1996).
replay strategy, applicable cases replayed sequence returning fromscratch planning. Eager replay simplifies replay process avoiding decision
alternate replay multiple cases. effectiveness approach dependent
underlying plan-space planning strategy (Ihrig & Kambhampati, 1994a). dersnlp's
eager case adaptation strategy allows case failure defined terms failure
single node search tree. particular, case failure defined failure
skeletal plan, contains constraints adopted advice
previous cases. Eager case adaptation means explanations case failure may
constructed use EBL techniques developed explain
analytical failures occurring planner's search space.

6. Summary Conclusion
paper described design implementation case-based planner,
dersnlp+ebl. dersnlp+ebl framework represents integration eager case adaptation failure-based EBL. EBL techniques employed building case library
basis experienced retrieval failures. approach improves earlier treatments case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Ihrig &
Kambhampati, 1994a; Veloso & Carbonell, 1993a). partial-order case-based planner,
dersnlp ability solve large problems retrieving multiple instances smaller
subproblems merging cases sequenced replay (Ihrig & Kambhampati,
1994a). dersnlp+ebl framework extends approach use new EBL
techniques employed construction case library. techniques
used explain plan merging failure identify set negatively interacting goals.
library augmented new repairing case covering interacting goals.
dersnlp+ebl's method storing multi-goal cases goals negatively interacting results small library size low retrieval costs. However, multi-case adaptation
also involves tradeoff since effort expended merging multiple instances stored cases.
dersnlp+ebl accomplishes merging increasing justification replay step addition decisions. strategy avoids addition redundant steps goals positively
interact. dersnlp+ebl therefore aimed domains Logistics Transportation
domain significant amount positive interaction. also aimed domains
negative interaction. course futile spend effort explaining case
failure none encountered.
194

fiStoring Indexing Plan Derivations

Section 4 describes evaluation overall eciency storage retrieval
strategy solving large problems complex domain. dersnlp+ebl shows improvement planning performance offsets added cost entailed
retrieving failure conditions. amount improvement provided replay shown
experiments seen lower bound since random problem distribution
may mean less problem similarity found real world problems.
conclusion, paper described novel approach integrating explanationbased learning techniques case-based planning. approach aimed issues
associated pure case-based planning, rule-based EBL. particular,
addresses mis-retrieval problem CBP, well utility problem. results
demonstrate eager case adaptation combined dersnlp+ebl's dynamic case
retrieval effective method improving planning performance.

Acknowledgements
authors wish thank Amol D. Mali, Eric Lambrecht, Eric Parker, anonymous
reviewers helpful comments earlier versions paper. Thanks due
Terry Zimmerman providing insight ucpop+ebl. research supported
part NSF Research Initiation Award IRI-9210997, NSF Young Investigator award
IRI-9457634, ARPA Planning Initiative grants F30602093-C-0039 (phase II)
F30602-95-C-0247 (phase III).

References

Barletta, R., & Mark, W. (1988). Explanation-based indexing cases. Proceedings
AAAI-88.
Barrett, A., & Weld, D. (1994). Partial order planning: evaluating possible eciency gains.
Artificial Intelligence, 67, 71{112.
Bergmann, R., & Wilke, W. (1995). Building refining abstract planning cases change
representation language.. Journal Artificial Intelligence Research, 3, 53{118.
Carbonell, J. (1983). Learning analogy: Formulating generalizing plans past
experience. Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine Learning:
Artificial Intelligence approach, Vol. 1. Palo Alto, CA: Tioga Press.
DeJong, G., & Mooney, R. (1986). Explanation-based learning: alternative view. Machine Learning, 1 (2), 145{176.
Doorenbos, R. (1995). Production Matching Large Learning Systems. Ph.D. thesis,
Computer Science Department, Carnegie Mellon University.
Fikes, R., & Nilsson, N. (1971). new approach application theorem proving
problem solving. Artificial Intelligence, 2, 189{208.
Fox, S., & Leake, D. (1995). Using introspective reasoning refine indexing. Proceedings
IJCAI-95.
195

fiIhrig & Kambhampati

Francis, A., & Ram, S. (1995). comparative utility analysis case-based reasoning
control-rule learning systems. Proceedings 8th European Conference
Machine Learning, ECML-95.
Friedland, P., & Iwasaki, Y. (1985). concept implementation skeletal plans.
Journal Automated Reasoning, 1 (2), 161{208.
Gratch, J., & DeJong, G. (1992). Composer: probabilistic solution utility problem
speed-up learning. Proceedings AAAI-92.
Hammond, K. (1990). Explaining repairing plans fail. Artificial Intelligence, 45,
173{228.
Hanks, S., & Weld, D. (1995). domain-independent algorithm plan adaptation. Journal
Artificial Intelligence Research, 2, 319{360.
Hendler, J., Stoffel, K., & Mulvehill, A. (1996). High performance support case-based
planning applications. Technological Achievements Arpa/Rome Laboratory
Planning Initiative: Advanced Planning Technology. AAAI Press.
Ihrig, L., & Kambhampati, S. (1994a). Derivation replay partial-order planning.
Proceedings AAAI-94.
Ihrig, L., & Kambhampati, S. (1994b). Plan-space vs state-space planning reuse
replay. Tech. rep. 94-006, Department Computer Science Engineering. Arizona
State University. Also available http://rakaposhi.eas.asu.edu/yochan.html.
Ihrig, L., & Kambhampati, S. (1996). Design implementation replay framework
based partial order planner. Proceedings AAAI-96.
Joslin, D., & Roach, J. (1990). theoretical analysis conjunctive goal problems. Artificial
Intelligence, 41, 97{106.
Kambhampati, S. (1992). Utility tradeoffs incremental modification reuse plans.
Proceedings AAAI Spring Symposium Computational Considerations Supporting
Incremental Modification Reuse.
Kambhampati, S. (1994). Exploiting causal structure control retrieval refitting
plan reuse. Computational Intelligence, 10.
Kambhampati, S., & Chen, J. (1993). Relative utility ebg based plan reuse partial ordering vs total ordering planning. Proceedings AAAI-93, pp. 514{519. Washington,
D.C.
Kambhampati, S., & Hendler, J. A. (1992). validation structure based theory plan
modification reuse. Artificial Intelligence, 55, 193{258.
Kambhampati, S., Ihrig, L., & Srivastava, B. (1996a). candidate set based analysis
subgoal interactions conjunctive goal planning. Proceedings 3rd Intl. Conf.
AI Planning Systems.
196

fiStoring Indexing Plan Derivations

Kambhampati, S., Katukam, S., & Qu, Y. (1996b). Failure driven dynamic search control
partial order planners: explanation-based approach. Artificial Intelligence, 88,
253{315.
Kambhampati, S., Knoblock, C., & Yang, Q. (1995). Planning refinement search:
unified framework evaluating design tradeoffs partial-order planning. Artificial
Intelligence, 76, 167{238.
Koehler, J. (1994). Avoiding pitfalls case-based planning. Proceedings 2nd Intl.
Conf. AI Planning Systems.
Korf, R. (1987). Planning search: qualitative approach. Artificial Intelligence, 33,
65{68.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
AAAI-91.
Minton, S. (1990a). Issues design operator composition systems. Proceedings
International conference Machine Learning.
Minton, S. (1990b). Quantitative results concerning utility explanation-based learning. Artificial Intelligence, 42, 363{392.
Mostow, J., & Bhatnagar, N. (1987). Failsafe: oor planner uses ebg learn
failures. Proceedings IJCAI-87.
Munoz-Avilla, H., & Weberskirch, F. (1996). Planning manufacturing workpieces
storing, indexing replaying planning decisions. Proceedings 3rd Intl.
Conf. AI Planning Systems. AAAI-Press.
Munoz-Avilla, H., & Weberskirch, F. (1997). case study mergeability cases
partial-order planner. Proceedings 4th European Conf. Planning.
Ram, A., & Cox, M. (1994). Introspecive reasoning using meta-explanations multistrategy learning. Michalski, R., & Tecuci, G. (Eds.), Machine Learning: multistrategy
approach Vol. IV. Morgan Kaufmann.
Ram, S., & Francis, A. (1996). Multi-plan retrieval adaptation experience-based
agent. Leake, D. B. (Ed.), Case-Based Reasoning: experiences, lessons, future
directions. AAAI Press/The MIT Press.
Redmond, M. (1990). Distributed cases case-based reasoning:facilitating use multiple
cases. Proceedings AAAI-90.
Smyth, B., & Keane, M. (1995). Remembering forget: competence-preserving deletion
policy cbr. Proceedings IJCAI-95.
Tambe, N., Newell, A., & Rosenbloom, P. (1990). problem expensive chunks
solution restricting expressiveness. Machine Learning, 5, 299{349.
Tate, A. (1977). Generating project networks. Proceedings IJCAI-77.
197

fiIhrig & Kambhampati

Veloso, M. (1994). Planning learning analogical reasoning. Springer Verlag. Number
886 Lecture Notes Artificial Intelligence.
Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Proceedings 2nd Intl. Conf. AI Planning Systems.
Veloso, M., & Carbonell, J. (1993a). Derivational analogy prodigy: Automating case
acquisition, storage utilization. Machine Learning, 10, 249{278.
Veloso, M., & Carbonell, J. (1993b). Toward scaling machine learning: case study
derivational analogy prodigy. Minton, S. (Ed.), Machine Learning methods
planning. Morgan Kaufmann.
Yang, Q., Nau, D., & Hendler, J. (1992). Merging separately generated plans restricted
interactions. Computational Intelligence, 8 (2), 648{676.

198

fiJournal Artificial Intelligence Research 7 (1997) 1{24

Submitted 2/97; published 7/97

Defining Relative Likelihood Partially-Ordered
Preferential Structures
Joseph Y. Halpern

Cornell University, Computer Science Department
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

halpern@cs.cornell.edu

Abstract

Starting likelihood preference order worlds, extend likelihood
ordering sets worlds natural way, examine resulting logic. Lewis earlier
considered notion relative likelihood context studying counterfactuals,
assumed total preference order worlds. Complications arise examining
partial orders present total orders. subtleties involving exact
approach lifting order worlds order sets worlds. addition,
axiomatization logic relative likelihood case partial orders gives insight
connection relative likelihood default reasoning.

1. Introduction
preference order set W worlds exive, transitive relation W . Various
readings given relation literature; u v interpreted \u
least preferred desirable v" (Kraus, Lehmann, & Magidor, 1990; Doyle, Shoham,
& Wellman, 1991) (it reading leads term \preferential structure"), \u
least normal (or typical) v" (Boutilier, 1994), \u remote actuality
v" (Lewis, 1973). paper, focus one interpretation, essentially also
considered Lewis (1973). interpret u v meaning \u least likely v".1
Interestingly, readings seem lead much properties.
literature, preference orders mainly used give semantics conditional logics (Lewis, 1973) and, recently, nonmonotonic logic (Kraus et al., 1990).
basic modal operator papers conditional !, p ! q interpreted \in preferred/normal/likely worlds satisfying p, q case". However,
view representing likelihood, seems natural define binary operator
formulas ' interpreted \' likely ". Lewis (1973)
fact define operator, showed related !. However, assumed
total; is, assumed worlds w; w0 2 W , either w w0
w0 w. many cases preferential likelihood reasoning, seems appropriate allow preference order partial. may well agent finds two
1. tradition, starting Lewis (1973), taking u v, rather u v, mean u
preferred desirable v. last reading historically comes interpretation
preferred world less far actuality. Since seems split reading
literature, traditionally taken mean \at least likely" literature qualitative
probability (Fine, 1973; Gardenfors, 1975), take reading here.

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHalpern

situations incomparable far normality likelihood goes. example, one situation
may better one dimension worse another.
show paper, subtleties involved starting partial
preference order worlds. ultimately interested ordering worlds,
ordering sets worlds. make sense statement like ' , need
compare relative likelihood set worlds satisfying ' set satisfying
. Unfortunately, many possible ways extending preference order worlds
one sets worlds. focus two particular choices, agree
definition given Lewis case preference order worlds total, differ
general. define using definition allows us make interesting
work default reasoning.
turn attention axiomatizing likelihood operator. Lewis provided
axiomatization case preference order partial. key axioms used
Lewis transitivity:
('1 '2 ) ^ ('2 '3 ) ) ('1 '3 );
union property:
('1 '2 ) ^ ('1 '3 ) ) ('1 ('2 _ '3 )):
latter property characteristic possibility logic (Dubois & Prade, 1990).
partially ordered case, axioms suce. need following axiom:
(('1 _ '2 ) '3 ) ^ (('1 _ '3 ) '2 ) ) ('1 ('2 _ '3 )):
hard show axiom implies transitivity union property (in
presence axioms), equivalent them. Interestingly,
property captured axiom isolated (Friedman & Halpern, 1997)
key feature needed likelihood ordering sets appropriate default
reasoning spirit (Kraus et al., 1990). Thus, considering preference orders
partial, able clarify connections , !, default reasoning.
rest paper organized follows. Section 2, consider go
ordering worlds one sets worlds, focusing differences total
partial preference orders. Section 3, present logic reasoning relative
likelihood provide natural complete axiomatization it. Section 4, relate
results work relative likelihood, well work conditional logic
nonmonotonic reasoning. conclude Section 5. Proofs technical results
found Appendix A.

2. Preorders Worlds Preorders Sets Worlds

capture likelihood ordering set W possible worlds partial preorder |that
is, exive transitive relation| W .2 typically write w0 w rather

2. partial order R typically assumed exive, transitive, anti-symmetric (so (a; b) 2 R
(b; a) 2 R, = b). assuming anti-symmetric here,
preorder.

2

fiRelative Likelihood Partially-Ordered Preferential Structures

(w0 ; w) 2 . usual, often write u v rather v u, take u v
abbreviation u v not(v u), u v abbreviation v u.
relation strict partial order , is, irre exive (for w, case
w w) transitive relation W . say strict partial order determined
.
said introduction, think providing likelihood, preferential, order worlds W . Thus, w w0 holds w least likely/preferred/normal/close
actuality w0 . Given interpretation, fact assumed partial
preorder easy justify. example, transitivity says u least likely
v, v least likely w, u least likely w. Notice since
partial preorder, may pairs worlds w w0 incomparable
according . Intuitively, may prepared say either one likelier
other. say total preorder (or connected, linear preorder)
worlds w w0 , either w w0 w0 w.
Since added likelihood worlds, seems reasonable also add likelihood
language, allow us say \' likely ", example.
exactly mean? Although semantic model allows us say
one world likely another, immediately tell us say set
worlds likely another set. But, observed introduction,
need make sense \' likely ".
extend likelihood ordering worlds one sets worlds? Clearly
want way preserves ordering worlds. is, using >
denote ordering sets, would certainly expect u v would imply fug > fvg.
could impose minimal requirements, certainly would enough
uniquely determine ordering sets. example, two general approaches;
distinguish them, put subscripts >.
1. Define >1 U >1 V u 2 U v 2 V , u v.
define strict partial order spirit two distinct ways.
(a) considering analogous procedure used get : define
>2 U >2 V U >1 V not(V >1 U ). call standard method
below.
(b) replacing definition >1 : define >3 U >3 V
u 2 U v 2 V , u v. call alternative method.
2. Define >4 U >4 V v 2 V , U , u 2 U , V
u v. Note approach focuses symmetric difference U
V . two ways getting strict partial order.
(a) standard method gives us U >5 V U >4 V not(V >4 U ).
(b) alternative method gives us U >6 V v 2 V , U
u 2 U , V u v.
first approach ( >1 ) used Doyle, Shoham, Wellman (1991) defining
logic relative desire, starting preference order worlds. Unfortunately,
3

fiHalpern

point out, relations weak allow us make important
distinctions. go define notions comparison, tuned
applications, spirit notions considering here.
second approach (typically >4 >5 ) widely used various applications
literature. example,
Dershowitz Manna (1979) use define ordering multisets,
used provide technique proving program termination.
Przymusinski (1987) uses order models database.
Brass (1991), Cayrol, Royer, Saurel (1992), Delgrande (1994), Geffner (1992)
use help model various aspects default reasoning.
paper, focus variant second approach, essentially due Lewis
(1973), interesting connections default reasoning. Roughly speaking, take
U likely V every world V , likely world U .
make precise, U; V W , write U V every world v 2 V ,
world u 2 U u v. easy check partial preorder, is,
exive transitive. (The superscript \set".) Moreover, total preorder,
. Finally, would expect, u v iff fug fvg, relation
sets worlds viewed generalization relation worlds.
apply standard method alternative method define
strict partial order. standard method gives us relation 0 , U 0 V holds
U V not(V U ). alternative method gives us relation defined
finite sets taking U V hold U nonempty, every world v 2 V ,
world u 2 U u v. (The reasons U taken nonempty
definition restricted finite sets discussed below.)
various approaches compare? Clearly U >1 V implies U V , although
converse hold general; >1 weak ordering. consequence, >2
0 incomparable, >3 s. Similar remarks apply >4 . Again, easy
see U >4 V implies U V . hand, two notions equivalent.
example, suppose v v0 . fvg fv; v0 g, fvg >4 fv; v0 g.
focusing , 0 , here, rather >1 { >6 (or notion)? likelihood viewpoint, seem reasonable; intuitions regarding
extending likelihood worlds sets worlds seem well developed.
may possible motivate finest relation extending certain properties, fact motivation here. Rather, interest motivated
deep connections 0 certain approaches nonmonotonic reasoning.
said that, many questions consider could perfectly well explored using >1 { >6 . apology, discuss >1 { >6 paper,
except odd remark.
explained two methods getting strict partial order sets
worlds partial order worlds. standard method alternative
method really different? easy see u v iff fug fvg iff fug 0 fvg. (This
true >2 , >3 , >5 , >6 well.) Thus, 0 agree singleton sets
extend relation worlds. Moreover, 0 strict partial orders
4

fiRelative Likelihood Partially-Ordered Preferential Structures

finite sets. (The requirement U must nonempty definition U V
ensure ; ;; strictly speaking, also added
definitions >3 >6 ensure strict partial orders.) shown
Lemma 2.9, 0 fact identical underlying preorder worlds total
preorder. However, following example shows, 0 identical general.

Example 2.1: Suppose W = fw1 ; w2 g, w1 w2 incomparable.
easy see fw1 ; w2 g 0 fw1 g. However, case fw1 ; w2 g
fw1 g, since element fw1 ; w2 g strictly likely w1 .3
Notice careful define finite sets. following

example illustrates why:

Example 2.2: Let W1 = fw0 ; w1 ; w2 ; : : :g, suppose
w0 w1 w2 : : :
easy see apply definition infinite sets,
would W1 W1 , would irre exive.4
approach extending definition infinite sets essentially due

Lewis (1973) (who case total preorders). idea say order
U V , enough every element v V element u
U likely v. definition allows W1 W1 Example 2.2.
Notice finite case, easy see U V , every element v
V , must u 2 U that, u v, u dominates V
v0 2 V v0 u. precisely domination condition
hold Example 2.2. observation provides motivation ocial definition
s, applies finite infinite domains.

Definition 2.3: Suppose partial preorder W , U; V W , w 2 W . say
w dominates V v 2 V case v w. (Notice total
preorder, equivalent saying w v v 2 V .) write U V U
nonempty and, v 2 V , exists u 2 U u v u dominates V .
easy see definition agrees earlier definitions U V
finite.
collect properties , 0 , . this, need definitions.
say relation > 2W (not necessarily preorder) qualitative (V1 [ V2 ) > V3
(V1 [ V3 ) > V2 implies V1 > (V2 [ V3 ). say > satisfies union property
V1 > V2 V1 > V3 implies V1 > (V2 [ V3). say > orderly U > V , U 0 U ,
V 0 V implies U 0 > V 0 . provide intuition properties following
Proposition 2.5, showing help us characterize , 0 , .
3. remark similar results hold >5 >6 . identical underlying order worlds
total preorder, example also used show differ underlying order
partial.
4. Similar problems arise >6 dealing infinite sets, solution described
Definition 2.3 applied >6 well.

5

fiHalpern

Lemma 2.4: > orderly qualitative relation 2W , > transitive satisfies

union property.

Proof: See Appendix A.
converse Lemma 2.4 hold. Indeed, orderly strict partial order
2W may satisfy union property still qualitative. example, suppose
W = fa; b; cg, fa; bg > fcg, fa; cg > fbg, fa; b; cg > fbg, fa; b; cg > fcg,
fa; b; cg > fb; cg. easily checked > orderly strict partial order
satisfies union property, qualitative.
definitions hand, state key properties relations
interested here.

Proposition 2.5:
(a) partial preorder W , orderly partial preorder 2W
satisfies union property.

(b) partial preorder W , 0 orderly strict partial order 2W .
(c) strict partial order W , orderly qualitative strict partial
order 2W .

Proof: See Appendix A.
discuss interpret properties considering light
result.
extent think > meaning \more likely than", orderliness
natural property require. U likely V , certainly superset U
likely subset V . thus surprising three
relations defined orderly.
Clearly union property generalizes arbitrary finite unions. is, > satisfies
union property > Bi , = 1; : : : ; n, > B1 [ : : : [ Bn . particular,
u vj j = 1; : : : ; N , fug fv1 ; : : : ; vN g, matter large N is, similarly
replace (since fact qualitative means satisfies union
property, Lemma 2.4). different probability, suciently many
\small" probabilities eventually dominate \large" probability. suggests
u v perhaps interpreted \u much likely v". generally,
> satisfies union property, U > V interpreted meaning U
much likely V . sense, notion likelihood corresponding
closer possibility (Dubois & Prade, 1990) probability, since relation \more
possible than" satisfies union property.
Note that, general, 0 satisfy union property. Example 2.1,
fw1 ; w2 g 0 fw1 g fw1 ; w2 g 0 fw2 g, fw1 ; w2 g 0 fw1 ; w2 g.
qualitative property somewhat dicult explain intuitively. three
relations considering, relation satisfies it. fact 0
satisfy follows Lemma 2.4, together observation 0 satisfy
union property. Example 2.1 also shows qualitative, since were,
6

fiRelative Likelihood Partially-Ordered Preferential Structures

could conclude fw1 ; w2 g fw2 g (taking V1 = fw1 g V2 = V3 = fw2 g
definition qualitative) fw1 g fw2 g, contradiction. interest qualitative
property stems fact that, precise sense, property characterizes
s. first arose (Friedman & Halpern, 1997), shown key property
required generalization probability called plausibility capture default reasoning.
discussed detail Section 4.
total preorder, get connections notions.
discuss details, need define analogue total preorders strict case.
relation > arbitrary set W 0 (not necessarily form 2W ) modular w1 >w2
implies that, w3 , either w3 > w2 w1 > w3 . Modularity \footprint" total
preorder strict order determined it. made precise following lemma.
Lemma 2.6: total preorder, strict partial order determined
modular. Moreover, > modular, strict partial order W , total
preorder W > strict partial order determined .
Proof: See Appendix A.
Modularity preserved lift preorder W 2W .
Lemma 2.7: modular relation W , modular relation 2W .
Proof: See Appendix A.
Although showed converse Lemma 2.4 hold general strict
partial orders, hold orders modular.
Lemma 2.8: > modular strict partial order satisfies union property,
> qualitative.
Proof: See Appendix A.
shown (Friedman & Halpern, 1997), connection nonmonotonic
reasoning, conditional logic, qualitative property. (This discussed Section 4.)
relationship best understood considering s, rather 0 ,
focus here. Lewis (1973) able use 0 focused total preorders.
following lemma makes precise.
Lemma 2.9: total preorder, 0 agree. general, U V implies
U 0 V , converse hold.
Proof: See Appendix A.
close section considering preorder 2W viewed
generated preorder W . result turns play key role completeness
proof, emphasizes role qualitative property.
Theorem 2.10: Let F finite algebra subsets W (that is, F set subsets
W closed union complementation contains W itself) let >
orderly qualitative relation F .
7

fiHalpern

(a) > total preorder F , total preorder W >
agree F (that is, U; V 2 F , U > V iff U V ).
(b) > strict partial order nonempty set F least 2log(jFj)
elements, partial preorder W > agree F .

log(jF j)

Proof: atom F minimal nonempty element F . Since F finite, easy
see every element F written union atoms, atoms disjoint.
Part (a) easy: w 2 W , let Aw unique atom F containing w. Define
W v w iff Av > Aw . easy see > total preorder F ,
total preorder W > agrees F . proof (b) considerably

dicult; see Appendix details.
clear requirement sets F least 2log(jFj)
elements
necessary. However, shown Theorem 2.10(b) hold without
assumptions cardinality elements F . example, suppose atoms
F A, B , C . Let > defined (B [ C ) >A, W >A, X > ; nonempty
X 2 F , pairs sets > relation. easy see
> orderly, qualitative, strict partial order. However, W = fa; b; cg, = fag,
B = fbg, C = fcg, ordering W > agree F :
easy see ordering must make a, b, c incomparable.
incomparable, cannot fb; cg fag. hand, allow C two
elements, taking W = fa; b; c; dg, = fag, B = fbg, C = fc; dg,
ordering = >: simply take c b d.
log(jF j)

3. Logic Relative Likelihood

consider logic reasoning relative likelihood. Let set primitive
propositions. basic likelihood formula (over ) one form ' , '
propositional formulas . read ' \' likely ". Let L
consist Boolean combinations basic likelihood formulas. Notice allow
nesting likelihood L, allow purely propositional formulas. would
diculty extending syntax semantics deal them, would obscure
issues interest here.
preferential structure (over ) tuple = (W; ;), W (possibly
infinite) set possible worlds, partial preorder W , associates
world W truth assignment primitive propositions . Notice may
two worlds truth assignment. shall see, general, need
this, although case total preorders, assume without loss generality
one world associated truth assignment.
give semantics formulas L preferential structures straightforward
way. propositional formula ', let [ '] consist worlds whose truth
assignment satisfies '. define

j= ' [ '] [ ] .
extend j= Boolean combinations basic formulas obvious way.
8

fiRelative Likelihood Partially-Ordered Preferential Structures

Notice j= :(:' false) iff [ :'] = ; iff [ '] = W . Let K' abbreviation :(:' false). follows j= K' iff ' true possible worlds.5
definitions, provide sound complete axiomatization
logic relative likelihood. Let AX consist following axioms inference rules.
L1.
L2.
L3.
L4.
Gen.
MP.

substitution instances tautologies propositional calculus
:(' ')
(('1 _ '2 ) '3 ) ^ (('1 _ '3 ) '2 ) ) ('1 ('2 _ '3 ))
(K (' ) '0 ) ^ K ( 0 ) ) ^ (' )) ) '0 0
K', propositional tautologies ' (Generalization)
' ' ) infer (Modus ponens)

L2, L3, L4 express fact irre exive, qualitative, orderly,
respectively; made precise proof following result. axiom Gen
analogue inference rule \From ' infer K'", typically known generalization.
inference rule here, since language allow nested occurrences
. Thus, arbitrary formula ', formula K' language.
language ' propositional; axiom takes care case.

Theorem 3.1: AX sound complete axiomatization language L respect
preferential structures.

Proof: validity L1 immediate. clear fact irre exive

qualitative, shown Proposition 2.5, implies L2 L3 valid. see L4
corresponds orderliness, note j= K (' ) '0 ) ^ K ( 0 ) ) ' ,
[ '] [ '0 ] , [ 0 ] [ ] , [ '] [ ] . Since orderly, follows
[ '0 ] [ 0 ] , j= '0 0 . Thus, L4 valid. also clear MP Gen
preserve validity. Thus, axiomatization sound.
completeness proof starts out, standard completeness proofs modal logic,
observation suces show consistent formula satisfiable.
is, must show every formula ' case :' provable
AX satisfiable preferential structure . However, standard modal
logic techniques constructing canonical model (see, example, (Hughes & Cresswell,
1968)) seem work case. Finding appropriate partial preorder worlds
nontrivial. use (part (b) of) Theorem 2.10. See Appendix details.
happens start total preorder? Let AXM consist AX together
obvious axiom expressing modularity:
L5. ('1 '2 ) ) (('1 '3 ) _ ('3 '2 ))
say preferential structure totally preordered form (W; ; ),
total preorder W .
5. K defined Lewis (1973), although wrote 2 rather K .

9

fiHalpern

Theorem 3.2: AXM sound complete axiomatization language L respect
totally preordered preferential structures.

Proof: soundness, check L5 valid totally ordered preferential

structures. straightforward left reader. completeness proof uses
Theorem 2.10 again, simpler proof completeness Theorem 3.1.
leave details Appendix A.
remark light Proposition 2.8, replace L4 AXM axioms saying
transitive satisfies union property, namely:
L6. ('1 '2 ) ^ ('2 '3 ) ) ('1 '3 )
L7. (('1 '2 ) _ ('1 '3 )) ) ('1 ('1 _ '2 ))
result axiomatization similar given Lewis (1973).
proof Theorem 3.1, showing consistent formula ' satisfiable,
structure constructed may one world truth assignment.
necessary, following example shows. (We remark observation closely
related cardinality requirements Theorem 2.10(b).)

Example 3.3: Suppose = fp; qg. Let ' formula (p (:p ^ q)) ^ :((p ^ q)
(:p ^ q)) ^:((p ^:q) (:p ^ q)). easy see ' satisfied structure consisting
four worlds, w1 ; w2 ; w3 ; w4 , w1 w3 , w2 w4 , p ^ q true w1 , p ^:q true
w2 , :p ^ q true w3 w4 . However, ' satisfiable structure
one world satisfying :p ^ q. suppose structure,
let w world satisfying :p ^ q. Since j= p (:p ^ q), must
case [ p] fwg. Thus, must world w0 2 [ p] w0 w. w0
must satisfy one p ^ q p ^ :q, j= ((p ^ q) (:p ^ q)) _ ((p ^ :q) (:p ^ q)),
contradicting assumption j= '.
hard see formula ' Example 3.3 satisfiable totally
preordered preferential structure. accident.

Proposition 3.4: formula satisfiable totally preordered preferential structure,

satisfiable totally preordered preferential structure one world per
truth assignment.

Proof: See Appendix A.
results previous section help emphasize differences
totally preordered partially preordered structures.

4. Related Work

related literature basically divides two groups (with connections them):
(a) approaches relative likelihood (b) work conditional nonmonotonic
logic.
10

fiRelative Likelihood Partially-Ordered Preferential Structures

first consider relative likelihood. Gardenfors (1975) considered logic relative
likelihood, took primitive total preorder sets 2W , focused
connections probability. particular, added axioms ensure that, given preorder
2W , probability function Pr property (in notation)
U V iff Pr(U ) Pr(V ). Fine (1973) defines qualitative notion comparative
probability, like Gardenfors, assumes preorder sets primitive,
largely concerned connections probability.
Halpern Rabin (1987) consider logic likelihood absolute statements
likelihood made (' likely, somewhat likely, on), notion
relative likelihood.
course, many quantitative notions likelihood, probability,
possibility (Dubois & Prade, 1990), ordinal conditional functions (OCFs) (Spohn, 1988),
Dempster-Shafer belief functions (Shafer, 1976). ones closest relative likelihood considered possibility OCFs. Recall possibility measure Poss
W associates world possibility, number [0; 1], V W ,
Poss(V ) = supfPoss(v) : v 2 V g, requirement Poss(W ) = 1. Clearly
possibility measure places total preorder sets, satisfies union property, since
Poss(A [ B ) = max(Poss(A); Poss(B )). true OCFs; refer reader
(Spohn, 1988) details. Fari~nas del Cerro Herzig (1991) define logic QPL
(Qualitative Possibilistic Logic) modal operator , ' interpreted
Poss([['] ) Poss([[ ] ). Clearly, ' essentially corresponds '. provide
complete axiomatization logic, prove equivalent Lewis' logic.6
surprisingly, analogue AX also complete logic. discussion
logic found (Bendova & Hajek, 1993). discuss connections
possibility measures, OCFs, logic below, context conditionals.
turn attention conditional logic. Lewis's main goal considering preferential structures capture counterfactual conditional !, ! ' read
\if case, ' would true" \if kangaroos tails,
would topple over". takes true world w if, worlds \closest"
w (where closeness defined preorder ) kangaroos don't tails,
case kangaroos topple over.7
abstractly, case W finite, subset V W , let best(V ) = fv 2
V : v0 v implies v0 2= V g. Thus, best(V ) consists worlds v 2 V world
v0 2 V considered likely v. (We take best(;) = ;.)
W finite, define
(M; w) j= ! ' best([[ ] ) [ '] .
Thus,
true.

! ' true exactly ' true likely (or closest) worlds '

6. Actually, axiomatization given (Fari~nas del Cerro & Herzig, 1991) quite complete stated;
get completeness, must replace axiom QPL4|true '|by axiom ' false [Luis Fari~nas
del Cerro, private communication, 1996].
7. really deal appropriately counterfactuals, require one preorder , possibly different
preorder w world w, since notion closeness general depends actual world.
ignore issue here, since somewhat tangential concerns.

11

fiHalpern

infinite domains, definition quite capture intentions. example,
Example 2.2, best(W1 ) = ;. follows = (W1 ; ; ), j=
true ! :p even makes p true every world W1 . certainly would want
say \if true case, p would false" true p true worlds
W1 ! solution generalization Lewis's definition case totally
ordered worlds, much like infinite domains. say j= ! '
u 2 [ :' ^ ] , exists world v 2 [ ' ^ ] v u v dominates
[ :' ^ ] . definition agrees definition given case finite W .

Lemma 4.1: W finite, best([[ ] ) [ '] iff u 2 [ :' ^ ] , exists
world v 2 [ ' ^ ] v u v dominates [ :' ^ ] .
Proof: See Appendix A.
Lewis (1973) argues definition ! captures many intuitions counterfactual reasoning. give ! another interpretation, perhaps natural
thinking terms likelihood. often want say ' likely not|in L,
expressed ' :'. generally, might want say relative ,

conditional case, ' likely not. mean
restrict worlds true, ' likely not, is, worlds ' ^
true likely worlds :' ^ true.
Let us define !0 ' abbreviation K : _ (' ^ :' ^ ). is,
!0 ' true vacuously structure hold world ; otherwise,
holds ' likely worlds satisfying .
Although intuition !0 seems, surface, quite different !,
especially finite domains, almost immediate formal definitions
equivalent. (This connection ! !0 already observed Lewis (1973)
case total proeorders.)

Lemma 4.2: structures , j= ! ' iff j= !0 '.
Proof: almost immediate definitions. See Appendix details.
Given Lemma 4.2, write ! ! !0 . lemma also allows us

apply known results conditional logic logic relative likelihood defined here.
particular, results (Friedman & Halpern, 1994) show validity problem
logic Section 3 co-NP complete, harder propositional logic,
case partial total preorders.8
recently, ! used capture nonmonotonic default reasoning (Kraus et al.,
1990; Boutilier, 1994). case, statement like Bird ! Fly interpreted \birds
typically y", \by default, birds y". semantics change: Bird ! Fly
true likely worlds satisfying Bird , Fly holds well. Dubois Prade (1991)
shown possibility used give semantics defaults well, ! '
8. remark also well known axiomatizations various conditional logics (Burgess, 1981;
Friedman & Halpern, 1994; Lewis, 1973). immediately give us complete axiomatization
logic relative likelihood considered here, since must find axioms language ,
language !.

12

fiRelative Likelihood Partially-Ordered Preferential Structures

interpreted Poss( ) = 0 Poss(' ^ ) > Poss(' ^ : ). course,
analogue definition ! terms s. Goldszmidt Pearl (1992) shown
similar approach works use Spohn's OCFs.
results clarified unified (Friedman & Halpern, 1997). Suppose start
mapping Pl sets partially ordered space minimal element ? (such
mapping called plausibility measure (Friedman & Halpern, 1997)). Define ! '
Pl(') = ? Pl( ^ ') > Pl( ^ :'). shown ! satisfies KLM
properties|the properties isolated Kraus, Lehmann, Magidor (1990) forming
core default reasoning|if Pl qualitative, least restricted disjoint
sets.9 Since s, Poss, OCFs give rise qualitative orders 2W , surprise
lead logics satisfy KLM properties.
remark also start !, define terms !. are,
fact, three related ways so. Define ' 0 abbreviation ((' _ ) ! (' ^
: )) ^:((' _ ) ! ); define ' 00 abbreviation :(' ! ) ^ ((' _ ) ! : );
define ' 000 abbreviation :(' ! false) ^ ((' _ ) ! (' ^ : )).

Proposition 4.3: structures , following equivalent:
(a) j= '
(b) j= ' 0
(c) j= ' 00 .
(d) j= ' 000 .
first translation essentially due Kraus, Lehmann, Magidor (1990), second essentially due Freund (1993), third due Lewis (1973). Since
equivalences close already literature, omit proof result
here. Using equivalences results (Kraus et al., 1990), Daniel Lehmann [private
correspondence, 1996] provided alternate proof Theorem 3.1. See remarks
proof theorem Appendix details.

5. Conclusion

investigated notion relative likelihood starting preferential ordering
worlds. notion earlier studied Lewis (1973) case preferential
order total preorder; focus paper case preferential order
partial preorder. results show significant differences totally
ordered partially ordered case. focusing partially ordered case, bring
key role qualitative property (Axiom L3), whose connections conditional logic
already observed (Friedman & Halpern, 1997).
9. is, V1 , V2 , V3 disjoint sets, require Pl(V1 [V2 ) > Pl(V3 ) Pl(V1 [V3 ) > Pl(V2 ),
Pl(V1 ) > Pl(V2 [ V3 ). result also requires assumption Pl(U ) = Pl(V ) = ?,
Pl(U [ V ) = ?.

13

fiHalpern

Acknowledgements
Many interesting useful discussions plausibility Nir Friedman formed basis
paper; Nir also pointed reference (Doyle et al., 1991). Daniel Lehmann,
Emil Weydert, referees paper also provided useful comments. preliminary
version paper appears Uncertainty Artificial Intelligence, Proceedings
Twelfth Conference, 1996, edited E. Horvitz F. Jensen. work
carried author IBM Almaden Research Center. IBM's support
gratefully acknowledged. work also supported part NSF grants
IRI-93-03109 IRI-96-25901, Air Force Oce Scientific Research
contract F49620-96-1-0323.

Appendix A. Proofs

repeat statements results proving convenience
reader.

Lemma 2.4: > orderly qualitative relation 2W , > transitive

satisfies union property.
Proof: Suppose > orderly qualitative relation. see > transitive, suppose
V1 > V2 V2 > V3. Since > orderly, follows (V1 [ V3 ) > V2 (V1 [ V2 ) > V3 .
Since > qualitative, follows V1 > (V2 [ V3 ). fact > orderly,
get V1 > V3 . Thus, > transitive, desired.
see > satisfies union property, suppose V1 > V2 V1 > V3 . Since >
orderly, (V1 [ V3) >V2 (V1 [ V2) >V3 . Using fact > qualitative,
get V1 > (V2 [ V3 ). Hence, > satisfies union property.

Proposition 2.5:
(a) partial preorder W , orderly partial preorder 2W
satisfies union property.
(b) partial preorder W , 0 orderly strict partial order 2W .
(c) strict partial order W , orderly qualitative strict partial
order 2W .

Proof: prove part (c) here; proof parts (a) (b) similar spirit,
left reader. fact orderly strict partial order straightforward,
also left reader. see qualitative, suppose V1 [ V2 V3
V1 [ V3 V2 . Let v 2 V2 [ V3 . must show v0 2 V1 dominates
V2 [ V3 v0 v. Suppose without loss generality v 2 V2 (an identical
argument works v 2 V3 ). Since V1 [ V3 V2 , u 2 V1 [ V3 dominates
V2 u v. u dominates V3 , clearly dominates V2 [ V3 must

V1 , done. Thus, assume u dominate V3 ,
element u0 2 V3 u0 u. Since V1 [ V2 V3 , must v0 2 V1 [ V2
14

fiRelative Likelihood Partially-Ordered Preferential Structures

v0 dominates V3 v0 u0 . Since u dominates V2 u0 u, follows u
dominates V2 . Since v0 u0 , v0 dominates V2 . Hence, v0 dominates V2 [ V3 .
follows v0 cannot V2 , must V1 . Thus, element V1 ,
namely v0 , v0 v v0 dominates V2 [ V3 , desired.

Lemma 2.6: total preorder, strict partial order determined
modular. Moreover, > modular, strict partial order W , total
preorder W > strict partial order determined .
Proof: Suppose total preorder. see modular, suppose w1 w2 .
Given arbitrary w3 , w3 w1 , follows transitivity w3 w2 .
hand, case w3 w1 , w1 w3 . Thus, either
w3 w2 w1 w3 , modular.
suppose > modular strict partial order W . Define w v
either w > v neither w > v v > w hold. Clearly, exive. see
transitive, suppose v1 v2 v2 v3 . three cases: (1) v1 > v2 ,
since > modular, either v1 > v3 v3 > v2 . cannot v3 > v2 ,
would v2 v3 . Thus, must v1 > v3 , hence v1 v3 . (2)
v2 > v3 , using modularity again, get either v1 > v3 v2 > v1. Again,
cannot v2 > v1 , must v1 > v3 , also v1 v3 . (3) neither
v1 >v2 v2 >v3 hold, claim neither v1 >v3 v3 >v1 hold. v1 >v3 ,
modularity, must either v1 > v2 v2 > v3 . v3 > v1 , either
v3 > v2 v2 > v1 , contradicts assumption v1 v2 v2 v3 . Thus,
conclude v1 v3 . Thus, transitive. Finally, almost immediate
definition > strict partial order determined .
Lemma 2.7: modular relation W , modular relation 2W .
Proof: Suppose modular. want show modular. suppose
V1 V2 , case V1 V3. must show V3 V2 . Since
case V1 V3 , must v 2 V3 u 2 V1 ,
u v . suppose v 2 V2. claim v v. see this, note since V1 V2 ,
must u 2 V1 u v. Since modular, either
u v v v. Since, choice v , u v , must v v.
follows V3 V2 .
Lemma 2.8: > modular strict partial order satisfies union property,

> qualitative.
Proof: Suppose > modular strict partial order satisfies union property.
see > qualitative, suppose (V1 [ V2 ) > V3 (V1 [ V3 ) > V2 . Since >
modular, follows either (V1 [ V2 ) > V1 V1 > V3 . (V1 [ V2 ) > V1 , then, using
fact > satisfies union property (V1 [ V2 ) >V3 , get (V1 [ V2 ) > (V1 [ V3 ).
Using transitivity, follows (V1 [ V2 ) > V2 . Using union property again, get
(V1 [ V2 ) > (V1 [ V2 ). contradicts assumption > irre exive. Thus,
15

fiHalpern

must V1 >V3 . similar argument shows V1 >V2 . Using union property,
get V1 > (V2 [ V3 ), desired.

Lemma 2.9: total preorder, 0 agree. general, U V implies
U 0 V , converse hold.
Proof: immediate definitions U V implies U 0 V , fact
converse hold shown Example 2.1. show 0 equivalent
total preorder, suppose U 0 V . Clearly U nonempty, since V ; V .
want show U V , must show v 2 V , u 2 U
dominates V u v. actually show u 2 U
u v0 v0 2 V . Suppose not. every u 2 U , vu
u vu . Since total order, means vu u. this, turn, means
V U , contradicting assumption U V . Since u 2 U
u v v 2 V , easily follows u dominates V U V , desired.
Theorem 2.10: Let F finite algebra subsets W (that is, F set subsets

W closed union complementation contains W itself) let >
orderly qualitative relation F .
(a) > total preorder F , total preorder W >
agree F (that is, U; V 2 F , U > V iff U V ).
(b) > strict partial order nonempty set F least 2log(jFj)
elements, partial preorder W > agree F .

log(jF j)

Proof: Part (a) already proved main text, prove part (b) here.

proceed follows. say pair (A; X ) minimal pair > X >
X 0 X (\" used denote strict subset) X 0 > A.
minimal pairs ordered relation determine it. Indeed, following stronger result
holds.

Lemma A.1: > >0 two orderly qualitative relations F

minimal pair (A; X ) > X > A, minimal pair (A0 ; X 0 ) >0
X 0 >0 A0 , > = >0 .

Proof: Suppose assumptions lemma holds X > ; must show
X >0 . Suppose atom . Since > orderly, must X >A.
Let X 0 minimal subset X X 0 > A. Since F finite, X 0 must

exist. Thus, (A; X 0 ) minimal pair >. assumption, X 0 >0 A. Since >0
orderly, also X >0 A. Thus, X >0 atom . Since
>0 qualitative, also satisfies union property, hence X >0 desired.
symmetry, follows > = >0 .
minimal-pair tree > rooted tree whose nodes labeled atoms
following conditions satisfied:
16

fiRelative Likelihood Partially-Ordered Preferential Structures

1. node tree labeled B immediate successor node labeled A,
must minimal pair (A; X ) > B X .
2. node tree labeled minimal pair > form (A; X ),
must atom B X node labeled B immediate
successor t.
3. exist path tree two nodes path
label.
4. node two distinct successors label.
minimal-pair tree rooted root tree labeled atom A.
Since subset F written unique way union atoms,
1-1 correspondence subsets F sets atoms. Thus, exactly
log(jFj) atoms. third condition, path tree length
log(jFj). Since atoms path must distinct, follows
log(jFj)! log(jFj)log(jFj) (= jFjlog log(jFj) ) possible paths tree rooted
A. identify tree set paths, means
2log(jFj)! 2log(jFj)
possible trees rooted atom A.
label element W minimal-pair tree way every
element atom labeled tree rooted A, every minimal-pair tree rooted
label element A. Since assumed least 2log(jFj)
elements, labeling. Let L(w) label node w. define W
w0 w iff L(w0 ) proper subtree L(w). Clearly strict partial order.
claim > agrees s. Lemma A.1, suces show (A; X )
minimal pair >, X A, (A; X ) minimal pair , X > A.
suppose (A; X ) minimal pair >. want show X A. Let w 2 A,
suppose L(w) = . Thus, minimal-pair tree rooted A. construction
minimal-pair trees guarantees successor root tree labeled B
atom B X . Consider subtree rooted B . minimal-pair tree
rooted B , hence must label w0 2 B X . Thus, w0 w. follows
X A.
suppose (A; X ) minimal pair . want show X > A.
Suppose not. show below, means exists minimal-pair tree rooted
node labeled atom contained X . Let w element
L(w) = . construction, element w0 X w0 w. Thus,
X A, contradicting initial assumption.
remains show exists minimal-pair tree rooted
node labeled atom contained X . Clearly, cannot X 0 >
X 0 X , then, preceding argument, would X 0 A, (A; X ) would
minimal pair s. follows (A; ) minimal pair >, must
, X 6= ;.
Two general fact orderly, qualitative relations useful construction:
log(jF j)

log(jF j)

Lemma A.2: >0 qualitative relation F >0 X , (Y , X ) >0 X .
17

fiHalpern

Proof: Notice (Y , X ) [ X >0 X . Since >0 qualitative, follows (Y , X ) >0 X

(take V2 V3 definition qualitative X ).
Lemma A.3: >0 orderly, qualitative relation (X1 [ X2 ) >0 X3
X 0 >0 X2 , (X1 [ X 0 ) >0 X3 .
Proof: Since >0 orderly, assumptions imply (X1 [ X 0 [ X2 ) >0 X3
(X1 [ X 0 [ X3 ) >0 X2 . Since >0 qualitative, follows (X1 [ X 0 ) > (X2 [ X3 ).
result follows using fact >0 orderly again.
start constructing tree whose nodes labeled atoms whose root
labeled A. proceed log(jFj) + 1 stages. stage, tree whose nodes
labeled atoms. stage 0, take single node labeled A. Suppose
constructed tree whose nodes labeled atoms whose root labeled
stage k < log(jFj). stage k + 1, leaf stage-k tree, labeled
B , atom C , minimal pair (B; ) > C , add
successor labeled C . call tree constructed end stage log(jFj) full
tree A.
next mark nodes full tree stages. kth stage, atom B ,
mark unmarked node labeled B one following three conditions holds: (1)
B X , (2) ancestor tree also labeled B , (3) minimal pair
(B; ) > successors label contained marked earlier
stage. unmarked nodes satisfying one three conditions stage k,
marking process stops. Otherwise, continue stage k +1. Since
finitely many nodes, marking process guaranteed terminate.
goal show that, end marking process, root full tree
unmarked. case, let subtree full tree consisting
unmarked nodes whose ancestors unmarked. easy check
minimal-pair tree marking procedure guarantees node labeled
atom contained X , done.
see root full tree unmarked, proceed follows: Define 0-cover
node full tree itself. Suppose defined k-cover t.
set Z nodes (k + 1)-cover exists k-cover Z 0
node t0 Z 0 labeled B minimal pair (B; ) >, Z consists
nodes Z 0 except t0 , together successors t0 labeled
atom contained . easy argument induction k shows following.
Lemma A.4: Z k-cover node labeled C k > 0, exist set
(C; ) minimal pair >, successors t1 ; : : : ; tm full tree, atoms
D1 ; : : : ; Dm = [mi=1Di Di label ti , = 1; : : : ; m, partition
Z1 ; : : : ; Zm Z disjoint subsets Zi ki -cover ti, = 1; : : : ; m,
ki < k.
Given set Z , let UZn consist union atoms labeling nodes Z still
unmarked nth stage (we take UZ0 union atoms labeling nodes
Z ); given node t, let Vt consist union atoms labeling ancestors
descendent label D.
key fact following result.
18

fiRelative Likelihood Partially-Ordered Preferential Structures

Lemma A.5: Z k-cover node labeled C k > 0, (UZn [ Vt [ X ) > C .
Proof: proceed induction k, subinduction n. k = 1,
set (C; ) minimal pair > nodes Z labeled
atoms contained . Since (C; ) minimal pair >, > C . Since >
orderly, (Y [ Vt [ X ) > C . definition, UZ0 = , takes care case n = 0.
Suppose n > 0 (UZn,1 [ Vt [ X ) > C . inductive step, suces show

(Y 0 [ V [ X ) > C
(1)
label node t0 Z marked stage n,
((Y 0 , D) [ Vt [ X ) > C:

(2)

suppose (1) holds label t0 . must consider t0 marked.
X (2) immediate. ancestor t0 also labeled D, Vt ,
and, since k = 1, Vt Vt [ C . Thus, since > orderly, follows
0

0

((Y 0 , D) [ Vt [ X [ C ) > C;

(3)

(2) follows Lemma A.2. Finally, suppose minimal pair (D; 00 )
> successors t0 labeled atom 00 marked stage n , 1.
Let Z 0 consist successors t0 labeled atoms contained 00 . Z 0 1-cover
t0 . Since UZn,1 = ;, follows induction hypothesis (Vt [ X ) > D. Again,
since Vt Vt [ C , (3) follows orderliness Lemma A.3, desired (2) follows
Lemma A.2.
suppose k > 1. Let Y; D1 ; : : : ; Dm ; Z1 ; : : : ; Zm ; t1 ; : : : ; tm sets nodes
guaranteed exist Lemma A.4. Since Zi ki -cover ti ki < k,
induction hypothesis, (UZn [ Vt [ X ) > Di . Since UZn UZn Vt Vt [ C ,
orderliness, (UZn [ Vt [ X [ C ) > Di . Since > qualitative,
(UZn [ Vt [ X [ C ) > ([i Di ). Since [iDi = > C , (3) follows, (2)
follows Lemma A.2.
Finally, suppose, way contradiction, root r full tree marked, say
stage n marking process. Lemma A.2 assures us \ X = ;, since (A; X )
minimal pair s, condition (1) marking process apply. Since r
ancestors, condition (2) apply either. Thus, must minimal
pair (A; ) > nodes set Z consisting successors r
full tree labeled atoms contained marked stage n , 1. Thus,
UZn,1 = ;. Since Vr = ; Z 1-cover r, Lemma A.5, follows X > A,
contradicting original assumption.
0

0

0









completeness theorems (Theorems 3.1 3.2) convenient start proving Theorem 3.2, since simpler, contains key ideas proof Theorem 3.1.

Theorem 3.2: AXM sound complete axiomatization language L
respect totally preordered preferential structures.
19

fiHalpern

Proof: Soundness proved main text, consider completeness here.

Suppose ' consistent AXM . want show ' satisfiable
totally preordered preferential structure. Let '1 ; : : : ; 'm basic likelihood formulas
subformulas '. definition, ' Boolean combination formulas.
Define atom ' conjunction form 1 ^ : : : ^ , either 'i
:'i. Using straightforward propositional reasoning (L1 MP), straightforward
show ' provably equivalent disjunction consistent atoms '. Thus,
since ' consistent, atom ', say , consistent. construct totally
ordered preferential structure satisfying . Clearly structure satisfy ' well.
Let p1 ; : : : ; pn primitive propositions appear '. Let consist
N = 2n truth assignments primitive propositions. take W =
let F consist subsets . define total preorder > F follows. Notice
set V F , corresponds propositional formula 'V made true
precisely truth assignments subset V 0 corresponds V .
precise, given truth assignment ff, let 'ff consist conjunction q1 ^ : : : ^ qn, qi
pi ff(pi ) = true, :pi otherwise. Let 'V disjunction formulas 'ff
ff 2 V 0 . (We take empty disjunction formula false.) Notice future reference
'V [V provably equivalent 'V _ 'V . Conversely, every propositional formula
mentions primitive propositions fp1 ; : : : ; pn g, corresponding
subset F consists truth assignments make true.
define binary relation > F follows: V > V 0 iff AX ` ) ('V 'V ).
claim > modular, qualitative, strict partial order F . fact >
irre exive follows easily L2; fact orderly follows L4; fact
qualitative follows L3; transitivity follows fact > qualitative
orderly, Lemma 2.4; modularity follows L5. arguments straightforward. prove fact > qualitative here, leave remaining arguments
reader.
Suppose V1 ; V2 ; V3 2 F , (V1 [ V2 ) > V3 , (V1 [ V3 ) > V2 . assumptions
definition F imply AX ` ) (('V _ 'V ) 'V ) AX ` )
(('V _ 'V ) 'V ). L3 straightforward propositional reasoning, get
AX ` ) ('V ('V _ 'V )), V1 > (V2 [ V3), desired.
Lemma 2.6, total preorder >0 F > strict partial order
determined >0 . Theorem 2.10(a), total preorder W >0
agree F . Since 0 strict partial order determined s, follows 0
> agree. Since total preorder, Lemma 2.9, > agree. Let = (W; ; ).
claim formula 'j one basic likelihood formulas
subformula ', j= 'i iff 'j conjunct . suppose 'j form 0 .
'j conjunct , clearly AX ` ) ( 0 ). Thus, > definition,
construction. Since consist worlds W
0 , respectively, true, follows (M; w) j= 0 . hand, :'j
conjunct , AX ` ) :( 0 ). must (M; w) j= :( 0 ),
(M; w) j= 0 , arguments would imply > ,
AX ` ) 0 , contradicting consistency .
Thus, satisfies , hence '.
1

2

1

2

0

1

1

3

2

3

2

1

2

2

0

0

0

0

20

fiRelative Likelihood Partially-Ordered Preferential Structures

Theorem 3.1: AX sound complete axiomatization language L respect

preferential structures.
Proof: Again, soundness proved main text, consider completeness.
ideas much spirit proof Theorem 3.2. take consist
N = 2n truth assignments primitive propositions. However, since plan
apply part (b) Theorem 2.10, longer take W = . Rather, take W consist
2n copies truth assignments . precisely, let W consist N 2n
worlds form wffi , = 1; : : : ; 2n ff 2 . Let F consist subsets
W correspond subsets ; is, V 2 F iff exists V 0
V = fwffi : = 1; : : : ; 2n ; ff 2 V 0 g. Clearly, F finite algebra N elements,
nonempty set F least 2log(jFj)
elements.
define strict partial order > F proof Theorem 3.1: V > V 0 iff
AX ` ) 'V 'V . before, > orderly qualitative strict partial order F .
necessarily modular, since longer L5.
Theorem 2.10(b), partial preorder W > agree
F . Let = (W; ; ), (wffi ) = ff. proof Theorem 3.2,
show j= . .
n

n

n

n

log(jF j)

0

noted earlier, Daniel Lehmann found another proof Theorem 3.1, using
results (Kraus et al., 1990). show formula L consistent AX
satisfiable, first translates formula conditional logic (using Proposition 4.3).
follows representation theorem (Kraus et al., 1990) translated
formula satisfiable preferential structure. original formula satisfiable
structure. proof allows us avoid using Theorem 2.10 altogether. However,
feel Theorem 2.10 gives insight connection partial orders worlds
partial orders sets worlds, thus interest right.

Proposition 3.4: formula satisfiable totally preordered preferential structure,
satisfiable totally preordered preferential structure one world per
truth assignment.
Proof: follows immediately completeness proof Theorem 3.2; structure
constructed proof one world per truth assignment.
Lemma 4.1: W finite, best([[ ] ) [ '] iff u 2 [ :' ^ ] ,
exists world v 2 [ ' ^ ] v u v dominates [ :' ^ ] .
Proof: Suppose best([[ ] ) [ '] . u 2 [ :' ^ ] , cannot u 2
best([[ ] ), since best([[ ] ) [ '] . Since W finite, exists world v 2 best([[ ] )
v u. Since v 2 best([[ ] ), v dominates [ :' ^ ] . Conversely,
suppose u 2 [ :' ^ ] , exists world v 2 [ ' ^ ] v u
v dominates [ :' ^ ] . u 2 best([[ ] ), must u 2 [ '] , not,
exists world v 2 [ ' ^ ] v u, contradicting assumption
u 2 best([['] ).
21

fiHalpern

Lemma 4.2: structures , j= ! ' iff j= !0 '.
Proof: Suppose j= ! '. definition, means u 2 [ :' ^ ] ,
exists world v 2 [ ' ^ ] v u v dominates [ :' ^ ] . immediately
follows (a) [ ' ^ ] = ; [ :' ^ ] = ; (b) [ ' ^ ] 6= ;,
definition j= ' ^ :' ^ . follows (a) [ ' ^ ] = ;
[ ] = ;, j= K : , (b) [ ' ^ ] 6= ; j= ' ^ :' ^ .
Thus, j= K : _ (' ^ :' ^ ); i.e., j= !0 .
converse follows equally easily. Suppose j= !0 '. Clearly j= K :
trivially u 2 [ :' ^ ] , exists world v 2 [ ' ^ ]
v u v dominates [ :' ^ ] . hand, j= ' ^ :' ^ ,
follows definition u 2 [ :' ^ ] , exists world v 2 [ ' ^ ]
v u v dominates [ :' ^ ] . Either way j= ! '.

References
Bendova, K., & Hajek, P. (1993). Possibilistic logic tense logic. Carrete, N. P., &
Singh, M. G. (Eds.), Qualitative Reasoning Decision Technologies, pp. 441{450.
Boutilier, C. (1994). Conditional logics normality: modal approach. Artificial Intelligence, 68, 87{154.
Brass, S. (1991). Deduction super-normal defaults. Proceedings 2nd International
Workshop Nonmonotonic Inductive Logics, Lecture Notes AI, Vol. 659, pp.
153{174 Berlin/New York. Springer-Verlag.
Burgess, J. (1981). Quick completeness proofs logics conditionals. Notre Dame
Journal Formal Logic, 22, 76{84.
Cayrol, C., Royer, R., & Saurel, C. (1992). Management preferences assumptionbased reasoning. IPMU '92 (4th International Conference Information Processing Management Uncertainty Knowledge-Based Systems), Lecture Notes
Computer Science, Vol. 682, pp. 13{22 Berlin/New York. Springer-Verlag.
Delgrande, J. P. (1994). preference-based approach default reasoning. Proceedings,
Twelfth National Conference Artificial Intelligence (AAAI '94), pp. 902{908.
Dershowitz, N., & Manna, Z. (1979). Proving termination multiset orderings. Communications ACM, 22 (8), 456{476.
Doyle, J., Shoham, Y., & Wellman, M. P. (1991). logic relative desire. Proc. 6th
International Symposium Methodologies Intelligent Systems, pp. 16{31.
Dubois, D., & Prade, H. (1990). introduction possibilistic fuzzy logics.
Shafer, G., & Pearl, J. (Eds.), Readings Uncertain Reasoning, pp. 742{761. Morgan
Kaufmann, San Francisco, Calif.
22

fiRelative Likelihood Partially-Ordered Preferential Structures

Dubois, D., & Prade, H. (1991). Possibilistic logic, preferential models, non-monotonicity
related issues. Proc. Twelfth International Joint Conference Artificial Intelligence (IJCAI '91), pp. 419{424.
Fari~nas del Cerro, L., & Herzig, A. (1991). modal analysis possibilistic logic.
Symbolic Quantitative Approaches Uncertainty, Lecture Notes Computer
Science, Vol. 548, pp. 58{62. Springer-Verlag, Berlin/New York.
Fine, T. L. (1973). Theories Probability. Academic Press, New York.
Freund, M. (1993). Injective models disjunctive relations. Journal Logic Computation, 3 (3), 231{247.
Friedman, N., & Halpern, J. Y. (1994). complexity conditional logics. Principles
Knowledge Representation Reasoning: Proc. Fourth International Conference
(KR '94), pp. 202{213. Morgan Kaufmann, San Francisco, Calif.
Friedman, N., & Halpern, J. Y. (1997). Plausibility measures default reasoning. Journal
ACM. Accepted publication. preliminary version work appeared
Proc. National Conference Artificial Intelligence (AAAI '96), 1996, pages 1297{
1304.
Gardenfors, P. (1975). Qualitative probability intensional logic. Journal Philosophical Logic, 4, 171{185.
Geffner, H. (1992). High probabilities, model preference default arguments. Mind
Machines, 2, 51{70.
Goldszmidt, M., & Pearl, J. (1992). Rank-based systems: simple approach belief
revision, belief update reasoning evidence actions. Principles
Knowledge Representation Reasoning: Proc. Third International Conference (KR
'92), pp. 661{672. Morgan Kaufmann, San Francisco, Calif.
Halpern, J. Y., & Rabin, M. O. (1987). logic reason likelihood. Artificial
Intelligence, 32 (3), 379{405.
Hughes, G. E., & Cresswell, M. J. (1968). Introduction Modal Logic. Methuen,
London.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models cumulative logics. Artificial Intelligence, 44, 167{207.
Lewis, D. K. (1973). Counterfactuals. Harvard University Press, Cambridge, Mass.
Przymusinski, T. (1987). declarative semantics stratified deductive databses
logic programs. Minker, J. (Ed.), Foundations Deductive Databases Logic
Programming, pp. 193{216. Morgan Kaufmann, San Francisco, Calif.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, N.J.
23

fiHalpern

Spohn, W. (1988). Ordinal conditional functions: dynamic theory epistemic states.
Harper, W., & Skyrms, B. (Eds.), Causation Decision, Belief Change,
Statistics, Vol. 2, pp. 105{134. Reidel, Dordrecht, Netherlands.

24

fiJournal Artificial Intelligence Research 7 (1997) 231-248

Submitted 7/97; published 11/97

Dynamic Non-Bayesian Decision Making
Dov Monderer
Moshe Tennenholtz

dov@ie.technion.ac.il
moshet@ie.technion.ac.il

Industrial Engineering Management
Technion { Israel Institute Technology
Haifa 32000, Israel

Abstract

model non-Bayesian agent faces repeated game incomplete information Nature appropriate tool modeling general agent-environment
interactions. model environment state (controlled Nature) may change arbitrarily, feedback/reward function initially unknown. agent Bayesian,
form prior probability neither state selection strategy Nature,
reward function. policy agent function assigns action
every history observations actions. Two basic feedback structures considered.
one { perfect monitoring case { agent able observe previous
environment state part feedback, { imperfect monitoring
case { available agent reward obtained. settings
refer partially observable processes, current environment state unknown.
main result refers competitive ratio criterion perfect monitoring case.
prove existence ecient stochastic policy ensures competitive
ratio obtained almost stages arbitrarily high probability, eciency
measured terms rate convergence. shown optimal
policy exist imperfect monitoring case. Moreover, proved
perfect monitoring case exist deterministic policy satisfies long
run optimality criterion. addition, discuss maxmin criterion prove
deterministic ecient optimal strategy exist imperfect monitoring case
criterion. Finally show approach long-run optimality viewed
qualitative, distinguishes previous work area.

1. Introduction
Decision making central task artificial agents (Russell & Norvig, 1995; Wellman,
1985; Wellman & Doyle, 1992). point time, agent needs select among
several actions. may simple decision, takes place once,
complicated decision series simple decisions made. question
\what right actions be" basic issue discussed settings,
fundamental importance design artificial agents.
static decision-making context (problem) artificial agent consists set actions agent may perform, set possible environment states, utility/reward
function determines feedback agent performs particular action
particular state. problem best represented matrix columns indexed
states, rows indexed actions rewards entries. reward
function known agent say agent payoff uncertainty
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMonderer Tennenholtz

refer problem problem incomplete information(Fudenberg & Tirole, 1991).
modeling problem incomplete information one must also describe underlying assumptions knowledge agent reward function. example,
agent may know bounds rewards, may know (or partially know) underlying
probabilistic structure1 . dynamic (multistage) decision-making setup agent faces
static decision problems stages. stage agent selects action performed environment selects state. history actions states determines
immediate reward well next one-shot decision problem. history actions
states also determines next selected state. Work reinforcement learning artificial intelligence (Kaelbling, Littman, & Moore, 1996) adopted view agent
operating probabilistic Bayesian setting, agent's last action last state
determine next environment state based given probability distribution. Naturally,
learner may a-priori familiar probability distribution, existence
underlying probabilistic model key issue system's modeling. However,
assumption ultimate one. particular, much work areas AI
economics dealt non-probabilistic settings environment changes
unpredictable manner2 . agent know uence choices
selection next state (i.e., certain environment strategy),
say agent strategic uncertainty.
paper use general model representation agent-environment interactions agent payoff strategic uncertainty. deal
non-Bayesian agent faces repeated game incomplete information Nature.
repeated game Nature agent faces static decision problem
stage environment state taken action chosen opponents.
decision problem called game stress fact agent's action
state independently chosen. fact game repeated refers fact
set actions, set possible states, one shot utility function
vary time3 . said, consider agent payoff uncertainty
strategic uncertainty. is, a-priori ignorant utility function (i.e.,
game incomplete information) well state selection strategy Nature.
agent non-Bayesian sense assume probabilistic model
concerning nature's strategy sense assume probabilistic
model concerning reward function, though may assume lower upper bounds4 .
consider two examples illustrate above-mentioned notions model. Consider
1. example, agent may know probability distribution set reward functions, may assume
probability exists without assumption structure, may partial information
distribution ignorant parameters (e.g., may believe reward
function drawn according normal distribution unknown covariance matrix).
2. many intermediate cases assumed changes probabilistic nonMarkovian structure.
3. general setup, sets may vary time. useful analysis done model
changes completely arbitrary.
4. Repeated games complete information, generally, multistage games stochastic games
extensively studied game theory economics. partial list includes: (Shapley,
1953; Blackwell, 1956; Luce & Raiffa, 1957), recently (Fudenberg & Tirole, 1991; Mertens,
Sorin, & Zamir, 1995), evolving literature learning (e.g., Fudenberg & Levine 1997).
incomplete information setup player ignorant game played inspired

232

fiDynamic Non-Bayesian Decision Making

investor, , investing daily certain index stock market. daily profits
depends action (selling buying certain amount) environment state
{ percentage change price index. investor complete information
reward function knows reward realized particular
investment particular change, strategic uncertainty changes
index price. So, playing repeated game complete information
Nature strategic uncertainty.
Consider another investor, 1, invests particular mutual fund. fund invests
stock market strategy known investor. Assume
state represents vector percentage changes stocks, investor
know reward function. example, cannot say advance would profit
would buy one unit fund stock prices increase 1 percent. Thus, 1
plays repeated game incomplete information. addition 1 attempt
construct probabilistic model concerning reward function market behavior,
non-Bayesian analysis may apply him. another example, assume Bob
decide evening whether prepare tea coffee wife gets
home. wife wishes drink either tea coffee wishes ready her.
reaction Bob's wife tea coffee may depend state day,
predicted based history actions states previous days. Bob
got married cannot tell reward get wife happy makes
cup tea. course may eventually know it, decisions learning
period precisely subject paper.
example generality above-mentioned setting, consider model
Markov decision processes complete incomplete information. Markov decision
process agent's action given state determines (in probabilistic fashion) next
state obtained. is, agent structural assumption state selection
strategy. repeated game Nature without added assumptions captures fact
transition state state may depend history arbitrary way.
agent performs action state st , part feedback would u(at; st ),
u reward function. distinguish two basic feedback structures.
one { perfect monitoring case { agent able observe previous
environment state part feedback, { imperfect monitoring
case { available agent reward obtained5 . Notice
feedback structures, current state observed agent called
select action6 . investors 1 face repeated game perfect monitoring
percentage changes become public knowledge iteration.
example, Bob make decision, situation imperfect
monitoring, Bob would able observe reward behavior (e.g., whether
(Harsanyi, 1967). See Aumann Maschler (1995) comprehensive survey.
literature deals (partially) Bayesian agents. rare exceptions cited Section 6.
5. Notice former assumption popular related game theory literature (Aumann &
Maschler, 1995). Many intermediate monitoring structures may interesting well.
6. also case evolving literature problem controlling partially observable Markov
decision processes (Lovejoy, 1991; Cassandra, Kaelbling, & Littman, 1994; Monahan, 1982). contrast,
Q-learning theory (Watkins, 1989; Watkins & Dayan, 1992; Sutton, 1992) assume knowledge
current state.

233

fiMonderer Tennenholtz

says \thanks", \that's terrible", \this exactly wanted", etc.). perfect
monitoring case, Bob able observe wife's state (e.g., whether came home
happy, sad, nervous, etc.) addition reward. cases Bob (like investors)
able observe wife's state making decision particular day.
Consider case one stage game Nature, utility function
known, agent cannot observe current environment state selecting
action. agent choose action? Work decision making uncertainty
suggested several approaches (Savage, 1972; Milnor, 1954; Luce & Raiffa, 1957; Kreps,
1988). One approaches maxmin (safety-level) approach. According
approach agent would choose action maximizes worst case payoff. Another
approach competitive ratio approach (or additive variant, termed minmax
regret decision criterion (Milnor, 1954). According approach agent would choose
action minimizes worst case ratio payoff could obtained
known environment state payoff would actually obtain.7 Returning
back example, Bob would known actual state wife, could choose
action maximizes payoff. Since hint state, go ahead
choose action minimizes competitive ratio. example, action leads
competitive ratio two, Bob guarantee payoff would get
half payoff could gotten known actual state wife.
Given repeated game incomplete information Nature, agent would
able choose one stage optimal action (with respect competitive ratio
maxmin value criteria) stage, since utility function initially unknown. So,
Bob initially know reward would receive actions function
wife's state, able simply choose action guarantees best
competitive ratio. calls precise definition long-run optimality criterion.
paper mainly concerned policies (strategies) guaranteeing optimal
competitive ratio (or maxmin value) obtained stages. interested
particular ecient policies, eciency measured terms rate convergence.
Hence Bob's case, interested policy adopted Bob would guarantee
almost day, high probability, least payoff guaranteed action
leading competitive ratio. Moreover, Bob wait much
start getting type satisfactory behavior.
Section 2 define mentioned setting introduce preliminaries.
Sections 3 4 discuss long-run competitive ratio criterion: Section 3 show
even perfect monitoring case, deterministic optimal policy exist.
However, show exists ecient stochastic policy ensures
long-run competitive ratio criterion holds high probability. Section 4 show
stochastic policies exist imperfect monitoring case. Section 5
prove perfect imperfect monitoring cases exists deterministic
ecient optimal policy long-run maxmin criterion. Section 6 compare
notions long-run optimality criteria appearing related literature.
particular, show approach long-run optimality interpreted
7. competitive ratio decision criterion found useful settings on-line
algorithms (e.g., Papadimitriou & Yanakakis, 1989).

234

fiDynamic Non-Bayesian Decision Making

qualitative, distinguishes previous work area. also discuss
connections work work reinforcement learning.

2. Preliminaries
(one-shot) decision problem (with payoff certainty strategic uncertainty) 3-tuple
=< A; S; u >, finite sets u real-valued function defined
u(a; s) > 0 every (a; s) 2 . Elements called actions
called states. u called utility function. interpretation numerical
values u(a; s) context-dependent8 . Let nA denote number actions A, let nS
denote number states let n = max(nA ; nS ).
above-mentioned setting classical static setting decision making,
uncertainty actual state nature (Luce & Raiffa, 1957). paper
deal dynamic setup, agent faces decision problem D, without
knowing utility function u, infinite number stages, = 1; 2; : : :.
explained introduction, setting enables us capture general dynamic nonBayesian decision-making contexts, environment may change behavior
arbitrary unpredictable fashion. mentioned introduction, best captured
means repeated game Nature. state environment point
plays role action taken Nature corresponding game. agent knows
sets , know payoff function u.9 dynamic decision problem
(with payoff uncertainty strategic uncertainty) therefore represented agent
pair DD =< A; > finite sets10. stage t, Nature chooses state st 2 .
agent, know chosen state, chooses 2 A, receives u(at; st).
distinguish two informational structures. perfect monitoring case, state
st revealed agent alongside payoff u(at; st). imperfect monitoring case,
states revealed agent. generic history available agent stage +1
denoted ht . perfect monitoring case, ht 2 Htp = (A R+ )t , R+ denotes
set positive real numbers. imperfect monitoring case, ht 2 Htimp = (A R+ )t.
particular case = 0 assume H0p = H0imp = feg singleton containing
p
imp = [1 H imp . symbol H
empty history e. Let H p = [1
t=0 Ht let H
t=0
used H p H imp . strategy11 agent dynamic decision problem
function F : H ! (A) , (A) denotes
P set probability measures A.
is, every ht 2 H , F (ht ) : ! [0; 1] a2A F (ht )(a) = 1. words,
agent observes history ht chooses at+1 randomizing amongst actions,
probability F (ht )(a) assigned action a. strategy F called pure F (ht )
probability measure concentrated singleton every 0.
Sections 2{4 strategy recommended agent chosen according \longrun" decision criterion induced competitive ratio one-stage decision criterion.
8. See discussion Section 6.
9. results paper remain unchanged agent initially know set , rather
upper bound nS .
10. Notice need include explicit transition function representation. due
fact non-Bayesian setup every transition possible.
11. Strategy decision theoretic concept. coincides term policy used control theory
literature, term protocol used distributed systems literature.

235

fiMonderer Tennenholtz

competitive ratio decision criterion, described below, may used agent
faces decision problem once, knows payoff function u well
sets . \reasonable" decision criteria could used instead.
One maxmin decision criterion discussed Section 5, another
minmax regret decision criterion (Luce & Raiffa, 1957; Milnor, 1954). latter
simple variant competitive ratio (and treated similarly), therefore
treated explicitly paper.
every 2 let (s) maximal payoff agent get state s.

(s) = max
u(a; s):
a2A
every 2 2 define

c(a; s) = uM(a;(ss)) :

Denote c(a) = maxs2S c(a; s), let





CR = min
c(a) = min
max c(a; s) :
a2A
a2A s2S
CR called competitive ratio =< A; S; u >. action CR = c(a)
called competitive ratio action, short CR action. agent chooses
1 fraction could gotten,
CR action guarantees receiving least CR
1
known state s. is, u(a; s) CR (s) every 2 . agent cannot guarantee
bigger fraction.
long-run decision problem, non-Bayesian agent form prior probability
way Nature choosing states. Nature may choose fixed sequence states or,
generally, use probabilistic strategy G, G : Q ! (S ), Q = [1
t=0 Qt =
t. Nature viewed second player knows reward function.
[1
(



)
t=0
strategy may course refer whole history actions states given point
may depend payoff function.
payoff function u pair probabilistic strategies F; G, G depend u,
generate probability measure = F;G;u set infinite histories Q1 = (A )1
endowed natural measurable structure. event B Q1 denote
probability B according (B ) Prob (B ). precisely, probability
measure uniquely defined values finite cylinder sets: Let : Q1 !
St : Q1 ! coordinate random variables contain values actions
states selected agent environment stage (respectively). is,
At(h) = St(h) = st every h = ((a1; s1); (a2; s2); : : :) Q1 . every 1
every ((a1; s1); : : :; (aT ; sT )) 2 QT ,

Prob ((At; St) = (at; st) 1 ) =


0



t=1

F ('t,1)(at )G( t,1)(st );

'0 empty histories, 2
t,1 = ((a1; s1 ); : : :; (at,1; st,1)) ;

236

fiDynamic Non-Bayesian Decision Making

definition 't,1 depends monitoring structure. perfect monitoring
case,
't,1 = ((a1 ; s1; u(a1; s1)); : : :; (at,1; st,1; u(at,1; st,1))) ;
imperfect monitoring case
't,1 = ((a1; u(a1; s1)); : : :; (at,1; u(at,1; st,1))) :
define auxiliary additional random variables Q1 . P
Let Xt = 1 c(At ; St) CR Xt = 0 otherwise, let NT = Tt=1 Xt .12 Let > 0.
strategy F -optimal exists integer K every payoff function u
every Nature's strategy G

Prob (NT (1 , )T every K ) 1 ,
(1)
= F;G;u . strategy F optimal -optimal > 0.
Roughly speaking, NT measures number stages competitive ratio (or
better value) obtained first iterations. -optimal strategy
exists number K , system runs K iterations get high
probability NT close 1 (i.e., almost iterations good ones). optimal

strategy guarantee get close wish situation iterations
good ones, probability high wish. Notice require
above-mentioned useful property hold every payoff function every strategy
Nature. strong requirement consequence non-Bayesian setup; since
clue reward function strategy selected Nature (and
strategy may yield arbitrary sequences states reached), best policy would
insist good behavior behavior adopted Nature. Notice however
two relaxations introduced here; require successful behavior stages,
whole process would successful (very high) probability.
major objective find policy enable (1) hold every dynamic
decision problem every Nature strategy. Moreover, wish (1) hold small enough
K . K small agent benefit obtaining desired behavior already
early stage. 13 subject following section. complete section
useful technical observation. show strategy F -optimal satisfies
optimality criterion (1) every reward function every stationary strategy
nature, stationary strategy defined sequence states z = (st )1
t=1 .
strategy Nature chooses st stage t, independent history. Indeed, assume F
strategy (1) holds every reward function every stationary strategy
Nature, show F -optimal.
Given payoff function u strategy G, -optimality respect stationary
strategies implies = F;G;u ,
Prob (NT (1 , )T every K )jS1; S2; : : :) 1 , ;
12. Note function c(a; s) depends payoff function u therefore random variables
Xt Nt .
13. interested reader may wish think long-run optimality criteria view original work
PAC learning (Valiant, 1984). setting, PAC learning, wish obtain desired behavior,
situations, high probability, relatively fast.

237

fiMonderer Tennenholtz

probability one. Therefore

Prob(NT (1 , )T every K ) 1 , :
Roughly speaking, captures fact non-Bayesian setting
need present strategy good sequence states chosen Nature,
regardless way chosen.

3. Perfect Monitoring

section present main result. result refers case perfect monitoring, shows existence -optimal strategy case. also guarantees
desired behavior obtained polynomially many stages. result constructive. first present rough idea strategy employed proof. utility
function known agent could use competitive ratio action. Since
utility function initially unknown agent use greedy strategy,
selects action optimal far competitive ratio concerned, according
agent's knowledge given point. However, agent try time time
sample random action.14 strategy chooses right tradeoff exploration
exploitation phases order yield desired result. careful analysis needed
order prove optimality related strategy, fact yields desired
result polynomially many stages.
introduce main theorem.

Theorem 3.1: Let DD =< A; > dynamic decision problem perfect monitoring.

every > 0 exists -optimal strategy. Moreover, -optimal strategy
chosen ecient sense K (in (1)) taken polynomial
max(n; 1 ).

Proof: Recall nA nS denote number actions states respectively,
n = max(nA ; nS ). proof assume simplicity n = nA = nS .
slight modifications required removing assumption. Without loss generality,
< 1. define strategy F follows: Let = 8 . is,

1
= 8:
stage 1 construct matrices UTF ; CTF subset actions WT
following way: Define U1F (a; s) = a; s. stage > 1, ,1
performed stage , 1, sT ,1 observed, update U replacing
(aT ,1; sT ,1) entry u(aT ,1; sT ,1). stage 1, UTF (a; s) = , define
F b;s)
CTF (a; s) = 1. UTF (a; s) =
6 , CTF (a; s) = maxfb:UTF (b;s)6=g UUTTF ((a;s
) . Finally WT set
2 minb2A maxs2S CTF (b; s) obtained. refer elements WT
temporarily good actions stage . Let (Zt)t1 sequence i.i.d. f0; 1g random
14. use uniform probability distribution select among actions exploration phase. result
obtained different exploration techniques well.

238

fiDynamic Non-Bayesian Decision Making

variables Prob(Zt = 1) = 1 , M1 . sequence generated part strategy,
independent observed history. stage, choosing action,
agent ips coin, independently past observations. stage agent observes
Zt. Zt = 1, agent chooses action Wt randomizing equal probabilities.
Zt = 0 agent randomizes equal probabilities amongst actions A.
complete description strategy F . Let u given payoff function, let (st)1
t=1
given sequence states. proceed show (1) holds K upper
integer value ff = max(ff1 + 2; ff2 + 2),


256
ff1 = 128
2 ln 3

n2 (n 8 + 1) ln
ff2 =
3
4



2
2n + 1


:
P

Recall Xt = 1 c(At; st ) CR Xt = 0 otherwise, NT = Tt=1 Xt .
slight change notation, denote P = Prob probability measure induced
F , u sequence states (A f0; 1g)1 (where f0; 1g corresponds Zt
values).
Let " = 8 . Define

BK =

(T
X

t=1

)


1
Zt 1 , , " K :


Roughly speaking, BK captures cases temporarily good actions selected
stages.
(Chernoff, 1952) (see also (Alon, Spencer, & Erdos, 1992)), every ,

P


X
t=1

!

2
Zt < (1 , 1 , ")T e, " 2T :



Recall given set , denotes complement .
Hence,
!
1

1
2
X
X
X
1
Zt < (1 , , ")T
e, " 2T :
P (BK ) P
Therefore
Since K > ff1 ,
Define:

=k

P (BK )

t=1
Z1

k ,1



e, " 2T dT = "22 e,
2

P (BK ) < 2

=K

"2 (K ,1)

2

:
(2)

LK = fNT (1 , )T every K g:
Roughly speaking, LK captures cases competitive ratio actions (or better

actions regard) selected stages.
order prove F -optimal (i.e., (1) satisfied), prove

P (LK ) <
239

(3)

fiMonderer Tennenholtz

(2) suces prove

(4)
P (LK jBK ) 2
define every 1, 2 2 six auxiliary random variables, Yt ; Rt; Yts ; Rst; Yts;a ; Rs;a
.
Let Yt = 1 whenever Zt = 1 Xt = 0, Yt = 0 otherwise. Let

RT =


X
t=1

Yt :

every 2 let Yts = 1 whenever Yt = 1 st = s, Yts = 0 otherwise. Let

X
Yts :
t=1
Yts;a = 1

RsT =

every 2 every 2 A, let
whenever Yts = 1 = a,
s;a
Yt = 0 otherwise. Let

X
Rs;a
=
Yts;a :

t=1

Let g integer value 34 K . show

P (LK jBK ) P(9T K ; RT gjBK )

(5)

order prove (5) show

LK \ BK f9T K ; RT g g \ BK :
Indeed, w path BK every K RT < g , then, w, every
K,

X
X
NT
Xt VT , Yt;
1tT;Zt=1

t=1

VT denotes number stages 1 Zt = 1. Since w 2 BK ,
N (1 , 1 , ")T , R > (1 , 1 , ")T , g








every K . Since M1 = " = 8 g 34 K , NT (1 , )T every K . Hence,
w 2 LK .
(5) implies suces prove

P(9T K ; RT gjBK ) 2
Therefore suces prove every 2 ,


P 9T K; RsT ng jBK 2n :
Hence suces prove every 2 every 2 A,
240

(6)

fiDynamic Non-Bayesian Decision Making



= P 9T K;

g
Rs;a
n2 jBK



2n 2

(7)

g
order prove (7) , note inequality Rs;a
n2 satisfied gw,
c(a; s) > CR nevertheless considered good action least n2 stages
b;s) > CR. b
1 (w.l.o.g. assume ng2 integer). Let b 2 satisfy uu((a;s
)
ever played stage st = s, 62 Wt t. Therefore




P 9T K; b played first ng2 stages st = sjBK :
Hence
(1 , x1 )x+1 e,x x 1,

ut



1, 1

nM

g2
n

:

g
e, n2 (nM +1) < 2n 2 :

Theorem 3.1 shows ecient dynamic non-Bayesian decisions may obtained
appropriate stochastic policy. Moreover, shows -optimality obtained
time (low degree) polynomial max(n; 1 ). interesting question whether
similar results obtained pure/deterministic strategy. following example
shows, deterministic strategies suce job.
give example agent optimal pure strategy.

Example 1: Let = fa1; a2g = fs1; s2g. Assume negation agent
optimal pure strategy f .

Consider following two decision problems whose rows indexed actions
whose columns indexed states:

D1 =

1 10
30 2

D2 =

1 30
10 2

corresponding ratio matrices:

C1 =

30 1
1 5

C2 =

10 1
1 15
241

!

!

!
!

fiMonderer Tennenholtz

Assume addition cases Nature uses strategy g , defined follows:
g (ht) = si f (ht) = ai , = 1; 2. is, every t, (at; zt ) = (a1; s1) (at; zt) = (a2; s2),
zt denote action state selected stage t, respectively. Let < 0:25.
Let NTi denote NT decision problem i. Since f -optimal, exists K
every K , NT1 (1 , )T NT2 (1 , )T . Note also sequence
((at; zt))t1 generated cases. NK1 (1 , )K implies (a2 ; s2) used
half stages 1; 2; : : :; K . hand, NK2 (1 , )K implies (a1; s1)
used half stages 1; 2; : : :; K . contradiction.
ut
analytical completeness, end section proving existence optimal
strategy (and merely -optimal strategy). optimal strategy obtained
utilizing -optimal strategies (whose existence proved Theorem 3.1) intervals
stages sizes converge infinity, ! 0.

Corollary 3.2: every dynamic decision problem perfect monitoring exists
optimal strategy.

Proof: 1, let Fm

sequence limm!1 = 0. Let
every 1

-optimal strategy, (m )1 decreasing
m=1
2
(Km )1


increasing
sequence
integers
m=1






Prob NT (1 , 2 )T every Km 1 , 2m ;



Pm
K
Km+1 2 j=1 j :

Let F strategy 1 utilizes Fm stages K0 + : : : + Km,1 + 1
K0 + : : : + Km,1 + Km, K0 = 0. easily verified F optimal.

ut

4. Imperfect Monitoring

proceed give example imperfect monitoring case, suciently
small > 0, agent -optimal strategy.

Example 2 (Non-existence -optimal strategies imperfect monitoring case)

Let = fa1; a2g, = fs1 ; s2; s3g. Let < 0 , 0 defined end
proof. Assume negation exists -optimal strategy F . Consider
following two decision problems whose rows indexed actions whose columns
indexed states:
!
2

2
b
2
c
D1 = b c
242

fiDynamic Non-Bayesian Decision Making

!

2a 2b 2c

D2 =

b c

a; b c positive numbers satisfying: > 4b > 16c. = 1; 2, let
Ci = (ci (a; s))a2A;s2S ratio matrices. is:

C1 =

1 1 1
2 2 2

!

1 1 2ac
2a 2b 1
b c

C2 =

!

Note a1 unique CR action D1 a2 unique CR action D2.
Assume Nature uses strategy G randomizes stage equal probabilities
(of 13 ) amongst 3 states. Given strategy Nature, agent cannot distinguish
two decision problems, even knows Nature's strategy told
one chosen. implies 1 2 probability measures induced
F G (A )1 decision problems D1 D2 respectively, every
2 f1; 2g, distribution stochastic process (NTi )1
=1 respect j , j 2 f1; 2g,
depend j . is, every 1








Prob1 Nti 2 Mt = Prob2 Nti 2 Mt ; 2 f1; 2g (8)
every sequence (Mt )Tt=1 Mt f0; 1; : : :; tg 1 .
give complete proof (8), rather illustrate proving representing
case. reader easily derive complete proof. show

Prob1 (N21 = 0) = Prob2 (N21 = 0)

(9)

Indeed, j = 1; 2,

Probj (N21 = 0) = 31

3
X

k=1

F (e)(a2)F (a2 ; uj (a2 ; sk ))(a2)

(10)

Let : f1; 2; 3g ! f1; 2; 3g defined (1) = 3, (2) = 1, (3) = 2.

u1(a2 ; sk ) = u2 (a2; s(k) )
every 1 k 3. Therefore (10) implies (9).
F -optimal, exists integer K probability least
1 , respect 1 , hence respect 2 , NT1 (1 , )T every K .
implies probability least 1 , , a1 played least 1 ,
stages time , K , particular = K . choose integer K
suciently large according Law Large Numbers, Nature chooses
243

fiMonderer Tennenholtz

s3 least 31 , stages stage K probability least 1 , . Let CR2
c2t denote CR ct decision problem 2, respectively.
> CR = max( 2a ; 2b ):
2
2c
b c
Therefore, = a1, C2(At ; St) CR2 St =
6 s3. Hence,
2
probability least 1 , 2 , + (1 , )( 3 + ) stages c2t CR2.
Therefore F cannot -optimal, choose 0 20 < 1 , 0

ut

0 + (1 , 0)( 23 + 0 ) < 1 , 0 :

5. Safety Level

sake comparison discuss section safety level (known also maxmin)
criterion. Let =< A; S; u > decision problem. Denote

v = max
min
u(a; s)
v called safety level agent (or maxmin value). Every action
u(a; s) v every called safety level action. consider imperfect
monitoring model dynamic decision problem < A; >. Every sequence states
z = (st)1
t=1 st 2 every 1 every pure strategy f agent induce
z;f 1
sequence actions (at)1
t=1 corresponding sequence payoffs (ut )t=1 ,
z;f
uz;f
= u(at ; st) every 1. Let NT denote number stages stage
agent's payoff exceeds safety level v . is,
NTz;f = #f1 : uz;f
vg

(11)

say f safety level optimal every decision problem every sequence
states,
lim 1 N z;f = 1;
!1

convergence holds uniformly w.r.t. payoff functions u sequences states
. is, every > 0 exists K = K ( ) NTz;f (1 , )T every
K every decision problem < A; S; u > every sequence states z .
Proposition 5.1: Every dynamic decision problem possesses safety level optimal strategy
imperfect monitoring case, consequently perfect monitoring case. Moreover,
optimal strategy chosen strongly ecient sense every
sequence states exists nA , 1 stages agent receives payoff
smaller safety level, nA denotes number actions.
Proof: Let n = nA . Define strategy f follows: Play actions
first n stages. every n + 1, every history h = hT ,1 =
244

fiDynamic Non-Bayesian Decision Making

((a1; u1); (a2; u2; : : :; (aT ,1; uT ,1)) define f (h) 2 follows: 2 A, let vTh (a) =
min ut , min ranges stages , 1 = a. Define f (h) = ,
maximizes vTh (a) 2 A. obvious every sequence states
1
z = (st )1
t=1 n , 1 stages u(at ; st) < v , (at )t=1
z;f
sequence actions generated f sequence states. Hence NT , n,
NTz;f defined (11). Thus K () = n , T1 NTz;f 1 , every K ( ).

ut

6. Discussion

Note notations established Section 5, Proposition 5.1 well, remain
unchanged assume utility function u takes values totally pre-ordered
set without group structure. is, approach decision making qualitative
(or ordinal). distinguishes work previous work non-Bayesian repeated
games, used probabilistic safety level criterion basic solution concept
one shot game15. works, including (Blackwell, 1956; Hannan, 1957; Banos, 1968;
Megiddo, 1980), recently (Auer, Cesa-Bianchi, Freund, & Schapire, 1995; Hart
& Mas-Colell, 1997), used several versions long-run solution concepts, based
optimization average utility values time. is, P
papers
goal find strategies guarantee high probability T1 Tt=1 u(At; St)
close vp .
work is, best knowledge, first introduce ecient dynamic
optimal policy basic competitive ratio context. study results sections 2-4
easily adapted case qualitative competitive ratio well. approach,
utility function takes values totally pre-ordered set G addition assume
regret function, maps G G pre-ordered set H . g1 ; g2 2 G, (g1; g2)
level regret agent receives utility level g1 rather g2. Given
action state s, regret function determine maximal regret, c(a; s) 2 H
agent action performed state s. is,

c(a; s) = max (u(a; s); u(b; s));
b ranges actions.
qualitative regret action maximal regret action states.
optimal qualitative competitive ratio obtained using action
qualitative regret minimal. Notice arithmetic calculations needed (or make
sense) qualitative version. results adapted case qualitative
competitive ratio. ease exposition, however, used quantitative version
model, numerical utility function represents regret function.
15. probabilistic safety value, vp , agent decision problem =< A; S; u > maxmin
value max ranges mixed actions.

vp = maxq2(A) mins2S

X

a2A

u(a; s)q(a);

(A) set probability distributions q A.

245

fiMonderer Tennenholtz

work relevant research reinforcement learning AI. Work area,
however, dealt mostly Bayesian models. makes work complementary
work. wish brie discuss connections differences
work existing work reinforcement learning.
usual underlying structure reinforcement learning literature environment changes result agent's action based particular probabilistic
function. agent's reward may probabilistic well.16 notation, Markov
decision process (MDP) repeated game Nature complete information
strategic certainty, Nature's strategy depends probabilistically last action
state chosen17 . Standard partially observable MDP (POMDP) described similarly introducing level monitoring perfect imperfect monitoring.
addition, bandit problems basically modeled repeated games Nature
probabilistic structural assumption Nature's strategy , strategic uncertainty values transition probabilities. example, Nature's action
play role state slot machine basic bandit problem. main difference classical problem problem discussed setting
state slot machine may change setting totally unpredictable manner (e.g.,
seed machine manually changed iteration). say
solving learning problem solved problem reinforcement learning
MDP, POMDP, bandit problems. later settings, optimal strategy behave
poorly relative strategies obtained theory reinforcement learning, take
particular structure account.
non-Bayesian qualitative setup call optimality criteria differ
ones used current work reinforcement learning. Work reinforcement learning
discusses learning mechanisms optimize expected payoff long run.
qualitative setting (as described above) long-run expected payoffs may make much
sense. optimality criteria expresses need obtain desired behavior
stages. One easily construct examples one approaches favorite
one. emphasis obtaining desired behavior relatively short run.
Though, analytical results reinforcement learning concerned
eventual convergence desired behavior, policies shown quite
ecient practice.
addition previously mentioned differences work work reinforcement learning, wish emphasize much work POMDP uses information
structures different discussed paper. Work POMDP usually
assumes observations current state may available (following presentation Smallwood & Sondik, 1973), although observations previous state
discussed well (Boutilier & Poole, 1996). Recall case perfect monitoring
previous environment state revealed, immediate reward revealed
prefect imperfect monitoring. may useful consider also situations
16. results presented paper extended case randomness
reward obtained agents well.
17. Likewise, stochastic games (Shapley, 1953) considered repeated games Nature
partial information Nature's strategy. matter one redefine concept state
games. state pair (s; a), state system action opponent.

246

fiDynamic Non-Bayesian Decision Making

(partial) observations previous state current state revealed time
time. may used setting completely clear, may serve
subject future research.

References

Alon, N., Spencer, J., & Erdos, P. (1992). Probabilistic Method. Wiley-Interscience.
Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. (1995). Gambling rigged
casino: adversial multi-armed bandit problem. Proceedings 36th Annual
Symposium Foundations Computer Science, pp. 322{331.
Aumann, R., & Maschler, M. (1995). Repeated Games Incomplete Information.
MIT Press.
Banos, A. (1968). pseudo games. Annals Mathematical Statistics, 39, 1932{1945.
Blackwell, D. (1956). analog minimax theorem vector payoffs. Pacific Journal
Mathematic, 6, 1{8.
Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observable
decision processes using compact representations. Proceedings 13th National
Conference Artificial Intelligence, pp. 1168{1175.
Cassandra, A., Kaelbling, L., & Littman, M. (1994). Acting optimally partially observable stochastic domain. Proceedings 12th National Conference Artificial
Intelligence, pp. 1023{1028.
Chernoff, H. (1952). measure asymptotic eciency tests hypothesis based
sum observations. Annals Mathematical Statistics, 23, 493{509.
Fudenberg, D., & Levine, D. (1997). Theory learning games. miemo.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Hannan, J. (1957). Approximation bayes risk repeated play. Dresher, M., Tucker,
A., & Wolfe, P. (Eds.), Contributions Theory Games, vol. III (Annals
Mathematics Studies 39), pp. 97{139. Princeton University Press.
Harsanyi, J. (1967). Games incomplete information played bayesian players, parts
i, ii, iii. Management Science, 14, 159{182.
Hart, S., & Mas-Colell, A. (1997). simple adaptive procedure leading correlated
equilibrium. Discussion paper 126, Center Rationality Interactive Decision
Theory, Hebrew University.
Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. Journal
Artificial Intelligence Research, 4, 237{258.
Kreps, D. (1988). Notes Theory Choice. Westview press.
247

fiMonderer Tennenholtz

Lovejoy, W. (1991). survey algorithmic methods partially observed markov decision
processes. Annals Operations Research, 28 (1{4), 47{66.
Luce, R. D., & Raiffa, H. (1957). Games Decisions- Introduction Critical Survey.
John Wiley Sons.
Megiddo, N. (1980). repeated games incomplete information played nonbayesian players. International Journal Game Theory, 9, 157{167.
Mertens, J.-F., Sorin, S., & Zamir, S. (1995). Repeated games, part a. CORE, DP-9420.
Milnor, J. (1954). Games Nature. Thrall, R. M., Coombs, C., & Davis, R.
(Eds.), Decision Processes. John Wiley & Sons.
Monahan, G. (1982). survey partially observable markov decision processes: Theory,
models algorithms. Management Science, 28, 1{16.
Papadimitriou, C., & Yannakakis, M. (1989). Shortest Paths Without Map. Automata,
Languages Programming. 16th International Colloquium Proceedings, pp. 610{
620.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.
Savage, L. (1972). Foundations Statistics. Dover Publications, New York.
Shapley, L. (1953). Stochastic games. Proceeding National Academic Sciences
(USA), 39, 1095{1100.
Smallwood, R., & Sondik, E. (1973). optimal control partially observable markov
processes finite horizon. Operations Research, 21, 1071{1088.
Sutton, R. (1992). Special issue reinforcement learning. Machine Learning, 8 (3{4).
Valiant, L. G. (1984). theory learnable. Comm. ACM, 27 (11), 1134{1142.
Watkins, C., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning, 8 (3{4),
279{292.
Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, Cambridge University.
Wellman, M., & Doyle, J. (1992). Modular utility representation decision-theoretic
planning. Proceedings first international conference AI planning systems.
Morgan Kaufmann.
Wellman, M. (1985). Reasoning preference models. Tech. rep. MIT/LCS/TR-340,
Laboratory Computer Science, MIT.

248

fiJournal Artificial Intelligence Research 7 (1997) 47-66

Submitted 10/96; published 9/97

New Look Easy-Hard-Easy Pattern
Combinatorial Search Diculty
Dorothy L. Mammen

mammen@cs.umass.edu

Tad Hogg

hogg@parc.xerox.com

Department Computer Science
University Massachusetts
Amherst, 01003, U.S.A.
Xerox Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304, U.S.A.

Abstract

easy-hard-easy pattern diculty combinatorial search problems constraints added explained due competition decrease
number solutions increased pruning. test generality explanation
examining one predictions: number solutions held fixed choice
problems, increased pruning lead monotonic decrease search cost.
Instead, find easy-hard-easy pattern median search cost even number
solutions held constant, search methods. generalizes previous observations
pattern shows existing theory explain full range
peak search cost. cases pattern appears due changes size
minimal unsolvable subproblems, rather changing numbers solutions.

1. Introduction

Recently, many authors shown solution cost various kinds combinatorial
search problems follows pattern easy-hard-easy function tightly constrained
problems are. example, pattern appears graph coloring function
average graph connectivity (Cheeseman, Kanefsky, & Taylor, 1991; Hogg & Williams,
1994), propositional satisfiability (SAT) function ratio number clauses
number variables (Cheeseman et al., 1991; Mitchell, Selman, & Levesque, 1992; Crawford
& Auton, 1993; Gent & Walsh, 1994b), constraint satisfaction problems (CSPs)
function number nogoods (Williams & Hogg, 1994) constraint tightness (Smith,
1994; Prosser, 1996).
regularity raises possibility determining, prior search, likely diculty
problems. Unfortunately, yet possible high variance associated observations. compounded fact single problem
viewed belonging variety problem classes, somewhat different transition points. Thus one important direction improvement investigate whether
simple additional parameters reduce variance allow predictions
higher confidence.
One approach question based explanation easy-hard-easy pattern
competition changes number solutions pruning unproductive
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMammen & Hogg

search paths function measure degree problems constrained. particular predicts problems many solutions tend easier,
average, fewer given number constraints. Thus, least one
aspect high variance search cost appears due variance number
solutions problems fixed degree constraint. observation motivated
introduction additional parameters describing problem structure based
precise specification number solutions (Hogg, 1996).
paper investigate generality explanation examining problems
number solutions restricted, including cases number specified
exactly either zero one. peak search cost fact arises generally
competition changes number solutions pruning, cases fixed
number solutions show peak. However, find peak continues
appear cases sophisticated search algorithms, fails appear
cases. calls question generality explanation based number
solutions, also suggests search additional problem structure parameters based
solely reducing variance number solutions likely sucient
accurately predict search cost. However, structural aspect problems likely
involved. Specifically, present data showing smallest problem's minimal
unsolvable subproblems correlates well search cost.
next section describe classes search problems. review
pattern search behavior current theoretical explanation it. following
section uncover limitations explanation examining problems
specification number solutions. shows easy-hard-easy pattern
general phenomenon suggested current explanations. suggest alternative explanation related problem structure, present data unsolvable problems
showing positive relationship problem structure parameter, minimum
size minimal unsolvable subproblem, search cost. problem structure parameter may explain differences search cost among solvable problems equal numbers
solutions, well. Finally, discuss implications observations
make suggestions obtaining better understanding greater predictability hard
search problems.

2. Classes Search Problems

common many previous studies transition phenomenon, use random binary
CSPs graph coloring example classes search problems. section describes
problems generated searched.

2.1 Random CSPs

constraint satisfaction problems used experimental results consist 10
variables three possible values one, cases, repeated experiments
problems 20 variables. Problem constraints specified number binary
nogoods, i.e., assignments pair variables considered inconsistent.
search problem find consistent complete assignment, i.e., value
variable include inconsistent pairs.
48

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

generated problems number ways fully sample range behaviors.
first method (\generate-select") generate CSPs randomly selecting specified
number binary nogoods. produce classes problems restrictions number
solutions, determine number solutions randomly generated problems
retain satisfying restrictions. example, produce class
solvable problems, solution included. Similarly, produce class
problems fixed number solutions, problems exactly specified
number solutions retained.
random generation method gives simple, uniform selection various problem classes. However, also inecient generating problems. instance,
nogoods, randomly generated problems solvable, hence requiring large
number random trials obtain even unsolvable cases.
address problem, also used ecient (\hill-climbing") methods. Specifically, generating solvable problems many nogoods, starting randomly generated unsolvable problem, removed constraints random problem became
solvable, restored number constraints removed constraints chosen randomly,
requirement problem become unsolvable again.
generating unsolvable problems nogoods, hill-climbing method started
randomly generated solvable problem, removed constraint constrained
problem least (the one whose removal increased number solutions least),
added randomly chosen constraint resulted problem fewer solutions
problem constraint removal. If, removed one constraint,
constraint could decrease number solutions, constraint increased number
solutions least chosen { slightly backwards step. speed process up,
checked one third possible constraints giving up, choosing one
increased number solutions least, starting another iteration.
methods generating problems specified requirements number
solutions also studied. One popular method solvable problems randomly
select assignment variables (a pre-specified solution) then,
random selection nogoods, avoid inconsistent pre-specified solution.
tends emphasize problems many solutions results instances
somewhat easier uniform random selection. Cha & Iwama (1995) also used
approach generating problems specific attributes, SAT problems, using AIM
generators (Asahiro, Iwama, & Miyano, 1993).
solved problems using dynamic backtracking (Ginsberg, 1993) cases,
using random variable value ordering. comparison, also searches
simple chronological backtrack instead. search cost measured number nodes
explored.

2.2 Graph Coloring

also experimented 3-coloring problem. constraint satisfaction problem
consists graph requirement assign node one three colors
pair nodes linked edge color. edge graph defines
binary nogoods problem, namely pairs assignments giving color
49

fiMammen & Hogg

two nodes connected edge. Thus edge graph gives three binary nogoods.
convenient measure number constraints , connectivity average degree
nodes graph. equal twice number edges graph divided
number nodes, edge incident two nodes. 100-node
graphs studied, number binary nogoods given 150 .
case, used simple chronological backtrack search combination
Brelaz heuristic variable value ordering (Johnson, Aragon, McGeoch, & Schevon,
1991). heuristic assigns constrained nodes first (i.e.,
distinctly colored neighbors), breaking ties choosing nodes uncolored
neighbors, remaining ties broken randomly. colors considered
fixed ordering nodes search. simple optimization, search never
changes colors selected first two nodes. changes would amount
unnecessarily repeating search permutation colors unsolvable cases.
Search cost measured number nodes explored.

3. Easy-Hard-Easy Pattern

section, present example search cost varies tightness
constraints class problems, describe behavior understood
terms changes structure problems, independent particular search
algorithms. review summary previous studies transition forms
basis comparison new results presented subsequent sections.

3.1 Example

Figure 1 shows typical example easy-hard-easy pattern function constrainedness problem. Problems many constraints tend easy
solve intermediate number dicult. fraction solvable
problems also shown Figure 1, scaled 1.0 left 0.0 right.
illustrates hard problems concentrated so-called \mushy region" (Smith
& Dyer, 1996) probability solution changing 1.0 0.0. particular,
peak search cost near \crossover point," point half problems
solvable half unsolvable. problem class, crossover point occurs
75 binary nogoods, peak dynamic backtracking solution cost occurs
85 binary nogoods.
results paper, include 95% confidence intervals (Snedecor &
Cochran, 1967). intervals estimate p
median obtained samples
given approximately percentiles 50 100= N data, N
number
samples. estimate fractions intervals given approximately
p
fraction. Finally, estimate
f 2 f (1 , f )=N , f estimated value p
means intervals approximately x 1:96= N x estimate mean
standard deviation sample. many cases paper, sucient
samples make intervals smaller size plotted points.
key point examples dicult instances within class
search problems tend concentrated near particular value constraint tightness
(here measured number binary nogoods). behavior seen
50

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost
200

150

100

50

20

40

60

80

100

120

140

Nogoods

Figure 1: Typical transition pattern. Median solution cost dynamic backtracking (solid line)

probability solution (dashed line) function number nogoods.
point represents 1000 problems 10 variables domain size 3, solved 100 times.
Error bars showing 95% confidence intervals included, cases smaller
size plotted points.

variety search methods, indicates concentration depend much
details search algorithm. Instead, appears associated change
properties problems themselves, namely solvability.

3.2 Explanation

observations raise number questions, peak search cost exists,
peak occurs near transition mostly solvable mostly unsolvable problems
thus independent particular search algorithm, behavior seen
large variety constraint satisfaction problems.
existing explanation concentration hard problems relies competition
changes number solutions amount pruning provided
problem constraints (Williams & Hogg, 1994). constraints, many solutions search usually easy. constraints added number solutions drops
rapidly, making problems harder. new constraints also increase pruning unproductive search choices, tending make search easier. constraints,
decrease number solutions overwhelms increase pruning, giving harder
problems average. Eventually last solution eliminated remains
increased pruning additional constraints, leading easier problems. Thus phase
transition, point precipitous change solvability unsolvability, less coincides peak solution cost. effects become
pronounced larger problems considered, leading sharper peaks abrupt
51

fiMammen & Hogg

transitions. qualitative description explains many features observed behavior.
pruning explanation also offered Cheeseman et al. (1991) respect
finding Hamiltonian circuits highly constrained problems.
explanation also used obtain quantitative understanding behavior.
instance, location transition region understood approximate
theory predicting cost peak occurs expected number solutions equals
one (Smith & Dyer, 1996; Williams & Hogg, 1994). example
310 possible
,10 2
assignments 10 variables problem. 2 3 = 405 possible binary
nogoods problem, counts number ways select pair variables
different assignments pair. given complete assignment 10 variables
solution provided selected binary nogoods use the,
assignment

pair variables given complete assignment. leaves 102 (32 , 1) = 360
possible choices binary nogoods. Thus expected number solutions given
,360
10

3 ,405


problems randomly selected binary nogoods. expression equals one
= 82:9, location observed cost peak. Furthermore, expected
number solutions grows exponentially number variables smaller
threshold value decreases exponentially zero larger, range
values expected number solutions near one rapidly decreases
variables added. accounts observed sharpening transition larger
problems.
quantitative success relating search cost peak transition phenomena
evaluation scaling behavior transition search cost peak (Kirkpatrick &
Selman, 1994; Gent, MacIntyer, Prosser, & Walsh, 1995).

4. Search Diculty Solvability

section take closer look behavior search cost, specifically,
examining behavior depends whether problem solution and, so,
number solutions.

4.1 Search Behavior

Figure 2 shows median dynamic backtracking solution cost solvable unsolvable
random CSPs generated described above, problems number variables n = 10
n = 20, domain size three. Except specified otherwise figure caption,
problems 10 variables generated 1000 solvable 1000 unsolvable problems
point, problems 20 variables generated 500 solvable 500 unsolvable
problems point, using \generate-select" method. also generated unsolvable
problems 10 variables 10 70 nogoods using \hill-climbing" method.
overlap range problems generated two methods show different
generation methods affect search cost.
figure clearly shows easy-hard-easy pattern solution cost solvable
unsolvable problems, problem sizes. two methods generating unsolvable
52

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost

3
10

2
10

2

4

6

8

10

12

14

m/n

Figure 2: Median solution cost using dynamic backtracking solvable (solid lines) unsolvable
(dashed dotted lines) problems number variables n = 10 (black lines)
n = 20 (gray lines) function number nogoods divided problem size, m=n.

problems generated using \generate-select" method except unsolvable problems shown dotted line, generated using \hill-climbing"
method. problems size 10, point median 1000 problems solved 100
times, except unsolvable problems generated \generate-select" m=n = 3 (30
nogoods) solvable problems m=n = 14 (140 nogoods), based 100
problems. problems size 20, point median 500 problems solved 100
times, except unsolvable problems m=n = 5 (100 nogoods) solvable problems
m=n = 12 (240 nogoods), based 15 35 problems, respectively. Error
bars showing 95% confidence intervals included, cases smaller
size plotted points.

problems give distinct curves: unsolvable problems generated \hill-climbing"
method harder generated \generate-select" method. Nonetheless,
sets problems show easy-hard-easy pattern.
Another example behavior shown Figure 3 median search
cost instances 3-coloring random graphs. contrast Figure 2, solvable
unsolvable cases similar median search costs near peaks. because,
described above, graph coloring searches unsolvable cases used symmetry
respect permutations colors avoid unnecessary search. Without optimization, costs unsolvable cases would six times greater values shown
figure. Similar peaks seen classes graphs, connected ones, although
somewhat different values .
data show random CSPs graph coloring problems exhibit easyhard-easy pattern solvable unsolvable problems considered separately.
53

fiMammen & Hogg

Cost
250
200
150
100
50
0

1

2

3

4

5

6

7



Figure 3: Median solution cost 3-coloring random graphs 100 nodes function connectivity using backtrack search Brelaz heuristic. solid dashed curves

correspond solvable unsolvable cases respectively. results started
100,000 random graphs value , additional samples generated
extremes produce least 100 samples point. random graphs,
crossover mostly solvable mostly unsolvable occurs around connectivity 4.5.
Error bars showing 95% confidence intervals included.

4.2 Solvable Problems

peak search cost solvable problems observed also seen extensively studies local-repair search methods problems generated prespecified solution (Yugami, Ohta, & Hara, 1994; Kask & Dechter, 1995; Williams & Hogg,
1994). search methods start assignment variables
problem attempt adjust solution found. Generally, methods systematic searches: never determine problem solution.
Thus empirical studies methods restricted consider solvable problems
incidentally provide useful examination properties solvable problems.
Furthermore, study satisfiability problems backtracking search consistent
peak cost solvable problems (Mitchell et al., 1992), insucient
highly constrained solvable problems make definite conclusion behavior
many constraints.
existence peak solvable problems fit explanation given
above? Certainly explanation based transition solvable unsolvable problems
cannot apply directly class solvable problems. However, competition
increased pruning decreased number solutions still applies. shown Figure 4,
number solutions solvable random CSPs size 10 first decreases rapidly
constraints added nears minimum value one, giving slower decrease.
54

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Solutions
4
10

1
10
0

20

40

60

80

100

120

140

Nogoods

Figure 4: Mean (solid) median (dashed) number solutions log scale function

number binary nogoods, solvable problems 10 variables, 3 values each, based
1000 problems generated \generate-select" method multiple 10 binary
nogoods, except 140 nogoods, based 100 problems. 0 nogoods
310 = 59049 solutions. Error bars showing 95% confidence intervals included.

Except change minimum value 0 1 solution, behavior number
solutions qualitatively similar general case including solvable
unsolvable problems. additional constraints continue increase pruning
unproductive search paths. Thus explanation given might continue apply
predicts peak point solutions drop (i.e., one
solution) rather becoming unsolvable (i.e., zero solutions).
Figure 5 evaluates idea. figure shows fraction problems
least two solutions changes function number nogoods divided problem
size random CSPs 10 20 variables. problems size 10, second
last solution disappears, average, 90 100 nogoods: median number
solutions dropped 2 90 nogoods, 1 100 nogoods (Figure 4).
peak solution cost solvable problems slightly lower this, 80
90 nogoods, close crossover point Figure 5 half solvable problems
one solution. perhaps close enough consistent explanation given
above. However, relationship hold problems size 20. class
problems, cost peak solvable problems around 180 nogoods (m=n = 9), whereas
point half problems one solution still reached
240 nogoods (m=n = 12). 180 nogoods, median number solutions 4 (mean
10.0), 240 nogoods, median still 2 (mean 1.83). inconsistent
explanation cost peak solvable problems due increasing effect
pruning given possible decrease number solutions.
55

fiMammen & Hogg

Fraction
1
0.8
0.6
0.4
0.2

2

4

6

8

10

12

14

m/n

Figure 5: Fraction problems least two solutions function number nogoods di-

vided problem size, problems size 10 (black line) size 20 (gray line). Data
problems size 10 based 1000 solvable problems created \generate-select"
method point, except 100 solvable problems m=n = 14 (140 nogoods).
Data problems size 20 based 500 solvable problems point, except
20 solvable problems m=n = 12 (240 nogoods), also created \generate-select"
method. Error bars showing 95% confidence intervals included.

Since explanation depending change insolubility apply,
pruning versus number solutions explanation fit data, factors
must work produce easy-hard-easy pattern solvable problems. suspect explanation related idea minimal unsolvable subproblems. minimal
unsolvable subproblem subproblem unsolvable, subset variables associated constraints solvable; Gent & Walsh (1996) referred
aspect SAT problems minimal unsatisfiable subset. idea
bad choices made initially, remainder problem becomes
unsolvable, unsolvability much harder determine problems others.
particular, variables involved minimal unsolvable subproblem,
harder determine subproblem unsolvable. make conjecture
cost peak solvable problems tied average size minimal unsolvable subproblem choice made results remaining problem
unsolvable.

4.3 Problems Fixed Number Solutions

interesting case behavior problems solutions shown Figures
2 3. example, Figure 6 shows solution cost problems exactly
one solution. also shows peak. observations problems zero one
56

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Cost
160
140
120
100
80
60
40

60

80

100

120

140

Nogoods

Figure 6: Median solution cost function number nogoods problems 10 variables,

3 values each, exactly one solution, generated using \generate-select" method
(solid line), hill-climbing one solution starting solvable problems
many solutions produced using \generate-select" (dotted line), solved using dynamic
backtracking. point median 1000 problems solved 100 times, except
hill-climbing generated problems 25, 30 35 nogoods \generate-select"
generated problems 140 nogoods, 100. Error bars showing 95%
confidence intervals included.

solution show even number solutions held constant, problems exhibit
easy-hard-easy pattern solution cost.
According explanation transition, number solutions held constant
increase pruning factor, giving rise monotonic decrease
search cost constraints added. Instead, see Figures 2, 3 6 even
number solutions held fixed zero one, still peak solution
cost, smaller number nogoods. Thus existing explanation capture
full range behaviors. Instead, appears factors work
producing hard problems. focusing closely factors hope gain
better understanding structure hard problems, may lead precise
predictions search cost.
also investigated effect algorithm pattern solution cost unsolvable
problems repeating search random CSPs using chronological backtrack. comparison chronological backtracking search previous dynamic backtrack search
results unsolvable problems shown Figure 7. figure, curves dynamic backtracking unsolvable problems shown Figure 2,
except cost curves shown logarithmic scale. Interestingly,
see peak search cost unsolvable problems using less sophisticated method
chronological backtrack.
57

fiMammen & Hogg

Cost
4
10

3
10

2
10
20

40

60

80

100

120

140

Nogoods

Figure 7: Comparison median solution cost log scale using sets unsolvable

problems chronological backtracking (black) dynamic backtracking (gray). Dotted
lines problems generated using \hill-climbing" method, solid lines
\generate-select" method. point median 1000 problems solved 100
times, except \generate-select" method 30 nogoods, based 100
problems. Error bars showing 95% confidence intervals included, smaller
size plotted points.

observation raises important point: easy-hard-easy pattern universal
feature search algorithms problems restricted fixed number solutions.
suggests competition number solutions pruning, occurs,
suciently powerful affect search algorithms (very simple methods,
generate-and-test, make use pruning show monotonic increase search
cost number solutions decreases), algorithms able
exploit features weakly constrained problems fixed number solutions
make easy.
contrast observations, monotonic decrease cost reported
unsolvable binary random constraint problems (Smith & Dyer, 1996) unsolvable
3SAT problems (Mitchell et al., 1992). case 3SAT, explanation may well
choice algorithm. Indeed, Bayardo & Schrag (1996) recently found incorporating
con ict-directed backjumping learning Tableau algorithm made difference
many orders magnitude problem diculty specifically rare, \exceptionally hard,"
unsatisfiable problems underconstrained region. would interesting see whether
easy-hard-easy pattern unsolvable problems would appear using algorithm.
respect Smith & Dyer's (1996) observations, difference may due
range problems generated, resulting different problem generation methods. Smith
Dyer used method akin \random" generation method, is, generating
58

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

problems without regard solvability, separating unsolvable ones.
method, \hit rate" unsolvable problems underconstrained region low.
possible Smith Dyer's data extend point cost
unsolvable problems begins decrease simply stopped finding unsolvable
problems point.
two possible reasons might found unsolvable problems using
random generation underconstrained region, Smith Dyer
not. One possibility since specifically interested unsolvable problems
far underconstrained region possible, may spent computational
effort generating region. Indeed, 40 nogoods, unsolvable problems occurred
frequency 4:5 10,5 , 30 nogoods, frequency 7:75 10,7 . rate, problems
30 nogoods took six hours apiece generate.
second possibility relates details generation methods. Smith
Dyer's random generation method, every pair variables exactly number
inconsistent value pairs them. implies degree homogeneity
distribution nogoods. hand, random generation method,
variable-value pair equal probability selected nogood, independent
one another. Thus least possible generation method, though still low
likelihood, nogoods occasionally clump, produce unsolvable problem.
idea discussed Section 5.
difference observation Smith & Dyer's (1996) reinforces important
point: relatively subtle difference generation methods affect class
problems generated. nogoods less evenly distributed average
using generation method, also clumped probability, whereas
Smith Dyer's generation method, homogeneous distribution variable pairs
guaranteed. types problems could different enough sometimes produce
different behavior.

5. Minimal Unsolvable Subproblems

observations classes problems restrictions number solutions
may shows common identification peak solution cost
algorithm-independent transition solvability seen general problem classes
capture full generality easy-hard-easy pattern.
solvable problems, explanation could readily modified use transition
existence solutions beyond specified construction class
problems symmetries problems might constrain allowable range
solutions. modification simple generalization existing explanation based
competition number solutions pruning. However, data
solvable problems support explanation, search cost peak
disappearance second last solution coincide roughly n = 10,
n = 20.
Furthermore, number solutions held constant, competition increased pruning decreasing number solutions cannot possibly responsible
peak solution cost. decrease search cost highly constrained problems (to
59

fiMammen & Hogg

right peak) adequately explained prevailing explanation, based
increase pruning additional constraints. explain weakly constrained problems also found easy, least search methods. low cost
unsolvable problems underconstrained region new unexpected observation
light previous studies easy-hard-easy pattern explanation. raises
question whether different aspect problem structure account
peak search cost problems fixed number solutions.
One possibility often mentioned context notion critically constrained problems. problems boundary solvable unsolvable problems, i.e., neither underconstrained (with many solutions) overconstrained
(with none). notion forms basis another common interpretation cost
peak. is, critically constrained problems typically hard search (because constraints must instantiated unproductive search paths
identified) and, since concentrated transition (Smith & Dyer, 1996),
give rise search peak. explanation include discussion changes
pruning capability constraints added. Taken face value, explanation would
predict peak solvable problems number solutions held constant,
classes transition solvable unsolvable problems. Moreover,
description critically constrained problems simply characteristic individual problem rather partly dependent class problems consideration
exact location transition depends method problems
generated. observation makes dicult characterize degree
individual problem critically constrained purely terms structural characteristics
problem. contrast, measure number solutions well defined
individual problem instances, facilitates using average behavior various classes
problems approximately locate transition region. Thus, currently described,
notion critically constrained problems explain observations
give explicit way characterize individual problems.
precisely defined alternative characteristic size minimal unsolvable subproblems. mentioned Section 4.2, minimal unsolvable subproblem subproblem
unsolvable, subset variables associated constraints
solvable.
problems one minimal unsolvable subproblem. example,
problem might one minimal unsolvable subproblem five variables, another, different one, say, six. computed minimal unsatisfiable subproblems
10-variable unsolvable problems generated. found monotonic positive relationship mean number minimal unsolvable subproblems number nogoods.
example, problems 140 nogoods average 35 minimal unsolvable subproblems
(range 4 64, standard deviation 8.7); 90 nogoods six (range 1
23, standard deviation 3.6); problems 50 fewer nogoods rarely
one minimal unsolvable subproblem. Similarly, Gent & Walsh (1996) observed unsatisfiable problems underconstrained region tend small unique minimal
unsatisfiable subsets.
behavior size smallest minimal unsolvable subproblem function
number nogoods shown Figure 8. Comparing Figure 2, see peak
60

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Size
10
9
8
7
6
5
4
3

20

40

60

80

100

120

Nogoods
140

Figure 8: Mean size smallest minimal unsolvable subproblem function number nogoods, unsolvable problems generated using \hill-climbing" (dotted line)
\generate-select" (solid line) methods. point based 1000 problems, except
\generate-select" method 30 nogoods, based 100 problems. Error bars
showing 95% confidence intervals included.

minimum size minimal unsolvable subproblems matches location search
cost peak unsolvable problems. result independent whether plot smallest
minimal unsolvable subproblem size, shown Figure 8, medians means,
shown here. Moreover, location peaks minimal unsolvable subproblem
size different generation methods correspond location respective
search cost peaks. peak search cost minimal unsolvable subproblem size
occurs around 40 nogoods problems generated using \hill-climbing" method,
significantly higher, around 60 nogoods, problems generated using \generateselect" method. strong correspondence minimal unsolvable subproblem size
search cost suggestive minimal unsolvable subproblem size structural
characteristic problems plays important role search cost. contrast, number
minimal unsolvable subproblems match pattern search cost. mentioned
above, increases monotonically number nogoods, suggesting play
primary role explaining search cost unsolvable problems.
behavior minimal unsolvable subproblem size function number
constraints simple explanation. Unsolvable weakly constrained problems generally need concentrate available constraints variables order
make assignments inconsistent. tend give one small minimal unsolvable
subproblem. constraints added, concentration longer required and,
since problems randomly selected constraints happen concentrated
variables rare, expect larger minimal unsolvable subproblems.
61

fiMammen & Hogg

Cost
350

300

250

200

150

4

6

8

10

Size

Figure 9: Mean solution cost function size smallest minimal unsolvable subproblem,
unsolvable problems 60 nogoods generated using \generate-select" method.
point mean median solution costs, based solving problem 100 times,
set problems corresponding smallest minimal unsolvable subproblem
size. points based following numbers problems smallest minimal
unsolvable subproblem size, totaling 1000 problems: 3 { 1; 4 { 17; 5 { 71; 6 { 156; 7 {
253; 8 { 283; 9 { 165; 10 { 54. Error bars showing 95% confidence intervals included,
except single problem size 3 confidence intervals cannot calculated.

Finally, constraints added, increased pruning equivalent
notion instantiating variables required find inconsistency.
means expect large number small unsolvable subproblems. qualitative
description corresponds observe Figure 8.
observations weakly constrained problems suggest search algorithms,
dynamic backtracking, able rapidly focus one unsolvable subproblems hence avoid extensive thrashing, high search cost, seen methods.
cases, one would expect smaller unsolvable subproblem, easier
search determine solutions.
order examine role minimal unsolvable subproblem search cost
closely, plotted mean search cost versus size smallest minimal unsolvable subproblem
unsolvable problems 10 variables multiple 10 nogoods 30 140
nogoods. every case, mean search cost increased function size smallest minimal
unsolvable subproblem. Figure 9 shows example one plots, peak
solution cost class problems, 60 nogoods. makes sense smallest
minimal unsolvable subproblem, easiest detect, would play significant role
search cost. However, situation surely complicated this, suggested
fact still variation among problems size smallest minimal
62

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

unsolvable subproblem. could due, example, one problem several
small minimal unsolvable subproblems, another might one minimal unsolvable
subproblem, even smaller. Number size minimal unsolvable subproblems
likely play role search cost.
Number minimal unsolvable subproblems seem play significant role
size smallest minimal unsolvable subproblem, effect also demonstrated.
sets unsolvable problems above, multiple 10 nogoods
80 140 nogoods, search cost correlates negatively number minimal unsolvable
subproblems. However, unsolvable problems 30 70 nogoods, variance
number minimal unsolvable subproblems lower (but variance search cost higher),
relationship search cost number minimal unsolvable subproblems. Additional clarification role search cost size number minimal
unsolvable subproblems left investigation. size smallest minimal unsolvable subproblem, correlates strongly search cost (1) unsolvable problems
taken whole (see Figures 2 8) (2) unsolvable problems fixed number
nogoods full range number nogoods, appears primary effect.
discussion minimal unsolvable subproblems also relevant solvable problems:
series choices precludes solution made search, remaining subproblem unsolvable one. example, 10-variable CSP, suppose values
given first two variables incompatible solutions problem.
means context two assignments, remaining eight variables constitute unsolvable subproblem. number search steps required determine
subproblem fact unsolvable cost added search backtracking
original two variables trying new assignment one them. Thus, cost
identifying unproductive search choices solvable problems determined rapidly
associated unsolvable subproblem searched. described above,
constraints expect unsolvable subproblems small
minimal unsolvable subproblems hence easy search methods able
focus subproblems. unsolvable subproblems associated incorrect
variable choices solvable problems may different structure, argument suggests changes minimal unsolvable subproblems may explain behavior solvable
problems fixed number solutions well. could also explain observations
thrashing behavior rare exceptionally hard solvable problems underconstrained
region (Gent & Walsh, 1994a; Hogg & Williams, 1994); would expect problems
relatively large unsolvable subproblem detect given initial variable assignments. Finally, would interesting study behavior local repair search methods
problems single solution see also affected change minimal
subproblem size.

6. Conclusions

presented evidence explanation easy-hard-easy pattern solution
cost based competition changes number solutions pruning
insucient explain phenomenon completely sophisticated search methods.
explain overall pattern problems restricted solvability number
63

fiMammen & Hogg

solutions. However, explanation fails number solutions held constant
sophisticated search methods used. cases solution cost peak
disappear would predicted. Alternatively, view explanation adequate
less sophisticated methods able readily focus unsolvable subproblems
encountered search.
considering relatively small search problems, able exhaustively examine
properties search space. allowed us definitively demonstrate importance search behavior aspect problem structure: size minimal unsolvable
subproblems. approach contrasts much work area involves solving
problems large feasible within reasonable time bounds. latter approach
gives better indication asymptotic behavior transition, suitable
exhaustive evaluation nature search spaces encountered, detailed
analysis aspects individual problem structure.
believe detailed examination structure combinatorial problems
yield information certain types problems dicult easy. class, graph
coloring random CSPs NP-complete, yet practice many problems actually
easy. addition, theoretical work area produced predictions
asymptotically correct average, variance among individual problems predicted
class enormous. Increased understanding relationships problem structure,
problem solving algorithm, solution cost important determining whether, so,
how, determine prior problem solving problems easy versus infeasibly
hard. contrast previous theoretical studies focus number solutions,
work suggests size minimal unsolvable subproblems alternate characteristic
study potential producing precise characterization transition
behavior nature hard search problems.

Acknowledgements
Much research carried first author summer intern Xerox
Palo Alto Research Center. research also partially supported National
Science Foundation Grant No. IRI-9321324 Victor R. Lesser. opinions,
findings, conclusions recommendations expressed material
authors necessarily ect views National Science Foundation.

References

Asahiro, Y., Iwama, K., & Miyano, E. (1993). Random generation test instances
controlled attributes. Second DIMACS Challenge Workshop.
Bayardo, Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques solve exceptionally hard SAT instances. Freuder, E. C. (Ed.), Principles Practice
Constraint Programming { CP96, pp. 46{60 Cambridge, MA. Springer.
Cha, B., & Iwama, K. (1995). Performance test local search algorithms using new
types random CNF formulas. Proceedings Fourteenth International Joint
64

fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficulty

Conference Artificial Intelligence, pp. 304{310 Montreal, Quebec, Canada.

Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings Twelfth International Joint Conference Artificial Intelligence,
pp. 331{337 Sydney, Australia.
Crawford, J. M., & Auton, L. D. (1993). Experimental results cross-over point
satisfiability problems. Proceedings Eleventh National Conference
Artificial Intelligence, pp. 21{27 Washington, DC, USA.
Gent, I. P., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects CSP phase
transition. Montanari, U., & Rossi, F. (Eds.), Proc. Principles Practices
Constraint Programming PPCP95, pp. 70{87. Springer-Verlag.
Gent, I. P., & Walsh, T. (1994a). Easy problems sometimes hard. Artificial Intelligence,
70, 335{345.
Gent, I. P., & Walsh, T. (1994b). SAT phase transition. Cohn, A. (Ed.), Proceedings
ECAI-94, pp. 105{109. John Wiley Sons.
Gent, I. P., & Walsh, T. (1996). satisfiability constraint gap. Artificial Intelligence,
81 (1-2), 59{80.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,
1, 25{46.
Hogg, T. (1996). Refining phase transitions combinatorial search. Artificial Intelligence, 81, 127{154.
Hogg, T., & Williams, C. P. (1994). hardest constraint problems: double phase
transition. Artificial Intelligence, 69, 359{377.
Johnson, D. S., Aragon, C. R., McGeoch, L. A., & Schevon, C. (1991). Optimization
simulated annealing: experimental evaluation; part II, Graph coloring number
partitioning. Operations Research, 39 (3), 378{406.
Kask, K., & Dechter, R. (1995). GSAT local consistency. Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp. 616{622 Montreal,
Quebec, Canada.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability random
boolean expressions. Science, 264, 1297{1301.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proceedings Tenth National Conference Artificial Intelligence,
pp. 459{465 San Jose, CA, USA.
Prosser, P. (1996). empirical study phase transitions binary constraint satisfaction
problems. Artificial Intelligence, 81, 81{109.
65

fiMammen & Hogg

Smith, B. M. (1994). Phase transition mushy region constraint satisfaction
problems. Cohn, A. (Ed.), Proceedings ECAI-94, pp. 100{104. John Wiley
Sons.
Smith, B. M., & Dyer, M. E. (1996). Locating phase transition binary constraint
satisfaction problems. Artificial Intelligence, 81, 155{181.
Snedecor, G. W., & Cochran, W. G. (1967). Statistical Methods (6th edition). Iowa State
Univ. Press, Ames, Iowa.
Williams, C. P., & Hogg, T. (1994). Exploiting deep structure constraint problems.
Artificial Intelligence, 70, 73{117.
Yugami, N., Ohta, Y., & Hara, H. (1994). Improving repair-based constraint satisfaction
methods value propagation. Proceedings Twelfth National Conference
Artificial Intelligence, pp. 344{349 Seattle, WA, USA.

66

fiJournal Artificial Intelligence Research 7 (1997) 125-159

Submitted 5/97; published 10/97

Analysis Three-Dimensional Protein Images
Laurence Leherte

Laboratoire de Physico-Chimie Informatique
Facultes Universitaires Notre-Dame de la Paix
Namur, Belgium

Laurence.Leherte@scf.fundp.ac.be

Janice Glasgow
Kim Baxter

janice@qucis.queensu.ca
baxter@qucis.queensu.ca

Department Computing Information Science
Queen's University, Kingston, Ontario, Canada, K7L 3N6

Evan Steeg

steeg@qucis.queensu.ca

Molecular Mining Corp., PARTEQ Innovations
Queen's University , Kingston, Ontario, Canada, K7L 3N6

Suzanne Fortier

fortiers@qucdn.queensu.ca

Departments Computing Information Science Chemistry
Queen's University, Kingston, Ontario, Canada, K7L 3N6

Abstract

fundamental goal research molecular biology understand protein structure.
Protein crystallography currently successful method determining threedimensional (3D) conformation protein, yet remains labor intensive relies
expert's ability derive evaluate protein scene model. paper, problem
protein structure determination formulated exercise scene analysis. computational methodology presented 3D image protein segmented
graph critical points. Bayesian certainty factor approaches described used
analyze critical point graphs identify meaningful substructures, ff-helices
fi -sheets. Results applying methodologies protein images low medium
resolution reported. research related approaches representation, segmentation classification vision, well top-down approaches protein structure
prediction.

1. Introduction
Crystallography plays major role current efforts characterize understand molecular structures molecular recognition processes. information derived crystallographic studies provides precise detailed depiction molecular scene, essential
starting point unraveling complex rules structural organization molecular
interactions biological systems. However, small fraction currently known
proteins fully characterized.
determination molecular structures X-ray diffraction data belongs
general class image reconstruction exercises incomplete and/or noisy data. Research
artificial intelligence machine vision long concerned problems.
Similar concept visual scene analysis, molecular scene analysis concerned
processes reconstruction, classification understanding complex images.

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

analyses rely ability segment representation molecule meaningful
parts, availability priori information, form rules structural
templates, interpreting partitioned image.
crystal consists regular (periodic) 3D arrangement identical building blocks,
termed unit cell. crystal structure defined disposition atoms molecules
within fundamental repeating unit. given structure solved interpreting
electron density image unit cell content, generated { using Fourier transform {
amplitudes phases experimentally derived diffraction data. electron density
map 3D array real values estimate electron density given locations
unit cell; information gives access structure protein1 . Unfortunately,
diffraction amplitudes measured directly crystallographic experiment;
necessary phase information constructing electron density image must obtained
means2 . classic phase problem crystallography.
contrast small molecules (up 150 independent, non-hydrogen atoms),
determination protein structures (which often contain excess 3000 atoms) remains
complex task hindered phase problem. initial electron density images obtained
crystallographic data macromolecules typically incomplete noisy.
interpretation protein image generally involves mental pattern recognition procedures
image segmented features, compared anticipated
structural motifs. feature identified, partial structure information
used improve phase estimates resulting refined (and eventually higher-resolution)
image molecule. Despite recent advances tools molecular graphics modeling,
iterative approach image reconstruction still time consuming process requiring
substantial expert intervention. particular, depends individual's recall existing
structural patterns ability recognize presence motifs noisy
complex 3D image representation.
goal research described paper facilitate image reconstruction processes protein crystals. Towards goal, techniques artificial intelligence,
machine vision crystallography integrated computational approach interpretation protein images. Crucial process ability locate identify
meaningful features protein structure multiple levels resolution. requires
simplified representation protein structure, one preserves relevant shape, connectivity distance information. proposed approach, molecular scenes represented
3D annotated graphs, correspond trace main side chains
protein structure. methodology applied ideal experimental electron
density maps medium resolution. images, nodes graph correspond
amino acid residues edges correspond bond interactions. Initial experiments
using low-resolution electron density maps demonstrate image segmented
protein solvent regions. medium resolution protein region
segmented main side chains individual residues along main chain.
1. Strictly speaking, diffraction experiment provides information ensemble average
unit cells.
2. Current solutions phase problem macromolecules rely gathering extensive experimental
data considerable input experts image interpretation process.

126

fiAnalysis Three-Dimensional Protein Images

Furthermore, derived graph representation protein analyzed determine
secondary structure motifs within protein.
paper presents brief overview protein structure problem analyzing
molecular scene. processes protein segmentation secondary structure identification described, along experimental results. Related ongoing research issues
also presented.

2. Protein Structure

fundamental goal research molecular biology understand protein structure
function. particular, structure information essential medicine drug design.
section review concepts involved protein structure. concepts
used later describing computational approach protein structure determination.
protein often characterized linear list amino acids called primary structure, sequence, protein. naturally occurring amino acids similar
backbone structure, consisting central carbon atom (Cff ), amino group (NH2 )
carboxyl group (COOH ). distinguished one another varying side
chains connected Cff atom. Figure 1 illustrates alternative representations
amino acid alanine, Figure 1(c) displays side chain consisting carbon
three hydrogen atoms. Associated side chain amino acid properties
hydrophobicity (dislikes water), polarity, size charge.
side chain
H
C

CH 3

N
+

C H
3

7

H3 N

2

C

COO

-



H
(a) 1D chemical formula

(b) 2D structural formula

(c) Ball stick model

Figure 1: Representations amino acid alanine.
Adjacent amino acids primary structure protein linked together
peptide bonds form polypeptide main chain, backbone, various side
chains project (see Figure 2). carboxyl group one amino acid joins amino
group another eliminate water molecule (H2 O) form peptide bond.
secondary structure protein refers local arrangement polypeptide subchain
takes regular 3D conformation. two commonly recurring classes
secondary structure: ff-helix fi -sheet. ff-helix occurs corkscrew-shaped
conformation, amino acids packed tightly together; fi -sheets consist linear
strands (termed fi -strands) amino acids running parallel antiparallel one another
(see Figure 3). secondary structure motifs generally linked together less
127

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

amino acid n
H


H
C

N
C

R

H

C

N

N

C
H

R

H



H
C


C

R

peptide bond

side chain

Figure 2: Proteins built joining together amino acids using peptide bonds.
regular structures, termed loops turns. discussed later paper,
characterization subsequence amino acids ff-helix fi -sheet determined
geometric analysis distance angle relations among local subsequences
amino acids.
global conformation protein referred tertiary structure. way
proteins adopt particular folding pattern depends upon intramolecular interactions occur among various amino acid residues, well upon interaction
molecule solvent (water). Two types intramolecular interactions often referred order describe secondary tertiary structure protein. first type
hydrogen bond, results sharing hydrogen atom residues.
ff-helices fi -sheets described terms regular specific hydrogen bond
networks. Figure 3 illustrates portion fi -sheet hydrogen bond interactions
link together parallel fi -strands. Additional stability 3D structure protein
provided disulfide bridges. second type interaction result chemical bond
occurring two sulfur atoms carried cysteine amino acid residues. bonds
energetically stronger hydrogen bonds contribute stability extreme
conditions (temperature, acidity, etc.).
Molecular biology concerned understanding biological processes macromolecules terms chemical structure physical properties. Crucial achieving
goal ability determine protein folds 3D structure given known
sequence amino acids. Despite recent efforts predict 3D structure protein
sequence, folding problem remains fundamental challenge modern science. Since
3D structure protein cannot yet predicted sequence information alone,
experimental techniques X-ray crystallography nuclear magnetic resonance currently provide realistic routes structure determination. remainder
paper focus computational approach analysis protein images generated
crystallographic data.
128

fiAnalysis Three-Dimensional Protein Images

















C

C



C


N

C



H

N

C

C
H

H





H

C



N

C


N



N

C

C

N
C



N

C

H

C
C



C

C

C



H

N




C

H

N

H





Figure 3: Hydrogen bonds (dotted lines) link three individual fi -strands (linear sequences
amino acids main chain protein) form parallel fi -sheet.

129

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

3. Scene Analysis
Research machine vision long concerned problems involved automatic image interpretation. Marr (1982) defines computational vision \the process
discovering present world, is". Similar visual scene analysis, molecular scene analysis concerned processes reconstruction, classification
understanding complex images. section presents problem molecular scene
analysis context related research machine vision medical imaging.
Early vision systems generally include set processes determine physical properties 3D surfaces 2D arrays. input arrays contain pixel values denote
properties light intensity. Considerable research carried extracting
3D information one 2D images. review application stereo vision
sets 2D images found (Faugeras, 1993). principles stereo vision
also applied moving images (Zhang & Faugeras, 1992). Range data provides
explicit depth information visible surfaces form 2D array (depth map).
Depending application, surface or/and volume fitting techniques applied
images. complete review vision techniques found elsewhere (e.g.,
(Arman & Aggarwal, 1993; Besl & Jain, 1986; Jain & Flynn, 1993)).
Similar crystallography problem, medical imaging techniques require genuine
3D data: magnetic resonance imaging (MRI) provides detailed high-resolution information
tissue density; emission computed tomography (ECT), includes positron emission tomography (PET) single photon emission computed tomography (SPECT), gives
noisy, low-resolution information metabolic activity. X-ray computed tomography
(CT) ultrasound also provide 3D density data. methods used obtain
series 2D images (slices) which, properly aligned, provide 3D grid.
interslice spacing may much larger spacing grid points slice,
alignment slices followed interpolation slices one area research.
low-level segmentation medical images typically uses 3D extensions 2D techniques. Edge detection becomes surface detection, region growing defines volumes instead
areas. Many applications typically require detailed, high-level models. Surface
information used construct models simulations, volumes surfaces provide
structural measurements. Higher-level models used construction \templates"
pattern matching. One interesting aspect medical imaging availability priori
knowledge, either database similar structures, images region
different modalities (e.g. MRI images brain used guide segmentation
lower-resolution PET image). One modality may also provide information clear
another modality. considerable research \registration" images { aligning
overlaying two 3D images combine information. Segmentation identification
matching \landmarks" important image representations.
Unlike input vision medical imaging problems, crystallographic experiment yields data define 3D function, allows construction 3D array
voxels arbitrary size3 . interpretation 3D atomic arrangement crystal structure readily available small molecules using data generated X-ray
3. Comparatively, machine vision techniques generally provide 2D image representations range data
provide surface information. Medical imaging techniques may result 3D grid, spacing

130

fiAnalysis Three-Dimensional Protein Images

diffraction techniques. Given magnitudes diffracted waves prior knowledge
physical behavior electron density distributions, probability theory applied retrieve phase information. magnitudes phases known, spatial
arrangement atoms within crystal obtained Fourier transform. electron density function obtained, (x; y; z ), scalar field visualized 3D grid
real values called electron density map. High-density points image associated
atoms small molecule.
construction interpretable 3D image protein structure diffraction
data significantly complex small molecules, primarily due nature
phase problem. generally involves many iterations calculation, map interpretation
model building. also relies extensively input expert crystallographer.
previously proposed process could enhanced strategy
integrates research crystallography artificial intelligence rephrases problem
hierarchical iterative scene analysis exercise (Fortier et al., 1993; Glasgow et al.,
1993). goal exercise reconstruct interpret images protein
progressively higher resolution. initial low-resolution map, protein
appears simple object outlined molecular envelope, goal locate
identify protein solvent regions. medium-resolution, goal involves locating amino
acid residues along main chain identifying secondary structure motifs. higher
resolution, analysis would attend identification residues and, possibly,
location individual atoms.
primary step scene analysis (whether vision, medical crystallographic data
used) automatically partition image representation disjoint regions. Ideally,
segmented region corresponds semantically meaningful component object
scene. parts used input high-level classification task. processes
segmentation classification may interwoven; domain knowledge, form
partial interpretation, often useful assessing guiding segmentation.
Several approaches image segmentation classification considered
vision literature. particular interest molecular domain approach described
Besl Jain (1986) , surface curvature sign Gaussian derived
point surface range image. Image segmentation achieved
identification primitive critical points (peaks, pits, ridges, etc.). Haralick et al. (1983)
defined similar set topographic features use 2D image analysis, Wang Pavlidis
(1993), later Lee Kim (1995), extended work extract features character
recognition. Gauch Pizer (1993) also identify ridge valley bottoms 2D images,
ridge defined point intensity falls sharply two directions
valley bottom point intensity increases sharply two directions.
examined behavior ridges valleys scale space; resulting
resolution hierarchies could used guide segmentation. Maintz et al. (1996) Guziec
Ayache (1992) use 3D differential operators scale space define ridges
troughs. provide landmarks used register images. Leonardis, Gupta
Bajcsy (1993, 1995)) use approach surface fitting (using iterative regression)
volume fitting (model recovery) initiated independently; local-to-global surface
along third axis may large, and, case, necessary align interpolate
multiple 2D slices.

131

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

fitting used guide multiple global-to-local volume fittings, used evaluation
possible models.
discussed next section, topological approach used
segmentation classification molecular scenes. Similar method Gauch
Pizer, critical points used delineate skeletal image protein segment
meaningful parts. critical points considered analysis segmented
parts. approach also compared skeletonization method,
described Hilditch (1969) applied protein crystallography Greer (1974) . Unlike
Greer's algorithm, \thins" electron density map form skeleton traces
main secondary chains molecule, proposed representation preserves
original volumetric shape information retaining curvatures electron density
critical points. Furthermore, rather thinning electron density form skeleton,
approach reconstructs backbone protein connecting critical points 3D
graph structure.
Critical points image also considered medical domain. Higgins et
al. (1996) analyze coronary angiograms CT data thresholding define \bright"
regions correspond area around peak critical points. seed regions
grown along ridges steep dropoff. Post-processing removes cavities spurs.
resulting volume tree-like structure, skeletonized pruned
provide axes. axes converted sets line segments minimum length.
similar BONES (Jones, Zou, Cowan, & Kjeldgaard, 1991), graphical method
developed applied interpretation medium- high-resolution
protein maps. method incorporates thinning algorithm postprocessing analysis
electron density maps. Also worth mentioning previously described methodology
outlining envelope protein molecule crystallographic environment (Wang,
1985).
distinct advantage molecular scene analysis, many applications machine
vision, regularity chemical structures availability previously determined
molecules Protein Data Bank (PDB) (Bernstein, Koetzle, Williams, & Jr., 1977).
database 3D structures forms basis comprehensive knowledge base template
building pattern recognition molecular scene analysis (Conklin, Fortier, & Glasgow,
1993b; Hunter & States, 1991; Unger, Harel, Wherland, & Sussman, 1989); although
scenes wish analyze novel, substructures likely appeared previously determined structures. Another significant difference molecular visual
scene analysis diffraction data resulting protein experiments yield 3D images,
simplifying eliminating many problems faced low-level vision (e.g., occlusion,
shading). complexity exist crystallographic domain relates
incompleteness data due phase problem.

4. Segmentation Interpretation Protein Images
use artificial intelligence techniques assist crystal structure determination, particularly interpretation electron density maps, first envisioned Feigenbaum,
Engelmore Johnson (1977) pursued Crysalis project (Terry, 1983). conjunction earlier project, topological approach representation analysis
132

fiAnalysis Three-Dimensional Protein Images

Figure 4: Depictions electron density maps viewed (a) 1
A, (b) 3
A, (c) 5

resolution
protein electron density maps implemented program called ORCRIT (Johnson,
1977). Recent studies suggest approach also applied segmentation
medium-resolution protein images (Leherte, Baxter, Glasgow, & Fortier, 1994a; Leherte,
Fortier, Glasgow, & Allen, 1994b). section describe support
feasibility topological approach analysis low medium-resolution electron
density maps proteins.
information stored electron density map protein may represented
analyzed various levels detail (see Figure 4)4 . high-resolution (Figure 4(a))
individual atoms observable; medium-resolution (Figure 4(b)) atoms observable, possible differentiate backbone protein side chains
secondary structure motifs may discernerable. clear segmentation protein
molecular envelope (region atoms protein reside) surrounding
solvent region still seen low-resolution (Figure 4(c)).
4. Resolution electron density images proteins often measured terms angstrom (
A) units,
1
A=10,10 meters.

133

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Methods machine vision crystallography considered development computational approach analysis protein structures. Among
studied, topological analysis provided natural way catch uctuations
density function molecular image. section overview method
mapping 3D electron density map onto graph traces backbone protein structure. present results applying method segmentation low
medium-resolution maps protein structures reconstructed using Protein Databank
Brookhaven. well, show critical point graphs constructed medium resolution
maps analyzed order identify ff-helix fi -sheet substructures.

4.1 Representation Protein Structure

Crucial molecular scene analysis representation capture molecular shape
structure information varying levels resolution; important step molecular
scene analysis parsing protein, protein fragments, shape primitives
allow rapid accurate identification. Shape information extracted
several depictive representations { example, van der Waals surfaces, electrostatic
potentials electron density distributions. Since molecular scene analysis primarily
concerned images reconstructed crystallographic experiments, electron density
maps provide natural convenient choice input representation.
mentioned earlier, electron density map depicted 3D array real, nonnegative values corresponding approximations electron density distribution
points unit cell crystal. task segmenting map meaningful
parts, also consider array terms smooth continuous function , maps
integer vector r = (x; y; z ) value corresponding electron density location
r electron density map. Similar related formalisms vision5, information
electron density map uninterpreted detailed level allow rapid
computational analysis. Thus, essential transform array representation
simpler form captures relevant shape information discards unnecessary
distracting details. desired representation satisfy three criteria put forward
Marr Nishihara concerning: 1) accessibility { representation derivable
initial electron density map reasonable computing costs; 2) scope uniqueness
{ representation provide unique description possible molecular shapes
varying levels resolution; 3) stability sensitivity { representation
capture general (less variant) properties molecular shapes, along finer
distinctions.
Several models representation segmentation protein structures considered. included generalized cylinder model (Binford, 1971), skeletonization
method (Greer, 1974; Hilditch, 1969). choose topological approach,
previously applied chemistry machine vision. chemistry, approach
proven useful characterizing shape properties electron density distribution
location attributes critical points (points gradient
electron density equal zero) (Johnson, 1977).
5. level representation electron density map comparable 3D version primal sketch
Marr Nishihara's formalism (1978) .

134

fiAnalysis Three-Dimensional Protein Images

following section, describe representation protein structure terms
set critical points obtained topological analysis.

4.2 Deriving Critical Point Graphs

proposed topological approach protein image interpretation, protein segmented
meaningful parts location identification points electron
density map gradients vanish (zero-crossings). points, local maxima
minima defined computing second derivatives adopt negative positive values
respectively. first derivatives electron density function characterize zerocrossings, second derivatives provide information zero-crossings; particular,
identify type critical points map. index value r = (x; y; z )
electron density map, define function (r).
Candidate grid points (those maximum minimum along three mutually
orthogonal axes) chosen function (r) evaluated vicinity determining three polynomials (one along axes) using least square fitting. (r)
tensor product three polynomials. location critical point derived
using first derivative (r). second derivatives used determine nature
critical point. critical point, construct Hessian matrix:

@ 2 =@x2 @ 2 =@x@y @ 2 =@x@z
H(r) = @ 2 =@y@x @ 2 =@y2 @ 2=@y@z
@ 2 =@z@x @ 2 =@z@y @ 2 =@z2
matrix put diagonal form three principal second derivatives
computed index value r:

H'(r) =

@ 2 =@ (x0 )2
0
0

0

@ 2 =@ (y0 )2
0

0
0

@ 2 =@ (z0 )2

three non-zero diagonal elements array H'(r) { eigenvalues { used determine type critical points electron density map. Four possible cases
considered depending upon number negative eigenvalues, nE . nE = 3,
critical point r corresponds local maximum peak; point nE = 2 saddle
point pass. nE = 1 corresponds saddle point pale, nE =0 characterizes r
pit. Figure 5 depicts 2D graphical projection potential critical points.
High density peaks passes critical points currently considered
study. Low density critical points less significant since often indistinguishable noise experimental data.
use critical point mapping method analyzing protein electron density
maps first proposed Johnson (1997) analysis medium high-resolution protein electron density maps. Within framework molecular scene analysis project,
use critical points extended analysis medium low-resolution
maps proteins. topological approach segmentation proteins initially
implemented Johnson computer program ORCRIT (Johnson, 1977). first locating connecting critical points, program generates representation
135

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Peak

Pass

Peak




X

Figure 5: Graphical illustration critical points 2D (X Y) plotted density
function .
captures skeleton volumetric features protein image. occurrence probability connection two critical points j determined following
density gradient vector r(r). pair critical points, program calculates
weight wij , inversely proportional occurrence probability connection.
collection critical points linkage represented set minimal spanning
trees (connected acyclic graphs minimal weight)6 .

4.3 Results Segmentation Medium Low Resolution

section presents experimental studies carried electron density
maps 3
resolution. Computations first performed calculated maps reconstructed available structural data order generate procedure
analysis experimental maps. Three protein structures: Phospholipase A2 (1BP2), Ribonuclease T1 complex (1RNT) Trypsin inhibitor (4PTI), retrieved PDB (Bernstein
et al., 1977), considered. structures composed 123, 104 53 amino acid
residues, respectively, chosen quality data sets. electron
density images proteins constructed using XTAL program package (Hall &
Stewart, 1990), analyzed using version ORCRIT extended
enhanced construct interpret critical point graphs low- medium-resolution
electron density maps.
Applying ORCRIT electron density maps generated medium resolution provides
detailed analysis protein structures (Leherte et al., 1994b). illustrated
Figure 6, topological approach produces skeleton protein backbone sequence
6. discussed Section 4, part program currently modified allow cycles
graph.

136

fiAnalysis Three-Dimensional Protein Images

alternating peaks (dark circles) passes (light circles). results obtained
analysis calculated electron density maps 3
resolution led following
observations:

peak linear sequence generally associated single residue
primary sequence protein.

pass sequence generally corresponds bond chemical interaction
links two amino acid residues (peaks).

Thus, critical point graph decomposed linear sequences alternating
peaks passes corresponding main chain backbone protein. larger
residues, side chains may also observed graph side branches consisting
peak/pass motif. observations featured Figure 7, illustrates critical
point graph electron density contour unit cell protein crystal.
practice, found critical point graph included arcs originating
presence connections critical points associated non-adjacent residues.
illustrated Figure 6 bottom left corner Figure 7; main chain
graphs jump occurred result disulfide bridge nearby
residues. bonds often identified, however, analysis
critical point graphs. example, disulfide bridges discerned representation
higher density values associated cysteine residues. overcome
problem errors critical point graph due ambiguous data plan generate
multiple possible models protein, corresponding different hypothesized backbones
resulting critical point graph. Thus, several alternative hypotheses considered used refine image iterative approach scene analysis.
Experiments also carried low (5
A) resolution, following
observed:

Secondary structure motifs, ff-helices fi -strands, correspond linear
(or quasi-linear) sequences critical points. case helices, sequences
trace central axis structure (see Figure 8), whereas tend catch
backbone fi -strands. average distance observed critical points
model protein backbone 1:68 0:59
A.

non-linear sequences critical points sometimes found representative
irregular protein motifs loops.

Highly connected, small graphs critical points appear regions maps:
solvent region, disulfide bridges close protein segments.

Although results segmenting protein images using topological approach
proved promising, ongoing research carried improve enhance
ORCRIT. particular, redeveloping code building graph critical points.
new version code incorporate domain knowledge order find
multiple possible backbone traces. also incorporate spline (rather polynomial)
fitting function interpolate critical points constructing function (r).
137

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

side chain

(pass) (peak)

disulphide bridge

peptide bond

amino acid

Figure 6: Planar representation critical point sequence obtained topological
analysis electron density map 3
resolution.

138

fiAnalysis Three-Dimensional Protein Images

Figure 7: 3D contour critical point graph unit cell protein 4PT1 (58 residues)
constructed 3
resolution. critical point graph figure generated
using output ORCRIT program.

139

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Figure 8: Critical point graph Cff chain (black) helix motif 3
(white) 5

(gray) resolution.
Currently, investigating relationships critical points varying resolutions. Figure 8 illustrates superimposition critical point representations
helix motif low medium resolution obtained using ORCRIT. figure shows,
linear segment critical points derived 5
resolution approximates detailed
critical point graph helix derived 3
A. careful analysis suggests
exists hierarchy peaks passes 5
3
A. relationship
critical points medium low-resolution illustrated Figure 9, individual critical points 5
resolution associated individual multiple points
medium-resolution.

5. Methods Secondary Structure Identification

critical point graph constructed, analyzed classify substructures
protein. statistical analysis conformation critical point sequences
terms geometrical parameters motifs consisting four sequential peak critical points
(pi ; pi+1 ; pi+2 ; pi+3 ) suggests useful parameters identification ffhelices fi -strands distance peaks pi pi+3 , individual
planar angles among critical points. describe criteria used formulate
rules identification secondary structure motifs medium-resolution electron
density map protein.
previous paper (Leherte et al., 1994a), described approach secondary
structure identification geometrical constraints critical point subgraph
140

fiAnalysis Three-Dimensional Protein Images

amino
acid 13

234*
147+
244*
106+
191*
122+
309*
74+
172*
38+
224*
76+
282*
77+
227*
132+
212*
52+

113*

4+

33+

24*
23+

71*

37*
34+
36*
38+
2+

48*
5 Resolution

109*
98+
349*
316*
83+
259*
123+
283*
49+
216*
137+
210*
125+
235*
23+
167*
43+
278*

amino
acid 29

3 Resolution

Figure 9: Relationship critical points 3 5
resolution amino acids 13
29 protein structure 1RNT. `+' `*' denote peaks passes main
chain. numeric values correspond critical points location ordered
list (based electron density) points. correspondence points
different levels hierarchy based interdistance (must less
2
A).

141

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

treated boolean fashion, i.e., either satisfied depending upon
whether values fell within predetermined ranges. procedure described
current paper relies probabilistic belief measures based statistics derived
PDB. Following, describe alternative approaches based comparison critical
point graphs idealized secondary structure motifs. templates used consisted
local subsequences critical points, point denoting residue idealized model
protein.

5.1 Estimating Probabilities Combining Evidence
construct model templates, first performed statistical analysis 63 nonhomologous protein structures retrieved PDB. set occurrence probability
distributions f (ssmjg) estimated given secondary structure motifs (ssm) geometric constraints (g). derived values ff-helix, fi -sheet turn motifs
geometric constraints based torsion bond angles relative distance
residues.
building procedures structure recognition discrimination, two important issues must faced: first, one compute primitive marginal conditional
probability estimates f (ssmjg); and, second, one combine information several different pieces geometric evidence class,
f (ssmjg1 ; g2 )? many tradeoffs consider.
single-attribute probability estimations, f (ssmjg), one use discrete categories estimate probabilities frequency counts. \bins" employed
for, e.g., ranges critical point inter-distance values, achieving sucient sample sizes
bin counts presents little diculty. number bins grows \width"
bin correspondingly shrinks, resulting histogram becomes better better approximator underlying continuous distribution, problems small counts
lead larger sampling error (variance). one chooses fit continuous distributions
data, bias/variance dilemma manifests choice distribution types
number parameters parameterized models.
combining individual terms representing secondary structure evidence, one must
address issue inter-attribute dependencies accuracy eciency tradeoffs
poses. Put simply, compute f (ssmjg1; g2) f (ssmjg1) f (ssmjg2)?
pure Bayesian approach without underlying independence assumptions requires exponentially many terms, therefore seek heuristic shortcuts.
Two methods determining confidence values secondary structure assessment
studied applied problem secondary structure identification: 1) Bayesian,
Minimum Message Length (MML) approach, similar previously used protein
substructure classification (Dowe, Allison, Dix, Hunter, Wallace, & Edgoose, 1996),
2) approach similar used expert systems MYCIN (Shortliffe, 1976).
emphasize primary goal described research construction
effective structure recognition systems, rather comparison alternative methods
machine learning classification per se.
142

fiAnalysis Three-Dimensional Protein Images

5.2 Bayesian/MML Approach

adopting Bayesian latent class analysis approach problem, decided treat
estimation combination issues together fitting mixtures continuous distributions
data class, conditional independence assumption commonly used
mixture model approaches classification clustering (McLachlan & Basford, 1988).
latent class analysis approach finding structure set datapoints, one begins
underlying parameterized model. example, one might posit set points
represented 2D scatterplot generated 2D Gaussian (normal) distribution,
means 1 ; 2 covariance matrix V12 . data might better explained
mixture, weighted sum, several Gaussian distributions, 2D mean
vector covariance matrix. approach, one tries find optimal set parameter
values representation datapoint x = (x1 ; x2 ). Optimality may defined
terms maximum likelihood, Bayes optimality, or, case, minimum message
length (MML)7 .
case hand, 11 dimensions instead 2, dimensions
best modeled simple Gaussians. generally accepted angular data
modeled one circular distributions von Mises distribution (Fisher,
1993).
Two independence assumptions, crucial computational eciency data eciency,
underlie approach:
1. Within given class, attributes characterizing segment mutually independent.
2. separate datapoints, corresponding segment, mutually independent.
Although neither assumptions strictly true application, assumptions commonly made circumstances, methods based work
well practice. dependence assumptions proves untenable, one employ elaborate models incorporate explicit dependencies, Bayes Nets
graphical models (Buntine, 1994).

5.3 MYCIN-Like Approach

determined method similar one used diagnosis system MYCIN (Rich
& Knight, 1991) also effective application. Frequency distribution values provide
measures belief disbelief secondary structure assignments based individual
geometric constraints:

MB (ssm; g) = f (ssm; g)
MD(ssm; g) = f (not ssm; g)

(1)
(2)

MB (ssm; g) measure belief hypothesis given peak associated
secondary structure ssm given evidence g, whereas MD(ssm; g) measures
7. However, use general term \Bayesian" informally Bayesian, Minimum Description Length
MML approaches distinguish jointly other, especially \frequentist" approaches.

143

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

extent evidence g supports negation hypothesis ssm peak. Figure
10 illustrates computed probability distributions geometric constraint (bond
angle, distance torsion angle) secondary structure motif (helix, strand).
Like modified Bayesian mixture modeling approach described previous section,
MYCIN methodology represents another heuristic approximation pure \naive" Bayes
approach. case, initial primitive probability terms simple frequency counts
rules combining probabilities assume implicitly different evidence sources
independent. shown lead nonsensical classifications extreme cases,
though practice approach often works quite well.
two pieces evidence considered, confidence measures computed using following formulae:
MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2)(1 , MB (ssm; g1 ))
(3)
MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))
(4)
Given measures, overall certainty factor, CF , determined peak p
critical point graph difference belief disbelief measures:
CF (ssm; g) = MB (ssm; g) , MD(ssm; g)
(5)
g corresponds geometric constraints associated peak p.
result application method interpretation ideal critical point
graph illustrated Figure 11. graph shows broad bands positive CF
indeed representative regular secondary structure motifs ff-helices fi -strands.
practice, critical point, approach constructs CF value secondary
structure hypothesis. end procedure, hypothesis highest CF
value selected. final results thus set sequences CF values characterized
subsequences various lengths identical secondary structure selection.
two pieces evidence considered, confidence measures computed using following formulae:
MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2 )(1 , MB (ssm; g1 ))
(6)
MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))
(7)
Given measures, overall certainty factor, CF , determined peak p
critical point graph difference belief disbelief measures:
CF (ssm; g) = MB (ssm; g) , MD(ssm; g)
(8)
g corresponds geometric constraints associated peak p. result
application method interpretation ideal critical point graph illustrated
Figure 11. graph shows broad bands positive CF indeed representative
regular secondary structure motifs ff-helices fi -strands.

5.4 Results

Following demonstrate two methods analysis described previous section
applied identification secondary structure critical point graphs.
consider graphs constructed ideal experimental electron density maps.
144

fiAnalysis Three-Dimensional Protein Images
0.45

0.18
MB(helix,torsion angle)
MD(helix,torsion angle)

0.35
0.3
0.25
0.2
0.15
0.1
0.05

0.1
0.08
0.06
0.04

150

-150 -100 -50
0
50 100
Torsion angle (degrees)

0.8

150

0.4
MB(helix,distance 1-4)
MD(helix,distance 1-4)

MB(strand,distance 1-4)
MD(strand,distance 1-4)

0.35

Probability Distributions

0.7

Probability Distributions

0.12

0
-150 -100 -50
0
50 100
Torsion angle (degrees)

0.6
0.5
0.4
0.3
0.2
0.1

0.3
0.25
0.2
0.15
0.1
0.05

0

0
0

2

4
6
8
10 12
Distance 1-4 (Angstroms)

14

0

0.6

2

4
6
8
10 12
Distance 1-4 (Angstroms)

14

0.3
MB(helix,angle)
MD(helix,angle)

Probability Distributions

Probability Distributions

0.14

0.02

0

0.5

MB(strand,torsion angle)
MD(strand,torsion angle)

0.16

Probability Distributions

Probability Distributions

0.4

0.4
0.3
0.2
0.1
0

0.25

MB(strand,angle)
MD(strand,angle)

0.2
0.15
0.1
0.05
0

-150 -100 -50
0
50
Angle (degrees)

100

150

-150 -100 -50
0
50
Angle (degrees)

100

Figure 10: Probability distributions computed measures belief (MB) disbelief
(MD) given secondary structure motif geometric constraint.

145

150

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

80
helix
strand

Certainty Factor

60
40
20
0

3-10

strand

turn

strand

a-helix

-20
-40
-60
-80
3

6

16

23

27
28
35
Residue #

47

56

Figure 11: Certainty factors obtained ff-helix fi -strand hypotheses ideal critical point representation protein 4PTI (58 residues) medium-resolution.
figure also denotes correct interpretation residues 16-23 (strand),
23-27 (turn), 28-35 (strand) 47-56 (helix).

5.5 Application Ideal Data
Two Bayesian/MML one MYCIN-based analyses applied secondary structure
identification ideal critical point trees. first Bayesian module (Bayes1 ) trained
using 60 63 ideal protein structure representations previously used
generate occurrence frequency distribution functions torsion angles, distances planar
angles (Figure 10). second Bayesian module (Bayes2 ) trained using 46 ideal critical
point trees 18 critical point representations obtained ORCRIT analysis 3

resolution reconstructed electron density maps. Three ideal critical point representations
kept testing: Cytochrome C2 (2C2C { 112 residues) characterized helices
turns only; Penicillopepsin (3APP { 323 residues) contains short helices (8 residues
less), turns, fi -strands 14 residues long; photosynthetic reaction centre
Rhodobacter Sphaeroides (4RCR { 266 residues) rich ff-helix structure regular
segments 24 residues.
statistical Bayesian modules allow classification critical points 11
geometrical attributes calculated: except first three last three points
critical point sequence, points participate four torsion angles, four distances
(pi pi+3 ), three planar angles. Bayesian module thus applied
secondary structure recognition segments contain 7 peak critical points more,
MYCIN-based module applicable 4-point (or longer) sequences. However,
comparison purposes, points 11 geometrical attributes could calculated
considered recognition. Results presented Table 1. table reports
146

fiAnalysis Three-Dimensional Protein Images

number segments8 correctly incorrectly identified either
Bayesian approaches MYCIN-based module. modules designed classify
recognized secondary structure motifs among four different classes: `helix', `strand', `turn',
`other'. Regarding class `helix', distinction ff-helices helices 310
made posteriori help interpretation results.
Two types percentage values given Table 1. first type, i.e., percentage
actual secondary structure information identified, computed total
number actual secondary structure motifs present three test protein structures: 25
ff-helices, 25 fi -strands, 10 310 helices, 42 turns. Higher percentage values observed
MYCIN-based results versus Bayesian results come fact longer segments
recognized potential helices strands. better overlap actual secondary
structure motifs thus likely occur using MYCIN approach. illustrated
first two examples described Figure 12. Selected secondary structure motifs proteins
2C2C 3APP compared hypotheses generated MYCIN-based Bayes
modules. observed that, two cases, longer identifications provided using
MYCIN closer actual secondary structure amino acid sequences.
percentage correctly identified points within ideal critical point segments
computed total number assigned critical point segments reported Table 1.
Regarding class `helix', longer segments discovered MYCIN-based module,
well larger number incorrectly recognized segments, lead lower percentage values
particular method. shown third example displayed Figure 12.
MYCIN-based module associates long ff-helix particular amino acid sequence
protein 4RCR deviates ideality five residues, Bayes modules provides
reasonable solutions.
worthwhile even segments correctly assigned,
percentage correctly identified peaks 100%. due fact
recognized segments (sequences peaks) shifted one residue respect
definition given PDB file.
results reported Table 1, clear first Bayesian module allows
finer differentiation helices turns (turns four five residue long segments
whose geometry may similar helix geometry) MYCIN-based approach.
MYCIN-based approach tends assign label `helix' actual turns shown Example
(4) Figure 12. hand, 310 helices correctly identified MYCINderived rules, less often discerned using first Bayesian approach (See Example (5)
Figure 12). MYCIN-based module actually strong tendency exaggerate
helical character segment distorted respect ideal case. raises
identification ambiguities 27 (51-24) short segments. wrong identification made
using first Bayesian approach, except one fi -strand. segment also identified
possible strand using MYCIN-based module, hypothesis later rejected
post-processing stage checks parallelism discovered fi -strands.
8. table segment denotes sequence (length 2) adjacent peak critical points belong
secondary structure class (helix, fi -strand, turn). comparing results, noted
PDB data set is, itself, strictly consistent since varying secondary structure definitions
assignment methods used assess structure proteins.

147

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

MYCIN

Bayes1 Bayes2

ff-Helices (actual = 25)
(correctly) assigned segments

(24) 51 (24) 24 (21) 22

% correctly recognized actual motifs

98

87

88

% correctly identified peaks

63

83

82

fi -Strands (actual = 25)
(correctly) assigned segments

(24) 24 (20) 21 (24) 30

% correctly recognized actual motifs

89

71

84

% correctly identified peaks

82

82

81

(10) 10

(7) 7

(7) 7

% correctly recognized actual motifs

97

56

47

% correctly identified peaks

70

70

61

310 Helices (actual = 10)
(correctly) assigned segments

Turns (actual = 42)
(correctly) assigned segments

(4) 4

(12) 12 (21) 28

% correctly recognized actual motifs

7

34

41

% correctly identified peaks

46

77

59

Table 1: Results application two Bayesian approaches MYCIN-based
method recognition secondary structure motifs ideal protein backbones constructed Cff CO centres mass. Note numbers brackets
denote number correctly assigned, versus total number assigned, segments
(sequences peaks).
148

fiAnalysis Three-Dimensional Protein Images

application second Bayesian approach trained realistic critical
point representations generated larger number identified fi -strands turns.
however went number incorrect identifications are, case fi -strands,
associated short segments (2 3 points). case turns, percentage
correctly identified critical points lower (59% respect 77%) due one particular
motif containing seven points.
analysis ideal critical point trees allows conclude second Bayesian
module accurate detecting fi -strand turn structures (there increased
number recognized motifs); use noisy data training stage leads
less acute ability module distinguish short helix-like motifs (there increased
number incorrectly identified motifs).

5.6 Application Experimental Data
presented results obtained applying methods secondary structure identification critical point graphs constructed ideal electron density maps. Following,
describe application methods recognition motifs critical point
representation constructed applying ORCRIT electron density map generated
experimental data. also show structure recognition approaches improved
postprocessing analysis representation. experiment carried
using 3
resolution experimental map Penicillopepsin, protein composed 323
amino acid residues (Hsu, Delbare, James, & Hofmann, 1977; James & Sielecki, 1983).
Neglecting passes located peaks, geometrical parameters computed
short fragments composed seven adjacent peaks main branch graph
protein. achieving geometrical analysis, preprocessing work done
order fit critical point graphs ideal model described above. Distances
computed sets adjacent peaks, peaks separated distance smaller 1.95

merged single point situated center mass. critical point linkage
checked: two adjacent peaks separated distance 5
peaks
assumed connected. Considering connected sequences three peaks time,
distance first third peak smaller 4
A, middle peak
considered part backbone protein (i.e., middle peak probably
denotes side chain). Finally, resulting sequences peaks (which thus likely
representative protein backbone) submitted three secondary structure
analysis methods.
Initially poor results observed MYCIN-like method motivated development
post-processing procedure imposed eliminate helical segments
negative torsion angle values isolated fi -strand segments, i.e., extended segments
parallel similar motifs. postprocessing step analyses global
properties structure, measures belief/disbelief focus local
geometric properties motif. Postprocessing drastically reduces number incorrectly
recognized motifs consequently increases quality recognition procedure (Rost,
Casadia, & Farisellis, 1996).
Table 2 presents comparison results applying three methods identifying
secondary structure motifs experimental electron density map penicillopepsin.
149

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

(1) 2c2c
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

4
H
H
H
H

5
H
H
H
-

6
H
H
H
H

7
H
H
H
H

8
H
H
H
H

9
H
H

H

10
H
H

H

11
310
H
H
H

12
310
H
H
H

13
310
H
H
H

14
310
H
H
H

15
H

H

16
H
H

17
H
-

4

17

(2) 3app
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

203





204


-

205



-

206


-

207


-

208


-

209





210





211





212





(3) 4rcr
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

149
H



150
H

-

151
H
-

152
H
H
H

153
H



154
H
H
H
H

155
H
H
H
H

156
H
H
H
H

157
H
H
H
H

158
H
H
H
H

203

212

159
H
H
H
H

160
H
H
H
H

31
-

(5) 3app
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

126
-

127
310
H
H
-

128
310
H
H
-

(6) 3app
cp no.
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

71
139
H
-

199
140
H
H

H

1370
141
H
H

H

32

H



33

H



34

H



35

H



129
310
H
-

506
142
H
H
H
H

36

H



37

H


130
H
-

131
-

75
143
H
H
-

38


-

162
H
H
H
H

163
H
H
H

163

149

39

31

(4) 2c2c
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

161
H
H
H
H

39



131
126

388
144
H
H



144
139

129

(7) 3app
cp no.
aa no.
Actual ss
MYCIN
Bayes1
Bayes2

188
129
H
H


482
H
-

205
135
H
H

235
134
H


905
133
H
H
H

320
132
H



756
131
H

-

581
132
H


122
H
-

422
H
H
-

1431
103
H
-

42
102
H
H
H

630
H
H

904
85
H
-

825
86
H
H

131
135
102
103

86
85

Figure 12: Selected amino acid secondary structure motifs identifications (`cp',
`aa', `ss' stand `critical point', `amino acid', `secondary structure',
respectively. `H', `T', `S', `-' denote secondary structure classes: `helix',
`turn', `sheet', `other'.)
150

fiAnalysis Three-Dimensional Protein Images

MYCIN

Bayes1 Bayes2

ff-Helices (actual = 3)
(correctly) assigned segments

(3) 7

(0) 0

(2) 3

% correctly recognized actual motifs

91

9

45

% correctly identified peaks

26

-

57

fi -Strands (actual = 15)
(correctly) assigned segments

(12) 12 (12) 12

(9) 9

% correctly recognized actual motifs

70

41

30

% correctly identified peaks

73

91

96

(1) 1

(0) 0

(0)0

% correctly recognized actual motifs

50

17

0

% correctly identified peaks

75

-

-

(0) 0

(1) 3

(1) 2

% correctly recognized actual motifs

0

33

27

% correctly identified peaks

-

100

43

310 Helices (actual = 2)
(correctly) assigned segments

Turns (actual = 1)
(correctly) assigned segments

Table 2: Results application two Bayesian approaches MYCIN-based
method recognition secondary structure motifs minimal spanning trees
constructed critical point analysis experimental electron density map
penicillopepsin 3
resolution. Note numbers brackets denote
number correctly assigned, versus totally assigned, segments (sequences
peaks).
151

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

According Table 2, MYCIN-based approach appears greater success
recognizing helical motifs experimental maps. Example (6) Figure 12 depicts one
three helix motifs correctly recognized using MYCIN-based approach.
However, approach also misidentifies several motifs helices. Among four incorrectly identified helices, two four-point segments actual turns, one four-point segment
characterized negative torsion angles, 15-point sequence critical points
succession three jumps (a jump connection occurring non-adjacent amino
acid residues) (See Example (7) Figure 12). Bayes modules incorrectly identify
turn region electron density map. Jumps problematic may
seriously hinder recognition rate, especially experimental maps blurred noise
errors.
Table 2 illustrates consideration noisier data training set (module
Bayes2 ) leads improvement number identified ff-helices respect
first Bayesian module (Example (6) Figure 12). However, also leads number
incorrectly identified segments. One segment length two wrongly identified helix.
actually corresponds jump non-adjacent amino acid residues; jump also
generates interpretation error MYCIN-based algorithm. poor accuracy
turn recognition (43 %) due wrongly identified segment.

6. Related Research
interpretation protein images greatly facilitated recent years
advent powerful graphics stations coupled implementation highly ecient
computer programs, notably FRODO (Jones, 1992) (Jones et al., 1991). Although
programs designed specifically visual analysis electron density maps
proteins, still require significant amount expert intervention interpretation
require considerable time investment. Unlike systems ORCRIT designed
automated approach protein model building interpretation.
research presented paper component ongoing research project
area molecular scene analysis (Fortier et al., 1993; Glasgow et al., 1993). primary
objective research implementation application computational methods
classification understanding complex molecular images. Towards goal,
proposed knowledge representation framework integrating existing sources
protein knowledge (Glasgow, Fortier, Conklin, Allen, & Leherte, 1995). Representations
reasoning visual spatial characteristics molecular scene captured
framework using techniques computational imagery (Glasgow, 1993; Glasgow
& Papadias, 1992). paper extends previous publications molecular scene analysis
placing research artificial intelligence framework relating work
machine vision. well, focuses use uncertain reasoning secondary structure
interpretation critical point representation provides experimental results
supporting approaches protein image interpretation.
Two kinds image improvement procedures considered conjunction
information stored critical point representation. first one consists improving phase information given resolution. necessary, dicult, step
protein structure determination carried experimental data. Structural informa152

fiAnalysis Three-Dimensional Protein Images

tion retrieved topological analysis might injected so-called direct methods
procedure, previously successfully applied structure determination
small molecules high resolution (Hauptman & Karle, 1953), recently macromolecules well. However, methods presently applicable protein images
low- medium-resolution data, time-consuming experimental methods generally
used phase recovery protein structure elucidation.
second set procedures protein image enhancement involves construction
interpretation increasingly higher-resolution maps. presently carried
visually crystallographers access well-phased medium- high-resolution
map. highest density regions fitted fragments retrieved database
chemical templates, eventually allowing determination protein's 3D structure
(Jones et al., 1991). two protein image reconstruction procedures interrelated:
improved phases lead reliable map motif identification take
place. considerations, secondary structure motifs detected low-resolution
map regions interest generate medium-resolution information, would
give access amino acid residue locations.
procedures give rise iterative approach molecular scene analysis.
iterative refinement process, portion image interpreted
information applied (via inverse Fourier transform) adjust current phases.
modified phases used generate new image. approach scene analysis thus
proceeds initial coarse (low-resolution) image progressively detailed
(higher-resolution) images substructures identifiable9.
implies particular resolution, necessary analysis
identify substructures. recognition parts scene used improve
phases, giving rise overall improvement image. new image
analyzed leading additional interpretations. process iteratively applied
(within heuristic search strategy) protein structure fully determined.
critical point representation described paper one component
knowledge representation scheme computational imagery. second component
scheme involves spatial logic, used represent reason
concepts qualitative spatial features associated protein molecule (Conklin et al.,
1993b; Conklin, Fortier, Glasgow, & Allen, 1996). Associated spatial representation
knowledge discovery technique, called IMEM (Conklin & Glasgow, 1992), based
theory conceptual clustering. system used discover recurrent 3D
structural motifs molecular databases (Conklin, Fortier, & Glasgow, 1993a; Conklin
et al., 1996). anticipate machine learning/discovery techniques
(e.g., (Hunter, 1992; Lapedes, Steeg, & Farber, 1995; Unger et al., 1989)) could applied
aid top-down analysis novel molecular scenes order anticipate classify
structural motifs. would complementary bottom-up scene analysis provided
topological approach described paper.
Molecular scene analyses benefit research protein structure prediction. particular, currently investigating formulations derived inverse folding
problem (Bowie, Luethy, & Eisenberg, 1991). Given amino acid sequence set
9. resolution image depends number experimental ections available well
amount phase information.

153

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

core segments (pieces secondary structure forming tightly packed internal protein
core), approach prediction evaluates possible alignment (threading) known
primary sequence amino acids onto possible core templates. problem identifying
individual residues critical point map medium high-resolution addressed
similar manner, i.e., attempting thread sequence onto protein structure derived
topological analysis. problem significantly simpler protein structure
prediction since involves threading sequence onto experimentally determined
structure, rather onto templates retrieved library possible models.
threading approach proposed Lathrop Smith (1994), scoring function used
derive statistical preference residue given environment. Modifications
current scoring function, incorporate properties available electron density map
critical point graph representations, implemented order customize approach information available topological analysis (Baxter, Steeg, Lathrop,
Glasgow, & Fortier, 1996).

7. Conclusions
reported paper topological approach effectively applied
segmentation protein images meaningful parts low- medium-resolution.
Furthermore, shown secondary structure motifs could identified mediumresolution images geometric analysis image representation; application
geometric rules probabilities yields measure confidence given peak
component known secondary structure motif.
Three secondary structure identification modules applied interpretation
ideal experimental critical point graphs. Two probabilistic Bayesian approaches
MYCIN-based method revealed geometric components torsion angles,
distances planar angles useful differentiate helices, strands,
turns.
Bayesian MYCIN-derived approaches relatively successful assigning
secondary structure identifications sequences critical points geometrically well
resolved. case noisy experimental data, accuracy decreased. anticipate
accuracy could improved use larger training sets
training 3-10 helix subclasses. However, expect achieve full
secondary structure recognition protein { rather expect interpret good (less
noisy) portions electron density map use information iteratively improve
image order carry analyses.
protein structures used compose training test sets contain backbone
information only. structures free heteroatoms and/or small solvent molecules.
prior knowledge chemical composition crystallographic cell would certainly
help anticipating problems connections non-adjacent residues
high density peaks. Additional experimental data would permit us extend scope
three approaches described present paper.
Modern crystallographic studies remain forefront current efforts characterize understand molecular recognition processes. long-term goal research
molecular scene analysis assist studies computational methodology
154

fiAnalysis Three-Dimensional Protein Images

aiding expert crystallographers complex imagery processes required fully interpret
3D structure protein. topological approach presented important
component methodology. research required, however, extend
analysis multi-resolution maps, incorporate domain knowledge
analyses.

Acknowledgements
authors wish thank Carroll Johnson providing ORCRIT program
ongoing collaboration project, Marie Fraser providing access
experimental electron density map penicillopepsin. Financial support research
provided Natural Science Engineering Research Council (NSERC) Canada
Belgian National Council Scientific Research (FNRS). also thanks FNRS
\Charge de Recherches" position.

References
Arman, F., & Aggarwal, J. (1993). Model-based object recognition dense-range images
- review. ACM Computing Survery, 25 (1), 5{43.
Baxter, K., Steeg, E., Lathrop, R., Glasgow, J., & Fortier, S. (1996). electron density
sequence structure: Integrating protein image analysis threading structure determination. Proceedings 4th International Conference Intelligent
Systems Molecular Biology, pp. 25{33. AAAI/MIT Press, Menlo Park, California.
Bernstein, F., Koetzle, T., Williams, J., Meryer, E., Brice, M., Rodgers, J., Kennard, O.,
Shimanouchi, T., & Tasumi, M. (1977). Protein Data Bank: computer{based
archival file macromolecular structures. Journal Molecular Biology, 112, 535{
542.
Besl, P., & Jain, R. (1986). Invariant surface characteristics 3D object recognition
range images. CVGIP, 33, 33{80.
Binford, T. (1971). Visual perception computer. Proceedings IEEE Conference
Systems Control Miami, Florida.
Bowie, J., Luethy, R., & Eisenberg, D. (1991). method identify protein sequences
fold known three-dimensional structure. Science, 253, 164{170.
Buntine, W. (1994). Operations learning graphical models. Journal Artificial
Intelligence Research, 2, 159{225.
Conklin, D., Fortier, S., & Glasgow, J. (1993a). Knowledge discovery molecular databases.
IEEE Transactions Knowledge Data Engineering, 985{987. Special Issue
Learning Discovery Knowledge-Based Databases.
155

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Conklin, D., Fortier, S., & Glasgow, J. (1993b). Representation discovery protein
motifs. Hunter, L., Searls, D., & Shavlik, J. (Eds.), Proceedings First International Conference Intelligent Systems Molecular Biology. AAAI/MIT Press,
Menlo Park, California.
Conklin, D., Fortier, S., Glasgow, J., & Allen, F. (1996). Conformational analysis
crystallographic data using conceptual clustering. Acta Crystallographica, B52, 535{
549.
Conklin, D., & Glasgow, J. (1992). Spatial analogy subsumption. Sleeman, &
Edwards (Eds.), Machine Learning: Proceedings Ninth International Conference
ML(92), pp. 111{116. Morgan Kaufmann.
Dowe, D., Allison, L., Dix, T., Hunter, L., Wallace, C. S., & Edgoose, T. (1996). Circular clustering protein dihedral angles minimum message length. Pacific
Symposium Biocomputing '96, pp. 242{255.
Faugeras, O. (1993). Three-dimensional computer vision: geometric viewpoint. MIT Press.
Feigenbaum, E., Engelmore, R., & Johnson, C. (1977). correlation crystallographic computing artificial intelligence research. Acta Crystallographica, A33,
13{18.
Fisher, N. (1993). Statistical Analysis Circular Data. Cambridge University Press, Melbourne, Australia.
Fortier, S., Castleden, I., Glasgow, J., Conklin, D., Walmsley, C., Leherte, L. & Allen, F.
(1993). Molecular scene analysis: integration direct methods artificial
intelligence strategies solving protein crystal structures. Acta Crystallographica,
D49, 168{178.
Gauch, J., & Pizer, S. (1993). Multiresolution analysis ridges valleys grey-scale
images. IEEE Transactions Pattern Analysis Machine Intelligence, PAMI15 (6), 635{646.
Glasgow, J., Fortier, S., Conklin, D., Allen, F., & Leherte, L. (1995). Knowledge representation tools molecular scene analysis. Proceedings Hawaii International
Conference Systems Sciences, Biotechnology Computing Track.
Glasgow, J. (1993). imagery debate revisited: computational perspective. Computational Intelligence, 9 (4), 309{333. Taking issue paper.
Glasgow, J., Fortier, S., & Allen, F. (1993). Molecular scene analysis: crystal structure determination imagery. Hunter, L. (Ed.), Artificial Intelligence Molecular
Biology, pp. 433{458. AAAI Press, Menlo Park, California.
Glasgow, J., & Papadias, D. (1992). Computational imagery. Cognitive Science, 16 (3),
355{394.
156

fiAnalysis Three-Dimensional Protein Images

Greer, J. (1974). Three-dimensional pattern recognition: approach automated interpretation electron density maps proteins. Journal Molecular Biology, 82,
279{301.
Gupta, A., & Bajcsy, R. (1993). Volumetric segmentation range images 3d objects
using superquadric models.. CVGIP: Image Understanding, 58 (3), 302{326.
Guziec, A., & Ayache, N. (1992). Smoothing matching 3-d space curves. Visualization
Biomedical Computing, Proc. SPIE, 1808, 259{273.
Hall, S., & Stewart, J. (Eds.). (1990). XTAL 3.0 User's Manual. Universities Western
Australia Maryland.
Haralick, R., Watson, L., & Laffey, T. (1983). topographic primal sketch. International
Journal Robotics Research, 2, 50{72.
Hauptman, H., & Karle, J. (1953). Solution Phase Problem, 1. Centrosymmetric
Crystal, ACA Monograph No. 3. Wilmington:Polycrystal Book Service.
Higgins, W., Spyra, W., Karwoski, R., & Ritman, E. (1996). System analyzing highresolution three-dimensional coronary angiograms. IEEE Transactions Medical
Imaging, 15 (3), 377{385.
Hilditch, C. J. (1969). Linear skeletons square cupboards. Machine Intelligence, 4,
403{420.
Hsu, I.-N., Delbare, L., James, M., & Hofmann, T. (1977). Penicillopepsin penicillium
janthinellum. crystal structure 2.8 sequence homology porcine pepsin.
Nature, 266, 140{145.
Hunter, L. (1992). Artificial intelligence molecular biology. Proceedings
Tenth National Conference Artificial Intelligence, pp. 866{868. AAAI, Menlo Park,
California.
Hunter, L., & States, D. (1991). Applying Bayesian classification protein structure.
Proceedings Seventh IEEE Conference Artificial Intelligence Applications
Miami, Florida.
Jain, A., & Flynn, P. (Eds.). (1993). Advances Three Dimensional Object Recognition
Systems, volume 1. Elsevier.
James, M., & Sielecki, A. (1983). Structure refinement penicillopepsin 1.8
resolution. Journal Molecular Biology, 163, 299{361.
Johnson, C. (1977). ORCRIT. Oak Ridge critical point network program. Tech. rep.,
Chemistry Division, Oak Ridge National Laboratory, USA.
Jones, T. (1992). FRODO. graphics fitting program macromolecules. Sayre, D.
(Ed.), Crystallographic Computing. Clarendon Press, Oxford.
157

fiLeherte, Glasgow, Baxter, Steeg, & Fortier

Jones, T., Zou, J., Cowan, S., & Kjeldgaard, M. (1991). Improved methods building
protein models electron-density maps location errors models.
Acta Crystallographica, A47, 110{119.
Lapedes, A., Steeg, E., & Farber, R. (1995). Use adaptive networks evolve highly
predictable protein secondary-structure classes. Machine Learning, 21, 103{124.
Lathrop, R., & Smith, T. (1994). branch bound algorithm optimal protein threading pairwise (contact potential) interaction preferences. L., H., & B., S. (Eds.),
Proc. 27th Hawaii Intl. Conf. System Sciences, pp. 365{374. IEEE Computer Society Press, Los Alamitos, California.
Lee, S., & Kim, Y. (1995). Direct extraction topographic features gray scale character
recognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-17 (7), 724{729.
Leherte, L., Baxter, K., Glasgow, J., & Fortier, S. (1994a). computational approach
topological analysis protein structures. Altman, R., Brutlag, D., P.Karp, Lathrop, R., & Searls, D. (Eds.), Proceedings Second International Conference
Intelligent Systems Molecular Biology. MIT/AAAI Press, Menlo Park, California.
Leherte, L., Fortier, S., Glasgow, J., & Allen, F. (1994b). Molecular scene analysis:
topological approach automated interpretation protein electron density maps.
Acta Crystallographica D, D50, 155{166.
Leonardis, A., Gupta, A., & Bajcsy, R. (1995). Segmentation range images search
geometric parametric models. International Journal Computer Vision, 14, 253{
277.
Maintz, J., van den Elsen, P., & Viergever, M. (1996). Evaluation ridge seeking operators
multimodality medical image matching. IEEE Transactions Pattern Analysis
Machine Intelligence, 18 (4), 353{365.
Marr, D. (1982). Vision. W.H. Freeman Company: San Francisco.
Marr, D., & Nishihara, H. (1978). Representation recognition spatial organisation
three-dimensional shapes. Proceedings Royal Society London, B200, 269{
294.
McLachlan, G., & Basford, K. (1988). Mixture Models. Inference Applications Clustering. Marcel Dekker, Inc.
Rich, E., & Knight, K. (1991). Artificial Intelligence. McGraw-Hill, Inc. Second Edition.
Rost, B., Casadia, R., & Farisellis, P. (1996). Refining neural network predictions helical
transmembrane proteins dynamic programing. Fourth International Conference
Intelligent Systems Molecular Biology (ISMB '96), pp. 192{200. AAAI Press,
Menlo Park, California.
Shortliffe, E. (1976). Computer-Based Medical Consultations: MYCIN. Elsevier, New York.
158

fiAnalysis Three-Dimensional Protein Images

Terry, A. (1983). Crysalis Project: Hierarchical Control Production Systems. Ph.D.
thesis, Stanford Heuristic Programming Project, Stanford University, California, USA.
Unger, R., Harel, D., Wherland, S., & Sussman, J. (1989). 3D building blocks approach
analyzing predicting structure proteins. Proteins, 5, 355{373.
Wang, B. (1985). Resolution phase ambiguity macromolecular crystallography.
Wyckoff, H., Hirs, C., & Timasheff, S. (Eds.), Diffraction Methods Biological
Macromolecules. Academic Press, New York.
Wang, L., & Pavlidis, T. (1993). Direct gray scale extraction features character
recognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-15 (10), 1053{1067.
Zhang, Z., & Faugeras, O. (1992). 3D Dynamic Scene Analysis. Springer-Verlag.

159

fiJournal Artificial Intelligence Research 7 (1997) 199-230

Submitted 5/97; published 11/97

Model Approximation Scheme Planning Partially
Observable Stochastic Domains
Nevin L. Zhang
Wenju Liu

Department Computer Science
Hong Kong University Science Technology
Hong Kong, China

lzhang@cs.ust.hk
wliu@cs.ust.hk

Abstract
Partially observable Markov decision processes (POMDPs) natural model
planning problems effects actions nondeterministic state world
completely observable. dicult solve POMDPs exactly. paper proposes new approximation scheme. basic idea transform POMDP another
one additional information provided oracle. oracle informs planning agent current state world certain region. transformed
POMDP consequently said region observable. easier solve original POMDP. propose solve transformed POMDP use optimal policy
construct approximate policy original POMDP. controlling amount additional information oracle provides, possible find proper tradeoff
computational time approximation quality. terms algorithmic contributions,
study details exploit region observability solving transformed POMDP.
facilitate study, also propose new exact algorithm general POMDPs.
algorithm conceptually simple yet significantly ecient previous
exact algorithms.

1. Introduction
completely observable deterministic world, plan find sequence actions
lead agent achieve goal. real-world applications, world rarely completely observable effects actions almost always nondeterministic. reason,
growing number researchers concern planning partially observable
stochastic domains (e.g., Dean & Wellman, 1991; Cassandra et al., 1994; Parr & Russell,
1995; Boutilier & Poole, 1996). Partially observable Markov decision processes (POMDPs)
used model planning domains. model, nondeterminism
effects actions encoded transition probabilities, partial observability world
observation probabilities, goals criteria good plans reward functions (see
Section 2 details).
POMDPs classified finite horizon POMDPs infinite horizon POMDPs depending number time points considered. Infinite horizon POMDPs usually
used planning one typically know beforehand number steps
takes achieve goal. paper concerned solve infinite horizon
POMDP.
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiZhang & Liu

1.1 Diculties Solving POMDPs
world fully observable, POMDP reduces Markov decision process (MDP).
MDPs studied extensively dynamic-programming literature (e.g., Puterman, 1990; Bertsekas, 1987, White, 1993). Recent works concentrated deal
large state spaces (Dean et al., 1993; Boutilier et al., 1995; Dean & Lin, 1995).
concerned partially observable case. case considerably
dicult fully observable case two related reasons. First, agent knows
exactly state world currently is, information past (past observations
actions) irrelevant current decision. Markov property.
hand, agent fully observe state world, past information
becomes relevant help agent better estimate current state
world. problem number possible states past information increases
exponentially time.
Second, MDPs effects action fully observed next time point.
POMDPs, hand, effects action fully observed next
time point. Hence one cannot clearly tell effects current action
agent's future behaviors. properly evaluate effects action, one needs look
future consider combination action agent's possible
behaviors a, possibly large, number future steps. problem number
ways agent behave exponential number future steps considered.

1.2 Previous Work
Previous methods solving POMDPs usually classified exact methods approximate methods (Lovejoy, 1991a). also classified according
aforementioned two diculties directly address. previous methods address
diculty exponential number future behaviors (Sondik, 1971; Sondik & Mendelssohn,
1979; Monahan, 1982; Cheng, 1988; Lovejoy, 1991b; Cassandra et al., 1994).
prune consideration behaviors never optimal matter information state (Section 4). methods deal problem exponential number
past information states either aggregating (Platzman, 1977; White & Schere,
1994) considering subset (Lovejoy, 1992; Brafman, 1997; Hauskrecht,
1997). approximation methods nature.

1.3 Model Approximation
previous approximation methods, approximation takes place process solving
POMDP. advocate model approximation methods. method approximates
POMDP another one easier solve uses solution latter
construct approximate solution original POMDP.
Model approximation form informative observation model,
deterministic action model, simpler state space, combination two
three alternatives. Cassandra et al. (1996) proposed approximate POMDPs
using MDPs. example model approximation form informative
observation model. also work reducing size state spaces MDPs
200

fiModel Approximation Planning Uncertainty

aggregation (e.g., Bertsekas & Castanon, 1989; Dean & Lin, 1995; Dean & Givan, 1997).
work conceivably extended POMDPs, leading model approximation
form simpler state space. aware model approximation schemes
form deterministic action model.

1.4 Proposal
paper proposes new model approximation scheme form informative
observation model. generalization idea approximating POMDPs using
MDPs.
transform POMDP assuming that, addition observations obtained
itself, agent also receives report oracle knows true state world.
oracle report true state itself. Instead, selects, predetermined
list candidate regions, region contains true state reports region.
transformed POMDP said region observable agent knows sure
true state region reported oracle.
candidate regions singletons, oracle actually reports true state
world. region observable POMDP reduces MDP. MDPs much easier
solve POMDPs. One would expect region observable POMDP solvable
candidate regions small.
terms approximation quality, larger candidate regions, less additional
information oracle provides hence accurate approximation.
extreme case one candidate region consists possible states
world, oracle provides additional information all. Consequently, region
observable POMDP identical original POMDP.
method determining approximation quality described later paper.
allows one make tradeoff approximation quality computational time
follows: start small candidate regions increase sizes gradually
approximation becomes accurate enough region observable POMDP becomes untractable.
Due problem characteristics, accurate approximation usually achieved
small candidate regions. many applications agent often good idea
state world (e.g., Simmons & Koenig, 1995). Take robot path planning example.
Observing landmark, room number instance, would imply robot
proximity landmark. Observing feature world, corridor T-junction
instance, might imply robot one several regions. Taking history account,
robot might able determine unique region current location. Also, action
usually moves state world \nearby" states. Thus robot
good idea current state world, continue good idea
next steps.
agent good idea state world times, oracle
provide much additional information even small candidate regions hence
approximation accurate. Region observable POMDPs small candidate regions
much easier solve general POMDPs.
201

fiZhang & Liu

1.5 Organization

first show POMDPs used model planning partially observable
stochastic domains (Section 2) give concise review theory POMDPs (Sections
3 4). propose new method dynamic-programming updates, key
step algorithms solve POMDPs via value iteration (Section 5). Thereafter,
formally introduce concept region observable POMDPs (Section 6) develop
algorithm solving region observable POMDPs (Sections 7, 8, 9). Section 10,
discuss decision making original POMDPs based solutions
region observable approximations, followed method determining approximation
quality (Section 11) method make tradeoff approximation quality
computational time (Section 12). Finally, empirical results reported Section 13
conclusions provided Section 14.

2. Planning Stochastic Domains POMDPs

specify planning problem, one needs give set possible states world,
set possible observations, set possible actions. sets
always assumed finite literature, state space continuous
well finite. paper, consider finite state space. One needs also give
observation model describes relationship observations state
world, action model describes effects actions.
background example, consider path planning robot acts oce
environment. set location-orientation pairs, set possible
sensor readings, consists actions move-forward, turn-left, turn-right,
declare-goal.
current observation depends current state world s. Due sensor
noise, dependency uncertain nature. observation sometimes also depends
action robot taken a- . minus sign subscript indicates
previous time point. POMDP model, dependency upon a-
numerically characterized conditional probability P (ojs; a- ), usually referred
observation probability. observation model.
region observable POMDP, current observation also depends previous state world s- . observation probability case written
P (ojs; a- ; s-).
state s+ world next time point depends current action
current state s. plus sign subscript indicates next time point.
dependency uncertain nature due uncertainty actuator. POMDP
model, dependency s+ upon numerically characterized conditional
probability P (s+ js; a), usually referred transition probability.
action model.
many occasions, need consider joint conditional probability P (s+ ; o+ js; a)
next state world next observation given current state
current action. given

P (s+; o+js; a) = P (s+ js; a)P (o+ js+; a; s):
202

fiModel Approximation Planning Uncertainty

Knowledge initial state, available, represented probability distribution

P0 . agent knows initial state certainty, P0 1 initial state

0 everywhere else. planning goal encoded reward function
following:
(
a=declare-goal s=goal,
r(s; a) = 10 ifotherwise.
preference short plans encoded discounting future rewards respect
current reward (see next section).
summary, POMDP consists set possible states world, set possible
observations, set possible actions, observation probability, transition probability,
reward function. MDP ingredients POMDP except
observation probability. state world completely observed
MDP.

3. Basics POMDPs

section reviews several concepts results related POMDPs.

3.1 Belief States

POMDP, agent chooses executes action time point. choice
made based information past (past observations past actions)
current observation. amount memory required store past observations actions
increases linearly time. makes dicult maintain past information
long period time.
standard way overcome diculty maintain, instead past information,
agent's belief state | probability distribution P (st jot ; at,1 ; ot,1 ; : : : ; a1 ; o1 ; P0 )
current state st world given past information current observation. well
known belief state sucient statistic sense captures
information contained past information current observation useful
action selection. Hence agent base decision solely belief state.
Compared maintaining past information, maintaining belief state desirable
number possible states world finite. One needs maintain
fixed finite number probability values1 .
initial belief state P0 . One question agent update belief
state time goes by. Following Littman (1994), use b denote belief state.
state s, b(s) probability world state s. set possible belief
states denoted B.
Suppose b current belief state, current action. observation o+
obtained next time point, agent update belief state b
new belief state b+ given
X
b+ (s+) = k P (s+; o+ js; a)b(s);
(1)


1. Storing values exactly could require unbounded precision. Approximations implicitly
made due fact machine precision bounded.

203

fiZhang & Liu

k=1=

P

s;s+ P (s+ ; o+

js; a)b(s) normalization constant (e.g., Littman, 1994).

3.2 POMDPs MDPs

belief state b action a, define

r(b; a) =

X


b(s)r(s; a):

(2)

expected immediate reward taking action belief state b.
belief state b, action a, observation o+ , define

P (o+ jb; a) =

X

s;s+

P (s+; o+ js; a)b(s):

(3)

probability observing o+ next time point given current belief state
b current action a. Let b+ belief state given equation (1). P (o+ jb; a)
also understood probability next belief state b+ given
current action current belief state b.
POMDP world state space viewed MDP belief state
space B. reward function transition probability MDP given
Equations (2) (3) respectively.

3.3 Optimal Policies

time point, agent consults belief state chooses action. policy
prescribes action possible belief state. Formally mapping B A.
belief state b, (b) action prescribed b.
Suppose b0 current belief state. agent follows policy , current
action (b0 ) immediate reward r0 (b; (b0 )); probability P (o+ jb0 ; (b0 )),
agent's next belief state b1 given Equation (1), next action
(b1 ), next reward r1 (b1 ; (b1 )); forth. quality
policy measured expected discounted rewards garners. Formally value
function policy defined belief state b0 following expectation:
1
X

V (b0 ) = Eb0 [

i=0

ri (bi ; (bi ))];

(4)

0 <1 discount factor.
policy 1 dominates another policy 2 belief state b2B

V 1 (b) V 2 (b):

(5)

Domination partial ordering among policies. well known exists policy
dominates policies (e.g., Puterman, 1990). policy called optimal
policy. value function optimal policy called optimal value function
denoted V .
204

fiModel Approximation Planning Uncertainty

3.4 Value Iteration

Value iteration standard way solving infinite horizon MDPs (Bellman, 1957).
begins arbitrary initial function V0 (b) improves iteratively using
following equation

Vt(b) = maxa [r(b; a) +

X
o+

P (o+ jb; a)Vt,1 (b+ )];

(6)

b+ belief state given equation (1). V0 =0, Vt called t-step
optimal value function. belief state b, Vt (b) optimal expected reward
agent get steps starting b.
following theorem (Puterman, 1990, page 361) tells one terminate value
iteration construct \good enough" policy.

Theorem 1 Let policy given
(b) = arg maxa [r(b; a) +

X
o+

P (o+ jb; a)Vt (b+ )]:

(7)

maxb2B jVt (b) , Vt,1 (b)j ,

maxb2B jV (b) , V (b)j 12, :2

(8)

quantity maxb2B jVt (b) , Vt,1 (b)j sometimes called Bellman residual
policy called greedy policy based Vt .
Algorithms POMDPs classified exact approximation algorithms depending
whether compute t-step optimal value function Vt exactly (Lovejoy, 1991a).
next two sections, discuss theoretical foundations exact algorithms
develop new exact algorithm. Thereafter, propose new approximation algorithm.

4. Piecewise Linearity Implicit Value Iteration

Since belief space continuous, exact value iteration cannot carried explicitly.
Fortunately, carried implicitly due piecewise linearity t-step
optimal value functions. explain piecewise linearity, need concept policy trees.

4.1 Policy Trees

t-step policy tree pt (Littman, 1994) prescribes action current time point
action possible information scenario (o1 ; : : : ; oi ; a0 ; : : : ; ai,1 )
next t,1 time points i. Figure 1 shows 3-step policy tree. tree reads follows.
Move-forward current time point. next time point, o1 =0 observed
turn-left. Thereafter o2 =0 observed turn-left again; else o2 =1 observed
declare-goal; else o2 =2 observed move-forward. forth.
relate back introduction, t-step policy tree prescribes way agent might
behave current next t,1 time points.
205

fiZhang & Liu

turn-left



2

0
turn-left

a1

O2

1

a2

declare-goal

2
a2

0

forward

declare-goal

a2
0
forward

a0

O1

1

turn-right


2

a1

1

turn-right


2

2
turn-left


2

2

declare-goal

a2
0
a1

forward


2

1

turn-left

a2

2

declare-goal


2

Figure 1: 3-step policy tree.
t>1, subtree rooted o1 node called o-rooted t,1-step policy
tree, denoted t,1 . mapping set possible observations
set possible t,1-step policy trees; prescribes t,1 step policy tree t,1 (o)
possible observation o. example, 2 (o1 =0) 2-step policy tree rooted
uppermost a1 node.
t>1, t-step policy tree pt two components: action current time
point o-rooted t,1-step policy tree t,1 next t,1 time points.
reason, shall sometimes write pt pair (a; t,1 ) call first action pt .
altering actions edges a-nodes, one obtains different t-step
policy trees. set possible t-step policy trees denoted Pt . 1-step
policy tree simply action, hence P1 set possible actions A.

4.2 State Value Functions Policy Trees

state t-step policy tree pt =(a; t,1 ), recursively define

Vp (s) = r(s; a) +


XX
o+ s+

V ,1 (o+) (s+ )P (s+ ; o+ js; a);


(9)

second term understood 0 t=1. expected discounted
total reward agent receives current time next t,1 time points
world currently state agent behaves according policy tree pt .
call Vp state value function t-step policy tree pt .
Without mentioning policy tree, shall sometimes call Vp t-step state value
function. collection t-step state value functions denoted Vt , i.e.
Vt = fVp jpt 2Pt g:
convenience, let V0 consist one single function zero s.






206

fiModel Approximation Planning Uncertainty

4.3 State Space Functions Belief Space Functions

worthwhile point t-step state value function state space function, i.e.
function state space , t-step optimal value function belief space
function, i.e. function belief space B. often use notations ff fi
refer state space functions. state space function ff(s) induces belief space function

X
ff(b) = ff(s)b(s):


Regarding b vector one component b(s) s, induced belief space function
linear combination components b. convenience, simply say ff(b)
linear b.
collection V state space functions induces belief space function

V (b) = maxff2V ff(b):

(10)

Note using V denote set state space functions belief space
function induces. V empty, V (b) 0 definition.
induced belief space function V (b) piecewise linear b sense that,
ff2V , equals ff(b) region fbjff(b)fi (b) fi 2Vg belief space B
hence linear b region.

4.4 Piecewise Linearity Optimal Value Functions

following theorem first proved Sondik (1971). first appeared present
form Littman (1994).

Theorem 2 (Piecewise Linearity) t-step optimal value function Vt
belief space function induced collection t-step state value functions Vt , i.e.
belief state b

Vt (b) = Vt (b):2

theorem true following reasons. Vt (b) reward agent receives behaves optimally policy tree pt , Vp (b) reward agent gets behaves according pt . one policy trees must optimal, Vt (b) = maxp Vp (b)=Vt (b).
Due theorem, say collection Vt state value functions representation
Vt .






4.5 Parsimonious Representations
size Vt increases exponentially t. matter fact, total number t-step
policy trees (Cassandra, 1994) is:

jOj ,1


jPt j = jAj jOj,1 :
potentially number t-step state value functions. Fortunately, many
state value functions pruned without affecting induced belief space function.
Let us make property explicit.
207

fiZhang & Liu

Let W X two sets state space functions. say W covers X induces
belief space function X does, i.e.
W (b) = X (b)
belief state b. say W parsimoniously covers X W covers X none
proper subsets do. W covers parsimoniously covers X , refer W
covering parsimonious covering X .
Theorem 3 parsimonious coverings set state space functions consist
number state space functions. 2
theorem known sometime (e.g., Littman, 1994). Due theorem, one
also define parsimonious covering covering contains minimum number
state space functions.
parsimonious covering V^t Vt also representation Vt sense V^t (b) =
Vt (b) belief state b. representation parsimonious consists
fewest number state space functions among representations Vt .

4.6 Dynamic-Programming Updates

question obtain parsimonious covering Vt . shown
next section, possible obtain parsimonious covering Vt starting
parsimonious covering Vt,1 . process computing parsimonious covering Vt
parsimonious covering Vt,1 called dynamic-programming updates (Littman et
al., 1995). key step algorithms solve POMDPs via value iteration.
Previous algorithms dynamic-programming updates include enumeration
pruning algorithms Monahan (1992), Eagle (1984), Lark (White, 1991), onepass algorithm Sondik (1971), linear support relaxed region algorithms Cheng
(1988), witness algorithm Cassandra et al. (1994) Littman (1994).
witness algorithm empirically proved ecient among
algorithms (Littman et al., 1995).

4.7 Implicit Value Iteration

procedure solvePOMDP shown Figure 2 carries value iteration implicitly: instead
inductively computing t-step optimal value function Vt itself, computes parsimonious covering Vt | set state space functions represents Vt . procedure,
subroutine update(V^t,1) takes parsimonious covering V^t,1 Vt,1 returns parsimonious covering V^t Vt . implemented using algorithms mentioned
previous subsection. subroutine stop(V^t; V^t,1 ; ) determines whether Bellman
residual fallen threshold parsimonious coverings V^t,1 V^t
Vt,1 Vt. See Littman (1994) implementation subroutine.
Procedure solvePOMDP terminates Bellam residual falls threshold
return set state space functions. set V^t state space functions returned
represents t-step optimal value function Vt . solution input POMDP.
planning agent keeps V^t memory. needs make decision, agent
consults belief state b chooses action using (7) Vt (b+ ) replaced V^t (b+ ).
208

fiModel Approximation Planning Uncertainty

||||||||||||||||||||||
Procedure solvePOMDP(M; ):
Input: | POMDP,
| positive number.
Output: set state space functions.
1. 0, V^0 f0g.
2.
t=t+1.
V^t update(V^t,1 ):
stop(V^t; V^t,1 ; ) = no.
3. Return V^t .
||||||||||||||||||||||
Figure 2: Implicit value iteration.

5. New Algorithm Dynamic-Programming Updates
section proposes new algorithm dynamic-programming updates. four
subsections. first three subsections, show parsimonious covering Vt
obtained starting parsimonious covering Vt,1 and, so, introduce
concepts results necessary development new algorithm.

5.1 Relationship Vt,1 Vt
L
Suppose W X two sets state space functions. cross sum W X W
X following set state space functions:

W X = fff+fi jff2W ; fi 2Xg:
evident cross sumLoperation commutative associative. Consequently,
talk cross sum Ni=0 Wi list sets W0 , . . . , WN state space functions.
action observation o+, define

Qa;o+ = f

X
s+

ff(s+)P (s+ ; o+ js; a)jff2Vt,1 g:

P

(11)

Note since o+ given, member s+ ff(s+ )P (s+ ; o+ js; a)
set function s, words, state space function. Hence Qa;o+ set state
space functions. Let 0, 1, . . . , N beL enumeration possible values o+. use
L
N
o+ Qa;o+ denote cross sum i=0 Qa;i .

Proposition 1 Vt = [a[fr(s; a)gL(Lo+ Qa;o+ )]:
209

fiZhang & Liu

Proof: definition set Vt Equation (9), state space function ff Vt
exist action fio+ 2 Vt,1 o+ 2
ff(s) = r(s; a) +

X X
fio+ (s+)P (s+; o+ js; a):
o+

s+

proposition follows. 2

5.2 Properties Coverings
Lemma 1 Suppose W , X , three sets state space functions. W parsimoniously covers X X covers , W parsimoniously covers . 2
Lemma 2 Let W , W 0 , X , X 0 four sets state space functions. W 0 covers W
X 0 covers X ,
L
L
1. W 0 X 0 covers W X .
2. W 0 [X 0 covers W[X .2
5.3 Coverings Vt Parsimonious Coverings Vt,1
Let V^t,1 parsimonious covering Vt,1 . action observation o+ ,
define

Q0a;o+ = f

X
s+

ff(s+)P (s+ ; o+ js; a)jff2V^t,1 g:

Note definition Q0a;o+ Qa;o+ except Vt,1 replaced
V^t,1 . Also define
MM
Vt0 = [a [fr(s; a)g ( o+ Q0a;o+ )]:

Proposition 2 set Vt0 covers Vt.
Formal proof proposition given Appendix A. Informally, fact V^t,1
covers Vt,1 implies Q0a;o+ covers Qa;o+ , turn implies Vt0 covers Vt due
Proposition 1 Lemma 2.
According Proposition 2 Lemma 1, one obtain parsimonious covering
Vt finding parsimonious covering Vt0 Vt0 defined terms parsimonious
covering V^t,1 Vt,1 . said parsimonious covering Vt
obtained starting parsimonious covering Vt,1 .
Monahan's exhaustive method finds parsimonious covering Vt0 enumerating
state space functions Vt0 one one detecting pruned solving
linear programs. Lark's algorithm works similar fashion except linear programs
fewer constraints. Since Vt0 consists jAjjV^t,1 jjOj state space functions, enumerating
one one expensive. algorithms (Sondik, 1971; Cheng, 1988; Littman,
1994) avoid diculty exploiting structures Vt0 .
210

fiModel Approximation Planning Uncertainty

|||||||||||||||||||||||
Procedure incrPruning(fW0; W1 ; : : : ; WN g):
1. W W0 .
2. = 1 N ,

W



W Wi):

purge(

3. Return W .
Procedure update(V^t,1):
Input: V^t,1 | parsimonious covering Vt,1.
Input: parsimonious covering Vt.
1. a2A,
(a) Compute sets Q0a;0 , Q0a;1 , . . . , Q0a;N .
(b) Wa incrPruning(fQ0a;0 ; Q0a;1 ; : : : ; Q0a;N g).
L
2. Return purge([a [fr(s; a)g Wa ]).
|||||||||||||||||||||||
Figure 3: Incremental pruning dynamic-programming updates.

5.4 New Algorithm Dynamic-Programming Updates
Let purge(W ) subroutine takes set W state space functions returns
parsimonious covering W . implementation purge found appendix.
Let W0 , . . . , WN sets state space functions. Consider procedure incrPruning

shown Figure 3. Let n number 0 N . Using Lemmas 1 2, one
easily show induction that,
end nth pass for-loop, set W
L
n
parsimonious
L covering i=0 Wi. Consequently, procedures returns parsimonious
covering Ni=0 Wi . procedure named incremental pruning pruning takes
place cross sum.
Let 0, 1, . . . , N enumeration possible observations, i.e. possible instantiations o+ . action a, suppose sets Q0a;0 , Q0a;1 , . . . , Q0a;N
computed. Applying incrPruning sets, get parsimonious
covering
L
N Q0 . Denote W . According Lemma 2, [ [fr (s; a)gLW ] covers V 0 . Due


L

i=0 a;i
Lemma 1, fact implies parsimonious covering [a [fr(s; a)g Wa ] also
parsimonious covering Vt0 hence Vt . Thus, parsimonious covering Vt
found parsimonious covering Vt,1 using procedure update shown Figure 3.
also use term incremental pruning refer algorithm dynamicprogramming updates. shown elsewhere (Cassandra et al., 1977) incremental pruning asymptotic complexity witness algorithm empirically
significantly outperforms latter.
211

fiZhang & Liu

6. Region-Based Model Approximation
far concerned exact algorithms. Experiments incremental pruning, presently ecient exact algorithm, revealed solve small
POMDPs (Cassandra et al., 1997). One needs resort approximation order solve
large real-world problems.
previous approximation methods solve POMDP directly; approximate
t-step optimal value function POMDP. rest paper, develop new
method approximates POMDP another informative observation model hence easier solve. latter POMDP solved solution
used construct solution original POMDP.

6.1 Basic Idea

make following assumption problem characteristics. POMDP M, even
though agent know true state world, often good idea
state. Justifications assumption given introduction empirical
evidence presented Simmons & Koenig (1995).
Consider another POMDP M0 except addition
observation made itself, agent also receives report oracle knows
true state world. oracle report true state itself. Instead selects,
predetermined list candidate regions, region contains true state
reports region.
information available agent M0 M; additional information
provided oracle. Since agent already good idea true
state world, oracle might provide much additional information even
candidate regions small. Consequently, M0 could good approximation M.
M0 , agent knows sure true state world region reported
oracle. reason, say region observable. region observable
POMDP M0 much easier solve candidate regions small.
example, oracle allowed report singleton regions, actually reports
true state world hence M0 MDP. MDPs much easier solve
POMDPs. One would expect region observable POMDP M0 solvable
candidate regions small.

6.2 Spectrum Approximations
region reported oracle always set possible states, additional
information provided, report true state world one
possible states information content. case, M0 solution
solving M0 equivalent solving directly. one extreme spectrum.
extreme, candidate regions singletons, oracle reports
true state world. Maximum amount additional information provided M0
actually MDP. MDP might good approximation much
easier solve M.
212

fiModel Approximation Planning Uncertainty

Previous methods solving POMDP either solve directly approximate
using MDP. allowing oracle report regions neither singletons
set possible states, paper opens possibility exploring spectrum
two extremes. One way explore spectrum start singleton
candidate regions increase sizes gradually. Approximation quality computational time increase one goes along. One stops approximation accurate
enough region observable POMDP becomes intractable. method determining
approximation quality described later.
set make ideas concrete starting concept region
systems.

6.3 Region Systems
region simply subset states world. region system collection regions
region subset another region collection union regions
equals set possible states world. use R denote region R
denote region system.
Region systems used restrict regions oracle choose report.
choice region system determines computational complexity region observable
POMDP M0 approximation quality. choose regions make proper
tradeoff computational time approximation quality open research issue.
preliminary approach. idea create region state including
\nearby" states. say state s0 ideally reachable one step another state
executing certain action state s, probability world ending state
s0 highest. state sk ideally reachable k steps another state s0
state s1 , . . . , sk,1 si+1 ideally reachable si one step 0ik,1.
state ideally reachable 0 step.
non-negative integer k, radius-k region centered state set
states ideally reachable k less steps. radius-k region system one
obtained creating radius-k region state removing, one another,
regions subsets others.
k 0, radius-k region system consists singleton regions.
hand, state reachable state k less steps, one
region radius-k region system | set possible states.

6.4 Region Observable POMDPs
Given region system R POMDP M, construct region observable POMDP M0

assuming time point agent obtains observation
also receives report oracle knows true state world. oracle
report true state itself. Instead chooses R one region contains true
state reports region.
amount additional information provided oracle depends
region system used also way oracle chooses regions. example,
213

fiZhang & Liu

oracle always reports region centered true state, implicitly reports
true state itself.
order provide little additional information possible, oracle consider
agent already knows. However, cannot take entire history past actions
observations account did, M0 would POMDP. current
observation would depend entire history.
non-negative state space function f (s) region R, call quantity
supp(f; R)= Ps2R f (s)= Ps2S f (s) degree support f R. Note f
probability distribution, denominator 1. R supports f degree 1, say R
fully supports f .
suggest following region-selection rule oracle. Let s- previous true
state world, a- previous action, current observation. oracle
choose, among regions R contain true state world, one
supports function P (s; ojs- ; a- ) maximum degree.
one regions, choose one comes first predetermined ordering among
regions.
arguments support rule. previous world state s-
known agent, current belief state b(s), function s, would proportional
P (s; ojs- ; a- ). case, rule minimizes additional information sense
region reported supports current belief state maximum degree. previous world state known around s- , roughly true. Also current
observation informative enough, landmark instance, ensure world
state certain region, region chosen using rule fully supports current
belief state. case, additional information provided. Despite arguments,
claim rule described optimal. Finding rule minimizes
additional information still open problem.
probability P (Rjs; o; s- ; a- ) region R chosen scheme
given

8
>
< 1 Pif R the0 first regionPs.t. s2R 0and region R0
P (Rjs; o; s-; a-) = >
s0 2R P (s ; ojs- ; a- ) s0 2R0 P (s ; ojs- ; a- )
: 0 otherwise.

region observable POMDP M0 differs original POMDP terms
observation; addition observation made itself, agent also receives
report R oracle. shall denote observation M0 z write z =(o; R).
observation model M0 given

P (zjs; a- ; s-) = P (o; Rjs; a- ; s- ) = P (ojs; a- )P (Rjs; o; s- ; a- ):
joint conditional probability P (s+ ; z+ js; a) next state s+ world
next observation z+ given current state current action

P (s+; z+js; a) = P (s+ js; a)P (z+ js+ ; a; s):
214

fiModel Approximation Planning Uncertainty

7. Solving Region Observable POMDPs

principle, region observable POMDP M0 solved way general
POMDPs using procedure solvePOMDP. advisable so, however, since
solvePOMDP automatically exploit region observability. section next
two sections develop algorithm solving M0 takes advantage region observability.

7.1 Restricted Value Iteration
region R, let BR set belief states fully supported R. Let R
region system underlying region observable POMDP M0 . Define BR = [R2R BR .
easy see that, M0 , matter current belief state b is, next belief
state b+ must BR . assume initial belief state BR . possible
belief states agent might encounter BR . implies policies M0 need
defined BR value iteration M0 restricted subset BR B.
restrict value iteration M0 BR sake eciency. implies
t-step optimal value function M0 , denoted Ut , defined BR
Bellman residual maxb2BR jUt (b) , Ut,1 (b)j. avoid confusion, call
restricted Bellman residual call Ut restricted t-step optimal value function.
Since BR continuous, restricted value iteration cannot carried implicitly.
next subsection shows carried implicitly.

7.2 Implicit Restricted Value Iteration
Let W X two sets state space functions let R region. say W
covers X region R if, b2BR ,
W (b) = X (b):
say W parsimoniously covers X region R W covers X region R none
proper subsets do. W covers parsimoniously covers X region, refer
W regional covering parsimonious regional covering X .
Let Ut set t-step state value functions M0 . According Theorem 2,
Ut (b) = Ut (b)
belief state b2BR .
region R, suppose U^t;R set state space functions parsimoniously
covers Ut region R. collection fU^t;R jR2Rg representation Ut sense
b2BR ,
Ut (b) = U^t;R (b);
(12)
Rb b2BR , i.e. Rb fully supports b.
shown next section, parsimonious regional coverings Ut obtained parsimonious regional coverings Ut,1 . Let ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg)
procedure takes region R parsimonious regional covering fU^t,1;R+ jR+ 2Rg
b

215

fiZhang & Liu

|||||||||||||||||||||||||||
Procedure solveROPOMDP(M0; )
Input: M0 | region observable POMDP,
| positive number.
Output: list sets state space functions.
1. 0.
2. R2R, U^0;R f0g.
3.
t+1.
R2R,
U^t;R ROPOMDPupdate(R; fU^t,1;R+ jR+2Rg):

ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R+ jR+2Rg; ) = no.
4. Return fU^t;R jR2Rg.

|||||||||||||||||||||||||||

Figure 4: Implicit restricted value iteration region-observable POMDPs.
Ut,1 returns set state space functions parsimoniously covers Ut region R
Let ROPOMDPstop procedure determines, parsimonious regional coverings
Ut,1 Ut , whether restricted Bellman residual fallen predetermined
threshold.
procedure solveROPOMDP shown Figure 4 carries restricted value iteration
implicitly: instead inductively computing restricted t-step optimal value function Ut
itself, computes parsimonious regional coverings Ut . words, computes sets
state space functions represent Ut sense (12).
Let 0 greedy policy M0 based Ut . b2BR , 0 (b) defined
Equation (7) o+ replaced z+ =(o+ ; R+ ) Vt replaced Ut . Since list
fU^t;R jR2Rg sets state space functions returned solveROPOMDP represents Ut
sense (12), b2BR
2.

0 (b) = arg maxa[r(b; a) +

X
o+ ;R+

P ((o+ ; R+ )jb; a)U^t;R+ (b+ )]:

next two sections show implement procedures

ROPOMDPstop.

ROPOMDPupdate

2. string \ROPOMDP" ROPOMDPupdate stands region-observable POMDP.

216

(13)


fiModel Approximation Planning Uncertainty

8. Dynamic-Programming Updates Region Observable POMDPs

section shows incremental pruning algorithm developed Section 5
adapted compute parsimonious regional coverings Ut parsimonious regional
coverings Ut,1 .

8.1 Properties Regional Coverings
Lemma 3 Let R region let W , X , three sets state space functions.
W parsimoniously covers X region R X covers region R, W parsimoniously
covers region R. 2
Lemma 4 Let R region let W , W 0 , X , X 0 four sets state space functions.
W 0 X 0 respectively cover W X region R,
L
L
1. W 0 X 0 covers W X region R.
2. W 0 [X 0 covers W[X region R. 2
8.2 Regional Coverings Ut Parsimonious Regional Coverings Ut,1
parsimonious regional coverings U^t,1;R+ (R+ 2R) Ut,1 , subsection constructs,
region R2R, set Ut;R state space functions shows covers Ut region

R.

action observation z+ =(o+ ; R+ ) M0 , let Qa;z+ ;R set
state space functions fi following form:

( P
fi (s) = s+ ff(s+ )P (s+ ; z+ js; a) s2R
0

otherwise.

ff 2 U^t,1;R+ . Define

MM

Ut;R = [a [fr(s; a)g (

(14)

Q

)]:
z+ a;z+ ;R

Proposition 3 set Ut;R covers Ut region R.
Formal proof proposition found Appendix A. Informally, fact

U^t,1;R+ covers Ut,1 region R+ implies Qa;z+;R covers Qa;z+ region R, Qa;z+
given (11) o+ Vt,1 replaced z+ Ut,1 . fact turn implies
Ut;R covers Ut region R Proposition 1 Lemma 4.

8.3 Possible Observations Next Time Point
definition Ut;R , cross sum taken possible observations. subsection
shows possible observations skipped.
action region R, define

Za;R = fz+ j

X
s+

P (s+; z+ js; a) > 0 s2R g:
217

fiZhang & Liu

||||||||||||||||||||||||||||||||||
Procedure ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg):
Inputs: R | region, region R+,
U^t,1;R+ parsimoniously covers Ut,1 region R+.
Output: set state space functions parsimoniously covers Ut
region R.
1. action a,
(a) Compute set Za;R enumerate members 0; 1; : : : ; .
(b) i=0 , compute set Qa;i;R .
(c) Wa restrictedIncrPruning(fQa;0;R ; Qa;1;R ; : : : ; Qa;M;R g; R):
L
2. Return purge([a [fr(s; a)g Wa ]; R).
Subroutine restrictedIncrPruning(fW0; W1 ; : : : ; WM g; R):
1. Let W W0 .
2. i=1 ,

W purge(W Wi; R):
3. Return W .
||||||||||||||||||||||||||||||||||
Figure 5: Dynamic-programming updates region observable POMDPs.
set observations agent possibly receive next time point given
current state world lies region R current action a.
many observations outside set. matter fact, observation z+ =(o+ ; R+ )
set possible reach regionPR+ region R one step.
z+ =(o+ ; R+ ), z+ 2= Za;R , s+ P (L
s+; z+ js; a) = 0 s2R.
case, Qa;z+;R = f0g according (14). Since, f0g W =W set W state space
functions,

MM

Ut;R = [a[fr(s; a)g (

8.4 Parsimonious Regional Covering Ut

Q

)]:
z+ 2Za;R a;z+ ;R

Proposition 3 Lemma 3 imply that, region R, set state space functions
parsimoniously covers Ut region R parsimoniously covering Ut;R region
R. According Lemmas 3 4, set state space functions parsimoniously covers
Ut;R region R found using procedure ROPOMDPupdate shown Figure 5 (c.f.
Section 5.4). procedure, subroutine purge(W ; R) takes set W state space
218

fiModel Approximation Planning Uncertainty

|||||||||||||||||||||||||||
Procedure ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R jR2Rg; )
Inputs: | positive number, region R
U^t;R covers Ut region R,
U^t,1;R covers Ut,1 region R.
Outputs: yes | restricted Bellman residual ,
| Otherwise.
1. region R,
(a) ag yes.
(b) ff2U^t,1;R ,
ag dominate(ff; U^t;R ; R; ) 6= nil:
(c) ff2U^t;R ,
ag



dominate(ff; U^t,1;R ; R; ) 6= nil:

(d) Return ag = no.
2. Return yes.
|||||||||||||||||||||||||||
Figure 6: Procedure determining whether restricted Bellman residual fallen
threshold.
functions region R, returns set state space functions parsimoniously covers
W region R. implementation subroutine found Appendix B.

9. Stopping Condition

section shows determine whether restricted Bellman residual fallen
predetermined threshold regional coverings Ut Ut,1 . region
R, let U^t;R U^t,1;R two sets state space functions respectively cover Ut
Ut,1 region R. definition regional coverings,
Lemma 5 restricted Bellman residual larger region
R belief state b2BR ,
1. ff2U^t;R ,
ff(b) U^t,1;R (b)+;
2. ff2U^t,1;R ,
ff(b) U^t;R (b)+:2
219

fiZhang & Liu

Let dominate(ff; W ; R; ) procedure returns belief state b BR
ff(b) > W (b)+. belief state exist, returns nil. implementation

procedure found Appendix B. procedure ROPOMDPupdate shown
Figure 6 returns yes restricted Bellman residual fallen otherwise.
couple notes order. First, reward function r(s; a) non-negative, Ut
increases t. case, restricted Bellman residual becomes maxb2BR (Ut (b),Ut,1 (b)).
Consequently, step (c) skipped. Second, r(s; a) takes negative values
a, constant added becomes non-negative. Adding constant r(s; a) affect optimal policy. However, makes easier determine
whether restricted Bellman residual fallen threshold.

10. Decision Making Original POMDP

Suppose solved region observable POMDP M0 . next step construct
policy original POMDP based solution M0 .
Even though assumption original POMDP agent good
idea state world times, guarantee belief state
always BR . oracle M. policy prescribe actions belief states
BR well belief states outside BR . One issue policy 0 M0
defined belief states BR . Fortunately, 0 naturally extended entire
belief space ignoring constraint b2BR Equation (13). hence define policy
follows: b2B,
X
(b) = arg maxa [r(b; a) +
P ((o+ ; R+)jb; a)U^t;R+ (b+ )]:
(15)
o+ ;R+

Let k radius region system underlying M0 . policy given
referred radius-k approximate policy M. entire process obtaining
policy, including construction solving region observable POMDP M0 ,
referred region-based approximation.
worthwhile compare equation Equation (7). Equation (7),
two terms right hand side. first term immediate reward taking action
second term discounted future reward agent expect receive
behaves optimally. sum total expected reward taking action a. action
highest total reward chosen.
second term dicult obtain. essence, Equation (15) approximates
second term using optimal expected future reward agent receive help
oracle, easier compute.
emphasized presence oracle assumed process
computing radius-k approximate policy. oracle present executing
policy.

11. Quality Approximation Simulation

general, quality approximate policy measured distance
value function V (b) optimal value function V (b). measurement
220

fiModel Approximation Planning Uncertainty

consider agent might know initial state world. such,
appropriate policy obtained region-based approximation. One cannot expect
policy good quality agent uncertain initial state
world obtained assumption agent good idea
state world times.
section describes scheme determining quality approximate policy
cases agent knows initial state world certainty. scheme
generalized cases small amount uncertainty initial state;
example, cases initial state known small region.
agent might need reach goal different initial states different times. Let
P (s) frequencyPit start state s3 . quality approximate policy
measured jV (s) , V (s)jP (s), V (s) V (s) denote rewards
agent expect receive starting state behaves optimally according
respectively.
definition V (s)V (s) s. Let U optimal value function
region observable POMDP M0 . Since
information available agent
M0 ,
P
P




U (s)V (s) s. Therefore, [U (s) , V (s)]P (s) upper bound [V (s) ,
V (s)]P (s).
Let 0 policy M0 given (13). 0restricted Bellman residual small,
P0 close
optimal M0 value function
V 0 close U . Consequently,
P
0




[V (s) , V (s)]P (s) upper bound [V (s) , V (s)]P (s) restricted
Bellman residual small enough. P 0
One way estimate quantity [V (s) , V (s)]P (s) conduct large number
simulation trials. trial, initial state randomly generated according P (s).
agent informed initial state. Simulation takes place M0 .
M, agent chooses, step, action using based current belief state.
action passed simulator randomly generates next state world
next observation according transition observation probabilities. observation
(but state) passed agent, updates belief state chooses next
action. forth. trial terminates agent chooses action
declare-goal maximum number steps reached. Simulation M0 takes place
similar manner except observations observation probabilities different
actions chosen using 0 .
goal correctly declared end trial, agent receives reward
amount Pn ,
n number steps. Otherwise, agent receive reward.
0

quantity [V (s) , V (s)]P (s) estimated using difference average
reward received trials M0 average reward received trials M.

12. Tradeoff Quality Complexity

Intuitively, larger radius region system, less amount additional
information
the0 oracle provides.
Hence closer M0 narrower gap
P
P


V (s)P (s) V (s)P (s). Although theoretically proved this,
3. confused initial belief state P0 , represents agent's knowledge
ninitial state particular trial.

221

fiZhang & Liu

P

empirical results (see next section)
do0 suggest V (s)P (s) increases
P
radius region system V (s)P (s) decreases it. extreme case
one region region system
possible states
P contains P
world, M0 identical hence V 0 (s)P (s) V (s)P (s).
discussions lead following scheme making tradeoff complexity quality:P Start0 radius-0 region system increase radius gradually
quantity [V (s) , V (s)]P (s) becomes suciently small region observable
POMDP M0 becomes untractable.

13. Simulation Experiments
Simulation experiments carried show (1) approximation quality increases radius region system (2) much uncertainty, POMDP
accurately approximated region-observable POMDP solved exactly.
section reports experiments.

13.1 Synthetic Oce Environments
experiments conducted using two synthetic oce environments borrowed
Cassandra et al. (1996) minor modifications. Layouts environments
shown Figure 7, squares represent locations. location represented
four states POMDP model, one orientation. dark locations rooms
connected corridors doorways.
environment, robot needs reach goal location correct orientation. step, robot execute one following actions: move-forward,
turn-left, turn-right, declare-goal. two sets action models given Figure
7 used experiments. action move-forward, term F-F (0.01) means
probability 0.01 robot actually moves two steps forward. terms
interpreted similarly. outcome cannot occur certain state world,
robot left last state impossible outcome.
state, robot able perceive three nominal directions (front,
left, right) whether doorway, wall, open, undetermined. two
sets observation models shown Figure 7 used experiments.

13.2 Complexity Solving POMDPs
One POMDPs 280 possible states 200. 64
possible observations 4 possible actions. Since largest POMDPs researchers
able solve exactly far less 20 states 15 observations, safe
say existing exact algorithms solve two POMDPs.
able solve radius-0 radius-1 approximations (region observable
POMDPs) two POMDPs SUN SPARC20 computer. threshold
Bellman residual set 0.001 discount factor 0.99. amounts time
took CPU seconds collected following table.
222

fiModel Approximation Planning Uncertainty

N

N
Goal
(south)
Enviroment B

Goal
(east)
Environment

Transition Probabilities
Action

move-forward
turn-left
turn-right
declare-goal

Standard outcomes
N (0.11), F (0.88), F-F (0.01)
N (0.05), L (0.9), L-L (0.05)
N (0.05), R (0.9), R-R (0.05)
N (1.0)

Noisy outcomes
N (0.2), F (0.7), F-F (0.1)
N (0.15), L (0.7), L-L (0.15)
N (0.15), R (0.7), R-R (0.15)
N (1.0)

Observation Probabilities
Actual case Standard observations
wall
wall (0.90), open (0.04), doorway
(0.04), undetermined (0.02)
open
wall (0.02), open (0.90), doorway
(0.06), undetermined (0.02)
doorway
wall (0.15), open (0.15), doorway
(0.69), undetermined (0.01)

Noisy observations
wall (0.70), open (0.19), doorway
(0.09), undetermined (0.02)
wall (0.19), open (0.70), doorway
(0.09), undetermined (0.02)
wall (0.15), open (0.15), doorway
(0.69), undetermined (0.01)

Figure 7: Synthetic Oce Environments.
Environment

B

Standard models
Noisy models
Radius-0 Radius-1 Radius-0 Radius-1
1.26
3373
1.35
5984
0.61
2437
0.72
3952

see radius-1 approximations took much longer time solve radius-0
approximations. Also notice region observable POMDPs noisy action
observation models took time solve standard models. suggests nondeterministic actions less informative observations,
dicult solve POMDP.
223

fiZhang & Liu

unable solve radius-2 approximations. approximation techniques
need incorporated order solve approximations based region systems
radius larger equal 2.

13.3 Approximation Quality Standard Models

determine quality radius-0 radius-1 approximate policies POMDPs
standard action observation models, 1000 simulation trials conducted using
scheme described Section 11. assumed agent equally likely start
state. Average rewards obtained original POMDPs (i.e. without
help oracle) corresponding region-observable POMDPs M0 (i.e.
help oracle) shown following table.
Environment
radius-0 radius-1
Average reward 0.806535 0.815695
Average reward M0 0.827788 0.818534
Difference
0.021253 0.002839

Environment B
radius-0 radius-1
0.866118 0.868533
0.883271 0.876356
0.017153 0.007823

see that, radius-0 policies used, differences rewards
obtained obtained M0 small environments. indicates
radius-0 region observable POMDPs (i.e. MDPs) accurate approximations
original POMDPs. radius-0 approximate policies close optimal
original POMDPs. radius-1 policies used, differences even smaller;
rewards obtained obtained M0 essentially same.
Consider rewards obtained original POMDPs. see larger
radius-1 policies used radius-0 policies used. supports
claim approximation quality increases radius region system.
another fact worth mentioning. differences rewards obtained
obtained M0 larger Environment B Environment A.
Environment B symmetric consequently observations less effective
disambiguating uncertainty agent's belief state world.

13.4 Approximation Quality Noisy Models

One thousand trials also conducted POMDPs noisy action observation models. Results shown following table.
Environment
radius-0 radius-1
Average reward 0.596670 0.634934
Average reward M0 0.812898 0.722441
Difference
0.214228 0.087507
224

Environment B
radius-0 radius-1
0.445653 0.565099
0.871903 0.818365
0.426250 0.253266

fiModel Approximation Planning Uncertainty

see differences rewards obtained rewards obtained
M0 significantly smaller radius-1 policies used radius-0

policies used. case especially Environment A. Also rewards obtained
larger radius-1 policies used radius-0 policies
used. support claim approximation quality increases radius
region system.
far absolute approximation quality concerned, radius-0 POMDPs (i.e.
MDPs) obviously poor approximations original POMDPs; radius-0
policies used, rewards obtained significantly smaller rewards obtained M0 . Environment A, radius-1 approximation fairly accurate. However,
radius-1 approximation remains poor Environment B. radius region system
needs increased.
Tracing trials step step, observed interesting facts. Environment B, agent, guidance radius-1 approximate policy, able
quickly get neighborhood goal even starting far way. fact
Environment around goal highly symmetric cause poor performance. Often agent able determine whether goal location
(room), opposite room, left room, room right
goal location. performance would close optimal goal location
distinct features.
Environment A, agent, guidance radius-1 approximate
policy, able reach declare goal successfully got neighborhood.
However, often took many unnecessarily steps reaching neighborhood due
uncertainty effects turning actions. example, agent reached
lower left corner above, facing downward. agent executed action
turn_left. Fifteen percent time, ended facing upward instead right.
agent decided move-forward, thinking approaching goal.
actually moving upward realize steps later. agent
would perform much better informative landmarks around corners.

14. Conclusions
propose approximate POMDP using region observable POMDP. region
observable POMDP informative observations hence easier solve.
method determining approximation quality described, allows one make
tradeoff approximation quality computational time starting coarse
approximation refining gradually. Simulation experiments shown
much uncertainty effects actions observations informative,
POMDP accurately approximated region observable POMDP
solved exactly. However, becomes infeasible degree uncertainty increases.
approximate methods need incorporated order solve region observable
POMDPs whose radiuses small.
225

fiZhang & Liu

Acknowledgements

paper benefited discussions Anthony R. Cassandra Michael Littman.
also thank associate editor Thomas L. Dean three anonymous reviewers
insightful comments suggestions pointers references. Research
supported Hong Kong Research Council grants HKUST 658/95E Hong Kong
University Science Technology grant DAG96/97.EG01(RI).

Appendix A: Proofs Propositions 2 3

Lemma 6 Suppose W X two sets state space functions. W covers X ,
non-negative function f (s),

maxff2W

X


ff(s)f (s) = maxfi2X

X


fi (s)f (s):2

Proof Proposition 2: Proposition 1 Lemma 2, suces show
Q0a;o+ covers Qa;o+ . definition Qa;o+ Equation (10), have, belief
state b,

X X

Qa;o+ (b) = maxff2V ,1 [

ff(s+ )P (s+; o+ js; a)]b(s)
X
X
= maxff2V ,1 ff(s+ )[ b(s)P (s+ ; o+ js; a)]






s+

s+



Since V^t,1 covers Vt,1 term within square brackets non-negative function
s+, Lemma 6

X
ff(s+ )[ b(s)P (s+; o+ js; a)]
Xs+ X
= maxff2V^ ,1 [ ff(s+ )P (s+ ; o+ js; a)]b(s)

Qa;o+ (b) = maxff2V^ ,1

X





= Q0a;o+ (b);



s+

last equation due definition Q0a;o+ Equation (10). So, Q0a;o+
cover Qa;o+ . proposition proved. 2
Lemma 7 observation z+=(o+; R+) region observable POMDP M0,
P (s+; z+ js; a) = 0;
s+ 2= R+ . 2
Informally, lemma says true state world must region reported
oracle.
Lemma 8 Let W X two sets state space functions R region. W covers
X region R, non-negative function f (s) 0 s=2R,
X
X
maxff2W ff(s)f (s) = maxfi2X fi (s)f (s):2




226

fiModel Approximation Planning Uncertainty

Proof Proposition 3: Proposition 1 Lemma 4, suces show
Qa;z+;R covers Qa;z+ region R, Qa;z+ given (11) o+ Vt,1 replaced
z+ Ut,1 .
Let b belief state BR . Similar proof Theorem 2,
X
X
Qa;z+ (b) = maxff2U ,1 ff(s+)[ b(s)P (s+; z+js; a)]


s+



X
ff
(

)[
b(s)P (s+ ; z+ js; a)]
+
+ s+

X X
= maxff2U^ ,1 + [ ff(s+ )P (s+ ; z+ js; a)]b(s)
s2R s+
X
= maxfi2Q +
fi (s)b(s)
= maxff2U^ ,1




a;z

X

;R

;R

;R



= Qa;z+ ;R (b);
second equation true fact U^t,1;R+ covers Ut,1 region R+
Lemma 8. term within square brackets non-negative function s+
0 s+2= R+ Lemma 7. fourth equation true b(s)=0
s=2R. proposition proved. 2

Appendix B: Domination Pruning

appendix describes implementation procedures dominate(ff; W ; R; ), purge(W ; R),
purge(W ). given main text minor adaptations
existing algorithms.
procedure dominate(ff; W ; R; ) takes, inputs, state space function ff, set
state space functions W , region R, nonnegative number . returns belief state
b BR ff(b)>W (b)+. belief state exist, returns nil.
implemented follows.
Procedure dominate(ff; W ; R; )
Inputs: ff | state space function,
W | set state space functions,
R | region, | nonnegative number.
Output: belief state BR nil.
1. W =;, return arbitrary belief state BR .
2. Solve following linear program:
Variables: x, b(s) s2R.
Maximize: x
Constraints:
X
X
ff(s)b(s) x + fi (s)b(s) fi 2W ;
s2 R

X

s2R

b(s) = 1

s2 R

b(s) 0 s2R:
227

fiZhang & Liu

3. x, return nil, else return b.
procedure purge(W ; R) takes set state space functions W region R
returns set state space functions parsimoniously covers W region R.
implement it, need two subroutines.
state space function ff pointwise dominates another state space function fi region
R ff(s)fi (s) s2R. subroutine pointwisePurge(W ; R) returns minimal
subset W 0 W state space function W pointwise dominated
region R least one state space function W 0 . Implementation subroutine
straightforward.
P

subroutine
best(b; W ; R) returns state space function ff W s2R b(s)ff(s)
P b(s)fi (s) state space function fi W . Implementation subroutine
s2R
straightforward except issue tie breaking. ties broken properly,
purge(W ; R) might return regional covering W parsimonious. correct way
break ties follows: Fix ordering among states R. induces lexicographic
ordering among state space functions. Among tied state space functions, chose
one largest lexicographic ordering (Littman, 1994).
following implementation purge based Lark's algorithm (White, 1991).
Procedure purge(W ; R)

Inputs: W | set state space functions,
R | region.

Output: set state space functions parsimoniously covers W
region R.

1. W pointwisePurge(W ; R).
2. X ;.
3. W6=;,
(a) Pick state space function ff W .
(b) b dominate(ff; X ; R; 0).
(c) b =nil, remove ff W .
(d) Else remove best(b; W ; R) W add X .
4. Return X .
Finally, procedure purge(W ) takes set state space functions W returns
parsimonious covering W . implemented simply follows.
Procedure purge(W ):



W ; ).

purge(

Here, set possible states world.
228

fiModel Approximation Planning Uncertainty

References

Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D. P. (1987). Dynamic Programming: Deterministic Stochastic Models.
Prentice-Hall.
Bertsekas, D. P., & Castanon, D. C. (1989). Adaptive Aggregation Infinite Horizon
Dynamic Programming. IEEE trans. auto. control, vol 34, 6.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structures policy
construction. Proceedings IJCAI-95, 1104-1111.
Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observable
decision processes using compact representations. Proceedings AAAI-96, 11681175.
Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Proceedings AAAI-97, 727-733.
Cassandra, A. R. (1994). Optimal polices partially observable Markov decision processes. TR CS-94-14, Department Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partially
observable stochastic domains. Proceedings AAAI-94, 1023-1028.
Cassandra, A. R., Kaelbling, L. P., & Kurien, J. (1996). Acting uncertainty: Discrete Bayesian models mobile-robot navigation. Proceedings IEEE/Robotics
Society Japan Conference Intelligent Robotics Systems (IROS-96).
Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple,
fast, exact method partially observable Markov decision processes. Proceedings
Thirteenth Conference Uncertainty Artificial Intelligence, 54-61.
Cheng, H. T. (1988). Algorithms partially observable Markov decision processes. PhD
thesis, University British Columbia, Vancouver, BC, Canada.
Dean, T. L., Givan, R., & Leach, S. (1997). Model reduction techniques computing
approximately optimal solution Markov decision processes. Proceedings
Thirteenth Conference Uncertainty Artificial Intelligence, 124-131.
Dean, T. L., Kaelbling, L. P., Kirman, J., & Nicholson A. (1993). Planning deadlines
stochastic domains. Proceedings AAAI-93, 574-579.
Dean T. L., & Lin, S. H. (1995). Decomposition techniques planning stochastic
domains. TR CS-95-10, Department Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Dean, T. L., & Wellman, M. P. (1991). Planning Control. Morgan Kaufmann.
229

fiZhang & Liu

Eagle, J. N. (1984). optimal search moving target search path
constrained. Operations Research, 32(5), 1107-1115.
Hauskrecht, M. (1997). Incremental methods computing bounds partially observable
Markov decision processes. Proceedings AAAI-97, 734-739.
Littman, M. L. (1994). witness algorithm: Solving partially observable Markov decision processes. TR CS-94-40, Department Computer Science, Brown University,
Providence, Rhode Island 02912, USA.
Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Ecient dynamic-programming
updates partially observable Markov decision processes. TR CS-95-19, Department
Computer Science, Brown University, Providence, Rhode Island 02912, USA.
Lovejoy, W. S. (1991a). survey algorithmic methods solving partially observable
Markov decision processes. Annals Operations Research, 28 (1), 47-65.
Lovejoy, W. S. (1991b). Computationally feasible bounds partially observed Markov
decision processes. Operations Research, 39 (1), 162-175.
Monahan, G. E. (1982). survey partially observable Markov decision processes: theory, models, algorithms. Management Science, 28 (1), 1-16.
Parr, R., & Russell, S. (1995). Approximating optimal polices partially observable
stochastic domains. Proceedings IJCAI-95, 1088-1094.
Platzman, L. K. (1977). Finite-memory estimation control finite probabilistic systems. Ph.D. Thesis, Department Electrical Engineering Computer Science,
Massachusetts Institute Technology.
Puterman, M. L. (1990). Markov decision processes. D. P. Heyman M. J. Sobel
(eds.), Handbooks & MS., Elsevier Science Publishers, Vol. 2, 331-434.
Sondik, E. J. (1971). optimal control partially observable Markov processes. PhD
thesis, Stanford University, Stanford, California, USA.
Sondik, E. J., & Mendelssohn, R. (1979). Information seeking Markov decision processes,
Southwest Fisheries Center Administrative Report H-79-13, National Marine Fisheries
Service, Honolulu, Hawaii.
White III, C. C. (1991). Partially observed Markov decision processes: survey. Annals
Operations Research, 32.
White, D. J. (1993). Markov Decision Processes. John Wiley & Sons.
White III, C. C., & Scherer, W. T., (1994). Finite-memory suboptimal design partially
observed Markov decision processes. Operations Research, 42(3), 440-455.

230

fiJournal Artificial Intelligence Research 7 (1997) 6782

Submitted 5/97, published 9/97

Identifying Hierarchical Structure Sequences:
linear-time algorithm
Craig G. Nevill-Manning
Ian H. Witten
Department Computer Science
University Waikato, Hamilton, New Zealand.

CGN@CS.WAIKATO.AC .NZ
IHW@CS.WAIKATO.AC .NZ

Abstract
EQUITUR algorithm infers hierarchical structure sequence discrete symbols
replacing repeated phrases grammatical rule generates phrase, continuing
process recursively. result hierarchical representation original sequence,
offers insights lexical structure. algorithm driven two constraints reduce
size grammar, produce structure by-product. EQUITUR breaks new ground
operating incrementally. Moreover, methods simple structure permits proof operates
space time linear size input. implementation process 50,000
symbols per second applied extensive range real world sequences.

1. Introduction
Many sequences discrete symbols exhibit natural hierarchical structure. Text made
paragraphs, sentences, phrases, words. Music composed major sections, motifs, bars,
notes. Records user interface behavior encode hierarchical structure tasks users
perform. Computer programs constitute modules, procedures, statements. Discovering
natural structure underlies sequences challenging interesting problem wide
range applications, phrase discovery music analysis, programming
demonstration code optimization.
search structure sequences occurs many different fields. Adaptive text
compression seeks models sequences used predict upcoming symbols
encoded efficiently (Bell et al., 1990). However, text compression models
extremely opaque, illuminate hierarchical structure sequence. Grammatical
inference techniques induce grammars set example sentences, possibly along set
negative examples (Gold, 1967; Angluin, 1982; Berwick Pilato, 1987). However,
crucial operation input continuous stream segmented sentences,
are, effect, independent examples structure sought. brief review
pertinent systems appears Section 8. Techniques Markov modeling hidden Markov
modeling make attempt abstract information hierarchical form (Rabiner Juang, 1986,
Laird Saul, 1994). Sequence learning also occurs areas automaton modeling
(Gaines, 1976), adaptive systems (Andreae, 1977), programming demonstration (Cypher,
1993), human performance studies (Cohen et al., 1990), generally plays peripheral
role.
paper describe SEQUITUR, algorithm infers hierarchical structure
sequence discrete symbols. basic insight phrases appear
replaced grammatical rule generates phrase, process
continued recursively, producing hierarchical representation original sequence. result
1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved

fiNEVILL-MANNING & WITTEN

strictly grammar, rules generalized generate one string. (It
provide good basis inferring grammar, beyond scope paper.)
scheme resembles one developed arose work language acquisition (Wolff,
1975, 1977, 1980, 1982), operated time quadratic respect length
input sequence, whereas algorithm describe takes linear time. let us investigate
sequences containing several million tokensin previous work examples much smaller,
largest mentioned thousand tokens. Another difference, crucial
importance practical applications, new algorithm works incrementally.
return Wolffs scheme, compare SEQUITUR, Section 8.
ability deal easily long sequences greatly extended range SEQUITURs
application. applied artificially-generated fractal-like sequences produced Lsystems, and, along unification-based rule generalizer, used recover original Lsystem. method inferred relatively compact deterministic, context-free grammars
million-symbol sequences representing biological objects obtained stochastic, contextsensitive, L-systems, turn greatly speeded graphical rendering objects.
applied SEQUITUR 40 Mbyte segments digital library generate hierarchical
phrase indexes text, provides novel method browsing (Nevill-Manning et al.,
1997). algorithm compresses multi-megabyte DNA sequences effectively
general-purpose compression algorithms. Finally, post-processing, elicited
structure two million word extract genealogical database, successfully identifying
structure database compressing much efficiently best known
algorithms. touch applications Section 3 below; Nevill-Manning (1996)
describes all.
paper describes SEQUITUR algorithm evaluates behavior. next section
gives concise description algorithm terms constraints form output
grammar. Section 3 gives taste kind hierarchies SEQUITUR capable inferring
realistic sequences. Section 4 describes implementation detail, particular
emphasis achieves efficiency. Section 5 shows run time storage
requirements linear number input symbols, Section 6 discusses algorithms
behavior extreme input strings. end quantitative analysis SEQUITURs
performance several example sequences, review related research.

2. SEQUITUR Algorithm
SEQUITUR forms grammar sequence based repeated phrases sequence.
repetition gives rise rule grammar, repeated subsequence replaced nonterminal symbol, producing concise representation overall sequence.
pursuit brevity drives algorithm form maintain grammar, and, byproduct, provide hierarchical structure sequence.
left Figure 1a sequence contains repeating string bc. Note
sequence already grammara trivial one single rule. compress it, SEQUITUR forms
new rule bc, replaces occurrences bc. new grammar appears right
Figure 1a.
sequence Figure 1b shows rules reused longer rules. longer
sequence consists two copies sequence Figure 1a. Since represents exact

68

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

repetition, compression achieved forming rule abcdbc replace halves
sequence. gains made forming rule B bc compress rule A.
demonstrates advantage treating sequence, rule S, part grammarrules may
formed rule analogous way rules formed rule S. rules within rules
constitute grammars hierarchical structure.
grammars Figures 1a 1b share two properties:
p 1 : pair adjacent symbols appears grammar;
p 2 : every rule used once.
Property p 1 requires every digram grammar unique, referred
digram uniqueness. Property p2 ensures rule useful, called rule utility.
two constraints exactly characterize grammars SEQUITUR generates.
Figure 1c shows happens properties violated. first grammar contains
two occurrences bc, p1 hold. introduces redundancy bc appears twice.
second grammar, rule B used once, p 2 hold. removed,
grammar would become concise. grammars Figures 1a 1b ones
properties hold sequence. However, always unique grammar
properties. example, sequence Figure 1d represented
grammars right, obey p 1 p2 . deem either grammar acceptable.
Repetitions cannot overlap, string aaa give rise rule, despite containing two
digrams aa.
SEQUITURs operation consists ensuring properties hold. describing
algorithm, properties act constraints. algorithm operates enforcing constraints
grammar: digram uniqueness constraint violated, new rule formed,
rule utility constraint violated, useless rule deleted. next two subsections describe
occurs.
2.1 Digram Uniqueness
SEQUITUR observes new symbol, appends rule S. last two symbols rule
new symbol predecessorform new digram. digram occurs elsewhere
grammar, first constraint violated. restore it, new rule formed digram
right-hand side, headed new non-terminal symbol. two original digrams
replaced non-terminal symbol.
Sequence

Grammar



abcdbc

aAdA
bc

c

abcdbcabcdbc

AA
abcdbc

Sequence

Grammar

b

abcdbcabcdbc

AA
aBdB
B bc



aabaaab

AaA
aab

CC
bc
B aA
C BdA

AbAab
aa

Figure 1 Example sequences grammars reproduce them: (a)
sequence one repetition; (b) sequence nested repetition; (c)
two grammars violate two constraints; (d) two different grammars
sequence obey constraints.

69

fiNEVILL-MANNING & WITTEN

Table 1 shows grammars result successive symbols sequence
abcdbcabcd processed. second column shows sequence observed far, third
column gives grammar created sequence, fourth column notes constraints
violated, actions taken resolve violations.
SEQUITUR adds final c symbol 6, digram bc appears twice. SEQUITUR creates
new rule A, bc right-hand side, replaces two occurrences bc A.
illustrates basic procedure dealing duplicate digrams.
appearance duplicate digram always result new rule. new digram
appears right-hand side existing rule, new rule need created: nonterminal symbol heads existing rule replaces digram. symbol 9 Table 1,
third bc appears, existing non-terminal symbol replaces third occurrence bc.
results new pair repeating digrams, aA, shown next line Table 1. SEQUITUR
accordingly forms new rule B, replaces two occurrences aA. SEQUITUR creates
maintains hierarchy iterative process: substitution bc results new
digram aA, replaced B. larger sequences, changes ripple
grammar, forming matching longer rules higher hierarchy.
symbol
number

string
far

resulting
grammar

remarks

1



Sa

2

ab

ab

3

abc

abc

4

abcd

abcd

5

abcdb

abcdb

6

abcdbc

abcdbc

bc appears twice

aAdA
bc

enforce digram uniqueness

7

abcdbca

aAdAa
bc

8

abcdbcab

aAdAab
bc

9

abcdbcabc

aAdAabc
bc

bc appears twice

aAdAaA
bc

enforce digram uniqueness.
aA appears twice

BdAB
bc
B aA

enforce digram uniqueness

BdABd
bc
B aA

Bd appears twice

CAC
bc
B aA
C Bd

enforce digram uniqueness.
B used

CAC
bc
C aAd

enforce rule utility

10

abcdbcabcd

Table 1 Operation two grammar constraints,
digram uniqueness rule utility

70

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

2.2 Rule Utility
now, right-hand sides rules grammar two symbols long. Longer
rules formed effect rule utility constraint, ensures every rule used
once. Table 1, symbol 10 demonstrates idea. appended rule S,
new digram Bd causes new rule, C, formed. However, forming rule leaves one
appearance rule B, violating second constraint. reason, B removed
grammar, right-hand side substituted one place occurs. Removing B
means rule C contains three symbols. mechanism forming long rules:
form short rule temporarily, subsequent symbols continue match, allow new rule
supersede shorter one delete latter. Although creation deletion rules
appears inefficient first glance, performed efficiently appropriate data
structures. importantly, keeps track long matches within grammar, obviating
need external data structures. simplifies algorithm considerably, permitting concise
proof linear time complexity (see Section 5).

3. Structures Inferred Realistic Sequences
described mechanism SEQUITUR builds grammar, embarking
efficiency issues, instructive consider structures simple technique infer
realistic sequences. case applied SEQUITUR large sample excerpted
part structure illustrative purposes.
Figures 2a, 2b 2c show parts three hierarchies inferred text Bible
English, French, German. hierarchies formed without knowledge preferred
structure words phrases, nevertheless capture many meaningful regularities.
Figure 2a, word beginning split begin ninga root word suffix. Many words
word groups appear distinct parts hierarchy (spaces made visible
replacing bullets). algorithm produces French version Figure 2b,
commencement split analogous way beginninginto root commence
suffix ment. Again, words Au, Dieu cieux distinct units hierarchy.
German version Figure 2c correctly identifies words sentence, well phrase
die Himmel und die. fact, hierarchy heaven Figure 2a bears
similarity German equivalent.
London/Oslo-Bergen corpus (Johansson et al., 1978) contains 1.2 million words tagged
word classes. example, sentence Labour sentiment would still favour
abolition House Lords tagged classes determiner noun noun auxiliary adverb
verb article noun preposition article noun preposition noun. hierarchy SEQUITUR infers
word classes corresponds possible parse sentence corpus,
tree expressed terms parts speech. Figure 2d shows part inferred hierarchy,
tags replaced actual words text. SEQUITUR identifies middle
part sentence, sentiment would still favour abolition large block, part could
stand grammatical sentence. adjectival phrase House Lords also
appears distinct unit, Labour, adjectival phrase precedes subject.
Figure 2e shows two Bach chorales SEQUITUR detected internal
repetitionsthe light gray boxes show two halves first chorale almost
identicaland repetitions chorales, denoted gray box second half

71

fiNEVILL-MANNING & WITTEN



n h e b e g n n n g G c r e e h e h e v e n n h e e r h

b

u c e n c e e n , e u c r l e c e u x e l e r r e

c

xx

n f n g c h u f G e H e l u n e E r e



Labour sentiment would still favour abolition House Lords

e

imperfect

perfect

Figure 2 Hierarchies various sequences: Genesis 1:1 (a) English, (b) French, (c) German;
(d) grammatical parse inferred sequence word classes; (e) repetitions within
two chorales harmonized J.S. Bach.
second chorale. section white box occurs four halves. Also, detecting repeated
motifs many chorales, SEQUITUR identifies imperfect perfect cadences end
first second halves, respectively. general, SEQUITUR capable making plausible
inferences lexical structure sequences, hierarchies produces aid comprehension
sequence.

4. Implementation Issues
SEQUITUR algorithm operates enforcing digram uniqueness rule utility constraints.
essential violation constraints detected efficiently, section
describe mechanisms fulfill requirement.
choice appropriate data structure depends kind operations need
performed modify grammar. SEQUITUR are:
appending symbol rule S;
using existing rule;
creating new rule;
deleting rule.
Appending symbol involves lengthening rule S. Using existing rule involves substituting
non-terminal symbol two symbols, thereby shortening rules containing digrams.
Creating new rule involves creating new non-terminal symbol left-hand side,
72

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES



B

c

B



b


cd
digram
Bc
index
ab

Figure 3 Data structures rules digram index
inserting two new symbols right-hand side. creating rule, substitutions made
existing rule replacing two digrams new non-terminal symbol. Deleting
rule involves moving contents replace non-terminal symbol, lengthens rule
containing non-terminal symbol; left-hand side rule must deleted.
ensure rules lengthened shortened efficiently, SEQUITUR represents rule
using doubly-linked list whose start end connected single guard node, shown
two rules B Figure 3. guard node also serves attachment point left-hand
side rule, remains constant even rule contents change. nonterminal symbol also points rule heads, shown Figure 3 pointer nonterminal symbol B rule head rule B. pointers, arrays necessary
accessing rules symbols, operations affect adjacent symbols rules headed
non-terminal.
rule utility constraint demands rule deleted referred once.
rule associated reference count, incremented non-terminal symbol
references rule created, decremented non-terminal symbol deleted.
reference count falls one, rule deleted.
digram uniqueness constraint difficult enforce. new digram appears,
SEQUITUR must search grammar occurrence it. One simple solution would
scan entire grammar time looking match, inefficient leads
quadratic-time algorithm. better solution requires index efficient search.
data structure storing digram index must permit fast access efficient addition
deletion entries. hash table provides constant-time access, adding deleting
entries requires little extra work. digram appears once, table need
contain pointer first symbol single matching digram grammar data structure,
shown Figure 3. hash table consists simple array pointers, collisions
handled open addressing avoid allocation memory chaining requires (Knuth,
1968).
Every time new digram appears grammar, SEQUITUR adds index. new
digram appears result two pointer assignments linking two symbols together doublylinked list (one forward pointer one back pointer). Thus updating index
incorporated low-level pointer assignments. digram also disappears grammar
pointer assignment madethe pointer value overwritten assignment
represents digram longer exists.
demonstrate mechanism updating hash table new rule created, Table
2 shows example Figure 1a, addition contents digram index.
second c appended rule S, digram table shows bc already exists grammar,
rule bc created. Creating link b c right-hand side rule
updates entry index bc point new locationthe hash table contains
pointer symbol b start rule A. Next, first bc removed. breaks link
b digram preceding symbol a, ab removed index. also
73

fiNEVILL-MANNING & WITTEN

Action

grammar

observe symbol c

abcdbc

change digrams

digram index

make new rule

abcdbc
bc

bc updated

{ab, bc, cd, db}

substitute bc

aAdbc
bc

ab, cd removed,
aA, Ad added

{bc, db, aA, Ad}

substitute bc

aAdA
bc

db removed,
dA added

{bc, dA, aA, Ad}

{ab, bc, cd, db}

Table 2 Updating digram index links made broken
breaks link c following d, cd removed index. Next, replaces
bc, creating links A, well d, adding digrams index.
process continues, resulting correct index digram pointers, costing one
indexing operation per two pointer operations.
Next, SEQUITUR requires efficient strategy checking digram index. Rechecking
entire grammar whenever symbol added infeasible, inefficient large portions
grammar unchanged since last check. fact, parts need checking
links made broken. is, actions affect
maintenance digram table performed, newly created digrams checked
index. course, every time link created, digram entered index,
time check duplicate. entry found already present attempting
add new digram index, duplicate digram detected appropriate
actions performed. Therefore, one hash table lookup required accessing
updating digram index.

5. Computational Complexity
section, show SEQUITUR algorithm linear space time. complexity
proof amortized oneit put bound time required process one symbol,
rather bounds time taken whole sequence. processing time one symbol
fact large O( n ), n number input symbols far. However,
pathological sequence produces worst case requires preceding O( n ) symbols
involve formation matching rules.
basic idea proof two constraints effect reducing
action
1

new input symbol observed, append rule S.

1

2
3
4
5
6
7
8
9

time link made two symbols
new digram repeated elsewhere repetitions overlap,
occurrence complete rule,
replace new digram non-terminal symbol heads rule,
otherwise,
form new rule replace digrams new non-terminal symbol
otherwise,
insert digram index

2

10
11
12

time digram replaced non-terminal symbol
either symbol non-terminal symbol occurs elsewhere,
remove rule, substituting contents place non-terminal symbol

Table 3 SEQUITUR algorithm

74

3
4

5

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

number symbols grammar, work done satisfying constraints bounded
compression achieved sequence. savings cannot exceed original size input
sequence, algorithm linear number input symbols.
Table 3 gives pseudo-code SEQUITUR algorithm. Line 1 deals new observations
sequence, lines 2 9 enforce digram utility constraint, lines 10 12
enforce rule utility. on-line appendix contains implementation SEQUITUR Java,
requires 400 lines algorithm.
numbers right Table 3 identify main sections algorithm, proof
demonstrate bounds number times executes. Action 1 appends
symbols rules performed exactly n times, every symbol input. Link
creation triggers action 2. Action 3 uses existing rule, action 4 forms new rule, action 5
removes rule.
Table 4 shows examples actions 3, 4, 5, associated savings grammar size.
savings calculated counting number symbols grammar
action. non-terminal symbols head rules counted,
recreated based order rules occur. Actions 3 5 actions
reduce number symbols. actions increase size grammar,
difference size input size grammar must equal number
times actions taken.
set stage, proceed proof. formally, let
n size input string,
size final grammar,
r number rules final grammar,
1 number times new symbol seen (action 1),
2 number times new digram seen (action 2),
3 number times existing rule used (action 3),
4 number times new rule formed (action 4),
5 number times rule removed (action 5).
According reasoning above, reduction size grammar number times
actions 3 5 executed. is,
(1)
n = a3 + a5.
Next, number times new rule created (action 4) must bounded. two actions
affect number rules 4, creates rules, 5, deletes them. number
rules final grammar must difference frequencies actions:
r = a4 a5.
equation, r known a5 bounded equation (1), 4 unknown. Noting a1 ,
number times new symbol seen, equal n, total work
action





saving

Matching existing rule

3

...ab...
ab

...A...
ab

1

Creating new rule

4

...ab...ab...

...A...A...
ab

0

Deleting rule

5

...A...
ab

...ab...

1

Table 4 Reduction grammar size three grammar operations

75

fiNEVILL-MANNING & WITTEN

1 + 2 + 3 + 4 + 5 = n + 2 + (n o) + (r + 5 ) .
bound expression, note number rules must less number symbols
final grammar, rule contains least two symbols,
r < o.
Also, expression (1) above,
a5 = n a3 < n.
Consequently,
1 + 2 + 3 + 4 + 5 = 2n + (r o) + a5 + 2 < 3n +a 2 .
final operation bound action 2, checks duplicate digrams. Searching
grammar done hash table lookup. Assuming occupancy less than, say, 80% gives
average lookup time bounded constant (Knuth, 1967). occupancy assured
size sequence known advance, enlarging table recreating entries
whenever occupancy exceeds 80%. number entries table number
digrams grammar, number symbols grammar minus number
rules grammar, symbols end rule form left hand side
digram. Thus size hash table less size grammar, bounded
size input. means memory requirements algorithm linear.
practice, linear growth memory poses problem. One strategy currently
investigating break input small segments, form grammars them,
merge resulting grammar.
number times action 2 carried out, digram checked new
link created. Links created actions 1, 3, 4 5, already shown
bounded 3n, time required action 2 also O(n).
Thus shown algorithm linear space time. However, claim must
qualified: based register model computation rather bitwise one.
assumed average lookup time hash table digrams bounded constant.
However, length input increases, number rules increases without bound,
unstructured (e.g., random) input, digram table grow without bound. Thus time
required execute hash function perform addressing constant,
increase logarithmically input size. proof ignores effect: assumes hash
function operations register-based therefore constant time. practice, 32-bit
architecture, linearity proof remains valid sequences around 109 symbols,
64-bit architecture 1019 symbols.

6. Exploring Extremes
described SEQUITUR algorithmically, characterize behavior variety
domains. section explores large small grammar given sequence length,
well determining minimum maximum amount work algorithm carry
amount work required process one symbol. Figure 4 summarizes extreme
cases, giving part example sequence grammar results. Bounds given
terms n, number symbols input.
deepest hierarchy formed depth O( n ), example sequence
creates hierarchy shown Figure 4a. order hierarchy deepen every
rule, rule must contain non-terminal symbol. Furthermore, rule need longer two

76

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

symbols. Therefore, produce deep hierarchy short string, rule one
terminal symbol longer one builds. order create rules, string
represented must appear two different contexts; otherwise rule incorporated
longer rule. One context deepest hierarchy, must participate. context
hierarchy, reduce size input string, appear rule S.
Note every rule Figure 4a appears hierarchy rule S. repetition
sequence, one terminal symbol appended, producing new level hierarchy.
point including repetition length one, mth repetition length + 1.
repetition gives rise mth rule (counting rule S). total length sequence
hierarchy depth therefore
n = 2 + 3 + 4 + ... + (m + 1) = O(m2)
deepest hierarchy depth = O( n ).
end spectrum, grammar shallowest hierarchy, shown
Figure 4b, rules apart rule S. grammar also largest possible one
sequence given length, precisely rules formed it. sequence
gives rise one digram ever recurs. course, sequence alphabet
size ||, O(||2) different digrams, bounds length sequence.
kind sequence produces worst case compression: repetitions,
therefore SEQUITUR detects structure.
bound

example sequence

example grammar



deepest hierarchy

O(n)

ababcabcdabcdeabcdef

ABCDDf
ab
B Ac
C Bd
Ce

b

largest grammar;
shallowest hierarchy

n

aabacadae...bbcbdbe...

aabacadae...

c

smallest grammar

O(log n)

aaaaaaaaaaaaaa...

DD
aa
B AA
C BB
CC



largest number rules

n/4

aaaaababacacadad...

AABBCCDD
aa
B ab
C ac
ad

e

maximum processing
one symbol

O(n)

yzxyzwxyzvwxy

ABwBvwxy
yz
B xA

f

greatest number rule
creations deletions

n new rules
n deleted rules

abcdeabcdeabcde...

AAA...
abcde

Figure 4 extreme cases algorithm

77

fiNEVILL-MANNING & WITTEN

Turning largest grammar smallest, Figure 4c depicts grammar formed
ordered sequence possibleone consisting entirely symbol. four
contiguous symbols appear, aaaa, rule B aa formed. another four appear,
rule contains BBBB, forming new rule C BB. Every time number symbols doubles,
new rule created. hierarchy thus O(log n) deep, grammar O(log n) size.
represents greatest data compression possible, although necessary sequence
one symbol achieve logarithmic lower boundany recursive structure do.
produce grammar greatest number rules, rule include
terminal symbols, building hierarchy reduce number rules required cover
sequence given size. Furthermore, rule longer two symbols occur
twice. Therefore rule requires four symbols creation, maximum
number rules sequence length n n/4, shown Figure 4d.
discussed size grammars, consider effort involved
maintaining them. shown upper bound processing sequence linear
length sequence. However, still useful characterize amount processing
involved new symbol. Figure 4e shows sequence repetition built yz,
xyz, wxyz, forth. second occurrence wxyz appears, matches
possible w, x, y. z appears, yz matches rule A, xA matches rule B.
Finally, SEQUITUR forms new rule wB. cascading effect arbitrarily large
repetitions continue build right-to-left fashion. amount processing required
deal last z proportional depth deepest hierarchy, matching cascades
hierarchy. maximum time process one symbol therefore O( n ). fact w,
x, fail match means require little time process, preserving overall linear
time bound.
Although bound linear, sequences certainly differ proportion work sequence
length. sequence Figure 4b, repetitions exist grammar formed,
minimizes ratio. sequence Figure 4f, consists multiple repetitions multisymbol sequence, maximizes it. time repetition appears several rule deletions
creations match lengthens. fact, every symbol except incurs rule creation
subsequent deletion, O(n) creations deletions. length repetition,
proportion symbols incur work 1/m, tends toward zero
repetition length approaches infinity.

7. Behavior Practice
give idea SEQUITUR behaves realistic sequences, turn artificial cases
sequence English text. Figure 5a plots number rules grammar number
input symbols 760,000 character English novel, shows increase
approximately linear. Figure 5b shows approximately linear growth total number
symbols grammar. growth number unique words text, shown
Figure 5c, high start drops toward end. Zobel, et al. (1995) observed
much larger samples English text thatsurprisinglynew words continue appear fairly
constant rate, corresponding neologisms names, acronyms, typographical
errors. example, number rules grows linearly because, words
recognized, multi-word phrases constructed, number phrases unbounded.

78

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

nearly linear growth number symbols grammar seems disappointing,
fact inevitable consequence information content English. Since symbols end
text convey similar amount information symbols beginning, lower
bound achievable compression rate. English text, corresponds entropy
English.
EQUITUR operates quicklyas shown Figure 5d, 760,000 character novel
processed 16 seconds: rate 50,000 symbols per second, 3 Mb per minute. figure
also illustrates SEQUITURs linear-time behavior practice. sequence Figure 4b,
repetitions exist rules formed, fast process, indeed processed
rate 150,000 symbols per secondthree times faster novel. sequence Figure 4f,
consists multiple repetitions multi-symbol sequence, slows performance 14,000
symbols per seconda ten-fold decrease fastest sequence. sequence Figure 4c,
consists many repetitions single character forms concise grammar, comes
50,000 symbols per second; novel. measurements performed
Silicon Graphics Indigo 2.
EQUITUR effective data compression scheme outperforms schemes
achieve compression factoring repetition, approaches performance schemes


b

200000

symbols grammar

rules grammar

30000

20000

10000

150000

100000

50000

0

0
0

c

200000

400000 600000
input symbols

800000



10000

5000

200000

400000 600000
input symbols

800000

0

200000

400000 600000
input symbols

800000

15

time (seconds)

vocabulary size

15000

0

10

5

0

0
0

200000

400000 600000
input symbols

800000

Figure 5 Growth rates English text: (a) rules grammar; (b) symbols
grammar; (c) vocabulary size input; (d) time

79

fiNEVILL-MANNING & WITTEN

compress based probabilistic predictions. SEQUITURs implementation evaluation
compression scheme described Nevill-Manning Witten (1997).

8. Related Work
mentioned introduction, research resembles work Wolff (1975).
described SEQUITUR, possible contrast Wolffs system, MK10, processes
sequence left right, forms chunk (equivalent SEQUITUR rule) whenever
digram seen 10 times. happens, occurrences digram replaced
non-terminal symbol, system either carries sequence, restarts
beginning. either case, digram frequencies discarded process starts over. worst
case algorithm corresponds sequence Figure 4f, long exact
repetitions. symbol repeated segment gives rise chunk, process starts
over. Figure 4f, length repetition linear length sequence,
number restarts length repetition, algorithm quadratic length
sequence. makes processing million-symbol sequences impractical.
number systems, Langley (1994), Stolcke Omohundro (1994), Cook et al.
(1976), form new grammar rules repeated sequences, also merge rules generalize
grammars. However, operate different domainas input, expect set sentences
drawn language, rather single long sequence. allows make inferences
based directly comparing corresponding parts different sequences. Furthermore, small
size training data means efficiency lesser concern. performance
algorithms measured ability accept test sentences language, reject
new sentences target languages. SEQUITURs case, one
sequence available, metric apply.
VanLehn Ball (1987) also infer grammars sets sentences. algorithm
enforces three constraints grammars purpose making version space finite.
are: (1) rule empty right side, (2) rule one symbol right side,
symbol terminal, (3) every non-terminal appears derivation string.
constraints reminiscent SEQUITURsfor example, third constraint weaker form
SEQUITURs rule utilitybut serve different purpose. SEQUITUR, operational;
drive formation grammar. VanLehn Balls work, make version space
tractable providing sensible restrictions form grammar, algorithm
search space.

9. Conclusion
paper presented EQUITUR , algorithm identifying hierarchical structure
sequences. Based idea abstracting subsequences occur rules
continuing operation recursively, algorithm works maintaining two constraints:
every digram grammar must unique, every rule must used once.
EQUITUR operates incrementally and, subject caveat register model
computation used, linear space time. efficiency permitted application long
sequencesup 40 Mbytein many different domains.
evaluated prediction accuracy EQUITUR paper. Evaluating
prediction accuracy fairly complex business. adequate simply give count
80

fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES

correct versus incorrect predictions, begs question likelihood
different ones occurring. Prediction schemes assign probabilities predictions
might offer, judged discrepancy probabilistic predictions
true upcoming symbols. whole question accurate probabilistic prediction sequences
tantamount compression sequences, substantial field right (Bell et al.,
1990). fact evaluated SEQUITURs performance compression found vies
best compression algorithms, particularly large amount text available
(Nevill-Manning Witten, 1997). point present paper different one:
SEQUITUR re-represents sequence way exposes underlying structure. fair say
compression algorithm produces representation way perspicuous.
Perhaps greatest drawback SEQUITUR algorithm memory usage,
linear size grammar. Linear memory complexity ordinarily considered intractable,
although practice EQUITUR works well sequences rather impressive size.
clearly room approximate versions algorithm partition input re-merge
grammars formed them, could perhaps applied recursively create algorithm
logarithmic memory requirements. conjecture, however, approximations
doubt turn useful practice, inevitably sacrifice property
digram uniqueness appealing feature original algorithm.

Acknowledgments
grateful many detailed suggestions Pat Langley anonymous referees.

References
Andreae, J.H. (1977) Thinking teachable machine. London: Academic Press.
Angluin, D. (1982) Inference reversible languages, Journal Association Computing
Machinery, 29, 741765.
Bell, T.C., Cleary, J.G., Witten, I.H. (1990) Text compression. Englewood Cliffs, NJ:
Prentice-Hall.
Berwick, R.C., Pilato, S. (1987) Learning syntax automata induction, Machine Learning,
2, 938.
Cohen, A., Ivry, R.I., Keele, S.W. (1990) Attention structure sequence learning,
Journal Experimental Psychology, 16(1), 1730.
Cook, C.M., Rosenfeld, A., & Aronson, A. (1976). Grammatical inference hill climbing,
Informational Sciences, 10, 59-80.
Cypher, A., editor (1993) Watch do: programming demonstration, Cambridge,
Massachusetts: MIT Press.
Gaines, B.R. (1976) Behaviour/structure transformations uncertainty, International Journal
Man-Machine Studies, 8, 337365.
Gold, M. (1967) Language identification limit, Information Control, 10, 447474.
Johansson, S., Leech, G., Goodluck, H. (1978) Manual Information Accompany
Lancaster-Oslo/Bergen Corpus British English, Use Digital Computers,
Oslo: Department English, University Oslo.

81

fiNEVILL-MANNING & WITTEN

Knuth, D.E. (1968) art computer programming 1: fundamental algorithms. AddisonWesley.
Laird, P. & Saul, R. (1994) Discrete sequence prediction applications, Machine Learning
15, 4368.
Langley, P. (1994). Simplicity representation change grammar induction. Unpublished
manuscript, Robotics Laboratory, Computer Science Department, Stanford University,
Stanford, CA.
Nevill-Manning, C.G. & Witten, I.H. Compression explanation using hierarchical grammars,
Computer Journal, press.
Nevill-Manning, C.G. (1996) Inferring sequential structure, Ph.D. thesis, Department
Computer Science, University Waikato, New Zealand.
Nevill-Manning, C.G., Witten, I.H. & Paynter, G.W. (1997) Browsing digital libraries:
phrase-based approach, Proc. Second ACM International Conference Digital
Libraries, 230236, Philadelphia, PA.
Rabiner, L.R. Juang, B.H. (1986) introduction hidden Markov models, IEEE ASSP
Magazine, 3(1), 416.
Stolcke, A., & Omohundro, S. (1994). Inducing probabilistic grammars Bayesian model
merging. Proc. Second International Conference Grammatical Inference
Applications, 106118, Alicante, Spain: Springer-Verlag.
VanLehn, K., & Ball, W. (1987). version space approach learning context-free grammars.
Machine Learning, 2, 3974.
Wharton, R. M. (1977). Grammar enumeration inference. Information Control, 33, 253272.

Wolff, J.G. (1975) algorithm segmentation artificial language analogue, British
Journal Psychology, 66, 7990.
Wolff, J.G. (1977) discovery segments natural language, British Journal Psychology,
68, 97106.
Wolff, J.G. (1980) Language acquisition discovery phrase structure, Language
Speech, 23(3), 255269.
Wolff, J.G. (1982) Language acquisition, data compression generalization, Language
Communication, 2(1), 5789.

82

fi
ff fi


!"$#%$&('*),+--.'/!01$2,3.1

@BA.CEDGFIH

456789:';<-=>?6
#& 98';-.'

JLKMANOJQPSRUTVJXW8FVJXYZP.[]\_^_Y`WLP.JXabab[LadcGe

fgPP.[Xh`iajfgP.CQ[LYkTVJmlnAFoDpH

[qFVToA.WnRrANO[

s_tbuVvUw"xzy`{ w"|~}~b{}"


"~bX,: :

}!}{_buxxuV

X,: :

5:!5XQ5.%_5%!<Vb,V S" 5
_ E,V !,V:

U b!
8 !!: b:L! $"$.$ o$.$_G$! $ !"$
!
X $ ,$8"q5" 5 !Q:$.$ X8$
$5! "%_"(( $ G$ <$Gq5" (5
`M $.L $ m$ z S$$.$ Z .
8 X%($,L< $$X z$ V$$ _ L! k! .
$ kQ%o $kL`q"8k8ok _ Q $ $
.55%!oz$ 5 L$$ 5 $ X! $k !$
$,8$
V_ !


ff ff "!#$ &%(')fi%ff*ff+ ,,*-. #/103245 &%67ff8%1%1ff ,28ff9 !!%152 /,: ,*
fi
;ff # #ff < =>/,24; ?!%5 A@ BC%1%7ff D=FEG<GEH$=, #$ I%>%5 , ffJ,*ff #$/$ K,*<7L@MN ,*
;ff D=PEG<QQHR ,*F?%ff28%S K#>%T@VUff W ff #=PEG<XGYZ[K%7F52\ ,*M;, KF#=,EG<G]H$^`_>)fiff aff #=
b,28ffcff aff d;ff\#ff/#/528ff*d!#4%ff eKfR#ff /<7F)fi;d!#ff(g<, &%1$ /affc/"ffCB>%1%ff Dhiff #a &%
&%ff #$ j@ B>%1%ff D=EGQ<]HS`k\lm 28"!%ff ffC@ nCo%5 &Fff R &% ^=EGQ<GH$=8#ff/ff #82;c;, 3fp28,/ff*c<\S*ff /1fqT
24%5 /ffrfR!#%ff sC)>;ff #ff\#ff F5fi#$ 288 %ffF@Vt\#$ 'ff <#ff - K,*su<,/D=DE&GGvYwZ[%F52
,*?M;, F#=EGG]wYxc W> ,*FyD *'<D=,EG<GEYkCff ,ff8%D ,*FUcz #82'ff #4={E&GGXY&aI "Uff ff '| K,* ;ff D=
EGG<}YaI ~Uff ff 'P=REG<QGYa Uff ff 'P=DEGG<H$^
C/1%[#ff28ff /%T=> !!#{ 24;ffF;, &aff"//%TN,ff ff ff874;ff #s"ff 4#/52#sg<, &%1$ /aff=fi)r74; Jfqff )
ff8,28ff !/,J@Vxc W: ,*9y *'D=6EGGEY~ff8#/ =6EGGEYrZ[ff #ff a<jff &% ^=cEGG<]H$^_>)fiff aff #=;ff
!!# 2;Jfu,/< K,*~U\ z 24'/4#z @$E&GGvHfi@V &%5/*ff aff8%!ff*J,*ff !,ff ,*ff /%T+{T~x\<, #$ '<5 =
EGG<vH>s , <ff\~1fqT &%"{/cff a<ff #T+ !!#{ 24;+4#$ 28$ %ff"#4ff /+ ,<("ff #S2/"ff=
g<, &%178 /aff(7?ff| ,*d;ff{ff <#$ ff* !!#4{ 24;ff~ff\fq#$ "ff )fi#4'3=;, Cfc$ {q
5$<[/ qw>@V_C#m tcyD
>H$=~)>;524;~;ffc#4ff /d!#%ff 2 K,ff|%aff*?~!,K%7TF5 &%
/"ff^M7,28ffJ$?ff8!#4ffbaff ff-7ff #s?f(g, I%o$ K/affJ7fq#d /,/"ffd;, ?f(;ff
&s &%#$ 288 %ff +F
>t\m _C# I%7<ff #$ @/k>ff ff8% ,*:Ucz #82'ff #4=RE&GGXH$=7(2 Kff"a<7ff )fiff*: \
&s &%>#$ <28$ %ff~/, &%ff #$ f[BC%o%ff Dhi{4ff #aI &%c &%ff #$ =!#4Ia<5*ff*N)fi;N?ff #/52dff "!#$ &%
fp<#s /D^
#$=;5!, !,ff #>28/{ff;ff>)fi#'F0,,*<7Fs I{s &%P#$ 288 %ffr, &%ff #$ fDBC%o%ff Dhi
&%ff #$ J/$ #4ff*J{T:k>ff ff8%C K,*+Ucz #$2'<ff #F@$EGG<XHr K,*+28/{ff*:T+t\#$ 'ff <#ff + ,*+u,4/
@$EG<GvH$=TdS*ff /1fqTff8;["<#ffcs &s &%#$ 28$ K%7ff(324%5 /ff\KfB>%1%ff Dhic &%ff #$ w^>Mff28,*P=
)fiff[28Fff>;5)fi;";ffC)<#'(fDu,s ,*"U\ z 24'/#z @8EGGvH8=TF!#a5*<F;ff>s &s &%
8,DI4Pi/iPi`q 4V 4 i8&cfi8q/Rq 4/ ii$/& >qqi/i\V8 i`i/
+--'Vfi~fi"$## 9: 9L5bff76
#& # fi

%&# #q9


fi,,8$w

R fib 1&
F /5b[
(5
F 4
q (
4
c & q (
" b1(
c1{/ {
/ b
cbV b
1ff

<off
F(








`,"

,,K7$



,9w














fi













fi







P+9w,fi
9
P9w
9

,9

9

,

F
F
4 ,<b85/,
,{ 85/,c

4 &15"!p>&1#85/, $
~74%



,:







&&'$<#(fi " )/fi4 ",8&*!p4s/?s +!p4 !-,>4. /10> *( />8'b
32',32?> K>! 54607.98:,C:&&'$'7;<2' w (sI{s&13=>32\! /|&&'8
/ 7? ?@2//!(s&s&13=N!|/":&&'$A.9$B< '& 9,DC,4/FEGIHHJ*K8
bL8~ /4d7L42, (IM&<'$F' { (fi+N!j d&{sIj&&8
'$ +8'6 d/+N!POQGRIS*QITLUWVYXZ[VYUW\] ^(fi {_I&5)`<P",@$ !q(8,"?
'&-2[87<E)a{,(>&1 bIHHc'K8d( |87<,[4c^= &1=e2"?fG2'C
/I?@2 L8 F2'B{(fi*&w /c\ 9gL$/>32L IM&<'$ C174$)2'c >c&5/
'<S"(fi " )h\4 ",8&P7*!qd/1jik=d 9! @8 (] K-&5/l85(/$N/'&F
,<'&:,$ *=,Cm. /n0> 1(fi $">8,/oE:(fi )/8/, !+82'8/K[!fi
8'b C! 4607.98:,C:&&'$,K,d >!/I?@2 {SIo3=
+ ))2L8)2'6! |,K,\5(+!q17([p5aI8/rqF)*2L8 sCo 1tij{_I&&&'8
aI8/u\Gg,` 78L8 $` >&$Kv?@2,&1$/[K,(? )/k/'&,4&
(fi >S^g31o3="&&/ JI,laI8/lc[' {$ fi(Ns&s&)$88&&'$<
, (96'5\ /9(fi ? )/>4 ",8&*!p4s/1#wbxaI87<zyF,"aI8/>J(fi
'6 c "&&7 8@)I8(,J \ "&&'$<cFs&s&:{;,&1=#aI87<}|
,~aI8/"<5)G2,c,>8<L4M2,F c,K,I
-5:ffLlnN1%6:nLj@
sCo 1ti|7)&rIM&<'$E:s>1 D7IH@u*Kfi5 ,/: "</N!3Q$ZX@UWVT<O)Q$UW#QQ$T>'XV_O3
VYTLUWQIGIX@ZO7s\J{_I& 5 '4/ {4<[?)2x 8,!j4& *2,$9(r7 ,
/'&+ d7G!q",r/& F ,,$"N![ ?7)& j4/,I8/8=>,r48SK/,, 3(fi
pL1_*3WI3j3G:3WI%Wff)YGIbW-ffIW-ff$W>-ffI"-ffI~-ff$~>-ff_IWIjIIWff_W3IjWff_Y@
)$ ))9WIb3IW3W-W)WY%jW3Web^3$1 W3I3$^3$


fi-YL'''j'"j'f*'*I~'f*$L_d 'I$-]*'x h'''~kj

d_)$k)7G5d3I5#@Y3'LG3Lkj)Y6YLW$$'3I[WY'I*h__v_'d3kzb*
L_x@h ^'LG3L N)6_')I3*)I>9IY#Lff9)G3Lp''7Lff '@3>3L_>)LI
W5ff
L5*9)'@Y3'LG3D])'fiLff"M*))$ L 53))

*LL$7)LN ! 535I)'6@Y3'LG3j"Lff)G3Lh
73)_$#}L _'vl'&%9)G3 b73)_$'(:)* h#he6L3IWb)G3L)L3]*))$
L*LNM*b*'3 +*$7"%f9)eh&, *.-xL/*G'L)N30, *.-'%)I3IG3G1%2ff5'5$1 3' h
')@h*I+M_)'LN3LkvGL$I_54-WI_GIWY26l798'YWY]@5*))hp:''
3L$[#'I~*1%>)'{G*e LN3xff
'*[h_31%]+'{G*3 @LeM@x;@I7>*))$
)G3<b) 7G*3< ''$'I=%5*)3 I_>Lff9)G3"M?<_*@*ff
L)L NM
NL?B M~)' L*LNM*9)G3L93'7b*$
CD%)' :G7_L7)')) )*)_?Lff)G3L FEHGJILKNM"OE Ld)^P*)G3L
L3 d)_$lD)'~ *[]$1 3'Q*'))'e{9d_)$]_GhN3L:%/R
__3I #)' W*j$1 3') '$'Ifi=%xGLff*3 3Le7NR$6+'){_SETGVUWLX
.Y WVZ\[\[ 3L_53 _)eI3]#)eIb)L#)7_d3I'L*k)'LN3Lb'd_3IG31*Gd@3
L>GlLdff3)])h")^5`_p3a
b )' ~)'))]3G$G5''G3L$#')*9)3'_)I") b [Mdc 9d_)$#$1e
3'<)*#L#WfGL3I)'7')H*M -WhgfdY[ihj\k\lnmpo1 3#NLd_)$%ehq*MI
)~)G3LLL3x_'x'@h *I_@ x7'_'6)'_]ff
*he x)^P @'5d9#*))h
5_'6)I''9Wj_'7*)) N3*IL3L__Lj$[1 )'9)G3LD^5_'7*))h
)]_30,LIrQ*ff,L'])*9 N63
stHuwvdx1y.x{zdv}|~i}3k\lnmpow\
%Lxe]d_)$)G3L3 b L3GLG5k\lmogh GI @M_IG)I @'
K0:*7')]_' 'f*Ik N)9d)_$-3*I9L> 9{eL36N^+^ b
LG[II= ^0dff? 5INL)L~L>) )G)I:%>=
b W'LG3^ q; 9d)_$'ehq*M)*))$f_')I3'eM@S&K
) ? NL fh)$>){YLW$i8 3$WW@5
b lMLeLG K0L7_$)L Whfvdp)')9ff
d35*))')G3> 3L_
)L @vI@)@dffd?:&r&&1''*@*)'9L*L*7)G3L+).*)I=%$p^3
b*$vN)P_30,LI>=%)'{_ff1 '5*L>#' 6_$>)L>7.6$*
Q )G ))'51jL3LG `>5NP
'@R' L$9)' W[ )Ie*M"
"zrz.x{y.x{zdv|r~|k\lnmpo@R^#Le:G5*)
"zrz2ff 7[$6.OMOn
?r0iqr@$0
QL,Le'3ff2%>)I*)*))')e@)DW)3

NL)3xNL>C@ \;'3).@ ff.OO=ff

stHuwvdx1y.x{zdvd~i}xvt=2>"tn{y.x1z)vs>x@vdy.x1rtxivrt:2>"t1y.x{zdv
%K .."\ A= L3 j)IPeW$'I3*IbLr'I L1%*'$ffL1%=e
G
'$]*3 )'^ )DeM@L$PG*ffz_d5 b [@>^$[W@^
_'3$-ff
'')I)^M@x#)' W)"j7') .5KK
". b 6hg3*LIWYI[Y
G]3I[WYfi&dFv h @Y3'LG3#'95)9['I]_GhN3L3 b 6_$
)^P@ }5d37@' -@h ^'LG+7'@7-)' @)!K(

.

fi

w2

ff
fi !#" $&% fi(')*%$+,-&fi.fi(0/1%)324%$,6587:9;+=<fi(, %>fi?<A@CBEDCF:GIHKJMLON PRQ/TSU
Vf
jfi 58VW 7: , 94XZ[Y4 ,k
fi(/l
fi($[$fi.
fi($fi\fi]^fi?<6 [,k_n,6m[og X,
k'Ifi(,p,;_q_`%&):fab<A$%h fi?fihKA ,#rhcds?tuf%ev$%fi?)+f/wC,^myg 'hx fi($=ig V
6

V
z4{:|C}~3
I>IM^
Z , fi?$\$fi %,:U
Q I\ SpQ
<>g , V afi-, fi?$8$fi %,:U,<
Q I\ SpQ
2;%$&,p<>g , V afi-, fi?$8$fi %,:m;x
.fC~??:3 [
fi($fi4h"% !, %'hf * 'Ifi#b-X>%$
')*%$\@B+DF3GIH0J8L(N PQ/Sm
.fC\ofi(fi.%,i%,k,<A\ V&W $?% '1Q f SE%$;\%g $ W Q ?> Sm0x
,h" $ , V " fiU
fiK)$'Ifi(Y[%$ W %)58739;'# W fi? Eg , , fi V fi?$&!8%M<>i-, X>gi
#fi(Y[fi(fi(,hgf i-a>fi
,<e'Ifi($i V -,)*%$'6 %,:mE;fi(a>fi($
fi fi?(U>Y;
fi(,h V %'Ifi?%4<fi(,^i)*!>-, Xh$ V fi;g V &fi?(U
fi
<> , V %,i V %,^a>fi(,-fi(,?m
ff
fiff24%$, 58739" " $% V
Ig ig 'Ifi?[f 'I%^0f" $fi(a> %g ! W , %Y;,I" " $%^ V
fi?%8$ V fi
'Ifi($i V ,<>gf afifi('"%$b$fi?%>,-, XU[fimXm[Q4fi(fi.,<8g $ VW fi($&?U ? \%>g $ W (U
? 5\fi
^fi($Afi(pbmU ?= fi $U ? >[ fi($fi(a> ,Zfi(Afm U ? Sm66Y[%$
'Ifi(,^i-%>,-, X

e
fiIV'#b]^ '#f[$ V fi#f Xfi( $M)%>g ,<T!T5\$ W fi(, X$&fi(,,<T %>,%,Q ?> V , , %.fi
fi] " $fi?fi?<;24%$,p587:9;Om

%g X
h"% !^, %'bU
fi;f X%>$
'" $fi?fi(,fi?<e ,#%>,%,I,<h\ &$?% 'nQ ? SE>g-&fi
fi] "fi(, afiAQ-\$fi fi?8%,h , fi?$*" $&%X$''h , Xpf X%$
'AS;%6Y;
fi(,Y[fi.V&W
fafi., %6, fi(fi?<%)="fi V
)!> , Xp'Ifi(&$ V ,)*%$'# %,:UC
fie)% %Y[ , XpY[fi W , %Y;,wg V %)0
fiIfi(8%)=24%$,T587:94\Y[
$fi?g 4 ,ke %Y[fi($ V %'I" fi]-!Af X%$
'm
6>=: ?::nhC~C*I| f|C
[
fis>Ivu(TQ;f ,:U f S8
fiTg %)24%$,y587:94 %,i-, X%).
fiTfi(A%)
fi] " $fi? %, 8 U Y;
fi($fi ,< $fi8ab$i-fi?OV U,< ;%, fi8%)j
fi8$&V fi %,.8U U U U
,< mx
[
fiTi !" $&% fi(')%$6
Ag V >A<fi(, %fi?<E.L(N PQ/SU+)%$Awfi(/q%)M"% ,^
f Xfi( $Z)%$&'Zgfim
.fC~??:3yE.L(N PQ/S:\% ab fie ,A , fi?$\ 'Ifi8 ,p&
fi. (fi.%)0/wm
.fChofi(fi fi($fi(a ,[fi(MfmQ f S\Q*)*%$" $ V V f0" g $"%^fi?\
fi#b-X>%$
'd%)=5\fi X$,<fi#,<
g " U ?> U V %g<fi." $&fi)fi($$&fi?<Sm;x
4fi]?UY[fiI<fi, fiZ&
fiZ" $&% fi('d%)E ,^fi($&fi?; ,T&
\""fi($4q&
fi. ,fi($af+& !" $%>-fi('
Y[
'Ifi($ V fi('I"%$fC ,)*%$'#i-%>,:m
?

fiR 6 0 0 ? f&^e #4?fR.4b 8 # K 0

fiff

fi!"$#&%'
(*),+&-/.&0132546)798;:fi8=<>+7?8=@A)B?CDEF&"G#&%=798=HJIK7ML=8N:fi+)<>),+OB9C=PQ(
RS<*B9T5),UV+WE)<>),+YX[Z]\M0Z_^a`,Zb.!c
B9CdT[79Ue:7?4Nfg) <ihDZ ^ Uj),kEU) <>),8N+>:fi8Ela<>+A79U+>:fi8Elmk6B9:fi8]+<n798=HZ \ ),8=H:fi8Elk=B9:fi8N+<nB9Co:fi8N+),UT97pfG<qZ6r
8:fi8=<>+798=@A)JB9Cd+WE)tkEUB4Nfg),uvB9CSwGx6y{z |A} ~5~5y{w$~]iwGw$y{dw$y$Fz y{|AwG3wGxi5|AF~5y{w$5xFC{B5Uq7m<e),+#
B9CO:fi8]+),UjT[7pfoUj)Af7?+>:fiB58=<,h=HN),8EB5+j) H/EF&"G#&%h:<n7F+EkNffi)-/.&0A10I2{r
8wGx6y{z |D|>z y{~5y{w$5x CBU:G<Q798:fi8N+),UkEU),+7?+>:fiB58CB5Um-.&0132r!9:g8=@A)&)F8EB[8E),) H+BU)AC{),U
+BF<>+79U+e:g8Elm798=H3),8=H:fi8Elmk=B?:g8N+<&B?CD:fi8N+),UT97pfG<,hE&)q)AE+),8=H+WE);8EB5+7?+>:fiB58a<e=@W+W=79+&"Z ^ %B4E+7p:fi8=<
+WE)t<>+A79U+>:fi8Elmk6B9:fi8]+;B9Co+WE):fi8]+),UjT[7pf"Z_%hE798=H<:fiuF:fG79U>ffiC{B5Uq"Z \ %Ar
83:g8=<e+798=@A)t:G<&<7p:GHm+jB46)t,~5y{wG&~],zY:+WE),U);)AN:<e+<S7Qu3BHN)AfoB9C&-/.&0132D<>=@jW+W=79+M+WE)
PQ(
RS<:g8I79U)t<7?+>:G<L=) H*hN&:fi+WT[7pffiE) <CBU7[ffoZ ^ 7?8=HZ \ 4N"Z ^ %Y7?8=H"Z \ %h5U) <ek=) @A+>:fiT5)Affi5r

9:fi8=@A)q),T),U ffg),83:fi8]+j),UT[7pf=Uj)Af7?+>:fiB58@,798m46)S)AEkEU) <<>) Hm7<d7QPQ(
R"/4EE+8EB+o8E) @A) <<j79U>:ffi75<d7QnB5U8
PQ(
R;%Ah=&)m@AB5NfGH:g8=<e+) 75HW=7pT5)JCB5UjuNfG79+j) H+WE)JkEUB54Nffi),u75<;73kEEU)m<79+>:G<LD794N:f:fi+>kEUjB54Nffi),uB9C7
<>),+MB9CoPQ(
RS<,hN4EE+<:g8=@A);&)q79U):g8N+),U) <e+) HF:fi8+WE)Sk=79Uj+>:G@ANf7?U<e+U=@A+EU):gu3k=B]<>) HB8m+WE)SkEUB4Nfg),u
4Nm:fi8N+),UT[7[foU)AfG79+>:fiB58=<;<>k=) @j:LD@,7pfffi&)QkEU)AC),Un+WN:G<&C{B5UuFNfG79+>:fiB58
r
5),T),U7pf@AB58=@A),kE+A<o79Uj)8E),) HN) H:fi8tB5UHN),UO+BSkEUj) <>),8]+O+WE)ny{~5|Ay{w$x]Q~5x6Qz x65wGxNY5w$x=y*~55z9,|>~9,h,C{B5U
SWN:G@jW&)t<>W=7pffdkEUB9T5:GHN)tk6B9ffi]8EBuF:G7pffi{+>:fium)m7pffil5B5U>:fi+WEu<ir&WE)@AEUe:gB=<SU) 7HN),USuF:fil5WN+S+),umk6B5U79U>:ffi
>Eumk+B5) @A+e:gB8CBUq+WE)F)AEkNf:@j:fi+FkEU) <>),8N+79+e:gB8B?C+WE)m7pffil5),4EU7<SSWN:G@jW&:ff46)kEUjB[T) H+jB46)
<>+7?U+>:fi8ElmB5U&),8=H:fi8Elk=B9:fi8N+<S7pffil5),4EUA75<,r
WE)FCB?fffiB9&:fi8ElHN)AL=8N:fi+>:fiB58=<379U)m8E),) HN) H+B+U7?8=<C),U;:fi8NC{B5Uu7?+>:fiB58C{UB5uv:fi8]+j),UT[7pf&U)AfG79+>:fiB58=<J+B
k=B?:g8N+;U)AfG79+>:fiB58=<,r

fiff

$,/D|>zp{"%Mz>D|>z "%dD|>z \ "%zeD|>z ^ "%'
O795)F+WE)FU)AfG79+>:fiB58bh6ffi),+F798=HZ46)F:fi8]+),UjT[7pfT979U>:G794Nffi) <,hd798=H@AB58=<:GHN),Ut+jWE)F:fi8=<>+798=@A)B9C
EF&"X[c5%nWN:@jWU)AfG79+j) <Q7?8=HZ&:fi+W+WE)FU)AfG79+>:fiB58FB58Nffi5rFP;)AL=8E)F+WE)FU)AfG79+>:fiB58/*|zp{"%&B58
U) 7pf*8]EuF46),U<M+Bt46)q+WE)Q<>NuF4=B9f6CB5UM+WE)&:fiumkNf:fi) HU)AfG79+e:gB846),+&),),8+WE)Q<>+79U+e:g8ElJk=B9:fi8N+<MB9Co798=H
Z6rW=79+&:G<,hNC{B5US4=75<:@U)AfG79+>:fiB58=<;HN)AL=8E)
D|>z {"jQ% pq
D|>z {"A;% 9S
/*|zp{"% 9S
D|>z "/E% 9S
D|>z $"% 9S
D|>z "/A% pq
/D|>zp{"{,% 9S
/*|zp$"93% "D|>z "%% ^= 0
798=HCB5UH:G<$>E8=@A+>:fiB58=<D|>z "%Q:G<+WE)U)AfG79+e:gB8<e]uF4=B?f@AB5UU) <ek=B58=H:fi8El+jBQ[V/*|zp{"p%ArEB5U
)A=79umkNffi)5h*D|>z {"j";%%dNq _r5Numum),+jU>:G@,7pffg5h6&)tHN)AL=8E)zeD|>z {">5%d+BF46)Q+WE);:fiumkNf:g) HU)AfG79+e:gB8
4=),+>&),),8),8=H:fi8Elk=B9:fi8N+<;l9:fiT5),8Nr;SB5+j)t+W=79+/D|>zp{"%S798=HzeD|>z {">5%&W=7pT5)Q+B4=)F)A:fi+WE),UQB9CqQhOQh
th
Qh
QhYt hoB5UJQr
_EU+WE),U h;&)HN)AL=8E)<>k=) @j:G7pf:G<79+e:gB8=<B9Cm+WE) <>)5h;4ND|>z \ "%D|>z {">S"j&j3%%798=H
z>*|zp ^ "%SKz>D|>zp{"n"n %%Ah6:r)5rfih*+WE)F:fiumkNf:fi) HUj)Af7?+>:fiB58=<QB58<>+A79U+>:fi8El"/),8=H:fi8ElE%Sk6B9:fi8]+<4]
NhEl9:fiT5),8+W=7?+S+WE)Q),8=H:fi8El"><>+79U+e:g8El_%k6B9:fi8]+A<q79Uj)Q]8EB9S8+BF46)t) =7pf/r


fiEE65=6E55E=A_

fi
ff
fi$5,p {6O{fiOD=pE


!"#%$'&)(+*-,/.10325476+498;:5< =;>=?@#7< =A7"B CEDGFIH9JLKNMffO$5P7* < =QRA7BS=?@#9TVUA7#W#VX">=?@# <Y=A7"Z,\[ff.
0325476498 [ :]B C^DF3HVJLK_M5O$`P-acb?@"#9#d>e=f
8 [ .g8ihjlkmon3pqsrutvOswxPsyzm|{0Ik4 w 47y:}~6c
5X"=, [ >??9<l>Q|#9B;a"Bxa# <u>="QRCT9BS,/acb_ nSq7vcpLSvq@rtSvSnrVptu;"
Q"=BS#9"%#VX>?, [ abr9pt Os,_P7
b"#VT@>A<uebS*U?I>=f~rdpq@rt <Y=Q"=Qx>=fB >=c#7?]>=?@#9"<SQB C-nIpq@rt <Y=Q?@# < T9#d>e=f_B >=c# ?*, [ >?
?9<u>Q#9B_a"Bxa# <u>="Q+CT9BS,acb_ lvc+ruSvcpLSvvnr9ptvv*LQ"=Bx#9"Q;r9ptv]Os,_P
3#`>?"<S?@b+#9B?d""%#9X< #5BS=bB >=#<lefx"aT <CBST9_U< "< T9"<SQQ"Q#9B8R
< =?sC"T9Td>e=fN>e=CBST9+< #@>BS=CT9BS>=#9"T9l<lT9"7< #d>eBx=?ff#9B_B >=c#T9"7< #@>BS=?QBc"?=BS#EAVX< =fS"_?9< #9
>?I< a>>#sbS*<x?5"7L"A7#9"Q
p Ofi
g!"#E$&(< =Q,< =>e=?d# < =A7"B CffDGFIH9JLKNM5O$5P _5X"=,>??9< #@>?I< a"_>
rVpt O@,_P>?E?9<Y#@>?I< a"%>gr9ptv]Os,_P>?E?V< #@>?I< a"S
p *7]b+#9X"C3<SA7#5#9X< #5#9X"<SQQ"Q?@#7< T9#@>=f< =Q+"=Qx>=fB >=c#T9"7< #@>BS=?ff< TV"<uT9"<xQbfSU<YT < =
#9""Q+#9BXB Q+>=< =b+BLQ"7B C^,ff
;"o@U<YX"<SQab_T9"?@"=#@>=fW<?9< #@>?I< a>>#@bZ<ufSBxT@>#9XO3fSBST@>#9X'LP< =QaT@>"7bQx>?9A7U?9?
#9X">=c#9U>#@>BS=a"X>=Q>e#>=RBST Q"T_#9B+>=Qx>A< #9"ffX< #S>=QRB CE<ufS"aT7<S?\>e#5BST9?CBST5X>?5>
XBS"7CUb~<YS">#ff"<S?I>"T#9B< T9"AV>< #V""7=>e#d>eBx=z
>T ?d#<S?9?@U"#9X< #8BS=bgA7Bx=c# <l>e=?ffBSTV=g%!ff?*5ffX>A9XBS=bT9"7< #9"?d# < T9#@>=f;B >=c#7?B C
>=c#V"T9l<u?!>="<YS"?5#9X"\>e=#9"T9 <uoT9"7< #@>BS=?"7L>AV>#W<S??@# < TV#@>=fB >=#ETV"7<Y#@>BS=?%< =Q+>="
AVX"A9?%?9< #@>?I<Ya>>#@b~B C-#VX"WTV"?@U#@>=f~?@"#EBYC?@# < T9#d>e=f+BY>e=#%T9"7< #@>BS=?!>e="?\#VBS_A7B "A7#>=
#VX"ET9"7< #d>eBx=?ffk .gy *?@UAVX+#9X< #]>=~< =cbBLQ"7#9X"?d"?@#7< T9#@>=f_B >=# ?]X<uS"E#VBa"%"xU<u3oI=
<SQQx>#@>BS=*CBST A7"?%<u-?@# < TV#@>=fB >=# ?#9B+a"Qx>?@#@>=A7#*#9X< #%< T9"_=BS#CBST A7"Q#9B+a""xU<u3%I#>?
AV"< To#9X< ##9X"5"xU<u>e#@b\CBSTVWU< "]>=QB%=BS#o<u"A7#?V< #@>?I< a>>#sbS]ffB 5"S"T*>#>?"?9?]AV"< To#9X< #
#9X"Qx>?@"xU<u>#sb+CBST9_U< ">=~A< ==BS#5< x"%#9X"ff>=?@#7< =A7"W, [[ .0I254 6+498 [ hZ:oU=?9< #@>?I<Yae"S
5X>?C3<SA7#>=Q""QCB B E?CT9BS<+T9BS"T9#@b~B CffffBxT9=;%!ff?*ffX>AVX>?%T9B S"Q>=5X"BSTV"
ff#^>="z* "c=B #VX< #-#9X"TV"E< T9"ff=B#@B%BLQ"7?^CBxT, [[ *SffX"TV"ffCBST-?@BS"Ek47y}~2*Lk .gy
>=Bx="ffBQ"7*< =Q+k m.g >=#9X"BS#9X"ToBLQ"7355X>?>?]#9X"5>=c#VU>e#d>eBx=a"X>=Q"7=>#@>BS=~Sx
Bl*>="~+A9X"AV?5CBST%?9< #@>?I< a>>#@bBYC-#9X""=Qx>=f~B >=c#7?B C-#9XBc?@"\>=c#9"TVl<u?ffXBc?d"N?d# < T9#@>=f
BY>e=# ?5X<uS"%#VBWa""xU<u>=<Y=cbBLQ"73]Co#9X"W<ufSBxT@>#9XT9"@@"A7# ?5< #5>="*#9X"=#9X">=?@# <Y=A7"
>?5BSaS>BSU?seb=BS#ff?9< #@>?I< a"S5ff#VX"T95>?@"%5"E=""Q<_A7BS=Qx>#@>BS=Bx=#9X"%<ufS"aT <$ff*A7BSTVT9"?@Bx=Qx>e=f
#9B"7=>#@>BS=z*S>=BST Q"Tff#9B_fSU<YT < =#9""?9< #@>?I<Ya>>#@bS
`X"CBSTV<u<SAVX>="T9b+CBYB E?

fi
* =o Ofi D=V 5&,
!"#$&(* < =Q%,.0325476498:c< =>=?@#7< =A7"-B CDGFIH9JLKNMffO$5P `X"o>=?@# < =A7"5, [ .0325476498h8 [ :
B C DF3H9JK_M5O$5P>?5?9<l>Q#9Ba"_nSq vcpSvSr5vr%oq 3,>#9X"T9""7c>?@# ?5<CU=A7#@>BS=~c6
jS.4 .% \?dUA9X+#9X< #ff8 [ .jlk Os Psy {03k4 w 4 yz:}~6c;"%Q"=BS#9"%#9X>?5T9"7< #d>eBx=acb~xr Os,4 , [ P
5X>?"< =?#9X< #`CBST"<SA9XT9"7< #d>eBx=*"7>#9X"T%#9X"_?@# < TV#@>=fB >=# ?B C-T9"7< #V"Q+>=c#V"T9l<u?%< TV"%CBST A7"Q
#9Ba""xU<u>e=<uBLQ"7?*BST#9X"bZ<YT9"%CBST A7"Q+#9B+a"_Qx>?@#@>=A7#>=<uoBLQ"7?5CoCBxTE?@BS"_,G5"
X<uS"Sr Os,47,%[P *z#9X"=~,%[>?E?V<u>Q#9B_a"nxq vc\pLx-Srvr
>_>< T@bS*ab"7zAVX< =f >=f?@# <YT9#@>=f<Y=Q"=Qx>=fB >=c# ?*ff5"~fS"##9X< #, [ >?rxpSv
Srvroq73,*Q"=BS#9"QSr Os,47, [ P


fi v+--L LuV ff
ufi
lS%S]-
!#"%$&(')+*-,/.10325476987:1;
=<?>A@CBEDFHGIDJLKMONQPER7STCS1UWV
X

~








X
X X
Xi
X~
X-
X

MZY[NQPER7SLTCSUY\V^]`_ba1cd/ef6gMh:
jkD lGnmoqpsrutwv^xzyb{ |f6gU :^}[<
}--}
]
jEsKIJ1+PEuSLSV?T
jD lGZmoApsrutvxzy-{ |f6gU eN
: }[<
e ^



e N e
]
}3-}
] e N
e
}<uj
}[<?#jEs
N e U
] 7_csg_d e 6g:gsP/uSSL VuT e
jkD lGnqnyb{ |f6 :q}[<
}--}
} >#



[D K X~ lqlHG

~ X J1 KJ3FG1 Kll7D sIF77KZFIAFHK-K

C}<uu<u"%$ ('qu Q L }j/C- %<s'1}<u=<su;>f=<;
sK-GM(NQP/R7STCSUV[KzIFGI1GHD lDGkKLDG1KDFGIDJLKl)O,E.10 2h4698:u%lFlK^8ff ID
JLlDFG1JLGMZYsNQPER7SLTYSUWVFHJ1G1IGTY[N PE#SSLVT e N e U K ffJLlDF/9K-D
lD1KL9IGlDFCJlJLKG1 KFHGI1GD +lDGFwG1lKKI lM9FF1I9G1lKdLdd
% -d_- %%c3 FwF1IG9F/IK l KLkF1IG9F/%D 9FFI9+G1ldLdd
% -M %%zc3
h9IfKLJ1ID FGIGD IDK-DD [lDGFbM9FFI9G1lKdd9d % bd_
_[c 9[ 9FZF1IG9F/IKfIDIl KLF1IGHFgD 9FZF1I9G1ldLd9d % hMO
_[c
KZD lQKLD KG1 KIK- LIlJlG1

~ X FHlKFF1IGHFgIG

}<uu<u"%$O'-s =<s'1}<u=<su;>f=< } ;
C
QF IK- IZ8(FF1I9CG1lhKI %%zc3qd _bg%lIDhDFGIDJLKMONQPER7SLTCS1UV
l)O,E.032h47698:G1 K%ll7D l9 F-f%lIDNQP/R7STCS1U V^FJ1GIGk_= e 6L_-a1csd e 6gMh:SZ:
9Fl J-IF1IG9F/IKZ%lFGIGD lDGF- G K-D9FF1IG9F/IK
K-G9J-IKLJ1ID K-DD [lDGLF^IDFHGI1GD lDGF-7Kl GIDID_[97c
d_-
7 KF1IG9F/IG 1lK-ffFl7G1 KFHKIK- IFI1KKLD KIF%llkF


fi
ff fi
ffff ff

!#"%$&(')+*,-/.103254768:9<;=>,?@.A0324B6<8C9<;3D
EGF/HI9J FLKBMNHKPO3HNQ RSLT
UVQ RWHXKZY SF/JOK[]\<^F`_bac(d#_:eaWf@dCghd:c(i<jlkNmWf@gonZprqbmks_/c(akc(dCtvuwj5md:t cIag unxf@kyaP_{zId:c:|
pBn!c(kdC}d:t/q/mkpBac(d:mt~QCMsH3^FMNF/HUV]Q R MNHKVR F!MA<3IUVX,.10325476<8C9<;<X^F/O3FH3^FEwMUVX
KVO3F`O3F!MNH3OQ#HF!Q RHN<UXK!M/ OMNH!GKZURvY URvHKZQ RwUO3REXMKVR MF!UR GKZRUH
URvHKZQ RKVRvVKVONQCKVJvY F!MsWvX^F/O3F5Q[F[ QHsKZURvY O3FYCKVH3FLMNHKVO3HNQ RST
UVQ RWHMUVQ RWHF/O3xKZYCM/[
vF/HONQC/KZYhY
JvF^ KVRSVQ RSMNHKVOHNQ RS7KPR F/R QRST UPQRvHM/v<FSF/H<H3^FB_/ac(d#_Ce<aWf/d:ghdCc(iwjlkNmWfb.
ghn!p%q/mk`n!t dCtvusj5mdCt
c]agunVf/kNaV_zIdCc:|pBnZc(kd:}d:t/q/mkpBac(d:mt
[
IsGvlAA
]G
FRUVTO3F!MF/RWHXH^FLKZY SF/JOKMwX^vQC3^KVO3FLMNHKVO3HNQ RS8AF/R Q RS;<T UVQ RvH{KZY SF/JOKM/[
!#"r)>&('*BGPI Z/]8yZ;<G8yZ;D
F/H - 8v%/;KVR ?< 8B;[]XUH3FH^ KVHX - URvHKZQ R M<KZYhY>J KMyQ#sOFY#KPHNQ UR MX
MN ^H3^ KPHXX^F/RF/F/Os5Z(UO<Q RWHF/O3xKZYIxKPONQCKVJvY F!Msl

%^ KMH3U^UVYC~Q RKVRvU5vFY]KVR
MNvF/H3OQ#/KxYoY G ? QCMwF!vQ VKZY F/RWHH3UB%^UPY#Q RSQ RKPRWUvFY[
Q OMH!UOsW B 5vF RF]8yZ;IH3UBJ
FLH3^FLMNF/HwUVOFY#KPHNQ UR MvMN ^H3^ KPHFQ H3^F/OsUVIH3^F
(UVYhYUV<Q RS^UVYCM/
8N
;
8yZ;
8N ;







- 8< ;
-3 83X ;
8X3;






\<^F/RvJvMN<Q H^vQ RSMNHKVOHNQ RSKVR F/R Q RST UVQ RvHM<UVGQ RvH3F/O3xKxY#M@vUOsW3 8NZ;GQ#MwvF RF!
H3UJ
FH3^FMF/HXUV>O3FYCKVHQUR Mv MN ^H3^ KVHwFQH^F/OUVH3^F(UVYhY UxQRS^UVYCM/
8N
;
8yZ;
8N ;











? 8< ;
?3 83X ;
83< ;



!#"r)>&:*BGPI Z/`GB@D
EGF/HL - KVR ? J FKMwQ RsF RvQHQUR [ GKVR vF RF H3UJ
FH3^FBMNF/HUV]O3FYCKVHNQ UR MvMN ^H3^ KVH
FQ H3^F/OsUVH^FsUVYhY UV<Q RS^UPY#M@
83< ;
8(< ;
8/;
83;
8(/;
8( ;
8;

























!

- -
- 83< ;
- 83X3;
! -
83w ;


fi>:
fiff

!#"$

%'&()"$
x* ,+-# .ff

/012123547698.:5;<=<0>?635@<-;A:8CBDEGF0IH JK;BLfi47M3N86O8BP356Q93QNRN>?J7S
\ 3]D354O47M3)Q_^F`:<.;Q7QGacbdfe

HOH7TRUF0J7SVE$ETWR>X;BLYZ$F0,Y[5>

g 8=<3Qh:NiB4;8B8BD47M3);<D35F6;QG;673]Q9^@@<=83Lj;QO;kBIiBlm<=8CB32;@@*35BLA8=no47ic47M8.QG;67498.:<3d
p 4c8.Q23;AQ90q4iqQ9353I47M;4W47M3,;<D35F6;Q;673,;r<s<]:NiBQt8.L356;F<0u<.;6D356247M;B?>wvxi623Nn;12@<3>U47M3
yhzO{Gl}|$i67B;<D35F6;> \ M8-:Mo:NiAB4;r8CBQ$~~ 3N<351235B4NQ5d
)X`--? M3QK8snj;<D35F6;Q J9R;BL,aWJKR :NiB4;8Bc3N<351235B4QG3;:Mo;kBL b ;BL
b :NiAB4;r8CBj 3N<351235B4NQO3;:M?d
)XNU Q_476;8DM49vxi6 \ ;6L2:NiA1F8B;4i698.;<'3Nn356:8.Q93;A:5:Ni6LA8BD#4i4M3L3NB8498iBQ5dGe
3 ;<.Q9iQ_353)47M;4G47M3W JKR ;BLaWJKR ;<D35F6;Q$3;:Mo:NiB4;8BfiP3)F;QK8-: 673N<.;4_8CiABQ5>`;kBLI47M;4 b
c
;BLacb:NiAB4;r8CB47M67353F;Qt8.:W673N<.;498iBQc3;A:7M?d Q9^FQ9^12@498iB673Q9^<4#;kBLj;BiBQ9^FQ9^12@4_8CiAB
673Q9^<4$vik<s<i \
)X`--?= M3O4 \ 3N<P3h;<D35F6;AQ@673Q935B473LcF02{G6;35BDA6735B2;BL2iBQQ9iBIJR> \ M8.:M
\ 35673]Bi4h:<.;QQt8=3Lo;AQU1#;n81#;<?476;:N4N;F<3>;673]3;:M8B:<^L3L8B,iB3 iv4M3);<D35F6;QGJKR ;BL
aWJKRd
)XNO 0Qt812@<0,:M3:7A8BD8B:<C^QK8CiAB,vx67i147M3)L3NB8498iBQ5d]e
)X`--?mp Bu;<=<ivU47M3I;<D35F6;Q JKR>XaWJKR> b ;kBLja b >47M35673;6732673N<.;4_8CiABQ \ M8.:M
;673]BiA4O3Nn@63Q7Qt8F<3F0I|Oi6B,{]?zOQG;<iB3d
GR>
)XN]p 4G8.Q3;Qt8=<0oPA35698=3L47M;4]47M3c@*i8B4]673N<.;4_8CiABQG8BL^:N3LjF0,4M3 <=<35Bq673N<.;4_8CiABQ J
JK2 R>XJ}c R>JE R;BLJHNR;k673]Bi4h|$i67B,{]?z$Q5dOe
p 4 \ ;Q iFQ93567PA3LuF0{G6;35BD635B;BLuiBQ7Q_iBJR]47M;4W47M3yhzO{Gl}|$i67B;<D35F6;j:5;kBBi4
3Nn@673Q7Q47M3UBi498iBciv?5Nxm=mxr>;BL 47M^QQt8B:N3U848.Q1#;n8C1;<46;:N4;F<3> \ 3:5;kBBi4 ;LL 47M3
673N<.;498iBJfGR47i]84 \ 847Mi^4<iQt8BDc476;:N4N;F8=<s8490d |$i \ 35PA356> \ 3h:5;BiF4;r8CBI; \ 3;356 0A354 ^Q93Nvx^<
673Q9^<4 F047M3cvxi<=<Ci \ 8BDiFQ93567P;498iB? 3cBi \ v67iA147M3c673Q9^<4Q]ikviBQQ9iBq;BL G; :Q_476 1
JARO47M;4c47M33Nn@673Q7Qt8PA8C490iv|$i67Bu{]?zOQcQ9^FQ9^1W3Qc47M;4civO47M3yhzO{Gl}|$i67Bu;<D35F6;>F0
3Nn@673Q7Qt8BDj47M3yhzO{Gl}|$i67Bu673N<.;4_8CiABQ2;Q)LA8.Qm9^B:N498iBQWivh@*i8B4c673N<.;498iBQ8CBu4M3Q94N;67498BDj;BL
35BLA8BD@*i8B4Qikv47M38B43567Pr;<.Q5d M^Q>hQt8B:N3j47M3jQ7;k498.Qt`;F8=<=8C490@6iF<351vi6IQ94;k67498BDq@*i8B4
;<D35F6;AQJK;BL35BLA8BD@*i8B4,;r<CDA35F6;Q5> \ M8.:Mvik<s<i \ QF0Q901212354670R2;<=<i \ ;67F8476N;670|$i67B
{]?zOQW673N<.;498BDqQ_4;67498BDj@*i8B4NQ5> \ 3:5;B:NiBP356742;B0qB354 \ i67j3Nn@673Q7Q_3L8B47M3yhz${Gl}|Oi6B
;<D35F6;8B4iq;B3A^8Pr;<35B4I8BQ94;kB:N3,iv ZN}c J.R]viA6Q9iA123Iiv]47M3,476N;:N4;F<3oQ_^F`:<.;Q7Q93Q
;F*irPA3> \ M35673#iAB<C0Q94;674_8CBD@i8B4Q ivU8B47356Pr;<.Q2;632673N<.;473LXd M3I;LLA8498iB;<O3Nn@63Q7Qt8P8490jiv
47M3cQ94;674_8CBDW@i8B4;<D35F6N;QO:5;B47M35B,F*3)^Q93L47ic3Nn@673Q7Q$3d(DdQ93A^35B498.;<=8C490J}^Qt8BD#iAB3)iv47M3
;<D35F6;AQG JGRi6Ga2JNGR7Ri6Oi47M356U673N<.;4_8CiABQOF*354 \ 3535Bfi8CB473567P;<.Q5d
\ 848.Q498123$47i]P35698=vx04M;447M3O@673Q_35B473L;<D35F6;AQ;673U8BL353LQ94;674_8CBD);kBLc35BLA8BD@*i8B4
;<D35F6;AQ5>673Q9@*3:N498P3N<0d vx3 \ ;^n8=<=8-;k670,L3NB8498iBQ];BLI63Q9^<4QO;673]B353L3LXd
A?-?'5-?u7?'
g iA6jU>*<C354c7JKR]]F3c47M35sA#ikv?>*47M;4$8-Q>*8svOjf>4M35Bq7JKXRO]A>8=v
fi 47M35Bj7JKXR>*;BLW8=v,>4M35Bj7XJKRdfe
*o'm X354Uf}UNa#NF3G;)Q94;k67498BD]@i8B4L3NB8473$8BQ94;B:N3Oikv Z5t7 JmUR> \ M8.:M
8.QU<i:5;<=<0oQ7;4_8-QK`;F<3)vxi6hQ_4;67498BD2@*i8B4NQOF0,Q9i123]1WiL3N<>X;BL<354]XF3c;BI8B473567@67354N;498iB
vxi6hQ_^:7MI47M;k4


fi**


ff fi !#"$%&
ff fi'(
)*+,' -!+, .
/10324'56879:5 ; #/1032 " ,'5687< " :56;
=
>@?:ACBD?9EFHGJIKML;?GJLN " EOGQPRI%SLNT3AVUWFYX[Z\X;SE] A^I_L;?%F`A^IaLDFYX;b%X;FYL
GJL1AcS3IdSeZfK,L
GJX;L1AcI%gRbhSJA^IaL KY=GJIT
Z\SX@FYIT3A^I%gRbSJA^I:L
KY=4GJI:PB;?GJI%g3FNACKiGkjlj^SJ>FHT4=G3Kj^SI%gRGKL;?%F A^XNX;F jCGJL1Acm3FnSX
T:FYXMZ\SX@X;F jCGJL,A^SIKM>@?:ACBD?
?GQmFNL;?%FnK;GeEF[A^IaL;FYXDb%X;FYL
GJL,A^SIKoSJZ6K1L
GJX;L,A^I%gbhSJA^IaL K-ACK@L;?%FnKDGJEFprq?%FYI_ " GQjCK,SsjcS%BYGQjVj^PdK;GeL,ACKutFHK
v Z\SXiK1L
GJX;L,A^I%g)bSeAcI:L
KYp
wnxQy4yz {N| bGJX;LMZ}X;S3E~BD?%FHB;3A^I%gRL;?%FN@KMA^I<=jcS%BYGQjfK;GeL,ACKutGJ:AVjVAcL,P*Z\SXK1L
GJX;L,A^I%gbSJA^I:L
KNBD?%FHB;%K
SI:j^P9X;F jCGJL1AcS3IKn>M?%FYX;FOLD?%F)A^IaL;FYXDmkGQjCK)L;?%FYP_X;F jCGJLDFGJXDF)Z}S3X
B FHT_L;S*?GHm3FL;?%FRK;GJEFOK1L
GJX;L,A^I%g*bSJA^I:LHp
A^IB FT:SaFHKMI%SL@XDF jGeL;FnFYIT3A^I%gRbSeAcI:L
K[SJZ&A^IaLDFYX;mkGQjCKY=4LD?%FnSI:j^PRL;?:A^I%gL;?GJLNGQUFHB L
K@K;GJL1AKtGJ:AVjlA^L,P
SJZrL;?%FHK1FnX;F jCGJL,A^SIKMACK[L;?%F`X;F jCGJL,A^mF)SX
T:FYX[SJZrFYIT3A^I%gbhSJA^IaL KY=geAcm3FYIGst%%FHTdK1L
GJX;L,A^I%gbSJA^I:LHp A^IB F
L;?:ACKMSX
T:FYXACKL;?%F)K;GJEF=%GJITR GeITR " B SJA^IBDACT:F)SIK,L
GJXDL,A^I%gbSJA^I:L
KY=%LD?%FNX;FHK,:j^L@Z\SJjVj^SJ>iKYp@
hd_8^ 4FYL v ( O(; %F[GNK,L
GJX;L1AcI%gNbhSJA^IaLT:F tI:A^L;F@A^IK,L GJIB F@SJZ< u;s@C =J>@?%FYX;F
Z\SXOI%Su'(
J( %=@)D
O;
GJIT7;
;<
%p+q?%FYI v ACKRK;GJL1AKtFHT
v
:P9L;?%FRES%T:F ji AVU# jcS%BYGQjVj^PK;GJL,ACKutFHK
Z}SXK,L GJX;L,A^I%g_bSJA^I:L
KGJIT K;GJL,ACKutFHK( "
=&Z\SX
`"%au'(
J( %]:M;f; :ap
wnxQy4yz {
| K;K,%E)A^I%gLD?GJLi K;GeL,ACKutFHK v =L;?%F[jCGJL;L;FYX@B SIT3A^L,A^SIAK[G)T3A^X;FHB LB S3IK,FH%FYIB F`SJZ8L;?%FnT:F tI:A^
L,A^SIKYp
8-P)L;?%FX;FHK,L;X,ACB L,A^SISI v =aKDGJL,ACKutGJ:AVjVA^LP)SJZ4FYmFYX;P)X;F jCGJL,A^SIoACKrBD?%FHB;FHTsaP`L;?%F@L,>SB SIT3A^L,A^SIK
L;Sg3FYL;?%FYXH=aGeITL;?%FKDGJL,ACKutGJ:AVjVA^LPRSeZ~ACK-A^IBDjcT:FHTA^IRL;?%FMj^SBYGQj8K;GeL,ACKutGJ:AVjVAcL,PB SIT3A^L,A^SIpq?:K v
ACKiKDGJL,ACKutGJ:j^Fp@
hd_8^ 4FYL v (
(; 8hFsGeIA^IK,L GJIB F)SJZf+u;s@C =GJITj^FYLN+( (; " fhF
K,BD?L;?GeL3\ v (;N p rSIK1L;X;B L@@"h( `"l( "V-aPRK,FYL;L,A^I%g

!
!

Sk> " ACK@K;GJL,ACKutGe:jcF[AVU_ACKYprq?%FNGJIGQj^SgS3KrXDFHK,:j^L@?%SJjCT%K-Z\SXFYIT3AcI%gbSeAcI:L
KY=:>@?%FYIRXDF Z}FYX;FYIB FHK
L;SOK1L
GJX;L,A^I%g)bSeAcI:L
K[GJX;FnBD?GJI%gFHTL;SFYIT3AcI%gbSeAcI:L
KY=hGJIT_;f 6AKMB;?GJI%g3FHTRL;SRDM
p
wnxQy4yz { MA^X;FHB L1jcPZ\X;SEL;?%FnT:F tI:A^L,A^SIKpfq?%FNXDFHK,L;X,ACB L,A^SIK-A^EbhSaK,FHTSIRL;?%Fn3GQjVAcL GJL,A^mFNX;F jCGJL,A^SIK
GJX;FGQj^X;FHGT:P9gGeX
GJI:L;FYFHT_L;S*?%SJjCT_A^IGJIaP_ES%T:F j= :PdLD?%FOX;FHK1L;X,ACB L,A^SIK`SI< " p SL;FL;?GJLn " AK
>F jVjcT:F tI%FHT*KuA^IB F3\G3T%T%KrLDSnF A^L;?%FYXFH3GQjVAcL,PS3X&AcI%FH3GQjVA^L,PZ\SXrGQjVjA^I:L;FYX;mJGQj8K,L
GJX;L1AcI%gNbhSJA^IaL KYp
qo?%FNb%X;SbFYXDLPSJZ FYIT3A^I%gObhSJA^IaL
KoZ\SJjVjcSJ>iKoaPRK,P:EEFYL;X;Pp
3f^Hy8\a
R&Yy4Yd%4
S3XiR=T:FYI%S3L;Fn:Pd: /J4-L;?%FnGJK,SJj^%L;F`mkGQj^%F`SJZ6=3ApFpJ/10324W
p
n"

a'(
-*;;
(

a'(
7;
(


q?%FNEOGkAcI*X;FHK,:j^L
KoZ}Sejlj^SJ>np
) :yxQ8\h q?%FGQj^gFY%X GK)-QoGeX;FK,L
GJX;L1AcI%gRbhSJA^IaL)GQj^gFY%X
GK=8GJIT_LD?%FsGkjcg3FY%X
GKnQGJX;F
FYIT3A^I%gObhSJA^IaLNGQj^gFY%X
G3KYp
wnxQy4yz { 4FYL v ( (;9&FGJIAcIK1L
GJIB FSJZf u;sfDrQ; =GJITj^FYLN+u(
(;*"@>A^L;?

YD v
(DN
p-P4FYEEOGhp%=>FdBYGJIGKDK,%EFLD?GJLZ\SXFYmFYX;P'(
J( %OO=F A^L;?%FYX
; );NSX`9; );%=rKAcIB F*AKK,L
GeX;L,A^I%g_bSJA^I:LOT:F tI:A^L;Fpq?aK=rL;?%FSI:j^P
X;F jCGJL,A^SIK[`>@?:ACB;?_GJX;F[j^F Z\LiGJX;FNL;?%S:K,FnK;GJL,ACKuZ\P3AcI%g


fi8$%_%%r% :J
ff fi
ffQfi fi

k

% N%_fi%&-fi

!" #fi
ff %$

')(*(,+.-0/

1

/

12435126+

')(-7/

1

/

12

')(,+8-0/

1

/

126+

1

/

'69;:<: +

-=

>?@ffACBDD?AFE<G6HIJGLKNM&A4O?P,IOQORA6IJGCM&ATSE UWVX?YAFGIJY6GCMZ[\D#?JMZGA4]ffR^I*_^?UffE`Obadce>JMZP`EfKgHIhALE`iDffOjM&PMG
ACGIkY6GCMZ["D#?JMZGAl@ ImOjOnY6E`O&IJGFMo?hZAeVXY?_pOQMZE\q^IJY6E\A6IJGCM&ATSE U8MZ%adc4rOsAF?@ATMZP`E"a;M_^D?AFE A<ItP`E,Y6GIMZ
?YUffE,Y?ZgACGIJY6GFMoZ[D?JMZffGA?JVuMZG6E,YvmIO&A,@LwuE^xffZ?JwdG6HIkG"wuMG6H?BGO?A6Ay?JV<[E,ZE,YIOQMGCR@LY6E`O&IJGCM?ZA
1{|1 2

?ZNOQMZEgz%P,IJZg]EY6E,DffO&IP`E Ug]ffRNE`MoGHE,Y

18{}1 2+

?hY

1 2

@uATMZP`E

IkZU

1 26+

1

M_^D?ffACE}UhM&A~C?JMZG

?YUffE,YFMoZ[ffA\?ZAFGIJY6GCMZ[D?JMZffGA,cuHffBA,@nwuMG6H?hBG\O?A6A?JVu[E,ZE,YIOQMGCR@LwuEWG`IJxE^K?ZffOR}G?}P`?ZffGIMZ
Y6E`O&IJGCM?ZAVXY?_OQMZE AtIJZUq@#MZffvE,Y6GCMZ[Y6E`O&IJGCM?ZA"P`?hZGImMoZffMZ[OjMZEY6E`O&IJGCM?ZAyw<HffMQOoEP6HIJZ[kMoZ[
G6HE`MY<UhMY6E P`GCM?ZnceV

wuE\P`?BffO&U^_^?UhMQVXRaMZG6?^IJZ.MZGE,Y6DY6E,GIJGFMo?hZ5aACBPHG6HIkGGHEfP`?ZUhMGCM?ZAu?JV



E,_^_ItqcQ"IJY6E\A6IJGFMsA)SE U@IJZUG6HE\Y6E`O&IJGFMo?hZAu?JV4OjMZEt^IJZUG6HE`MYuMZffvE,YACE A<IkY6E"A6IJGCM&ATSE U@G6HE,Z]R


E,_^_I"q#c@A)MoZP`E\GHE ACE\Y6E`O&IJGCM?ZAuUff?tZ?Gu?JvE,YCO&IJDwuMG6H

'90:e: +

- @awu?BffO&U.]E"I_^?UffE`On?JVnK"@

IJZUG6HE\YE ACBffOG<wu?BffO&U.VX?JOQO?Jw"cLTZUffE,E U@wuE\ACHIOQOA6IJGFMsA)VXR.OQMoZEttY6E`O&IJGCM?ZAwuMG6HG6HE\]IATM&P*Y6E`O&IJGFMo?hZ
(

?ZE,vE,YR5IJY`PJc
'

rVXE,wIJBffiffMjOQM&IJY6R|UffE`SZffMGCM?ZA^IkY6EtZE,E UffE UV?Y\G6HE^P`?ZACGY6BP`GCM?Znc^*E`SZE%
OE IACG*Z?Z,E,Y6?_^E,_t]E,Y*?JVLG6HEWACE,G '

'C4-




')

UhM&ACGIJZP`E]E,GCwuE,E,Z}ACG`IJY6GCMZ[tD?JMZffGAMoZadc<MvE,Z%I^



')

^%

-L

'

@ffOE,Gt


'


-

G6?]#E^G6HE

-6-\^. @ffMc!Ec@#G6HEyOoE IhACGfZ?hZ,E,Y6?
-

]#E"G6HEtACE,G

-6ff

Mc!Ec@eG6HE}AFE,G^?JV<MZffG6E,Y6vmImOsAwH?ACE?YUffE,Y.?JVE,ZUhMZ[ND?JMZffGA.HIAtG6?|]#ESiE U@G?|_IMZffGIMZgO?P,IO
A6IJGFMsA)SbIJ]ffMQOjMGCR@L]ffR


Ja

V?YI[JMvE,Z"@hOE,G<#

')ff-ff^

wuMG6HffMZA`[hY6?BD - @JIJZU gt

'

Fh


?G6E\G6HIJGeV?Y<E,vE,YR
E,GW



')

')





'

-



'

- @

t%

ACBPH%G6HIkGV?Y<E,vhE,Y6R

Fh



(

>BDD?ACEG6HIJG

'

')




-

UhM&ACGCMZP`G*E,ZUhMoZ[.D?JMZffGAMoZ%a

G6HELVBZP`GCM?ZtBZffM&BE`ORUffE,G6E,Y_tMZE U

MZ}a@ACBPHG6HIJGuV?YuE,vE,Y6R
--L

Fh

'

- c^rOsAF?@

')-n

n`^



'

- @

'C-6-`=



c




%

M&A"\ce?Y<E,vhE,Y6R



>BDD?ACEG6HIJG







(

'C

M&Afc?YE,vE,Y6R



'C

Nd

G6?]E^G6HEBZffM&BE`ORgUffE,G6E,Y6_tMZE UVXBZP`GFMo?hZ

@

MGuM&AfI8_^? UffE`O4?JVKcMYACG @ACE,Gf



')



J

EtP`?ZACG6Y6BP`G*G6HEMZGE,Y6DY6E,GIJGFMo?hZ}a



-

'

M&A\BZffM&hBE`OoRgUffE,G6E,Y6_8MoZE UN]ffR}a

%





-

-6 h' G6HEfZffB_t]E,Yu?JV

-8g^ @#Mc!Ec@nGHE^ZB_t]#E,Y"?JVfUhM&ACGCMZP`G^ACGIJYGCMZ[D?JMZffGA*MZgadc?hY6Y6E,

ACD#?ZUhMZ[}G?}@LUffE`SZE5y





'

'



-

]ffRG6HE\?hYUffE,YCMZ[?hZE,ZUhMoZ[D#?JMZG`Au?JVW



'

E,_^_IqcQc^?G6EtG6HIJG"t

-e


')

')


--L

' ')-n

Fh

'

IAVX?JOQO?JwfA,@UffE,DE,ZUhMZ[?Z
'

- @IJZU.V?YfIOQO

.%

-L

')


z

( @IJZUIVXGE,Y6w<IJYUAuDY6?JvEG6HIJG

@ AFE,Gfa ')

-L


@#ACE,G

^%

-

.%

-6-=

-n


q

' z



')-

-=





@ACE,G

h '





')-n

z -n



'

'C#



z -=

'C

- c

fi##Nd`

`

`

`m

`J



C6`C",C,y N6^6ffJuJff
u,fi

6^f`J.ffoJu6`



6,








oC\, C6gJ "!#%$%&(')* *L,+6
.hJff-*C,0/213!#045$5&/6!#879$;: <<+,>=?@*C,

C6J

-

sk6 Cu,

A!#?F$E:
'

/ 1 !A? 4 $B&C/D!# 7 $E:



:



!HG,I

'

!#?F$
J

)




$LK

NO*5P= `C6`C;*%^Q.ff`R6kCTS=Tg<+,U= J 66,6^h6*L.ff,^J

.h JffLu6ff WVYX!#?F$t6,`-.E*k. 6|.ff,C2C`J6CgkoffLJ6
.ff,Fs,m Z/
k.[/\1 u

ffff/\#
1 ,Q]=^JC`_-ba XhffCJC^JffLb=[c,. ed *J.
P=f
c ,. hg *i/ 1 ft.iff. ` kja

\6k kVl!#,4

$ bA=.^,6C&, 0m
,

]=*\` <J4<t^6"`h+,ff,ff

h66J6`


< |5}.~Ck6C#J%moh<Q*fk.VY}J ,.hog#J
nYoEpPqsr,ptvuxwzyF{ u
<

r,qEq \6N+\ff]=6| } ,C*T`"OV } ,CykA=ff^^,6C&,
6 C`]= yg66ffJfJ
,6, *9u` JNCJ`a&N#`Qo-.ff]=~=

6`&JC0Y6JCTzh
=
!z
$
!$
!zL$
!>%$
L














&



-9-

->
!>k $
%K

>C^6k 8 ,mj]=6JC`_-.RC`J6CJffLl=TC^.i.ff`/ `/
PL.
FJ6CJffL*Jeoff6,>+J<*;uNp6J*6`&JC%.Q%

C

^ C "`,6|h ff,fh

-

fix3Q QQ]BQBQiPNQP-@QiP,LUQRb-,xObHPQ[%QRQQ@]B

QN<N~RUAQ->@]>Q<8[-%O%[-UR5`] >NA]T-NZ,>]"
3AN]LP<"QPBRALNUA]QOPL<Qj]R>Q0Q>PN;NxQ<><]xP<UQQP>5N
<Q<LH]AQ%LNff2ULHPUA]z>eQ-%YN P]<UA]QYeQ>NA]
kPe]O>QN]Q>Q]kU-A]>NA]z>D]QORNk<<>Y]ANffQUNA`sNP]NLZ
A,e;AQNT>N5T,]k,i5>A`sNP]kPA>>A]QY%QP\j]L"BA<\]#F9B
D# 0S <<>2<R~RH]R,ffAUT>ND# Lj]B~YUQN>-A
AL>A]QRN]8]YQ<ZA<O #k6 Cz%<<>[~ kP]#SO;L@l
kQ<Q<<k # B LUQ<fz<#8>A`-l]f jF5e]QO>NA]PPkQ<fN
]ffk> QN@>Nff # # LEN>bP[A>>"^ LEN[
ffUNA`-EBPk 0YQPxN5N UQ%>-AP]kzNe]Nff<k
><R,]>OAQNT>Nb]A]>Q
P%,]<QL<

Q]%U>-A]AN]-5>N"#sNPe]AlSB"LN>A]QON<Q

ff
fifi
"!$#
%fi&'(
) < <LHj<QLk>%Q<-P-S>QY>>-UQ->Q>PN>
* +,.- /10/32 -5476'859;:2 -<+=?>@2 ACBD/'-EF0/32 -GH:2 -<7+=I
J ]<;L
K "MDN PORQSTUWVXOLQY[Z;\]S^_'\]Q
NPY
K 0N`"MDN NjUQ%z>baNLdceafK
kQ<>hgiaj2
g
A<lk?mnM N >,l>OXOLQSTU;
2
V p^
NPRPRYPA]R]<<PL]"[
k ,]>-P
]e
k
* +,.- /10/32 -5476]qr9RstuD+Fvuw3E-7+I
yx{z}|~U|7p^S
U ]CM N ffYQFz <QAfA<0PQ-^
[M Ne AEB
zff8eQ-%N]PQY, ]^N> N N%PM

* +,.- /10/32 -547619Rw'A"27W0>@2 -<+=I
"<kimMD
N %U,[UR^YjQ;_HORQSTUWV0SNP[;LK kEN0AbP]>]RNPNB>Q
P[YPA]k@NR
K >%Q]e
k 2
l= EAuDw3+46p QYA<
k MDdc #;LK LP` RK R
Z
`

ffHlAkPb

v2uD27/30/32 -46]4 ffPlP><L"-A]N;P]>][ N ,]AkPfA<k,]AkP;
v22L <dk7N U;k7HlARA<BN]<k k7EjAk7P59NffRKkxQ<
;L[
K nk
S%<<> ggE YP0P]>]ZR@N>QPZYPA]%NkZNeK
N>0Q"k
Qk`]%k]P><LA-P]R8P]>%PQY<NjA<<P]lP]>]RNP
YP]NA]0N>%U]P-z>
k N >Q%>-"PbzNeNff k
Q zNe]HQl[<Q<L,e>NA]NE< T-@NN>AN UiAU vLP%kPU

%`]Pee-Z<L`][B>QOQ>PNBP[;>";ONLbP;ZLFS>P[>R,]PA
P[A<L<



fi.FFF FLR
C 71r;jD[e1[{LLe;;j[Rh[{;F;j'
1 FF;}F;L{Lde i}
L[L1?;}1 1 X }F[11[[ 1L
ff [
F PFj1F@3F ff
.fi
F
rpff7%F;
F;PL{LffP b
}i
dFF{
1H


F;"Fj1'p1
{ 1L1
l pir 7 dp

F 7 1}11PFF;F1H'p
W {;FF{ % !#"".
$"ff%
!"P[ F 3f 1 &("
' [
!$"
' ff)

d3lF; 1 ;
* ;}Fp1Fff+ [;{
,. -1 /"0
!1
l3}PFXLLCLj11@
2
!4
3;{;FL1F;XL{Rfi
, ;R LR5
,n1 [{ Fj1[l [
LR15
,lDF;6
!2" D11 "Fff}FL 7
(
!8
H{
, 1{};RL {
{;Fd 1@[{:
9}L ffj1R;[}F{}dFd1[h;X;R@ff ,(
d}
;[d14
;
1Ljh{.L{L }F; 1< 91L1ff1{R ,2
l3} 1
FH[;j;R {h{;Fj ~L{LL1 [H ;ff11 ;L
F=
HF1l p1
;?
>
F"ffF@[ 1 FF ;; pffA9hF$
.CB;[F; XLR1D
1"1< 91L1 { L{L Lj11} 1[L1;[;{L;FFhF; F
F
E}{f
FFG Ffi
HF [F
@

C 7IH;?J"[A97@Kd/LNMh1;
POQJSR " 2U J"A9{WV
F;d@ p 1F1d}XJYHF; POQJSR 1[{L{L
L5
Z "F[9 .Kl2LNM hL{Le;5[bP{;F W
H



OQJSR [ \ [ ]
P
1
1
BX
% !8" P
OQJSRR ' % !8"[h}F;;;L{LCLX1 C@:
"0
!hH1 P
OAJRF
LLP [[7
!2"^
' [Of0
L1F;12
[ F+ RRF;2
!0" 4
_ [4
`;5
,
Fp1FX+ [;{d. -11
!P
HF{;}3@FX4
_L1F;LR1?
, 1;RLL?
, 1
[{lFj1d;FFL{L1
,d1L
!0"e
' _ba }{ _ ;R LR7
,el[{F
@@ F};ff11 ff1{R , h;X;R 4
_~@ {H}[;j;R HP
OQJSRRY
>
C 7dcr; X[@A971X;l:Kl/LffMd;h1;
PO2R $" U ;;8J" @A9&eV
F;d@ p 1F1d} P F;"POf(RD1[dL{L
L?
Ll1L1 }b;[ff4FgfXE 11FFhFF=>
HF'p1
hd}F B;ff}1d'dFL1L}LFHDFXd1F

7 7dk; XhA971j;dPKd/LNMd;h1;l1m F@dD
1l 1C Sl3 9FF;7n Kl/LNMld
ij

n

' U ' V d}A971oV
prq

fistIu1vw0x8yztd{Py|}P~y<wy<|r$o<|.y1fi|r|.o5| u%o<~y/ twv0xow~tb$};td{P

=+0&<do
5.W1o1<41 /(b <do.dofibAC<oW+%4+
Pddo1=C:^o?<1r&0W+4#GY;&<1<ddoN%5+:ddo1=o<b
<5 (b78o4<d+4+< o# <1+<b8 h 7=<1+%X+7 ddo1
b6 h Nr<d .d+<40 4;2W+4$GS.d4<5o<oeS1
<W+48hN4Wo o4fi<1+<b4 ;7+^0&# Wo88o
o4doN1185r<d=gd7+?
=<1+%db+oo0r/fio<bfidoo.glCbA<ggo=4orr
<Y5.doodgd7+
W 1< dood)dr2orddorbA<ggdd%d.do++
o<44+b+.gdo=<611Cdd21^+1d6%d doodr)Sdor
dorbA<ggdo=+1%d .do++
5.W1=o1<71PbPCbA<doP=+ +SgdoobPbA<do<Y1Addo8G
=<1fi 8+oo+5r4d0YAd1/ 1 $1/1r0oX $1bAC<o
o1<+# .d C gd6 ;1+4$
2;^


fiff


o11do/C: ddr
oo1 Y4<b?P 1r 8 o<bfi:^
+r<1Ad=+o+ )G518lo11doY6$. $b=.bbA<do11#<1
5 b bA<do
5o<l11do8^gd4r <#r:bdo1;?<b81.o
b#d<44<
&
18<1?+o=rrAd15+/ =o<b8o=%
<do 1ro+<do.doodo+++
o% 1C b=o?bAC<oW1#1;d7o++ 4r<d41C d+ r
;gdr
l.X1++rW ;gd
b= bA<do%:o%Addo/G) Pgd 1
<doC15<?o11do4N dr!
Po =1.o#
"o% $&!'( )*/ &
,+
gd4 ; 4?o4+<PoP%oo$l bPbA<d Sg4) o1Ad=+o+G
-#
.
?=+fid+.g2CbA<do5d%d N+/
01
? <$%
<do1Ad1
2(b?dX%d.do+1#<1? =o<b815bA<do1o<C4
o74doN;=13

Yb==d+.gdbA<do
d1fiX.dod <<r=o?r=dgd4 1<+
& . '879+ & ff 7: <; =
6
bbA<d= o#P4<
> @?( .dro< <21ff+P<bS=4<
o$I^ ?2
1.gPo11l8d<++doB> > C1CA ?<b$d+.g2CbA1rDE &
4o<N
e+ 1d<d.P1$1=o7o4 4 >fi' & +<Qo%.gdr+1%d
dB> 11&+#
F#1.<d.1/1 oo4 8G
F A' +oQo%brld
1C<=dB
A^H
fioo=+o+ 41+I
> ' + A' +P1J
> ' & + >fi' & +N L
K F K
?25+ 1I
>Wgg:CbA1r
51Ad15 <+?o8+1d%d b;b<++ NdB
> 1J
>I
1(1fid4bA1r 06;Ad1C
> 1M
> d1<$o0%d .
+4oo
+
6
P
7: ffN
&
0 .
b01rdQ
> 5Ad1 16
5 1Ad1o11do
>fi' +SRT>U' & +#bA1r(o5++ 42;4<bfibfi/#&o > d+.gb, V
odW
&
W18<b7ob? o1?5 od <ro?rr==
r<dCd7+
5

XY

fiZ\[^]^_a`cbGda[^`cbMegfch^bGi0ih
b

j
k lNnpo)lGqsrptvuauxwzy|{c}c~,|^
|L~^GG}:y|N^}c ()y*c
o)nmnG0\^~0:GEv}c~1:}9D|y|^S(y|:~,y|1a}:y|P^}9 ()y:G N1~}cG}NE|,|}c
^P}#(y|^
^S^y}N}c.a4,\44y|^ }.cL(300^Mc1P,|SDc^4~1:~S:~04z/@:G
y|^I#}#0:cI}cNy|Sa}:y|P^}9 ()y@,|ScNPG^zy}N}c:cG}:y|N^}c ()y@,|ScH^zGG)y@,
}cy|^JL(y}1a}:y|P^}cyv*1E4c4Jy|^:~4aN~}cG}NE|,|}cB^^^:GJ^#~,Ny|Iv}:yy|}4

nmonm(Go)6rmtvu^=M4E(^v}c~@,:~,|^{IG}:|Ny{94^~c4::GDM0E\^v}c~@4G9|^{a}:|P
y|{c4^~94N(I,}:y|::Ny|D|G}:y|N^}c ()yH,|Sc
)
o)nmnG0I^~}9^4}c~4 ^ :GC^4}9~4 ^|9c
^}9~D|G,0:G010WII^4~C}cNy|x0}cN)|G G}N1)y|{c4^~0}9~ NycHC4:/G,
HD4^ |G,c}:IppS 4^ y|^DJ:GW^mE|G0Cp%H8 Ic^^}cNy|Ca}:|PDy{94^~
v}c~ Ny(:S}C:GMwzy{9}c~,|^^|Jy}B0}cN)|G#}9NyG}:|Ny{94^~v}c~ Ny(:c1N
)yy|}:!v}c~ GJG44~z\}9~,4c0}c*Ny0N|,cpc\DG)yy,4c
nmonm(Go)6rmtvuPO%wIy|{c}c~^^|LG, HD4^ |G,9J}:Ipm@S! 4^ y^L1GC^
| I0}c*Ny0N|,JG0}cS|BJ0
o)nmnG0I^#G~0,~:GEv}c~1,|}cy|:~yJ0:cIJH,|Sc^#|N|,()y\:G*GG)yH,0:c
4JI,|ScHNH~}cG}P8}9^^H:G.^Sy|}N}cM(D0^0^6Ja,|SHcc|^{.
,|ScPG4
^#~,Ny|,|^{C0}cSNy|0N|8(IJ 0
}cG:N}#^}cG)cI^~}P}:GG:^,I)y|{c4^~cH:~^cG)y|{c4^~0c IN(S:~:~,|^{
}c~L4G9^{G}:|Ny{94^~c|/wzyy4@#|N4~:)y)y|{c4^~^JE,44#y|c0y|MG:D^4~^}cNy(.a
S}c~C)y|{c4^~c*|O^C:*B,~G0^~cI^B9N:N:{c}:#^C~Ny0S^~4P|ON(
G:a4~*G:*}cG0.,0:~,|^{.}c~4G9|^{/G}:|NC)y|{c4^~( v}c^G 8:G^~}:cM}MGW}c^:
G}9a}:y|P^}cyv*B)y|{c}c~^v}c~ :,(Ep:Ny|,:G^J0^4GE|}cM}WS4~,(*4Sa}c~)y
|N}9~1:,|}cC~#}c^)|^}c~~4c

ff
fi
ff!#"%$&'()*)*!+)
,

04N,y|c@^ ,:~Jv}c~I~c0:Ny| ,^G)y|{c4^~c}wIyy|4@z|P4~)y)y|{c4^~G9Ia0}cSD*}c~
, ^,41,(:@NCv}^0GE|^{B}9WGG9|^{B~c0:Ny|1y{94^~c#G::~.-0/:*12-0/c|^1,4G,G:
^}C)y|{c4^~,~0y.0}cN)|N|^{|(~c0NycL^DN|}c^44~,|^{W}c~JN 4a0y\:G436^
5 ~94~
8 797cNHIc!} GGC1)N)y~90:Ny|D,^py(c#0}cP0)|N^{J)yy^LN|~44GcE(#~0y(:}9G4
^;
:=<'> ?#
@0S)y|{c4^~^
IN(|Cc^9|,|}c^
AN+
1CB8ANI)P|1yy{94^~ 0}cP0)|N^{)yy^
GcE(3~0y(:,|}cG4I^* ,'D Ez}c~By{94^~S0}cN)|G
Fc
F ~0y(:}9G4H
G}c~#~04Pyc ~0:c4^{c~4
:GJ
I}cG,}c 8 797cNG9 (N4P,GN^S}c~S1)N|1)y\~c0:Ny|1y{94^~c4 0|{cND}:IIN(
:~z}:EL K4#^*
MNF
c:G }c^I}EL K4
OP
7MPP
EI}:4c4~:^y(:4~}9^GS}#aI}:@^}DGcPE|G0#:P
|G,:G0#}:,(EpNy|,Sv}c~G:)y|{c4^~3(I)y|I)!:,(Ep:Ny|c^^Ny||I0}cP0)|G^~0y(:}9
Q ^3}9~S4~I)y|{c4^~ccC0}9P^~4#Gc83~0y(:,|}cG4
E6H~}ca}PE|,|}c
OGR OM.) G1^W,0y|cC^}c^)P|1y3)y|{c4^~0c}: ~0:c4^{c~4O:G
I:}cG,}c/S 77cN\~ |Gy|GN^1)y|{c4^~9}:\^0^~~4N#G:G4~
Ez}:4c4~a|D~4)|G#}
^I^4^4~^4J:~#1)N|1)y}9~\^}9
I^L}:H^D1}N}:y(!}9~:G)y|^E|^{11P|1)y ~c0Ny|,(;
T)*
UVA@, 0S
@W/9X1(c}cC^^
y(c,z}:^)y|{c4^~
^IN(^~,4~9~c00:Ny|,c

YNZ

fi[]\C^+_(`4acb(d(\Leffb(fhgffi(bkj`*b(lf8monp(lkjfSb+qrqsmtqvu(wyxzf8fSm{]|Rq}xzfN^ mli(b~6\`(_4aym`(i(\2jog&\Leffm
c9HL8L*S+
0c(=(0 s(.S*V6*'(+0r Lr8L*+4
LLPRLP(L8(+SL(rzsv(29(s0L(8 }tSL(=]zs
sLt8h(+(6s(} r*L+
=(6;s8L=9'ksr L(r*L;8LrHz(*LN(
}SP88CJc=(sk0=&02 (02SLL(0= }*+
(0=ffP2 L6(0= 2
}S+}' +6( rsr89r=
(ySL;*2&9 *L(0Lr*L*6s(*L*=L(.9 L(+N9(rz*%c
c9HL8Lr6*Pt4++(]S+v.*;008
Lr=L

ff
fi fi
+(

;


*+

;


.
+(
0

fi !"

}SP88$#k =2;Sr k HC.S=*+ok =W0SH*}S%9 L
}S+J(6;;*+.*&z+}*+6( rs;rSr*+y N=&%*L(0o*+
+*0Lvr8 'rff
zk8 H sN9yNtLySL;*(}(SL(r9
}SP88)(=(N9(r&*Sr+*S(-,S.+/,*6ySLySr9r*L
}S+&;((L(;(v(L&
021"34oWz+H*+o6( s88 'r'24(*8=0LLyS
(+ L+*H(s28 t(9L(42* 9+9 (L(;(sLt (*ff+s2
(+ L+6H(8SL(6rSL4s(}*=( LySL(=;*+;v}0*
(68 z**t; LL6
5(8 7(=
&L 9+HJ(* +*;(48 2L+*c=((; s8;r*sL( *+ +9L( *Lt
L9y*L*0(s*;Lh82S'9(rSLL( r*LW=9+=;'*tJ
:< > =z4SL(r(
(rWv( ;
:< >=z;SL(r((*+
}SP88L +sc+*'o2&('}(+=*( ;
? 6(6=*L+r*+8A@ !BDC fi+fiEGF+*-HJI(0'sffr*'(sKE ySrSL;L < :
.
L.M
NQP L fi N/RSC ff=(o(}* *L L 96.? L
}S+H& +LL+9trNc'sL;(r 2( ;:< >=z;SL(r ff*L+
(0 8 L L !
E+=*4 8z(0+ 2v2*LT
;t*+4s(
N P 26SL*=8;L&
UV

fiWYX[Z[\^]`_.a^X[]`_cbed`f[_.ggfQ_

hi.j2hlkmhAkonYkqp.rtsmu.v"wxvykmpGzY{}|>hk~nAwxj`nDk$sm `wk$.wxv hti.j2h `;rphjkqp.nAjs$shi[w.j`nDk~rws~j2hkm`p.n>u.nDkmp[
w`{.{hi[wu[hk$skmhy`Q"w^wsjp.v [
u r`wthx.x`"`jp.vhi"u.n zrphjkqp.njs$s.j`nDk~rws~j2hkqp.n{
kmp.rwj2pSnu[rts~j`nnA2Assmwp8njsqw[jrphjkqp"kmp[ js$s-hti[wK.j`nDk~rws~j2hkm`p.nAi.j`nht.w/r`phjkmp[wxv
kmphti[wS;>A`pcjsm`w[jkmp`v"wKhy.whj`rhj"sqw`}j2p.vkon/>r`"sqwhtw`hti[wk~nwyw^ws
j2p.v u[
rt`whxx``">r`"smwhwp[wxntnA2s$sm2;n{
wxn"kmhwhi"k~nwxnu"sqh`kmhnwwn^nnDkm"smwhw[[wxnnlr`p.nhjkqp"hn`pS`"`~K2kmp"hwjsonkqhti[`u[h
wxnhtk~rhkmp[Khi[wkmYj.n2smu[hw^nDkmhkm`p/kmphkmw`j2p.vnhk$s$s.`[hjkmpj^2smp[`kojsqhkqwKjsm``kmhi[S[u[h
hi"k~nkonYsqwhA`lu[hu[wY{
A2K[`p[w/km`i"hK`u[wxnhkqpShi[w/wsmwjp.rw2hi"k~nYphti[wK`u[p.v[nhi.jh;hi"k~nA/km`i"h;^w
.
u nhwkm`i"h}`u[hhi[u.nj2p.v[nl>``w2..hj`rhj"sqwnu[.jsm`w[jn{i.j2hk~n2w`u"s~vs$km`whi.j`w
jwxnu"smhnDkm/k$s~j2h/hi[wu[p"k~`u[wjkmjs$kmhtwxnu"smhYhi[w;>prts~j`ntn[ni[2kmp[hti.j2hhi[wxnw
j sm`w[jnYjwhi[w`p"smjsm`w[j`nnj2hk~nD`kmp[n`wn.wxrtk$r/rkmhwkm`p 2}wsmwj2p.rw`{l|>p>j`rhx"wxrwp"h

wxnu"smhn"hi[wYj2u[hti[`n}j2`wp[`wpKjp.vK2`p.ntn`p[x``.nhj2hwhti.j2hj2p"hj`rhj2"smwYnu[rtsojnn}hi.j2h
k~np[`h`wh"p[Ap kmp&hi[wskmhwj2hu[wrj2p[p[`hr`p"hjkmpS`wKhti.j2pShi[twwK.j`nDk~rws~j2hkm`pykmp.rtsmu.vkmp[
r`p"`wnwxn>htwxri[p"k~rjs$sm`kmhrj2p[p[`hr`p"hjkmpc.j`nDk~rws~j2hkm`p.n`hti[whti.j2pT;j2p.v;`
[t.`{i"k~nwxj2p.n-`kmp.nhj2p.rw`hti.j2hKhi[whSjsm`w[j`nzj2p.vc;j2whi[w
`p"sm6j"kmjshjrhj2"smwjsm`w[j`nr`phjkmp"kqp[yhi[w/ws~j2hkm`p}j2p.v6hi.jhKj2py`whu[p[[u["s$k~ni[wxv
hjrhj2"smwnu[rts~j`nni.jnh.wsmwxnnw[[wxnnDkm`wkmp&hwtnhi[wKp"u[/.w2.j`nkorws~j2hkqp.nhi.j2p
hi[w[wxnwph;jsqw[j`nr`phjkmp"kqp[.`w.j`nkorws~j2hkm`p.n{
&D2[22>
|>hnwwnlj2[[`[k~j2htwYhtnu[j2k~nwhi[w;nhj2hu.n}2hi[w;nwxj2ri/`jkmjs.htj`rhj2"smw;nu[rts~j`nnwxn
2s$smwp8nAkmp"hwjs-jsm`w[j[i[wwkqihp[wj"kmjshtj`rhj2"smwKnu[.jsqw[j`nA[wxnwp"hwxvkmp6hi"k~n
.j2^w/kmp.rwxj`nw hi[wp"u[^w/2ru[wp"hsm&"p[2pjkmjshtj`rhj2"smw nu[rts~j`ntnwxn/hywkqihwwp
kmp.rtsmu.vkqp[yhi[w;>prts~j`nnw^ws-j2p.v [
u rt`whxx`""j2p.vhi[wp"kmp[wjsm`w[j`nl`u[p.v
j2wp[`wpSj2p.v 2p.nn`p6``"{
p[wjp[hwhi.j2hhti[wwk~njr`p.nDk~v"wj2"smw2`wsoj .whwwpShi[wxnw`nDkmp.rwKhti[wnDkmwxn2hi[w
jsm`w[jnj2w``>p[w2`[2>wkm`i"h"`[x>wkm`i"h`j2p.v/"`">`p[w22hi[wnu[2hti[wnkqwxnl^wkqp[
/u.ri`twhi.j2p [x`Q{[kmp.nhj2p.rw`QYwni[2YwxvkqpSj2`wp[`wpj2p.v`p.nn`pyx`"hi.j2hlhi[w
`p"sm/ws~j2hkm`p.n2hi[w;>A`pjsm`w[jhi.j2h}k~np[`h}kmp.rtsqu.v"wxvkmpjp2hi[wjsm`w[j`nvk~nru.nnwxv
kmpShi.jh.j2.wj2whi[wws~j2hkqp.nj2p.vy {
r`u[nw`}hi[wu"smhkmj2hw`jslk~nKhtrts~j`nnDk$hti[wSnwhK;j"kmjsYhtj`rhj2"smwnu[[
j sm`w[jn[u[hSnDkmp.rw&hi[ww&j2w&2Snu[rts~j`nnwxnhckmpwxnhkmj2hw`Ahi"k~nk~nSrtsmwxj2sqffjcp[`p"hkmk~js

hj`n{wxrwphwxnu"sqhn`pShti[w
`fiff `;n.j2hk~jswxjn`p"kmp[S2`p.nnpSj2p.vSj`wp[`wp
x``;ni[2ehi.jhK[u[hw)`rwwhi[[v[nrjp&i.j`wnu.rrwxnnkmprti.j2j`rhwkonkqp[6hi[wr`"smwhw nwh
2hjrhj2"smwnu[rtsojnnwxn{Si[w[wxnwp"hK["sqw k~ni.j2v"wkmhi nw`wjs`v"wn2j`p"kmhu.v"w`
i[2w`wxnkqp.rwhi[w >Sjsqw[jSr`p"hjkmp.n`p"sm& twsojhkm`p.n{ wwhi[wsmwxnn}kmhk~nwp.r`u[t
j 2kmp[hp[`htwhi.j2hhi[wtwj2w`p"smu[j"kmjshj`rhj2"smwnu[rts~j`nnwxn-hi[w/>jsm`w[j[
2
`u[h2hi[wj[[kmj2htwsq6 [x nu[rts~j`ntnwxn{ynwphkqp[wxvTj2.2`w`wxrwph/wxnu"sqhn"&hi[w
j2u[hi[nj`wp[`wp j2p.v 2`p.ntn`px"`js~n[2`k~v"wKj/.j2thk~js-rts~j`nnDk$rj2hkqp-hj`rhj2"k$s$kmh
kmpSAs$sqwp njsm`w[j["u.nDkmp[ nDkm/k$sojwhi[[v[n{
l`p.rwp"kmp[whkorhkqw`"kmh;nhk$s$swjkqp.nh/[2`k~v"wKhti[w;p"kmp[wKjkmjs htj`rhj2"smwKjsm`w[j`n
2j`wp[`wp/j2p.v/2`p.nnpx``"^kmhin`wkqp.v2.whk~rlhw^`js"kmp"j2hkm`p{}nDkm"smw
w.j2/kmp.j2hkm`pni[2;nhi.j2hYw rj2p[p[`h/u.nwhi[w[wxnwp"h/hwxri[p"k~u[w`Ynkqp.rw hti"kon`u"s~vGj2`whi[w


fi "!$# % '&(# )+*(, #.-/# 0/)214365 0.-/)7#8891:8<; =?>)2)716@Afi8B>)C160/, #EDF "!?16 , G-4*H'&(1


J2KML/N'OMP'Q RES7N'R6JUT IVS6KWYX[Z]\V^6_`/N'JUO
J$a'bMLKMOS6c c4O
JfegLS7NhP'OSOMP'i6JI
JVNGSOMP'^6QKP'Qc/L\VJ2cjT:klI9JVNFSmOMP'^6QKn^6Q
MK OSmI
OMP'Q R^6IJUQcgP'Q Rl`C^P'Q:OKpoI
L "
Q q/r6s:tvu:w$axWJUTJVN(SQcEy{zL I\9|6JUI
O7o~}266.o:SQc+i6JUIMPhklO
dSOYSONJ2SgKMO
^6Q J^mO
JYWnXZ]\V^g_`/N'JUO
JYS7N'R6JUT SgK^~XI
^6`C^:KP'OMP'^6Ql fiPGKP'Q\9N'Lc/J2cCoK^n^6IO9d/PFKpo:KM^6_J^6O
JUI|gP'Qc
^JV.`
J2K9KP'i6P'OMklPGKQ JUJ2c/J2c6J2SI\9d/P'Q Rl^6In^6O
JUIBKMOSmI
OMP'Q R?^gIJUQcgPQ R4`^P'Q/OBS7N'R6JUT IS6K\V^gL/NFcjS7NGKM^
TJ<I
L/P'OML/NvL

JUI2ovP'OKMJUJU_$K`C^:K
KP'T/N'JO
dSOnO
J<O
J2\
Q/PGegL J2K`
J2KJUQ:O
J2c+d JUI
J\USQSNFK^?TCJfLKJ2c
^6IJV
JUQcgP'Q R?O
J`C^P'Q:O9ZPQ/O
JUI
iS7N(S7N'R6JUT IS$a]PhNGS7P'Q~o}266/P'O
dl_JUO
IMPG\OMP'_J6
$?~H ]H~(


J"dS7i6Jl^6L QcJVP'R6d/OlQ JU_?S7/P_$S7NO9IS6\VOST/N'JKML T\9NFSgK
KMJ2Kl^mBNhN'JUQ~K$P'Q/O
JUI
iS7NfS7N'R6JUT onSQc
`
^igPFc/J2c4O
JU_P'O
d4_JUO
IMPG\O9JU_`^6IVS7N~P'Q/^gI
_?SOMP'^6Q4^6QKOSI
OMP'Q R$^6IJUQcgP'Q Rl`^mPQ/OKn^P'Q:O9JUI
iS7NGKUo
LKP'Q RO
J[^6I9_?S7NhPGKM_^^6I9Qf~KHaM^6QK
KM^gQfSQcynS6
z \9|.KMO9I2^6
z _Eo6}766/n`SI
OI
^6_I
JU` I9J2KMJUQ:OPQ R
`
^6RgI
J2K
KP'Q$O
JnI
J2KMJ2SI\9d?S7P'_P'Q RSOSB\V^6_`/N'JUO
J\9dSIS6\VO
JUIPFK9SOMP'^6Q$^~O
JO
ISg\VOST/N'JKL T\9NGS6K
KMJ2KH^
NN'JUQ~KPQ/O
JUI
iS7NS7N'R6JUT g

d/PGKH^6`JUQKH^6ISB\V^6_T/P'QSOMP'^6Q$TJUOMJUJUQ?O9d JYJV `
J2K
KP'igP'Oxk^O
JYnZ
^6I
QlS7N'R6JUT ISSQc$S7N'R6JUT S6Kd/PF\9dE\USQ$JV.` I9J2K
KV2/2CG6hTJUOMJUJUQ$P'Q:O
JUI9iS7NGKUo ` I9^igPGc/J2c$O
dSO
^6Q/N'kEKMOSmI
OMP'Q R^6IJUQcgP'Q R?`C^P'Q:OVK^P'Q:O9JUI
iS7NGKnSI
JI
JVNGSO9J2clP'O
d"YnZ]^6I
Q4I
JVNGSOMP'^6QKU


6(vE]C(~C6
dSQ | KHO
^Hd IMPGKMO
JUIynS6
z \
| KMO
I7^6
z _Eo:JUQ
klSL
6o SQcO
JnOx^SQ ^6Q/k:_^gLKI
JUigP'JUJUIVK^6Id JVN'`/L/N



\V^6__JUQ:OKp

g( C
nYn]Z]v}a}76 }/M2VV6:M:766Gg6(gUU2M2CH6f{ 7G6gC2h67V
Yn{
6monQSd JVP'_EoH(o{6fY_JUIPF\USmQK
KM^ \9PGSOMP'^6Qj^6InI
OMPh\9PGS7N]Q/O
JVNhNhP'R6JUQ\VJ6o(nnY
X[I
J2K
KV4 X[I
J2K
KU
nYn]Z]g4a}266.<M2VV6:mBM:E67~g66C6(6p7x7V6{ 7G6C2F
g2V?nY{
g9mo/X^6I
OMNGSQcoYo{6 Y_JUIMPG\USQEK
KM^ \9PGSOMP'^6Ql^6InI
OMPh\9PGS7NQ:O9JVNNhP'R6JUQ\VJ6
NhNJUQ~o Ca}26g/~"S7P'Q:OVS7P'Q/PQ R$|/Q ^NJ2c/RgJBST^6L OO
JU_`^6ISNP'Q/O
JUI
iS7NGKU(6/66vM
:[o 6/a}g}6g7.7:
NhNJUQ~o
~aV}26 }V U
J _`^6ISN(I
J2S6KM^6Q/P'Q R"SQc"`/NGSQ Q/P'Q RQNN'JUQ~o(v'o~SL
6oB'oXJVNGS2igP'Q~o
FoSQc U
J Q JUQ/TJUI9Ro '
J2cgP'O
^6IVKUonVU6:":96/<h6 Uo(\9dS`
JUI"}6oH`SR6J2Kl}V /:4^6I
R:SQ
SL/_?SQ Q~
yHJUQ UJUI2oHa}766/4QO
J$O
^6`^mN^gR6k"^YO
J$R6JUQ JUOMPG\Q JEKMO

L\VO
L I9J6l]Qx7VV6G/M/
666CYV667M7G7VU'og`SR6J2K}2/U}2g

nJ2\9d:O9JUI2o'o4JVP'IMP]on'oSQcXJ2SINovna}26 }m

JU_`C^6IS7NB\V^6QKMO
IVS7P'Q:O$Q JUOM^gI
|.Kp 7Gg

C2hg2V2o/ }V 6
nJVN'R6ISmQc/J6o XSQcYL ` OSvo:a}766/I
JU`
J2KMJUQ/OSOP^gQ$^6IJ\9P'JUQ:OnO
JU_`C^6IS7N~I
J2S6K^6Q/P'Q R
Qa]nYn]Z]g o}266/Vo:`SmR6J2K6 }.66
nISm|6JUQ R6I
JUQ~o ~SQc"^6QK9KM^6Q~oXa}766/"S7/P'_?S7NO
IS6\VOSmT/NJKML T\9NGS6K
KMJ2K<^(NhNJUQ~KP'Q/O
JUI
iS7N
S7N'R6JUT IVS (XI9JVNP'_P'QSI9klI
JU`^6I9O2]Qja]nYn]Z]6vo}766/o/`SRgJ2K667 6



fi
fiff ff

"!#%$&'#%$)(+*-,+.$/10.2$34352$)()67,)89;::=<>,?*@2.AB./3BDC2EGF=HI#%J4#KC4HL3'3NMPOQC%.J5MR2$S2.TfiJ'CJ.U=MPHPMRJWV

MR$YXZHPHR#%$)[\3] HI&#%U,7^_$S`fia5b;cddefhgji"klbnmpohqjdsrt.ohqDugovd;agwovfLbgwxybfhgoZz{bg%m%d;a5d|gcd-bgD}-aovf ~fic|fLwx
ugovd;xhxPfid;gcd%+u'y+z}uK%,{*@2K.FF#;.;,
#%'#%MR$=M_(X,R(jC'=U#%4J;({,R(.$/jC4.#)#%;(,89;::=>,D*)#%EGF2 Hfi'#;3n2$=MR$&YMR$*MREs#%&.F
^ j^5^,Zu;{}-l=xhxd|ovfLg(=8W=>9,
2.HREpU=MLC.(+,+],.$/.EMR;(+-,+89|::=>,l{2EsF=HR#=MIJ5VY.$/|HR&25MRJ'E3T2B'#;352$=MI$&D.U2J
J5MREs#X&.FvJ'#%2'#%JnMC.FF'2jC'),ybjagwx)b5mpohq=d?}z(=j=85=>R99||Q99%,
0.2$3'352$)(+67,Q.$/C 4!3nJ';2 EY(],+89;::=>,XHPMR$#;.'vF'2&.EsEMI$&Y"FF'2jC4YJ'2J'#%EsF2|H7'#;.
352$=MI$&,^_$S8_X]XX^__:(@9;::=>(F.&#;39;|+9;.j,
0.2$3'352$)(=6,=.$/.!#%$&4#%$)(*-,89|::=<>,XC2EsF=HR#%J'#?C4HL343NMPOQC%.J5MR2$D2.T)J'CJ.U=MPHPMIJ5VMR$DZB{_,
yb=agwx)b5m]}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdd%k%dwa5cqj(j999,
-.J4(,.$/1@/=!MR$)(67,789;::9.>,^_$=J'#%&.JnMI$&Es#%J'5MLCs"$/J'#%EsF2|Hfi|HPMRJ.J5MR#J'#%EsF2|H
'#;352$=MR$&,^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B.9.j,
2U".!M3({,89;::=>,D#%$35#J5MREs#Y.$/SJ'#%EsF2|HBC2$35J' MI$=J3AMRJ' ,Y^N$AB.'J'2J|(,
.$/Z#%U#H_(,R(#;/MRJ'23%(`a5b;cddefhgji.k-b5msohqjda5eDugovd;agwovfhbgwx{zbg%m%d;a5d;gcdbgS`fiafhgc;fQxPd%kbg
gbxde;idfidnQa5d%k%d;govwovfLbgwgeDfidw.k%bgfhgji-Bn""(@F.&#;3-."(@fi.EU5ML/=&#()X()-X,
2'&=.$-"=TEK"$$),
2U".!M3(B,89|::=>,*@CJ"U=HI#/ML3hW$CJnMI2$32.T]HPMR$#;.YC2$3nJ'|MR$=J3%,^N$`fia5b|cddefLg=i.kKb5m
ohqjd-geugovd;agwovfhbgwx+z{bgmd|aWd|gcdBbg`fiafLgc;fQxPd%kBwge`aWwc;ovfhcd7m%baz{bgk%ova5wfhgo+`aWbia5wfLg=i(
F.&#;3B:=<%=<j(fi.EU5ML/=&#(Xp,
)3'35#%(0,_,=.$/CXZHR2j2$)(,89;::=>,XC%"$2$=MLC%|H+T24ETv2{&#%$#%|HPMI%#;/GHPMR$#;.]C2$35J'|MR$=J3%,
yb=agwx)b5m-+ s4bxPfLcz{bB+jovwovfhbg()9;R9Q9%,
#MR5M_(^,89|::9.>,=2EU=MI$=MR$&|HPMRJ.JnMI#l"$/p.$=J5MRJ.J5MR#BC2$3nJ'|MR$=J3+MR$J'#%EsF2|H'#;3n2$=MR$&,
^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B =<j,
Z#%U#H_(],.$/- C4!#%'J;(,_0,89;::=>,2.TvJ5AB.'#T2pEC'=MR$#Y343NML35J'#;/.$|HRV3WM32.T]XZHHR#%$)[\3
MR$=J'#%' H|HR&#%U,.X].|MPHL.U=HR#T42EJ'#.J'23UjV.$2$jV=Es23TvJ'FT'2E.+.fi5=+j)j|l5
3?;=j+|Q|Q.j.j+ .j"=j@%)N.{5,
Z#%U#H_(],7.$/- C'!#%4J;(,_0,89;::=>,D#;3n2$=MR$&.U2JJ'#%EsF2|H'#HL.J5MR2$3%GXEK|=MREK|H
J'CJ.U=HR#35U+C4H3'3B2"TXZHPHI#%$)[3MR$=J'#%' H|HR&#%U,yb=agwx7b5mohqjd}z(j=89.>j|,
j.$/=#%AB|HPH_(+B,89;::">,)dwov=aWdkwgeG{xPjd|gohk%,=T2/YZ$=MR#%3NMRJ5V6'#;3'3%,
2$&(fi,{"$/{2#%$)(B-,89;:=>,*l#DMR$jJ4#%'F'#%J.JnMI2$2.T?J4#%EsF2|H]'#HL.J5MR2$3MR$$.4.J5MR#,
^N$1`fia5b|cddefLg=i.k-b5mpohqjd%ohq;@-wovfLbgwxz{bgmd|aWd|gcdbgD}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdL}}]}u'4(
F.&#;3B<|j|< (J;,6.=H_((Xp,X]Es#%nMC%"$DX?3'3n2C4ML.J5MR2$Tv2X'J5MPOQC4ML|H^N$jJ4#HHPMR&#%$C#()2'
&j"$Y-.=TE.$$),
..$p#%#%!+( 67,89;::>,%XFF'2|jMREK.JnMI2$p|HR&2nMIJ4EK3Tv2)J'#%EsF2|H='#;352$=MR$&,.^N$5ML/=..$)(.,",R(
#;/MRJ'2|(B`aWb|cddefLg=i.kKbnmYohqjd1rr.ohqugovd;agwovfhbgwxybfLgosz{bg%m%d;a5d;gcdDbg}-aovf ~fic;fhwxugovd;xhxfPid|gcd
u'y+z}-u4 4(F"&#;3-9;:9Q9;:(#%J''2.MRJ;(^(-X,2'&j"$-.=TvEK.$$),



fi
fiff !"$#%!&'(')"*',+-/.0&"1
23'4.05ff6"!879 : /" ;$< "
= > ?8@<ABABCEDFHGJILKMMNOLGQPRA>SUT?V?WX> YT[Z\^][Z>&_`V\(> \UV=A,\ABacb6Td(>&_JV?efT[da/> \UVT?QGhg9iLjlk monkfipq6r(s6jltqfiquk:v
w[tsnLtDxyz{N[M|B}~N[G
= > ?@<ABABCJDoFHGh> ?TAB?QDPGILKMMOLG8H>L\c> ?> bbdT&Va/> \Acd)A>SUT?V?W> Y6TZ\\ABacb6Td(>&_
dAL_;> \VT[?SBG90Ejlpjlkfisp[qQr(s6jltqfiq`kuw[tsnLtDI~O(zK&~N&}EKB[G
V`_:>5V?QDQG@GQILKMyNOLGQSUSU\ABaelTdd)A>SUT?V?W/> Y6TZ\\UVacAGh?Ri&n(tLtLk;sw 4jfi*tcs6&Q[
pjlkfispqst&it&snLtsg9i(jlk mon&k;p[qr(sjlt&q;q`k`wts6n(t,;gggrv LD b> WASK&M|B}NKDFHV\\(SYZdWQD*F6D
GacABdV:B>?89SSUT)V:>\UVT?XelTdRd)\UV`E)V:>5_?*\AL_`_`VWAB?LAG
V`_:>5V?QDG@GD59>Z\D5,GBGD > ?9= > ?@<ABABCJDF
GG I(K&MyMO(G[T?S\d(>&V?\QbdTb> W> \UVT?4>&_WTdV\)a/S
elTdc\ABabTd(>5_dA>SUT[?V?W6zdAB=[V;SUAdABbT[d\G?otLpkfis*w8k;spq`k;jlpjlkfitotLp [skfis*wp*)j
<*&kfin(p[qJ&jlt&4BDb> WAS~|5~&}~yKG*$TdW> ?9>Zefa/>??QD > ?8> \ABTD6G

5

fi
