ff fi!"$#%$&('*),+--.'/1023%+465789:;<>=.?6-.'A@B9#& <C-.?-.'DFEHGJILK>MONQPSR.TVUXW.YZR.TQD[T(I]\^GJE_K>`acbd%begfihVjlknmCoprqtsVu!vtwyx%z8x|{ v }~8.A%8%!|6Vr _XHH8%8L]8r"1,8] 8 .8 %1.__,|OAH" r][V l!OrV_8.|$ $ A$$r Z 1, 8_AL% ">rr$r] .;$[r$r.1 8 n$$.r ;r$ 8A!% $$ r|$ "!.6 y$ ! $6.;r%$ $1 8|r$8VO1 "rr,V $66 $ryAC tCO$6 ,.1.8l%$8 1$Vrt ! $ ! $ 6 $$rCr8;" Crr rA1 $ $ !.c!;O !.$.rOt _8! $18(1 A. ! $ 1$.y* r r$! 18$ O$$ 6r.O $ rr,r> rL;$r|r , ;! ;r C Cr 8 $ $.tVr$.6t H1rCr! $ $L$y$ 8OO$$Z OO$ O(1r,rr;$ 1|".t!VrC l$ rl $$.A$ ! 1r r$ , $,r $. _6 $ 8$ r_1$ Z $ .l! $FAr1O r|$ Z% $$6C; V$, 8r 8|l,HH r8g$.C $tArVg(; ,y1 11 $O$.C $rVlH.,(,r8rr_Cl. !._rVlQ. r$.r ,r _ $,, |$rOt rVrr$ _%$ (18|$XH8>H| . y$r!Al, ..81 $ $ $ rOrVl( !C > $.Z ;!r,r8.88% A$ $181V1$. 1.$|$>r.rA r1 $,C18.$rVlQ $ $.r$ 6 1 ,$_ 8 .rV$.C $1; ,y$ $r$$ 8r 8"r .C; ($6_r|68rVg( ( ,$ 1r8r(6 16r . 8ryr8|.8 ,$ $.fiff V!ojlkfi !#"$&%(')&*+!$+,.-/$102)334,56!578:94";$&"<3=$&;".02%16'>"/33?@ 6"<ACBED>FHGJI.K#L(M.NOQPRI.K#LTSNUIWVRL(MS#LTXOYNZK\[]^I6NG_XK\`aL(bcYI6MX<GLTOdULTOYMK\I6NbeLTOdUfT[QMK:LCS:LgM.NhfLTO;G>NOi[)GjifCS:LCkNZUI.O2SI.OilLTK\X<OdG)I.O2Sb.mYb#jYM5noNb.ml<LCK5S\jYNfYS\KNhLCOiLTOdUJpq]ENZG8crIsI.SsNftTmru6vvwyxhz{NZX|I.SsNftTmdu6vv} ~m.LTOiS\I.KNMS:LCl<I{I6ijYM.NS#LTXO/pXK^LTOYb#SNOYMImZLTOl<LCK5S\jYNffiniLgb:S\XK#L(M.Nfb#I.S5S#LTOdU2b.mLTG)I.OiS\Ifs]ILdILCKNdmsu6v<vd~miLTOiS\I.K\OdI.S\k&cYN<b#I6LCOi&XK\GNS#LTXO;LTO2S\I.U<KNkS#LTXOpLffLgNZG>b#XOm^[ M.NZKNdmdV+I6M\`<I.K6mu6vvi~m2zXcrXdsjd;K\XcYX<S#L(M|NOY/b#[iO2S\ndI.S:LgM|b:X M.MI.K|p#RLCSNOdXI.SNhftgmYu6vv<wdmdu6vvi<~m.LTOiS\I.KNMS:LCl<IHI.OiS\I.K\SNhLCOdGJI.O2SRpqPHN[I6b:kzXS\nmK\X_{OYb#S5XOm2+I.OmYu6v<vwdx2zILffT[u6vv<i~mfiNOYYX<S\I.O2S:LgNhfGjifTS#LTk&K\XcrXS#L(Mob:YNMI/GL(b\beLTXOYb.t]I6NZG8_XK5`LTOb#jYM\nMX<G)ifTImi[2OYNZGL(MiXG>NhLCOYbL(b+G)XK\I|S5nYNOQNbeLTG)ifTIjdOiLCX<OQXZbeLTGjifTSNOdI.XjYb|MXiXK<LTOYNS5I6QN<MS#LTlLTS#[tFHOLffTjYb#S5KNS#LTl+--A'>fitfi"$##d < <8slff:Vs19#& # fir%&# #&<fidsiY)iT{d\<gi642sd.)YJ.6\<d|6<d.r\\a\.Y6:Cdr.)5Yfi\d{<.5.YY.#..QeT)iT)i<TY#TY\6\(R5.odY52dT6i6To5d|T\.\d5dY#6a\d<g:#TY#Tr.q..<<TY\\)Yi#TTdTo;{<TY\\hR(|eT8iTZd.Y|Yoi<TY56oi\aeTY.rdd{TR(+d<Ye(i.\6;\6\#T<CdT/<2rd.<.6r(|yJiCJs\6\|d)<.\.Y4C\dq>qC5d#TY(+\Y+{iT)\6\>ii6RT2<T)2<CYZ#TrT<d<C:C<TZ{T6#RT2<T6|)J/\62h^ZYoiY.Z#To)dJ\6).r..igJ\#(5T/& Y:6\doi.dJ.2)Z;.d.hH)diZ\6Z85Q5Q.YZiC\6\Q<4<d.\.2:Ch<.Tdo5d>dY.\T2#T6ZR<)iTsiiY(.iT\<d).2.Y\#(i(6C\d6#.iT\<d).2.\6Z).Y.5.Q.Y<d2\.<.:CdrTY)iT.\Yr2\eTiTTYYe(#\.i)<C.+H\d/:gYJ.2hW#\)+\d.).i.^d.\.i#T\6).r.+Y#+Y2TiT)di(.\)\/((\i<TY:C<>dd5\d.\)5#Y5.i<C5d).i>.Z&\..ZY#oY5#(igZ>\6Z).Y.J\dddY656<CT&idTd\6#rYeTiC:C6fi|\/<(\.WdddY6\6dY5\diT#T6.)6Z>+Y#H52Y+r.YiTas)iT\:CdJY.#&\>ZYYJYiTiTQ5.\2iTTd/Y\6T .Z#Td/\6#d6R\)..HZ2><2#Td.Y5T6.{Ri&\\dY5CCJiC.J.2\6iC:CZ.2+# :\.>&\.Jh\d\<gia\dWd665\\JY2TiTq;TQi<TY:C<QY;)di(.#T/&{d.\.i+\6\aT#Y5i>TY#.diTd2.6r6Y5#(igZ6T\d6:>#d#\.>..i|54:ddiT6iTT\/d\.i(dd6i>Td#r65i<TY#Td.<6T\/\d+&id\d2dd.\hCi#T6+s)iTi2Y4giTY.Y5d|TiY2Ti(##Y5od\.i(dd6i<TY:C<T6dfi5Wi##(Cd56T(seT)iT><iT\Wi#(5CYZ\HYad\.i(J<Y2\qCiT|#Td.Y5T6.Wyd\\d.\J\yC\.hTd;dQ5)TY\6qCdZCJiC\6\/eT\Y#TY\d6#<TY#TTd\6)i#T2YhT\6d6d<T#TeTYo2<CYZ#Ti(YJ\/i>T#r65i\d..ddfir{\.Y#6T)\d.si<>TY. Y#562i<TY#TJY5|Y{\6i6qC<d6&{65/d.i>hCdQ.i\HiiY\d6qgJT\i(\#(5T;g5Y)d\<g<Td<.24T\.d.H)di|\6\.YiT6\d.\di\65>#Y5<iT#T6.Y5)diH.YiT6/<.2J\d\<d)YeT)56#>ZYd{i<TY#ToY)di(.#Tyd\(<Td)\d.\d+\6<igqC5YiCiT#T\6Z85Y5.d.J i((#T\.Y#\6\.YZiT#T6\i\|i>TY.{<|iTii6W:Y\5.Y#>\aT)iT.).i#T\6ddC(#/.Y#d\6Ye(#5.YT\6Z85\25)di(.#TY;q(5gid.W65\dY\T\6.i\d.:C6Y\6\|Yr.d)\+d\(i{5d56iT\6J)dig<YiTiC|56#iTdWr\6\YTr.1Y|1Y&6r&(<d\sd. .65|6<d.s.<6\Rsd.Rdd6.6ffq fi < +\2#6<H\2:+Y.+6H52#/gid.H6<iZYqTi\6#rYeTiC# q.diTd2.a6iZ\o#)|\d/d\4Cd.i)d6J)d5d6#{..6)2:856#65\aYC6 \diTT#Y556<\\d.#T6aTdi(<Tdd<#(.di(.#TYaqZ.diCdi.EY6<iig+\:g5Td\6#.i+ !"# 6r&$ fia.d.hE)dis56<\d.T62&%('*) qeT)Y,+d&-/.1032<\Y5 46'{T\r2&%('*) gY#6J>5d1Yfi1Y&Y&1d\d.\q.<6\da.HT6rsd.o .6\<dE6<d.Yd6iddRC+(#)YhT(|YJTQ:).#6Y5\HR5\d37ff#$ fi89:d+\d.\ H52#(H\2:4;+Y.6(H\i#>(id.6YiiY.{iT|2&%<'=)Y#67#TiCi\.i#TYs<\dYqgdi(<Td)iT 5WY56)\^T)\d|YZ\6>(\d.\56).Y.digJd>a)iT)iC.5ig.h#\5Y\d\?qTi+T2\.i#TY.TY<C<(iY{Ti\.2:C<YWY;YT8ZYd|5d.A @rT25.2#T2&%('*)B C"DAEGFIHKJMLONAPRQ&SUTWV5XZY1P#NAL\[R]9Q\^AX`_aX V5N$^bXZc`_aL\Q\d`e?V5d<_\f$_gVih_jkh5Ql_d?_^1N$^khiV5^#QH?m#mQ\^#PAV5nCoApfiq9rtsvuwxWy{z|#}~|R}q}uvs=rw6tA\U&t\UAt3 6UAt$A67U#U\UtAt\UA#A6A R 6tA RU6Rl7 : &t:Ut:U\UOUtUaA\UkA\U6UtAt\U6t<=\UaUtU#Z$A6#\tU7* 6tA8\UWUOt"A81 tUt:U\{&<=R\,`a:U$8#=ta\U#7A\Z ,t8g t:aUaA#\At$\U89#R=t8A{ZUUtR1#gUtU98\ t*g$\(R:Ut::: U&#\7Ut::gAW:vA$g=a A#U8g8OA9a#A67A$={Zt::aA#AtU#\UAA RAtU#\U9 :l# AZ`R:a#UAA$1R\tgAt#\UtUAt\UA<=?A$8\UR:U#\U{U tUa#RUZ9\t{RU&\t# \U#,U{l &\#\UWWAA6A1U GtA U,A<1t#Ua$tG#8a\#< \#,`/g3U#<=t#/g$ \ARv\#kG/t#\#Ua#693A\U#A&A3::U\$8\U1U&<=5=tA$R:U#aAga ,tAgAa#ggA&tA7Ot"A8#&<=UaA$#=t#aUaAA\ ,tAg\ U# \U\${t :UA$a7 6tA\U# #Og#\`ZU AA U#6W&t=t#aUAA\$8A{1A8t#Ua#3 tUt:U\U 6tA\U#\7\/a 7# #a#UAtUARG U\UA&7A$\UU UAA$R<t 1<#6W\a1&<=# #aU$#A3U"A\U*U6tA\UUAt/$atU# #k/1At/$ata# #=\a8/OA :# $v=\a#t $vv*O&A{R`U R $9 \lR#\`AR`U # vOO?:W R R&\( \#,6UUtR<At#5 ttU=7A#U$#at\\a 6U,A$,# \U&tk3$atU# $"#at\A#{=7#Z ttUa#69"?g tR" t:aU/Aa#\A\U3v6R7 U `A# gZ$t&8{#R#a\Ag=gRG\7#v 6U,A$kgt tUZ/{# #WRA#3A67U#U8$tU# a#=1 :,a\a$atU# $t\UkAt$G8vtU&al tUUvAA$t ?#6W=#\7* 6tA8\U t$U\U=t1UA 1U1\, # $t&g$#kAt::g##6A/{$a#/6\t#U#Ua\$8$&A \UR:U#\U=&<=g#A A,A$3a36$ata#OA ` # $?tU3\A/ UtA7At#ttU#AA:AAt#{vR=7AAtA U7#\#{3tA$gR:#8\Uv&(*#g=#R,t \ a3=#`\a#tUA$8$tU#A17A$ tU AtaAt$U #<\laAA$aU ,A$aR:U`tA U7#UtgAtU,A6Z$tUt=\aU#\At$1tA$R:U# A\UAt$R#\tU$Z#\/a#AI:U\a$\U=7A $&89&(*Ua =tA UAt#<={O\{AA;UtUAAt#AA$Rl,t ,/#6W&AUaUtAtUAA7v\AAk : Z$A6*v&g\aAOAtU# v`\#8t`tAt\UAa$t3a3tA#&W=*OafiffA# #t W`\#/al8#??A A?a/7A$( ,t tRUA?t:U# \U ::9 =a#\=Ua#AltA$`(&<=Ut:"At\UA$Z#\Z$AA,U$ 13:AA6\atUtAAlgA=v#6A8t:U\U#1\\=UtRUU#8v=3\ZA/8AAU/ ,t #ttU#\URGtUA$8$tU#AW{U$ \AR?A 6tA\U\$Afi"!$#&%'!(*)&!,+.-(/021354&+063$7+0!8)9-:#;63-:5!2<=#;!"+0>&)&!"+0#;6%#;?#A@B,)&C-(>;+)D)9E-:"+0F!"+0#;6#&%?G;5HI!)&<87#;GJF(#;1/05<K$+06L)M/0N7#;"/EKE#A<K)M+063OP;-:!,+Q#A6SRT:UP;-:!"+0#;6WVJEA+-:@3,!(5#;"+0#&%!)&<87#;GD)&63EJ"GA5!C-!:+0$+0<=F/X+-5)&!"+0#;63$%#;PY[Z\]^UAP;-:!"+0#;6I_ 6:`!aE(-:"+013PY[Z\]^bc#;@+0<=F/05<=56!Ed<e#'E:/#&%*!)f<g7#;(GhU8P;-:!,+Q#A6jiWEA+-:@3,=PY[Z\]^kl":/0-:!"+0>;S-:#A<=<8@6+.-5)f!"+0#;6?UP;-:!"+0#;6nmfiF("56Y!:=)dE5!C)M+X/0Eo:`F35,+Q<e56Y!C)p/q5>&)M/0@3)&!"+0#;6?UnP;-:!"+0#;6srtEA+-:@3"e:/)&!Eu7#;(GhUv+063)M/X/0H;b$P;-:!"+0#;6twIF"56!CD"@<=<K)fHK)&63ES%x@!@(7*#AGhUyBz8{&|}|}~2MfA3;Bdd?shL;;}+[+06Y>A"!"+04Y)&!"+0#;6%#'-:@3,9#;6!(5g"5F3)&:)&!gE#A<K)M+0635U7#=#&%!=E#;<L)M+063 )&(J13);"E#;6))M/0N7#;"/EuEA+"!"+01@!Eb+06Y!5:);-:!"+0>;W+0<g@/)&!(#;=-:#;<=<=5C-(+)M/X/0HoE5>;:/0#;F3E%#;8<8+X/X+Q!:)&Hd!:)M+06+Q64O*)p/.E5e5!K)M/}U0bD;;VT:Ujfi+0<g@/)&!(#;=563)&1/0e>A+.)65!"7#;GA+Q64#&%J"5>;5:)M/ -:#;<=F@!5C-:)&!,+Q#A6=#&%/)&4;5N}-5)p/Q;bV;n"H6!5!"+-13)&!!,/Q:3:/E5b7959@<K)&635b);7:/X/)A$Y@63EE2#;25>;56!#;@3()&63E2#&%?+06Y!(://X+04;56! )&63EW"5<+QN+06!:/X/X+Q4A56Y!)&4;56!C-5)&6W-:#;NF3)&!"+-(+0F3)&!IO$)&<813D5!9)M/}U0b;;iT:U3C"!E#;<L)M+06?bY\[!!C);-(G=Ov+04;@(qfTCb&+06>;#&/0>;F+X/0#;!9)&4;56!C%#;*)-:#A<=F3)&6Hg#f%aO@F=!#:+04;!5T"H6Y!(5!"+-J)&!!:);-Ge:/+-:#;F!(5C5UJ-:#;<=F3)&6HW"!C)&!:*)f!9!#;<=5N13)A";b795I!J-:#;<=<L)&63E5F+X/0#;!fi)&4;56!I3C"!W"563E=#ACE5C=)&63Ej+063"!@3-:!"+0#;63L!(#d!t-:#A<=F3)&6H^<=5<815C5Unt-:#;<eF3)&6YHF#-:"8!("W#;CE5Ce)&63Eu!56o1354f+Q633HA+Q64u!#&79)&CEI!:+0K"F-(+X3E(;X8&5;3ba+U;U0b!)&)%x#A<79+-n!-:#;<=F3)&6Ho7+X/X/g)&!!C)A-Gu!fi565<8H;Us+X/0d56#A@!fi!#!13)&!!"/05NF3#+0!"+0#;6?bhE5F563EA+064fi#;6!#;CE5Ccb!g-:#A<=F3)&6HK<=5<815C9<L)He3HL!#;4;5!5[#; EH63)&<8+-5)M/X/0H"F/X+0!8+06Y!(#tF(5N}E5!5<8+06Eo"@1!)f<K5U963-:W!S-:#A<=F3)&6Ht();-8)Y;X;Ye;3b+0!g3)p/Q!:5U96d#;L!"7#o:;D:/+-:#;F!(5CL3H%x#;(7)fCE)&63E3C,!S-:#A@!W!fi13)&!(!"/0tF#Y+0!"+0#;6?U);"E#;6-:#;<=<8@6+-5)&!"+0#;6e%#;<!( -:#;@!Ccb;#;!5-:#;<=F3)&6H8<=5<8135Ca3H8%#;79)&CEI!#!D13)&!!,/Q[F3#Y+0!"+0#;6?U[5;bM+063EA+Q>A+E@3)M/?F+X/Q#A!C5F)&!EA/0H8<K);"GO}+E&T?!:+0:/X+-:#;F!5C2)&63EI@6<K);"GI!#q,#Y#;!$<8++X/0)&!D565<8Ht!:)&4;5!CcUJ963-:e!=)&!!C);-(Gfi-:#;<=F/05!cb!=:/X+-:#;F!5C54;#;@Fd)&63E5!(@6!#K!(:+Q#;<=5N13)A";Udn+X/0fi56#;@!(K!#!W#A<=5N13);"O}#;I+06+0!"+)M/X/QH!#&79)&CE!(K13)&!(!"/05NF3#Y+0!"+0#;6T:b+X%)&6Hg-:#;<eF3)&6YH8<=5<815*"F#;!C$565<8H8>;5+-(/QF3#Y+0648)D!)&!!#I!9-:#;<=F3)&6H;b&+0!)M/05!C#A!5C5U-:#;<=F3)&6Ho!56n5>p);EW)f63Eo1HYF3);("=!(t565<8Ho>;5+-(/05bD79+X/0^)M/"#uF#;!-:!,+Q64+0!C":/X%@3+064J4A@635Un56=! -:#A<=F3)&6HJ5!@(63)M%:/0H8!##;<=5N13);,;b&+0!)f<K)&63E8(:%x@:/5bA);EHA+Q64+0!C":/X%%x#A!=6:`!<8++0#;6?U=\D6d#&>;5>A+057#&%*!(=#&>;5C)M/X/")fC-d)&63EE5>;:/0#;F<=56!J:?#;![+06!+E#A<K)M+06?b+0<g@/)&!,+Q#A6=+06%C);"!(@3-:!@;b;<+/0"!(#;65b)&63E=)&4A56Y!153)>A+0#;C+F,56Y!E+06WO+X//5! )M/}U0b;r;T:UHOLDINGPOINTHOMEBASEBATTLEPOSITIONRIDGEENEMYVEHICLESv+Q4A@=;\9!(!C);-(GKE#;<K)M+06?-:#A<=F3)&6H=3HA+064=+06t,@1!)&<K6!K"-:#;63EE#;<L)M+06?bBC)&63"F#;!8Ov+04;@=RT:bh"H6!5!"+-8!C)f63"F3#;(! :/X+-:#;F!5CIF#A!-:!E1Hfi-:#;(!:/+-:#;F!(5CD3H"HY6!5!"+-8!(#Y#AF39!#L/)&63EUI}6u)L!HF+-5)M/<8++0#;6?b?!"7#L#;D%x#A@ -:#A!:/X+-:#;F!5C8)&63E%#;@!#W!"7:/Q>Ag!(C)&63"F#;!D:/+-:#;F!(5CI!C)&G;8#&d%#;<,5F3)&C)&!="+0F3I)&!q,)W!#563E55>;#A@39)&!*)/X+06GYN@FF3#&+06!U(-:#;!C!56WF#&>;+EJ)F#;!-:!"+0>;J-:#&>;52!#8!D!C)&63"F#;!:/X+-:#;F!5CE@"+064W!56!"+0+Q4AY!D!#K)&63ES%x(#;<!:+0DF5N}"F3-(+X3E/)&63EA+064W5#;6eO}795I!fi*L?;.YM^2;"Y(5";3A"e;YcC;KpQeKM0YA&0; (&K$&?=J55W"Y5,.0;&;5C[}D&(;"9f3A53:;Y(5C3M0A;fi0;g8"& :0;;LANDING ZONESEAESCORLANDESCORTRANSESCORPORTSTRANSPORTSESCOR0;(JC&3"; ;LM0W0t"5":A9&3W:&3"3A::;(5C50C;LM0nfi;"Y5,."'5:5[0C&o5M}08;;:A3.&0Y5(3&"0;3M "5:5=;(3&=5;8;3ACJ&3o,Y5"W&;5C5M0=ofJ;e;"0"fCQeg0"&A5Y"',5K5e "Y(5"9&;5C;&pA5fK$XXh3&,.(03&(0K(3C,*;fiff ;(3&=5*&ff D0&3&? "3&3"A0W0;8"&":A=35"0L&Kc[0;;:0Y"3$;B;5:"3;9:;%;KpQIXXQ3,C&"0;[&3(&8*A%q(3MX05;5!"&fi$#&'(8;?00"M}0=05=5C&"0;?(K:X:;5=X0;Kf;5Y:5K5;:0;u0u);&05;C&(^&A5Y&C(0:+*[5*:X};9Y"50YA5WM}0D;&:,&;(oX0;Sf;5YeA83;";"53&:&t:AYu&-;Y&M;=A"3(X0;D&;5C&A=05C&C(Y9;=. 30;/,pDW3A"0;d&9Q5:&C(Yo"B&8;0Y(Y9&8?1Y"50Y;*M;;C5C&AC&;5(08X.ffioA:"0;.f3W:;==;0n3"0;5W&;5fi&C(0:c "3(;W&C(0:8:"0Q2;:,QA;3&;(^A35C&(;J:;3"CI&:;3A0"0;o(Q;K":0:"0;?IXg(Q;K&X5&"0;d:A=0:;5C&;="AYM:CD&3nXXg(Qe;5Q3f"0;?49afYI;&0YA;0J;3&(JA;8$Q5:&C(Y.A:"0;;M} ;0M0;&;53&03AQA3M5ff L353MA0;dAg(&8*A%t&e;Q3A0A3M59;KM0"(6 ht:;CA03&,QA&325 ;;:;e=;0K;0L;5"3L.7?;C0L"3D&;LM0fi[98":&M?;;323&;;:0;":}fi=<9:0?>5;;A"@?M0C; ;CQ3(03A0;L&9"B&8fi5fiM}0A;C;5AB*Q:"5?M;/2;C;(};e03"C&3:;DMx(5S:A"0o3&"030"0;?h8:A9:':(98&fi(J0;(Y"DpQ,Qe35033&93f"03YQ,QAL.:;(}; "&9L0QA0"MXQ;0K"/C(5*X0;9&;5C&355588;5(QcXQQ(L353M;0;:&3L:;f0u&;5D0Y5:;:"0;?5&:XQu5&o:;CA03&"0;u9;;DCA3&=(t5=;3,C&0353MA0;C5E<9&5;53A9IY85C9f*&;5C9&3;5(Qq03:;":0D353M0;C5I5"&3;KM0W:35C}K&WX0;C:35&fiL"3(Xfi:;=0:fi80;350;6 h5& 835C&B3&"(03&fif;5YQ5CA:"0;39""};:;:L0WDXBFHGJI.KMLON+P Q RSTN5UWVYX.X.Z\[JRE]TP%R^2_%`1a.S5RbDcdR]TPeT]TcObDPL\]TeR%]f]TUDPghLH`i_jST^R]kKM_jLlIHNmKMP+LONP+enghLOeT]kKM]TcD]TP oigTI\gTp0U9R%e;qr_KMLDPbKMLsKML`icOST]TUDPS0STPeTPYRSTN5U-RLDbs^tRYKML\]TPLdRLDNPE_%`fi]TUDPgTI\g4]TP%R%^EGuWU\KwvMPE]TUDPRcD]TUD_.SN_.L\]kKML\cDPe]T_x9PSTPeTy9_jLOekKMx\vMP`i_jSf]TUDP]TP%R^zA_jST{|KML-]TUDPny\v}R~.PStRa.P+L\]Te[_j]TUOP+STefUdR.PE^tRbDPnekKMajLHKwdN%R%L\]EN_jL\]TSkKMxOcD]kKM_.LDe]T_EKMLOb\KM.KMbOcRYvR%a.PL\]x9P+U9R.KM_.STeGfiA?;i?%?.?%?\h?\.\WOifiEXECUTEMISSIONFlyflightplanPreparetoreturntobaseEngageFlycntrlrouteHighlevelLowlevelSelectpointSelectrouteMaskInitialize MaintainhovermaskedContourNOEUnmaskpositionEmployweaponsInitializehoverreturncontrolpointDipSelectMaskGotonewmasklocationPopupEmploymissile............;i?%1n%jlldfi4%Yl96i 9\DMf"\.9%i\j9j9%?s?".\%jOiiDEi%h .-i.fifi"9s\i%?-\OA%?\9.r6i"9"5.DA;?%\h9??D.ji"9iiD%99i\9%D9%W5O6i?%Dsi?-d9Y"\"%ji"9"W.?\jhDfiO951;i?%|6hj-YlO61%9-i 91? %D9%sd}i?%DH?%?ii%? .\%?\W:\ \".?\%DA?-9???D%E%?Ds5O6?DEh r?%?\(?Y9tlOi?5"D6JW.ji"9ih9"\9"i"\DAss%?"j9??%:9%\-?%DA9\\D;%?\%9%\\.O1}.YDH:;ijO?\%Eh?d\j9ji?Tj9\:%%"9hW\"9i9Yi"9Y90%D9%5O6i?%D\%? %D9%O6i?%D'+"Y9?"D%l9YY??.?"D.%Difi:??AWfiD?Of? ??D0D \O5\6605%m6\m6%d\O%d065E50%% d.mDs\9Ds\9%?55mj5EDsH5H}OD9\H9O6s% %54\A}m0\0OH9\45\5m6:Dm656D"0DmjDm65lOi96)\mjf5OHd3H65j?'06}W56O6-+O5\5mj96hDmH+?'9hDm5\5}95 D:.5j})Y+\mjW695}665i9O\?5E55H15Ds\90500\6mjs}96m%6EhD0m+Oj D56 5+HDD66D\O%9jY5j96W555.W}m665iH?D+%5hO5O55jTf5-5\0\+5H556D56m}O"9066650mj\sH5%fi4%m6h0%6\0mDsH5D}s+OED6m-5sDi96-H5jWT\6fiO5%E%6iO5%m(Y+\mjODmD 9\045D0+O5j5H556fO5656D\99\\ 0\65j|69}m%6 h O16m1OT}m5%9Ds\9E5O4hDmH+?%m 665i\D+%5Ejmj96rH6}.5lH6}%H5E5 D56-mD6 55.\% %mj5OHdE %m10\6mjs}96m%6 0%-m%mjDm.5nDi96D69jfT5m5m6D45%949mDsH9%6}Ofi\Dd;5mD0OHdn% %5A4%5f6D5.\j%\551YD\%.5j}n5%9A506};5fis% %5?4%5;5n0}mD5%A+\ff9j 0fi %YD5%m%m14%m:\65 m%6j\mDmi\5O56Dj661DO96H %% O%i6Ddm%5.5O5D9O%6YDm%1}6O HD%9fi.5j}9%5m5\Oj-mDi69|D5Dfi0\4Dj?m6:}6O\Dd9iD69hDm O55jA\-md\j5+H59?6+6mDfd9H50mDmH1HjfTl\-Ym5%s%H5D?0%H6JOHds% %m0+\Df\HE656\"9mOHd|r\66j5E}h%05\05%6065m}ODsOD9m}9O01E5%\+H5YD\6%4\A%6iDm%5f15D%Y%9+\66H6}\4jEm 5m+HD96 m\%6j.6jD}050695%h%50\6O5?\H:66mH\%m+HDh5OOfiHm1OH9Ds\9%5}mDs\9E9 6965%69"!$#&%'()+*+*-,/.10.2435687-0()9:*;,<'=?>;0A@CB:'DEFEG.H;0(IDJ'5@LK':'1B5E-0./'EF9:*N0E-,O-0;35J.H'">-0BB:;B)'5EP0 0,2QR>TS:Q 0,/>-05,ffN,VUW0"B5+X :*.&9' ;,H,Y,ffE =Z0[+*Q;,O-0[3\.'P>]\^-1,/.E 'E:.;B_E`0 .-0a*?E-,K"$.O(b'Y 0,.HOc,2SC,/.H( 'E:./E:;,.', 0[*9F.'\E ;0,ffE*S '()9:*87d.H;0(IDJ'5@), E-0/'T,Y,/ Ob=e0[+*;, '5ET./E:-0[*+*Sf ;KVg&O:-,Y0F*N0H)E:(6>]I'=h,/9- N0[* 0,/ 'T'8B54E-0A./'E`9:*N0E-,I0H)9-'.HET./N0[*+*SiE ;,,0SKj4E-0a*k*SYl.mn,B5+X :*..'I-,/I,/ Of9:*N0E-,oEG'.HOhB:'(P0[E-,Kp 3Eq.O;,/rB5+X :*./;,YD&GO-0[3s91,/;Bq0Et0[*.HE-0./3r099'T0 OuU9H'a35NB:`0E:.1,D&.Os0IE10[*v()'B:8*V'=w.H;0(IDJ'5@LKlg&O60AET.8, 0AEf.OEG.O(F,/8*3;,H;0,/'EG0>]'..O8 'Q'1B5E-0.24'5E x '()(IE: 0./'Ef;,29-'E-,ff>:+*+./a,0,DJ8*+*v0,&0ET.2 9-0.Hy0E-BF0[3'NB_zZ'{H 'a35V=R'(f|.;0(ID&'@<=Z0[+*4H;,K&% Oc0AEc0A99'T0 O60[*N,/'H;}:;,V0EI879:*+ .&9;,2ET.10A./'EI'=L0E:.1,~[.;0('T0a*n,\0E-Bs.;0A(9:*N0E-,l=R'.O-0A.N,\.O)3Ss>-0,n,y='5";0,2'E:E0>]'.".;0A(6D&'H@LK)<E:='5.QE-0.8*SY:.Oh0AET.[~,v'59-10.H'VO:10 OTSF,/O'DE\4Ef\9;,/E:.1,w4.8,V'DE)0 ./354.24;,K{g&O:-,Y0[*.O'5OP.O0E:.lN,&9'35nB:;BcE:='5(P0./'Ef0>]'.V.1,.;0(b(P0.;,Y5.O8&9-0./ 9-0./'EFEF9-0Q./ :*N0h0 .2435./;,n,oE'.{879:*+ .\zZ>.{80.O;YA4(b9:*k .<4Ef.HO ':'1B5E-0./'EF9:*N0E-,8|1Ky,&0H;,/:*.;Y.O0E:.v(F0[E-,45E'10E:.w05,v.'DO: O6'59-10.H'1,.:*SET3'A*435J.H;0(IDJ'5@y0AE-B".HO{.;0(b(P0.;,ET35'*3;BsEi.O(GKF'm4E-,2.10E Y&1[TRI8Nj0E-B[T5;"0AIE`H;0[*+4./Ss.;0(0 ./354.24;,ET35'*3Ef.OE:./ '5()9-0E:SL]DO:+*dI8y0AE-Br:-I8ET35'*3"E'F.;0(ID&'@ KV.OH()'YEP,/'(b{.;0(.10,2@C,'E:*S6,/>.H;0(P,V0ET3'A*435;B YT0BB5E".H'h.OB5+X :*./SI'=-8*SE\'E()9:*+ .;fi {:;2T1A/-ff-8PH6H;)PH;&:;jr;A1/aH6s)I:PA/N):+NHI;/:1/rH6H;8/H6H6H;b6]1- HN:T/N[8/5/;)<-/1-8l8-ffN:"H;8//-rIR/[;+N:P5;;8VRGZH65c2;1[8N:+{5?HoA1;1&VvlTkHRR+lCRNb1:R8Z<J8518VH-/]Tff/F:+h<Z81l[8vZf/-H)12C"4A4:V- HP\;8// -fo4No)-H1:hb;/:yA-f;2]68I:;s8/54/f-AJH;/:1&&:Nh5+d8:/FH;/:1/FN<h/];HkL\bIThA1:;8H\T24H ckf 1H:;8;o)T245;Fr;8/iH&)-H1:/-8-8I1AT&&f8:+NH4H;T[N&-F:N-Hy88[G8)I):1-s8:15-/;/-5-ff:k+/;I1<I;j--2;sGH)1[V):8;I&b:4; Z)-/-8< -b8:kNH;/:1/b ;ATan-:N-l&8+J8)c4H)T8-s;/]-ff:++424;bj-:;V:1I 18;j8rrb:P/Nf:F[Z/-;H+LG8:15-245`:N-;5rs ):/;;I& [+;V)V-fff "h] Pv51aL;I&\/;&-[<-f]T/;cf+1A\{f;5L[vHT/)1-;vA:4:&;v<:s6[ZV;5:1"o)/;H)TH-:;j-f54H;8/r):):;[jNsf51vIj-F-/;`5"G2-;H+L/G:G:;ffvo ;8/-i1ae1AG-A :5P[Z/-;H+LI;5/:8;/;/N//N {;A6&HL v:{/T]; -1A/-[LH;IJ5"):8N&8:N-5T2nak) 5 ;/s24;H/-8s /-Hq)C:8NbP[-F- :+8:45;r-_-:1/:C mZr:8:rT]&"-[ 8-/;js--R[-RHf{G ;5v;vC;5h[Z ;ff$-d ;5?;5;:1A451G:8[+4; P["/];HkLA/-;8//i-&;&fi:FT:/-_un/ -f5J;bs;8/:/P8f:+Nfi/:{::/-\[)--1ak8N<]T/8J+fT8 \ :/h n:[?;5ffT/];$ HT/h 1A- ;:8&j-;wnA-IjNIH24 -i5J;q;8/$j;8/j/1H;\):+N/-I )5/;ff"/+;\)1A/-[ P:;ff:;HNff-qjC8;Hf/ -8)-A;)H-:++/;f5N:;:fi:THT/-A-s-;wNs/;\TN<N;/:;d4r:1akVi;8/-f-"!$#&%('*),+.-0/1+2-43.+.-5)6'"+"798:*3;'*<1=&>fi/:THT/- 8)&s` 5;&;5vV;$;v ;HF"[Z{[ff:C8-/;oGI;@?Afi:):1[?/1A[+4;jN]{-R[-R-A;ACBDfiA4:/b4:-; 8/f ;A)I-1<Efi/T/G8bI;fHP8):/F-;A8/v<:kI-[+)-8+54b-VI&h:m4[FGfi/T&8)IbTlFIN{:8-;FHfi:-8ffN/:T[lff1:&;IB?ff6H:JT<Jr/1A- 8):/f; 8/v$n:5;GffB"(KJ.Ll1ELsNfH84-8PHN-/Mh:;H8/-;j-8"]-:;I;HP:fIff/:NfHPI-[+f-8+0L I- [N/&ffK B".J.NoN rH68-5/-"A/Nff-;(P5QHRTSSUWVYX[Z\ZV]Z>^_VK`baFZ>cdUWc_X[SNSe ^;VKSfVKg5VhUWi_X[UFj@fNaTklcff`W`bVKmUWSe>noX[SaWV5Qp5qfirts;uTvwx(y{z"|5}ff~6_|1}rH}ffvTu>swffHTWY[MK>;KW_5E4WdKT>ffb_4;54$5$ 5dWffKM>ffW;4ff4GW_[Wff]4b_EK1KW_[N>bWff5ffHT_bY4K>;KWA>ffW_[Nh_KK1TW;4ffW0>ffb_4Eff4b; 5bffK5ff_1WdN]54ff"1.WbKK54.bffKE>ffb_4_]NK1Fb_42Wff]t5bd5E["Y4E54d9T ] "9T"ffff]ffffKb {NThW4&K>;K"9NMffK"W;45dt[*bffE1N4ffEff1Y_]NK1KDN>ffbWKbN o4b4_ [bW{_K1KW_[N{Wbff5Ao 5(D@_4][5l]]>K5Y[ Kd5ffffb54W]N945KbY{b;5bffK1Y2ff_1WdN]54ff 1 WW]N]54;YK4dWGo4WK{_4T1MNbWYhW>;ffWdNdW54bT;KNl;Y1 >ffW_[_;KdEKd;5{.ffb{K.ffMG;K5Kbff45]4b.9>;ffK5CYffH]K4K9ff]ff*{ffEff.Y;K45hK.K594.4Y4ff;5d9>_lNTGK.1.4ff5]9.9ff];4ff5(..dK;4;ff K]4;5 Effb41ffFffK.H(TK5d;K5K594.4EK5ff]0@ffEE50ff];4ff494; ff_FW>MYff>MW_H(Y; 4K> 6MK594.4HK5d;K5E@K9ff;ff ffYEff;1.E2N4ff5K2,1ffH E4ff45ff; ]@.4ff9K.G.dEK4K.]5{Wff6.hK4dK;4ff5(2.ff];4;ffMKK4_.t25ff9dE]T9dKd5(T].1".lMoEKff9]94_K.1ff{K;"5Y;K.2K2EK EK59{K5E.d KYK.EF]K5Yd0ff9K4_MK.E;;64Nff9;4KH]Y1K.1T2N>GK9K4K.ffh6M@ff4ff.5Mff ;6hff9K94;E4.K5HK.HK594.4tlY1*K5.dt]K.FK5ffd54_.]_.;d"55KKlNMWffTAff" ffK]9ffd(.Y.ffffff.6;4K.YHW1]K54;K5ff5ff; 4]Kd90.;4EK4K]59Kff.ffl1ffff..;d;YEK590K5HKMWff;bK.ff"fiffff9]94_hDffff.]W1K54.1ff;5{ff4@KWGff>.9;ffK0ff0.;4>Eff;.1ff9ff9;4K5EKYEK590K5HK5Y;K.F.2ff K>]4K.ff@]>4_ff494;5AG4_K4_];ff9K94;@ffEMK.Y{;6dff1>K55Y;NDKdK{].1T.,.d9K94;Y4{!"$#.245KdYMff{1K.K5%'&)(.d9K94;YM ffK"*,+$+.- /Td4"{ffEEE]o4KhK;Y4Dff];4d.];694.4Y{.;]0.].ff9]ffK{K.1t2W].ff5d>K@5Y;94;102354687:9;2=<?>=@$ABAB9C35AB0,D!3E2oNEff ]Ft]ffKWHGEff4K{K;KffK">.4Y6lK4_>E5dK;4ff494;ff_1E>MY>M dW*H">;4dK5ff9]94_@K5KJIG94.4ff ;K5hKKdKQP!Gfi* LG MG$cM5Y;N;DfiNff dW ;"K52ff.[Z\X=X=S^] fiX _ ` baec5"5]]4W44WT;5b5bffK1F44_h_1[N d15ff`YffG\ffKK0]5h;NMYEK590K5FRTS VUfiS$WYX5H ffW]td]YK51" ( "K(T d$Y5E]__4"5" ffW[W5[4FK1KY[(ffTl5MWWF`fd_"RgS VUfiS$W%Xh ic[j8kl!mn] nS,opUWYS qfkVl!mn]1Z\X=XrS] fiXcs8tvugwyx{z}|Y~rELYL^|QK:B%|KLBu1x{L/C$=H~5H|QtLv%=r=$,:|%555Hgugwx{LCL5Bfi=,.Q==rttv,ugwyx|QL~5L,L,~|YL55LH=|%H:|Y,~5,fizfizfiKK$,=!L,L,L5y5~ELKKF5YKL%zfiL,~5EL,EL=$tWdKWWffff"5bffKff5bKT5bffKff >dW_[ff_]N.GW_["9_[Fbff1051ffWbffff2WKb_1_ff;_4bff(TDW5bffK5((W(T>1(TDW1bffK5E$O[W[5WM5bffKWhW_[fifi"V$Ev5$$,pI^\5\$Cpr,rVCV1$fi%VC\%.%=VvY%$V,B[gv%C=VC,b%%VC\%$%=pv= V=$vV%BV%IV1= Y^F=[=%YY, $=.HV%$;/%v'%Vv=1%85V='rBEv%.%= v.%rVvv.$r=.v%rVr\%gV5$r=,VQI ,=$$C/%[ggpYff$%B$V$ fi$g V,%vg5%B% .,v ^%='!=:$,/%v CB$%V$,fiv$YV^Vi$\%%= vQ\V5$ rg%, %,8%% .%$!'!=.,B%v% V =C$$YV.,fi v[Y%%p$Kv;fi ,%%$I.;{$$%%.$i vF%Yrv \% ,%%$ r$%ff; =.v%rv%, ) vr."%Ve. $%rv$ v %%Y$$gB% ?v.;%,f%, vr v=$vV,!$Ci=$" !v $!%I%[,=V;Q gf1$# $ ;\.,=V;Q,f$B$V%=5v,$F.$C$v\ $/%, ) vr iv Qv%1$Q %v$,%v% vi.viC%Qg5$5%%g$' &fi(*),+.-0/21435 687:9;1=<*>?@/25"A23Bp=$Yr$\%IHV\Y$v8yY =.v=[DC!EGFIHfJKLCg$\v$, $HV%\%$NONP %\%RQTS\=vLNNPU%%QQVCV,DNONW"rpvY,$fiXVrfY%vVM%=,\$ /$=V%Q.v%%vV$, v5 4F$, ZYIE$5!FVCYC\ Cg%1$V [L., v5 !5COi5Vi$=$ \f.,/v.$CVv"$V [L] !5 v5E iE.CF.%,=%,IY^F=rg=Cv.r%$ [L.=$v\$\%rFI$%.* [LV$=Q.^Gv5 v5E E$CgV !v,.CiB V %v$VCVv..;Vv^[%rI &$1$=$v8vYv.= / VCQ.?$=Q.v%vvV. .Y:rYgr%, %,%, $F%, %vQe$ $%$,r$_ &%\%Q`S\=v=NNPar\bCg=%:cedVE CvV EG FH fXF$[hg E=5E$ C! EG FIHf L L =v/:F!%iV !vV$ffXfiv%5 %{=f% ' &gv$[IL = \ X%V %%,Vr%v$'F%i$Y $Qv,=gIHV1$=Q.jCeVV% ,fikVCIvYvV, %v[!==iv $Y Y= V%Y,Y!jlnmYVolDm ;'!,Yp !$ i$=$vrq*sFFVCY F ,=%, vV Qv,Yt !v, =.v%rVr=$vQY%,\v5$ v=Bu i":XL'H* vMw* i* kXx* k * l V$%,g/$%.oyLz[L\VC 7g rk x %V $=Q. igQkDmv%,YvMlDmfi{% |v$} XL KHf~ vw k xkDmfilDm;t %\5^i=$v.$v\%[%C !v,=,X}t,%JYpv8Z , hIJ"tt' ' Z#$' G , \: %nZ2$0 $p pt p,!enF$ 5 , ZJ0% ,% [ }!}.0$X}t[%JV%D0 JOZptDV' ' ,L Z}X[ $prt VFE,$L$yG '"}=$C $ rt VG 0\F tJ, TG 0:y0[p Z5$ ' 8p,Vt J$ *",u LK ;ZG]Zt$"Z : $2 =$C:Vt ^ "rKYp8u 0V' ' ,L Z0$YpF_ $ } \prQp V RZ0 K$p JV$%%J:Zu 8@=$C ] $%"%JV%pF. $ b C%2G0KGX'4_]ZL_f0p'u*n0__J;b,~J}K,==K_D;,';t4'K}f_J:]0GL0K_"'GGfiu"} =r* Z X }J} fffiff ! fi#"%$'& "ff!fi#ff()+* #,-/.'021.436570#8'9:;36<>=.'0?57@A3BDC EF50#B=7?G8 0#B7HI5DEFJ402=7.'0K0< =DEF50MLN0JA?POQ3R=0#36S2TUBVEF< =0<=)EW?X<4BY36<48J40I:EF0IOffBYL.'0<>0<'Z 36Z0#8GEW<>=70#36SL[?X5\^]`_ff<>=. E;B0<48 0#3ba?5bcd3P<fe19g50C'570#BD0<=IBh3`:EFSEF=DEF<'ZfH3XBD0ij B j 3b::F@c'L.'0<k0<'Z36ZX0#8EF<M3=0#36Sl3HI=DEFaXEW=D@c'3=70#36Sm?< :F@Y.43XB[3VC4365=DE;3b:1.43650#8'9d:n3P<2op9/19Nq(] -N.'09N19rEnBs3MBD<436C4BD.'?X=?6O[=.'0=0#3PS2TUBtSY0<=I3b:uB)=(36=0sEF<A3kC4365=)EnH j :;365B EF= j 36=DEF?<REF<v=.'0IEF5s=0#36SLN?5\wc36<48RO j 5=.'05HI?XSYS j < EnH3P=DEF?<A36<48xC :;36<'< EF<'ZRE;B?6Oy=0< j BD0#8z=?{O j :|'::=.'0KHI?<48XEF=DEF?<4Bs?6O36<ve19op3b:F=.'? j Z.}c~EF<G8 @ <436SE;HY8 ?XSK3bEF<4Bcw=.'0=0#36SSK3b@M<'0a053HI= j 3b::W@ROy?5S36<e19/q(]~v0sO?'H j B?<=.'50050I:F0a636<=3P50<43BtEF<xL. E;H.vC43P5=DE;3b:EF=p@RSK3b@M0IE;BD=VEF<G3M9/19]^e EF5(BD=bcw=.'050#H7EFC40KRSK3b@MJ~0?< :F@vC43657=DE;3b::W@BDC40#H7E|40#8w]x057=(3bEF< :F@c}EF<>8 @<43PSE;HY0< aEF5?X<'SY0<=IBcB j H7.>3B=.'0Y?<'0#BV?6ONEF<=0570#BD=EF<>? j 5YLN?5\wc50#H7EFC40#BkHI? j :;8>J~02HI?<4B E;8 050#8>=7?0aX?6:Fa0K?6a05=DEFSY0cN3Bs=0#36SkB570#3HI=DEFa0I:F@f8 0#H7E;8 0=.'0k<'0I=YBD=70CAJ43B)0#8J4?=.?<=.'0MHI?<=70I=Y36<48z=.'0MH j 550< =BpEW= j 36=DEF?<}]ve'?X5EF<4BD=(36<4HI0cuEF<>=.'0==I3H\8 ?SK3bEF<}c=.'0M.'0I:EnHI?XC'=052HI?SYC436< @vSK3b@50#3HI==?v0<'0S@a0. E;H7:F0#BMBD00<>0<'5? j =0c=. j B0a?6:FaXEF<'ZM=.'0IEF550#H7EFC40] HHI?5I8XEW<'ZR=?R19=7.'0?5@cw=0#36SSY0SJ405S j BD=3655)EWaX0h36=S j = j 3b:%J40I:EF0IOEF<2=.'0IEF5<'0I=BD=0CwoDBIq}D][e?50#3H7.B)=0CM}EF<2=.'0s50#H7EFC40cw=.'0s50I:F0a36< =B j J'Z5? j CMS j BD=/O?57S31.43650#8'9d:;36<}]10#HI?X<48wc=.'0R=0#36S2TUB=(3BD\3b::F?'H36=DEF?<SK3b@>J40> 4D(I~#+Ic%0]Z4]FcN=.'0x36Z0< =K?5kZ5? j C=?C405)O?57SC4365=)EnH j :;365=(3XBD\xSK3b@<'?X=J40M8 0=05SEW<'0#8w]`_ff<>=. E;BBpEW= j 36=DEF?<}c%=0#3PSSY0SJ405(BVEF<=70<48=.436=t=.'0500I E;BD=BD?SY0VEW<48XEFaXE;8 j 3b:[?5B j J'Z5? j CR=?K8 ?k=.'0=I3BD\w] SY?<'ZK3XHI=DEF?<4BHI?X<4B E;8 050#8x3B350#B j :W=?6O%=.'0EF<=70<48XEW<'ZM=7.436=#cXEF<48XEWaXE;8 j 3b:BVSK3b@Ya?6: j < =005=7?YC405DOy?5S=.'0 j <'50#HI?<4H7E:F0#8x=(3B)\^c?5C~05(B j 38 06b?5(8 05?=7.'05(BN=?Y=I36\0?aX05[=7.'0=(3B)\^]-/. EW5I8wcwEF<48XEFaE;8 j 3b:;B{?5B j J'Z5? j C4BSK3b@2<'?X=.43#aX0K36==(3EW<'0#8x36C'C'57?C'5DE;36=0YS j = j 3:J40I:EF0IOBsOy?5Oy?5SEF<'Z>36<re19c:F0#38XEF<'Z=7?AHI?SYS j < E;H36=DEF?<LNEF=. EF<=.'02=70#36S2]?SYS j < E;H36=DEF?<SK3b@>3b:;BD?365DE;BD0M8 j 0M=?v36Z0< =(BTN7EF<=70<=DEF?<=.436=I236==)EW= j 8 0KJ~?=.>=?6L365(8'B=.'0IEF5Y=70#36SZ? 3b:/36<48=7?L365I8'B=0#36S{SK36=0#BT3HI=)EWaXEF=DEF0#B]%e'?5EW<4B)=(36<4HI0c63N=0#36SS{0ShJ~05#TUBEF<=70<=DEF?<s=.436=wEF=(B=0#36S8 ?3P<3HI=DEF?<}Dc36<48sEF=(BuJ40I:EF0IOd=7.436=HI?SYS j < E;H36=DEF?<k?6OB)?SY0C43657=DE;H j :n3P5%EF< O?X5SK36=DEF?<{LNE:+:}0<436J :F0=.'0=0#3PS=?8 ?}Dc6LNE::':W0#3X8sEF==?HI?SYS j < E;H36=0N=.43P=}EF< Oy?5SK36=)EW?X<h=7?=.'0=0#36Sop3B:F?<'Z3BB j H.YHI?S{S j < E;H36=)EW?X<8 ? 0#B<'?=HI?< 'E;HI=LNEF=.2C'570aEF? j BHI?SYSEF=S{0<=(Bq(]}Fl^vb~[w4}6R4 wv^b^ ^6n{}sM_ff<1- c p?6EF< =EF<=0< =DEF?<4B3650 j BD0#8z3BJ j E:n8XEF<'ZvJ :F?'H\'B?PO[=0#36SLN?5\w]{10a05(3b:[38 a636< =(36Z0#B3HHI5 j 0x8 j 0x=?v=. E;B j BD0]e EF5(BD=#cN=.'0xHI?SYSEF=S{0<=(BhEW<3kD?6EF< =YEF< =0<=)EW?X<rJ~0Z6EF<=?vC'5?6aXEn8 0x3C'5DEF<4H7EFC :F0#8>Oy5(36S{0L[?X5\MOy?550#3BD?X< EW<'Zv36J~? j =YHI??X5(8XEF<436=DEF?<>36<48>HI?SYS j < E;H36=DEF?<zEF<>=0#36SLN?5\w]-N. j Bc6=. E;B Oy5(36SY0LN?5\J40ZPEW<4Bu=?38'8 50#BB=0#3PShLN?57\Off3bE: j 50#BB j H7.Y3B =.'?BD0EF<Ye EWZ j 50']%10#HI?<48wc=.'0%D?6EF< =[HI?SYSEW=7SY0<=IB EW<sD?6EF<=uEW< =0< =DEF?<4B%C'57?aXE;8 0Z j En8'3P<4HI0Oy?5%SY?< EF=?X5DEF<'Zh36<48Sk3bEF<=0<43P<4HI0?6O3M=70#36S3HI=)EWaXEF=D@c}Eff]0]nc36Z0< =(BsBD.'? j :;8vS{?< EF=?5hHI?X<48XEW=)EW?X<4B=.436=H3 j B)0K=.'0{=0#36S3XHI=DEFaEF=D@v=?J403XH. EF0a0#8k?5 j <43H7. EF0a36J :F0?5uEW5750I:F0a36< =#cw36<48YSk3bEF<=(3EW<M=7.'0=0#3PS3XHI=DEFaEF=D@K36=:F0#3BD= j < =DE:?<'0?6ON=.'0#BD0YHI?<48XEF=DEF?<4B3P5DE;BD0#B]-N. EF5(8wc3Vp?PEW< =EF<=70<=DEF?<G:W0#3X8'B=?M36<x0IC :E;H7EF=Y50C'50#B)0<=(3P=DEF?<x?6O[3=0#36Sl3HI=DEFaXEW=D@c'36<48{=. j BOff3H7E:+EF=(3P=0#BN50#3B)?< EF<'Zh36J~? j =N=0#36SLN?5\w]w_ff<MC4365=)EnH j :;365bc3XBBD.'?6L<:;36=705#c36Z0< =(BH36<K570#3BD?<K3PJ4? j ==.'0570I:n3P=DEF?<4BD. EFCMJ40=DLN00<K=7.'0IEW5N=0#3PS3HI=DEFaXEF=p@k36<48K3P<EF<48XEWaXE;8 j 3b:ffTUBt?5B j J'=0#3PS2TUBHI?< =5DEFJ j =DEF?<4Bt=?sEF=#]t?6LN0a05#cw3MB EF<'Z6:F0p?PEW< =EF<=70<=DEF?<GO?53k. EFZ.':F0a0I:N=0#36SZ? 3b:ufE;BEF<4B j H7EF0< =h=7?KC'5?6aXE;8 03b::[?PO/=7.'0#BD0K38 a636<=I36Z0#B]M- ?2Z j 365I36<=700HI?X.'050<=s=0#36SLN?5\wc~O? j 5h38'8XEF=DEF?<43b:NE;BB j 0#BsS j BD=J~038'8 50#B7BD0#8w]Kt050c}=7.'0K1.43P50#8'9:;36<4Bs=.'0?57@2.'0I:FC4BVEW<36<43b:F@BpEnBs?6O1- TUB36C'C'5? 3H.}c}3P<48REF<?<'0H3B)0c41-t 8XEF50#HI=D:F@MJ4?X55?6LBOy5?S1.436570#8'9:;36<4B] \0@k?J4BD05a636=DEF?<kE;BN=.43P=[36<43b:F?ZX? j B#fiw'R46D;b46#';64N%' ;'Y'>D464D'X(6'k#6RUY (b/)(6 ''hX;6 FNF DF4/'4ID;D'NF 6F#IX'4IFY7#6[X#6Y4Ih4)%''(D'I{YD6F'DFz46RFfD7;IY6N'IF 6FF DFxy' F'FI#6u 4 #w%' F'X4D#bNF''%D47YI4DIbF#b#6gY4II ;s''(D'bF746DFD6F'DFx46744PQ64II%#7x'#wDk'K'X#/;K 76I'N'k46#'dnP'ff2' #D#D47I'74Ihfi2D' F'M~4M7'#6Y4I(W DF4t4666(' GX'XW)WX}%46#'d;64KP4'6#th'74bd~IWItWKI{Y27#7W~46)n P446#'dnP4yF4XWX; 4bD4%Fv'kIYYx#7F~74'I6DF'2#I'(pWX F(6(7fiK{4D'hIX'4It%A 6''77Y'46IbWI;46%P46#'d;64 '6[X#bF' ;'X PW F7'DF4(P'46z46#';64YN46tn%uQ 4)# 6FF )WX4k' nXF'x F7WI6(7 n+M' ;M'k'YIb67DF4 P^F4XFXn 4d#PmY4I'64Y4)'46#6Y4IY''()'GzIYYD6F'DF46}ff46D;I ;6#Y{DF'##6)+F#/Ffi46; kbF44PWXM#IDFs nP44#7F~MKYPWXhDMfiMD ')W'k '#I'DF}tff%4t'#7F46F#'/kD 7 ! F# '#I'DFx"M7' DF#62uQ !X F#467'DFs#6PX#pw64{y 6F F )WX4{ #I'VF#'#I')'4DY6DX' 6FuF DF46NyY#wPF#XF'h7 F(6(7fi%$'DF''s 464pWXP ; WI6(7"/kDMF 6F#xYD''#6'x46D''#64D6FtF DFM{4Dy 746D}uy%26kF4XWX; 4b;F 6F# WR'h)} F4D%ymPF DFk 746[D7} KX'(bff't#D FDF'F7DF{ WI6(7"YX6F#fi46;b} 44XF'MM' F46DF4N7'#6l4I' (#IX4w'&7) ([P4+*I64,.-fiX;I47%'N(X 0 /wF'6{'6'F yK6)WXY#6Y4I4DKbF (bFv64'#6{K6#~IDFFDF# 46D;I ;6Dx'xKD712W 6F#ARD''#62PvF4XF; 4bff3&) (KP44*(64' #7 ;s( 5 /AF46#';64D'6RFG)466RW#IDF46'8 7'~ !X W)W'R46#6Y4( '624PQ{#7F4n)(x46 FG#6YKP0 px4Dy F(YI)WX4''{''2 (b;YP'M#7F46F;6Dt% ! F#s4PFfXDK2)4N;s4)7Y#xfiGRD''#69ffX 4D6F4XF; 4b%#6lY4: (kbF W'{#6lY4(I'D''#P2U 6F F DF;ff'Y7IW66 h7#6Y4# F7DF<M4)7'K)}KN ;VF7DFz(7F'R'#'VW 6F2 IbW# ;6#IX W)WX}%4FVFA''XF4sN3p64=>-fiIff4)#wk7#6{h~4Dx4K6 FY7kW y746F(V#6Yk6#/W 43QP''K z'F74?v '#I'27'2D@/ nF WkbVIX4D(bF ;Y'#I#76A4#64)'7N;D#PmY4I%K4'4P W7Y F'I' [)(646}'t#6XIDFF)4n%46'IFY#P IDFXW)4sffbFr6467#v r'XFDF}NDYkF yKPDF64X'Y'44 4kI;6DF4) WM6YX'#6Y4II)WX4;%4DIy 4FY{ FDF'4 %X;I4D#Fv#IDF B48 7'F({;D';'64bF'67'I''7#I47W#'kDtFx46#'dnP4t%yK6FW DF>v7 nP''kx#62 6F F DFyKv)@tn{Dx~'47 F6 F;N ;6' F'AKRF#z'Y#6 k4(D64bfi(K'k64Dk6'F FD;b''7 F6 FCRY'M's47 F +FDF#'K64) ;z4Y7'K64D4Ik6 F'{6MD''(XDM2kD''#6F4XFXn 4u7'ffbF'Y6N'IF6 F4XF; 4bXQD''7#6FA~DyF'x'KD''IDwK f)4>MD#7A7#6Y4YI(V2 W'k'M6''')nP26 KD''#PyY~DyF'v'M7IW66 K(XD^zQ{x#D F#N66 Y66F' %F()I+ D'X#DX'%F4XF; 4b;tD''#PK%~Dym7''4 F'#{()^EfiFHGfiI%J'K'L<MONPQR'SUT"PQVF,QJ'W%IXG'K'YZ=[\]^'_`)abficAd'ae^'fhg.\Adfiia jkg5lfiinmoipc)q#rsgqtl?aXcAd'au_Aa`)^fimc=]0[v]cAd'a _w\ g0^h`xa`%l?a`yipzfia`,mpg\ff{s]0[vg`ff`yi|f'rta ffic}_Aa ~fimpg0f'ffiif'|#r^h`)cwcAd'a fg.z'zfi_Aa`A`=cAdfiip`]cAd'a _e\ g5^h`)a[^'_AcAd'a _ez.ip`A\^h`A`Ci].fifa\c)i]fhfihfhgm<ip`A`)^'aiU`|a f'a _gkmnig0cxi].f]0[="w>X38`=\]rtr^'ffiip\ g0c)i]f;\ g0~hg0lfiiomoicxia`uj.ipgtgdfiq"l'_xiUz g0~'~'_A]"g.\Ad cAdhg0ce\]rlfiif'a`cAd'a~'_Aa`ff\_)i~'c)i]fh`X]0[>cAd'aC]0ifficwifficAa ffic)i]fh`eg5~'~'_A]"g\ffd=icAd;`)]rtag`)~?a\c`]0[>dhg0_Aaz'mpg0fh` >{.a q+].lh`)a _Ajkg5c)i]fslhg.`)azt].f#Ae_ff]"`)eu_g0^h` b< <iU`,cAdhg5c%cAd'ae\].rtr^'ffiiU\ g5c)i]f ifOC]0ifficuif"cAa ffic)i]fh`X\]^fimpz ~h].cAa f"cxiUgkmnmq;lhaOg0_A_)ijaz g0cwif@dhg5_Aaz'mpg0fh`uj.ipg#g"i]rO`ezfiahffiif'|h?p.4" O']_uifh`)cg5fh\ab\].fh`yipzfia _cAdhg0cgOcffag0rrta rlha _dhg`u]l'cgif'az~'_)ijkg0cffaiffi[]_ffrsg0c)i]f4g0l?]^'cecffd'a+g\ffdfiia ja rta fficX]0[%cAd'acffag0r8`u\^'_A_Aa fficecffag0rg.\c)i]fv0fO)]0if"cuifficAa f"cxi].fh` b<cAdfiip`cAag0rra r+l?a _=iomom`xa {1cff]g0cAcgif4r^'cA^hgkm%lhamoia[wifVcAd'aOg\Adfiia ja ra f"c]0[Hv0bmagz.if'|1cff]\]rtr^'ffiip\ g0c)i]f#yfV\]fficA_g`)cb?ifdhg0_Aaz'mpg0fh` b>cAd'acAag0rra r+l?a _8`X\]rr+^'ffiip\ g0cxi].fV=]^fimpz3g0_)ip`)alha\ g5^h`)awiic hh0X" cAd'aXcffag0rzfi]`x]rtaXg\c)i]f#vuwdfiip\ffdO[]5mnm]0e`=0b g5fhz ioi,cAd'aXcAag0r\ g0f'f']czfi]#X=icAd']^'cgkmnm%cffag0rra r+l?a _`ulhaif'|4gwg0_AaX]0[wg\Adfiia ja ra f"cX]0[%0=dfi^h` b?[^'_ffcAd'a _h_`)cX~'_xifh\ffi~fima`_Aag.`)]ffiif'|hblhg.`)az;]f;ifficAa _A_Aampg0cxi].fh`)dfii~h`+g5rt]f'|g\c)i]fh`:b<ip`X_Aa.^fii_Aaz;cA]zfia _xij.a_Aama jkg5f"ct\]rtr^'ffiip\ g0c)i]fifdhg5_Aaz'mpg0fh` },l'^'cifVcAdfiip`ifh`)cg0fh\ab?)]0if"cifficAa f"cxi].fh`~'_ff]kj.ipzfiat[]_`)^h\ffd1\]rr+^'ffiip\ g0cxi].f#=icAd']^'cucAd'aX_Aag`)].ffiif'|?yft|a f'a _gkmb5io[cffd'aHcffag0r8`cAa _ffrifhg0c)i]f]0[].f'aeg\c)i]ft>ip`a`A`)a ffic)ipgm'[]._>cAd'a=cAag0rcA]X~?a _)[]._Ar`)]raX[]0mom]0=if'|;g\c)i]f b<cAd'a~'_Aa`ff\_)i~'c)i]f;if#)]0if"cif"cAa ffic)i]fh`cff]g0cffcgifr^'cA^hgmlhamoia[wifcAa _Arifhg5c)i]f]0[%cffag0rg\c)i]fh`ip`Xgzfia.^hg0cAa[]._w_Aama jkg0fficX\]rtr^'ffiip\ g0c)i]fe]0=a ja _bfiif1`x]rta\ g`)a`:begz'z.ic)i]fhgmt\]rtr^'ffiip\ g0c)i]flhg.`)az]f`)~ha\ffio\iffi[]_ArOg0c)i]f'zfia ~ha fhzfia fh\q_Aampg0c)i]fh`)dfii~h`g0rt].f'|g.\c)i]fh`iU`gmp`)]4a`A`)a ffic)ipgmV]_ifh`)cg0fh\ab,cAd'a`A\]^'c`Xif@cAd'a#cAcg\ff{4zfi]rsgif@f']c]ffimqiffi[]._Argkmnm>\]rt~hg0ffiq#rta rlha _`]0[%\]rt~fima c)i]f;]0[>cAd'ai_`ff\]^'c)if'|g.\c)ijic)q;C`)]tcffd'a\]rt~hg0ffiq\ g0frt]0ja[]_ffg5_z?b?l'^'cgmp`)]#cAd'a~'_Aa\ffip`)as\]fi]_z.ifhg0cAa`u]5[Ha f'a rq#m]'\ g0c)i]f4cA]Oa fhg0lfimatcAd'at\]r~hg0f"qcA]O] \ \^'~fiq#|]fi] z;g0cffcg\ff{if'|t~?]"`yic)i]fh`iffi[]_Arsg0cxi].f'zfia ~ha fhzfia fh\q?^h\ffd\].rtr^'ffiiU\ g5c)i]f4\]^fimpzgmp`)];lha#~?]cAa ffic)ipgmomqzfia _)ijaz[_A]rcAd'a#g"i]rO`]5[ hh@" ifdhg0_Aaz'mUg5fh` b%l'^'ctg0ccAd'a\]"`)c]0[[^'_AcAd'a _w_Aag.`)]ffiif'|h">Xzfi]fia`f']c_ffamq]fcffd'a>h_`)cff~'_)ifh\ffi~fima`_Aag`)]ffiif'|[_ff]rifficAa ffic)i]fcAdhg5c[]_<ic`\]rtr^'ffiip\ g0c)i]fbfi_Aamq.if'|]ftcAd'au~'_Aa`A\_)i~'c)i]fh`,]0[')]0if"c,ifficAa f"cxi].fh`>ifh`)cffagz<>w]0=a ja _b"w>Xa ~fim]0ic`a'~fimnip\ffictzfia\ffmpg0_g0c)i]f;]0[>iffi[]_Arsg5c)i]f'zfia ~ha fhzfia fh\q4_ffamUg5c)i]fh`)dfii~h`g0r]f'|g.\c)i]fh` b?[]_g.z'z.icxi].fhgm\]rtr^'ffiip\ g0c)i]f==dfi^h` b'wd'a f;\]rtr^'ffiip\ g0c)if'|OcAd'aXcAa _Arifhg0cxi].f]0[%gcAag0rg\c)i]f#)b<"w\ffd'a\A{'`[]_%g0ffiqXiffi[a _A_Aaz]_%zfia\ffmpg0_Aaziffi[]_ArOg0c)i]f'zfia ~ha fhzfia fh\q#_ffamUg5c)i]fh`)dfii~h`,=icAdsg0ffiqX[]0mom]kif'|g\c)i]f3<k;=d'aiffi[]_ffrsg0c)i]f3_Aama jkg0ffic[]._<ip`tgmp`)];\]rtr^'ffiip\ g0cAaz3wd'a f@g0cAcgkiffiif'|;r^'cA^hgmlhamoia[wif;cAd'acAa _Arifhg0cxi].f1]5[H)XX`egO_Aa`x^fimcb<lhg`)az ]f;cAd'at`)~ha\ffio\iffi[]_Arsg5c)i]f'zfia ~ha fhzfia fh\q_Aampg0c)i]fh`xdfii~@`)~?a\ffinhaz<b>z.ioa _Aa fficXcCqfi~ha`u]5[%iffi[]._Arsg0c)i]f4g0_ffa+\]rtr^'ffiip\ g0cAaz<b2wd'a f4cAa _ffrifhg0c)if'|#=d"^h`:bvcffd'as`A\]^'c`\ g0fV\]rr+^'ffiip\ g0cffascAd'am]'\ g0c)i]f3]0[wa f'a rq4^'ffiic`Xd'a f\]rr+^'ffiip\ g0cxif'|cAd'a\]rt~fima c)i]f;]0[>cAd'ai_`A\].^'c)if'|t#|0ija fcffd'aXiffi[]._Arsg0c)i]f'zfia ~?a fhzfia fh\q;_Aampg0c)i]fh`)dfii~4=icAd cAd'a~fimpg0f'ffiif'|s]5[2g5cAcg\ff{if'|~h]fi`yic)i]fh` >[vf']t`)^h\Ad#_ffamUg5c)i]fh`)dfii~Oip`w`)~ha\ffiohaz<b?]_>io[>]cAd'a _,_Aampg0c)i]fh`)dfii~h`g0_Aa`x~ha\ffiohaz<b<cAd'a`A\]^'c`==]^fimpz\]rtr^'ffiip\ g0cAaz.ioa _Aa fficwiffi[]_Arsg5c)i]f">Xcffd"^h`O`)cg0_ffc`=icAd4)]0if"cif"cffa f"c)i]fh`:b=l'^'cscAd'a fl'^fiiomUz'`^'~dfiia _g0_\Adfiip\ gm`)cA_A^h\cff^'_Aa`cAdhg0c~hg0_gmomamwcAd'a dhg0_Aaz'mpg0fh`cAd'a ]._Aqb~hg0_Ac)ip\^fimpg0_)mqb>~hg0_ffc)ipgmedhg0_ffaz'mpg0fh` ;=d'aO_Aa`)^fimct\]^fimpzlhat\]fh`CiUzfia _ffaz4gOd"qfil'_)ipz rt]'zfiam%]0[%cAag0r=]_A{<b'cAdhg0culh]._A_A]0e`[_A].rcAd'at`)cff_Aa f'|cAdh`]0[%lh].cAdOC]0ifficif"cffa f"c)i]fh`[]_ArOgmoig5c)i]fs]5[\]rtricAra f"c`if#l'^fiinmpz.if'|#g0fhztrOgif"cgkiffiif'|X)]0iffic%ifficAa ffic)i]fh`%g0fhzdhg0_Aaz'mpg0fh`Czfia cgiomaz;cA_ffag0cArta fficw]0[%cAag5r8`ug0cAc)icA^hzfia`ifV\]rt~fima1cg`){'` bg.`w=amomg.`w^'f'_Aa\].f'\ffiomaz4cg.`){ `X=dfiip`uip`u]0[\].^'_`)af']cXcAd'a]ffimq~?]"`A`yilfimaOd"qfil'_)ipz<X`urta ffic)i]f'az;ag0_xmnia _b[^'_ffcAd'a _a'~fim]._g0c)i]fif cAd'a`)~hg\a]0[vcAag5r+=]_ff{trt]'zfiamU`ip`e\ffmag0_xmq#a`ff`)a f"cxiUgkmfi<'%fi>O>s;"w38hypU3 ')'4fi 5Afip uA)tfip0h:tt=A5AfiAff'Afi)'@)@X=''0.)hu5w"w>XAp0AAuA0= # 0h0fioo)=' 'k. u#"wUfifffi fiyA)=A0 fip0h' t0 fifi h4"w)A5h 0A,= ')A' th)0"xU5Afiff "!#$!%!#" !20? 0A.X'fioUff)& @''AA#ff08( ')0"tx.) >'fio& #A'tff fip0*)ffh..pfih? 0A +wfipA 'Affw00 fi8,0wx.) ( ,ff'Xfi 0ff- /.2'A10'h 5A)'0w243u)hA528>'"5 3e0A A09h 0A:%wfio;A' O0Ah..pfih+.h 0ff20x.)w)hff.6fi798"8:$!-;< fi79>=? @AXB=? "$!-;C=A-"8:1D fi8:(E F$" fi!G@fiH-Ie5Aw'0yo& ; 'ffA)4A0.h 0ff <X)'0wJ.2.'AK0'<=AVx.)X0>h..Ufihk)''A5su 'ffA)4ufffinpfiA 30=A')h 0A:LC20h 0As0 =AM)9NO+O0A"fip o& ''A #)''A0O,Afipufis:QQR[ EXECUTEMISSION ]R[ Flyflightplan ]............QR[ Engage ]............[ Waitwhilebattlepositionscouted ][Flycontrol]routeQ P[ TravellingOverwatch ][ Travelling ]HighlevelLow ContourNOElevelPHighlevel............P[Travelling] [TravellingLeadCover ]*Low ContourNOElevel............&Scout][ MaskObserve ]* [ forward *EmployweaponsPRUnmask*Mask............waitforscouting............Employmissile............popupInitialize Maintain Select Gotonewmasklocation Diphoverposition Mask2'ffT0UwAOfisVUWff)#0>t .:Xhh 5Awfi 0AYsffZfiff[fi fi.X==AOh..Ufihk%h 5A fiA5.h 0ffwp)Ohyp)w0 U( %'Ah.);Afi \]o^0'fiop 0)3Afi\>0hJooXA Ah0)Afi K' A' 0h 5AUOA5h 5Au0Oh.pfih=h 0A=puY "h5p o_ ;fi A'< ,yh0AxUfip0hw' ;015 "a`."0Oh 0A, 'x.'A'w? 0A.>pw0''0A=A#0b)'')'5 "+'wfipff#s9hOY "h0U kn& 4fi A'AOhs5h..Ufihkx''A0<A0 c,=A'*) 'x'0 fi> +peh0A)pfip0uA0u)''A0A'Xh 0A=pufi A' AhA0 h 5A,wA') 'x'40. "> +pA's0 fiT`.>xnA>A' 30;h.pfihe.h 0ffXA)fi O=fih'Affp)A0 ')'#tff0 h 5A=p'etfio ?''e 0?cdhfifi_ 4fi ff'0='')#)t .2'A10Afih,ooh)A0ff=A'Y Xh'0)O0v? 0A%ffh0,Ue fifip <A'Xwff sfisf s0s5AfiA0A0 h 5A gBW"o<A0t h >h)HCfi0' .hy& s)agBWAO)0fiop)Vh')0""A fi)J&')0"ufiA fi) <gBW=ooHhtfi 'ff1.12:gBWi3"jia,b.2'A0'fi0=A'efi'x% 'ff'eA5As,6')0fi>"ff ")Oa2 'ff kpAy 3"jl ,y) A.pe0Afip ')0",fiA "x.'A'uA0 s9 ff')0",fiA "x.b2 '"0 3 j ? ,x ApX0 2 '"0 3 jh.pfihwA0 +? XoH)Xh..Ufihk.h 0ffA# tfiF -k=0?h <Afih.A'h.pfih,fiA fi)h ,e "xfffi 0ffY #0n ')0fi0hh..pfih%fiA fi)h=pAfih,.Atw' ;00 fi=h0A)pffh0AA0= <opfiqsrYtuvwyxGzV{|fi}~-{9|Zq(|fiutcrv-6?c%fibfi-cG9&->O_%&>cF6&O><^ficFY:"F&fiJF&>_% &Y%Ofi#>F >F%*F><FY&Ffi%>fi>>Fa"m1FfiYF%>fiKYF6LF*aT%9#:_KF#ficKfiyfi4%&#&bVF%% 1Yfi9&V F>?&%&%Y6Yfi> &%FiFn("F% &Lfifi?6F("?%%9:&&Y&"9:_G_1&Yfi&fiTF#fi?(F*fi%KfiKL#>&TsF*9%-e_Y&%9OO"FY&LfiKLY"F&fi/%F"mficF*cY_&fiYF%KfiVa-6?cF/9"G9&Y>9&bF>(fiB%F"_%&fiVc"6ifi1%FCKfifi%%G-%mfiF[CT#BG9&->O_%&>F6*fiYF?F>FfiVF%FYbF>FmficF&1%F&%Fa&VKVfi"%yF[>Ffi- cfi"&fiG"(&K#-Gfi6CE :nF&fi%m<&fiY&c %>Ffi>-_C%F yF*F&-&YY&fi%BKE :K&(-%>Bfi%fi% &KT1F[MFGfiY&G%aKE :%C&cfiYE(FlmeF&Y?&Y-_:Bi"-%?FLL&Y&L*m-6?c Y&LCF:_F&bCE :nF&fi%**>Y&%/fifi-F% aF%Gfi>K-_ &fi&fic#fi6FLs n fi>9:&F&fiF?fi%>fi>&ficY"F%LYBFfi%>fi>&ficF[Y"F%>:?Y>F&fiGFlFF%#9fisF[>F-F%:nF&fi%::^("&fi%fiKF[F6KYY_J JF "F*Ffi#>Ffi>JY&F %>Ffi>KF%F>LF/Tfi%F&fiFL-6iJfiCfi>9aKEYaFFLs n-6?c9"&- F&fifi-fiK_K-<&MFLfiy?K Y_fi&%Y"FY&MF%FY::&&cF%KfifiZaF>Y&&bY"LY&Tfi/CEYB_Y_FfiY>Y&KfiY"#fiY"9:&J_ JF_ &_FfiYL%%9fi&fiJ% y-6iKY9&Y>9&fiKbY 9&$&%Y%%YYafi#>F&fi%9aKEYY& fi4#&&G^ F1Y&LfiY"Y*FfiY>%%9 _ ><&FLfiyKfifi"FGfi>O&F_ %KFaF%FY::&&1fiY"5%F&*K%h_YfiFC&/F -6F>Y&G^F:&F&%&fi%GF "%Cfifi%KFL-6i&Y>Ofi&fi%&"%aF[fi#>FfimE&fi&b-m?cZ]fi&fi%LY&%-6?cJ6F%Y:&&fiKKfiY& &MF%Y"FY&%a>O&%%YfiYfiK&-6?cF#F>&a%% :/Ll(YyKE9nmVYy&KETL[fi%FfiF ->T%%6>Y"&Bfimae_Ym_YY&fiV-%-mL $L % $ff&>fi ! "#%$!&'$()*#$!$+, &!-&!./&'102&'3$!&4%5$!.6879(:;&!- <=#4%&! >/68 ?@A#B CD#$'&4E5$'.#$F6G79(:H IKJ(LM>F6NPO B &$!&4%5$!.*C5&!.5 B &!5Q5E*5&R'#<S&(!TA"#%$!&U /VW= 4X5 B &!$ZY5[5 B &!.*&!%\C5&/W B &!5]&'.#^_'"+#5` aA#b $-Q#$'$4%, a. B R[&'W B T^c&!W B R! "#%$!&&'Q0d#$'&4E5$'.Q B &eJ[6879(:;Jf (>/6g= B h#$!&+5$!.687i9(:Hj 7k5&[W B &!5=lmY5nRY5@#$!&+5$!.6879(:oJf (>/6g#$!&+5$!._LM>/6pNfOe&Y"cY:&maL"L # yfiF%F ->9fiF"G Y_GF?c-#c6%fi6CT#q _(r <6%F_m%-&&fi _s=t _ 3Yu >K%F"Y"FhFCT#FfiG%_&*&fi&fiL%>FY:Y_GF&-C&-Y&fiEL"&fi Kv a&LE&fi]T-:&aL$T A% #fiF Hcw fiYsfi>9cCT#6&>6cFfi%>fi?fi(E&fiVE_(%>1Y:&fiEFlY_#%&F&YY%G&bfi_xfiz8{@|(}=~=+@ h Z23fh d= 8]@#=TX=_H##TXS*@+Q#D3f=G=n1# Xm# %e)#@(=+@ (#/Af+H@=# #+ 8M%*E[3@=+fAP# c/##@ = /_/=##@ = c@#=@+# #@XPp#'D@A!e# +X@DP#=a@_# ipHf_@+f+P*'==H# + #_@#=T_+S*#(=@+F#/##[ ==)=f#f@@=# + S)Z2e!+ 8(@##=+S)H# id# =k=+f##@# @ + Xc#S# +aP#=#3 =f+=@ffh4=-S#=+d3f(8c# p#-=ka#a#@@X+@ff@m# X+X#c!a@#AFp!/=f*# +#P# Q#a+Af@/++fA]a@=f+c!A@# /]@3+=-)@#H#@HmX=F#@#@ i#a@+/A@+# 8SG]@=## mX# p)@a##a+@-#@#@#8/#D D# p#A8=+=_##X++hmAkc+ 8!M/+i#mX_#@_p#= 8/@=T=D*##SAQe= @+T#D+#k=Acm#im@ a/## Xp# a#a++[/2+#Hf+=*2*# X+X#e#@Dm # aki@=fST!M)da@=f+p# 1/=fcp#m@#=@+i#@#2#@# k@@X+@m#@H +X#@c#@k#a+@c#@H# \HS@ k X+A[=@+@_# a/#8Xff=-mAmpi#P=-D+Ap4=SS+%]+iHS@k@=+#a# [+*=ff_+@@# XkQ/=8D=3mA_p#P@c-4X==#=+_=@_@HS+#a=8+#HM@ @#af#4@f//E(-@hSX@++Hm+@@ k8+#D*Mm+S!X=+#K]@ff@#a+d+d3k c# X#Hfa#P4 8(S)Z S*/E3A##Aa@#Aec=#@-#TXS/+@@# # XkMpA#S/#m+=!=+fmAm=caa@=f# @mh@@_@@S@+HX(#@a@=f+D #eS)Z@ #@n-=#c+@==#f+=c/#S/@2+@EQ@k=P/#TXSc=#m2P@## n##@H@##=/F+fm+#3i@#S@+F//@)=#mX+@!==#f+=mAp+p _P=TffpZ *##a++[ /++@@pS+mc=kipQ=k+ H+i@a@@-#@a#@#*)=i@#c@+!)# = )#X)#=f!3+ #@H# k)@##=+S/=#=+ =K@=#=f@f#aH@#=TX=/=PFf/+=/_#@-# \+S@ka@=PX+_#f* @# 8# +=+@o #@S@+hPX+@D##a)#@*)A)EXSK8E# H'@+[SH+ h#@a=f+o =#mX+@!==#f+=_k-/@) A/#a@##@/[MaX+Xm# +[#@@8eZ-a# =A@#@-/@_a@=f+P@X# 8@kAaK%!=32) )EXSKA i@ S+K@QkEXS=P #Hf==+ -#@+ XQ+=@=nm) ip###X#m =@=#=f@ d=Q#T=_@8k/==_=#m*#@e=S *@*T=c@@-)[3@X#HF= #Q)3-#@a_/ S+f@/fH=@#c#@=n#m+@!=p=k#f+=[F/=f=n#m+i#@GQ@+kc# +_#@-@*= /# a#Q=Q@@#@PX#/@a@#@=#c+@fi fffffi ffff ffff!#"$!#%$!#%$&(')&(*+,"$*-%ff!#%./0%1.32/5476984:2/0*%;"ff<3*>=-/!4?8ff-/0.:/0*%$8@A&(*+7+ABff%/5&#8>.C/D*-%FE$!(G/0H/I@J/K.L'MN84!(Gff"@8O/D%ff!?!8><C@J/0!#<P/0%RQ!&(.:/0*%RSffTUSVTXWY[ZK\^])_a`cbd#_fe>bg`fhji`ck;l7monqpi`[`br`hst%ff!u+v8>w:*<v4C*Bff<x&(!y*z6{.3!8>+}|~*<3u698/I@0Bff<3!4#M84}*Bff.C@J/0%ff!/0%)Q!&(.:/0*%1ffM/548>!#%.x4#/D%$8zH/J@I/0.:'1.3*+,*%/0.3*-<{.3!8>+"!#<:6r*<3+v8>%$&(!TQt698&/I@J/0.x8z.3!4}4:B$&32+,*%/0.3*<:/0%ff?H'u!(Gff"@D*z/D.C/D%ff/D.(4!(Gff"@J/5&/0.<3!#"ff<3!4C!#%.x8z.:/0*%y*>6.3!8>+*"$!#<x8z.3*<x4#T9%y"$8z<3.:/5&(B@58><MaQt8@I@D*>|48>%!(Gff"@I/&/0.}4:"$!&/If&#8>.:/0*%u*>6+,*%/0.3*-<:/0%ff&(*-%$-/D.C/D*-%$4~.3*A!#.!#<3+}/0%ff!8-&32/0!#=!#+,!#%.MBff%$8&2/0!#=O8>H/I@I/5.:'*</0<3<!(@D!#=>8>%$&('*>6.3!8>+*"ff!#<x8>.*<x4#Tq9%u8ff-/0.:/0*%MQt698&/I@I/D.(8>.3!4P!(Go"@I/5&/0.A4:"!&/Jf&#8z.:/0*%u*>6.2ff!<3!(@58>.:/0*%$4:2/0"uH$!#.:|~!#!#%y8.3!8>+*"$!#<(8>.3*< 8>%$A/D%$-/0=-/5B$8@54#$*-< 4:BffHff.3!8>+y4 &(*%.3<:/0HffBff.:/0*%$4.3*/0.T~QPB$4:!4.32ff!4C!4:"$!&/I$&#8>.:/0*%$4.3*/0%6!#<~.32ff!8&2/D!#=-!#+,!#%.~*<Bff%$8&2/D!#=>8>H/I@I/5.:'*>6[8.3!8>+*"!#<x8>.3*-<T[~2ff!4C!4:"!&/If&#8>.:/0*%$48><3!H$8-4:!*%.2ff!{%ff*.:/0*%?*>6 8:IT<3*z@D!/548>%y8zH$4:.3<x8&(.t4:"!&/If&#8>.:/0*%R*>6.32ff!{4:!#.*>6 8&(.:/0=-/D.C/D!48>%7/0%$-/D=-/5B$8@[*<t8N4:BffHff.3!8>+Bff%$!#<3.x8z!4q/0%y4:!#<3=-/5&(!*z6[.32ff!t.3!8z+yU4*>=!#<(8@I@c8&(.:/0=-/0.L'T~2B$4M8N<3*>@0!&(*%$4:.<x8/0%$4{8.3!8>++7!#+AH!#<A-/9*<{8y4CBffHff.3!8>+t.3*4:*-+,!v4:BffH*"$!#<x8z.3*<#L4t*"$#t*z6.32ff!.3!8>+*"!#<x8>.3*<}Is5~TAV*</0%$4:.x8>%$&(!Mq4:Bff"ff"$*4:!v84:BffHff.3!8z+)/548434/0%ff!.32ff!,<3*>@0!}*>6t8?(q/0%R.32ff!t.3.(8&3,*+8/0%T~2/54~<*>@0!{&(*%$4:.3<x8O/D%$4.32ff!4CBffHff.3!8>+.3*}!(Gff!&(Bff.3!{.32ff!4:BffH*"$!#<x8z.3*<#L4.*4&(*Bff..32ff!H$8>..:@0!"$*4/0.:/0*%/0%u4:!#<3=-/&(!N*>6[.32ff!*>=!#<(8@I@c.!8>+*"$!#<x8z.3*<KKLqKI#CrrI#o>#Kr5V9#x-r(L4:!#!{a/0Bff<!AxT84C!j*%F.32ff!?%ff*.:/0*%*>6{<*>@0!4#M .2ff<3!#!y"ff<:/0+}/0.:/0=!u<3*z@D!#r<!(@8z.:/0*%$4:2/0"$4ur/rA:x,5r5-r/I/r~tL(,#K$rK}8>%$r/I/J/r~-JLCo$$t&#8z%v&(Bff<3<3!#%.:@0',H$!4:"!&/J$!/0%yQtjT~2ff!4:!"ff<:/0+}/0.:/0=!j<3*>@0!#r<3!(@58>.:/0*%$4C2/D"$4&#8@I@0!^:I#:}$Kr(5F(ff#r:K$K}/0+,"@0'1.32ff!?6r*>@I@0*O|/D%ff<3!(@58>.:/0*%$4C2/D"$4H!#.:|!#!#%y8.3!8>+*"!#<x8>.3*-<Ds[8>%$7/0.x44:BffH*"$!#<x8z.3*<x4#~~ L:#30(r5#X~5y0N[L:05X~5y0P#Ir33#a 3 Kff2ff!4:!y"ff<:/0+}/0.:/0=!u<3*z@D!#r+7*%/0.3*<:/0%ffF&(*%$4:.<x8/0%.(4}+v8'H!R&(*+}H/D%ff!MP.3*4:"!&/I6';+,*<!y&(*+,"@0!(GR<3!(@58>.:/0*%$4:2/0"$4#Tff*</0%$4:.x8z%$&(!M6r*<.32ff<3!#!,8>!#%.x4-/9M[w{8>%$uM|~/0.32<3*>@0!4*" Ma*" 8>%$*"$ Mff8}&(*+}H/0%$8>.:/0*%:s<3*>@0!<!(@8z.:/0*%$4:2/0"&#8>%H$!{4C"$!&/I$!u84~3*"$# *"$ *"$ -xTQt?rH$84:!j8>!#%.x4}&#8>%j%ff*>|/0%6!#<7.32$8>.}.32ff!<3*>@0!v%ff*-%ffr"$!#<:6r*<3+v8z%$&(!*>6 *-"$ -+v8>!4Bff%$8&32/0!#=>8>H@0! ~HffBff.{.32ff!<3*>@0!%ff*%ffr"$!#<:6r*<3+8>%$&(!,*>6w:B$4:.{*%ff!*>6-/*-<Aw/54{%ff*-.A&(<:/0.:/5&#8@t.3*TQ>/0+}/I@58><:@0'Mq6r*<.:|~*8z!#%.(4-/8>%$Rw#MH$*-.328>%js ~9&(*+}H/0%$8>.:/0*%"@0B$4<3*>@0!#9!#"$!#%$!#%$&('+v8'yH!v4:"!&/J$!j84N3*"$# *-"$ *"$#*"$ O3(T ~*>@0!,+,*-%/D.*<:/0%ff&(*%$4C.3<x8/0%.x4+v8'H$!}4:"$!&/I$!/0%y.3!#<+v4~*>6q/0%$-/D=-/5B$8@54#<*>@0!4#Mff*<t4:BffHff.3!8z+yU4~<3*z@D!4T2ff!A+7!&32$8>%/54:+46r*<.<x8&/0%ff.3!8>+7+v8>.3!4#<3*>@0!}"$!#<C6*<+v8>%$&(!,*<P/0%6!#<<:/0%ffy.32ff!(/0<{<*>@0!,%ff*%ff"$!#<C6*<+v8>%$&(!N/54"$8><3.C@D'R*+8/0%!#"!#%$!#%.T,4+,!#%.C/D*-%ff!?/0%Q!&(.:/0*%SffTSffM/0%4:*+,!,*+8/0%$4#M8>%u8>!#%.t%ff!#!?%ff*.t%ff*O| /0.x4P.3!8>+,+v8z.3!U4~!#.x8/I@0!?"@8z%*-<.3<(8&3.32$8>./D%u!#.x8/I@9MHffBff.+8'<3!(@0'*%2/02ffK@0!#=!(@*H$4:!#<3=>8>.:/0*%$4#Tff*</0%$4:.x8>%$&(!Mo/D%.2ff!t.3.x8&,*+v8/0%M/I6 8}2ff!(@I/5&(*"ff.3!#<P/4P!4:.3<3*>'!M.3!8>+ +,!#+}H$!#<x4/0%6!#<}<3*>@0!%ff*%ffr"$!#<C6*<+v8>%$&(!76*<.2ff!8 !&(.3!.3!8>++,!#+}H$!#<T9%R*-.32ff!#<A&#84C!4#M4:B$&2 8-4{.2ff! ~*-H$* Bff"Q*ff&#&(!#<*-+v8/0%M%ff*R4:B$&22/02ffK@0!#=!(@t/0%$-/5&#8>.:/0*% /54A8=>8/I@8zH@D!T9%$4:.!8Mfffifififi"!#$&%('*),+-/.10),02,- 3),45-6'789:-<;=?>"@5AB(8C7ED,-6F7EGH-6'ff),D&),45I64 J*JK0'L:I7),-5M/L:),+*'4H'BN;ff=?>O@<ABP8C7ED,-QF7EGH-6'ff),D63C7RG -6'-62PL:II64HJ*JK0'ffL:I7E)PL:4H'S9T7E'G 0C7EG -UJV76WX8-K'-QI6-6D,DY7E2,WH$RZ[+L\9:-VG -Q'-62Y7)PL:'G'7),02Y769"9T7E'G 0C7EGH-]L:D?I602,2,-6'ff)P9:W4 0),DPL:F-V),+D,I64H^-/4.;ff=?>O@<A_3H;=?>"@5A`F4ff-6D"'4 )^2,-6IY9:0F-D,0IY+*7/^4HD,DPL:8L\9:L:)PWH$@a9:),-62,'C7E)PL:bH-c9:W 3C7E'K72,)PL\dIcLT769I64HJ*Je0'ffL:I7E)PL:4H'9T7'GH07G - 3D,0IY+7ED5f(; L:F'-6263"gih hEjk/JV76WX8-50D,-6F$fim/n"oKprqstuffvrwHxXv"uffuy`wz{z}|"wHs~1vz1uuff6,z[sv& u~vr,zsw6~1zv~(s{stuffvwwEHsE~1v"tcrsvu ztvr~1w6~1zv/QRsS|&u5}"Rr &u\t1~(xsr(suffstuffvrwX~1vw"u[*z}|&z"K"xc~1r(swi~z}vy"sx6r~1v"ts"usywzu u ~1us&sxx Kz}S"vr~ffsw6~1zv{[s|usv"zw"uffx6z}"H uSz?~1vr,z[sw6~1zvufftsHy}~1v"tz1uSv"zv"&uffiNzE[sv& u5a~1Hx6wrsx5y}~(x &xx6uy|u zOV51usy"x~1v&y}~}~(yr&s(xVwEzsv"v"z"v& uVzuffYE&sv"tuxwzw"uSwus{?sv&ywr&xz}w"uffwusuffS|uffHx~1v&y}~Eu w61~1vr,uffz1uff,uff6Nz}[sv& uS~1vr,z[sw6~1zvu zv&y/&s}xUy}~(x &xEx6uy~vu wi~z}v"1}"V[s_1usy~1v&y}~1~(yr&s(xwzy}~Eu w61{ zS"vr~(ffswuw"u ~1Xz1uv"zv",&uffiNzE[sv& u5y"y}~1w6~1zv&s1?s_,uffyrz[sC~v"P~1v&yruffuffv&yruffvw_u&svr~xi[x*,ze~1vrNuffE6~1v"tSz1uX&uff6,z[sv& usEuV"z~(yruy~1vV5*r&xffrz1uXv"zv",&uff6,zsv& uV~(x~1vrNuffEuy~?v"z~1v&y}~1~(yr&s*zxi"|"wus~xXx6uE~T&uyNzX&uffiNzE[sv& uzsz1u6sxe~1v~wEuff"&a~1t"uSrH*xiz&~]s5~1v&y}~1~(yr&s(xS]~wEr~vs[x6"|"wEussuNz"v&y~1v&ffs&s|r1uzK&uffiNzES~1v"tw"u ~1z1uxffRV~1vrNuff xVw"uuffvrw6~1uSx6"|"wusffsv"v"zwV&uffiNzE~1wHx*z1ui}|&sx6uySz}vw"u*z1uff,zvr~1wz}6~1v"t z}v&x6wHs~1vrwHx5sv&ySwE"uVz1uVuff6Nz}[sv& u*~1vr,z[sw6~1zv[s|z"wwus[swuxffr5~vr,uffHxewusz&uff swzX5(wz_|&uX"v&sEr~uffs|r1u"~1we~1v}zuxVuff&s~1(,zuffr(sv"vr~1v"t&effsx6w6~1v"t{Euff&s~1sx_swusz}&uffHswEzstuffvrwHxs"wEz[sw6~(ffs1uffv&x6"uw"uSuffvwi~Euwus:x z}S~1wuffvrwXNz}w"u ~1_uffr(sv"vr~1v"tcw"uSuffvw6~1uSwus~xsCu wEuy~(~(x"v&s}r~1uffrs|r1uH""Ew"uffzEu?stuffvrwHx~1vr,zwEus[swEuxXv"zwzvr1s|z"wzxxc~1|r1uuff&s~1Eux6r1wHxffR|""ws(x6zuff&s~1X"v&sr~1uffs|r~T~PwQz~1u 1uffCsv& ]"us w6~1zv&xwHs}uffv~1vx6uff}~ uSzV\uff&sC~E yruff&uffv&yzvw"u zvrwu w [\Euff&s~1(Vsx~1vz}uyyr"uwz(Kxyrz[s~1v"Yx6uE~"v&sEr~uffs|r~~(w6zv&y}~1w6~1zv&xffyrz}[s~1v"Yx6&uE~SEuff&s~1X~xw6~1tt}uffuy/ v zvrwHsxiw}~T\uff&s~1P]s}xe~1vz}uy{yr"uSwzz1uff,z}vr~wEz6~1v"t zv&x6wEHs~1vw_Ys~1"uxffV51usy"xusEst}uffvwSwz&Hx6wsv&sCrffuw"usC~T1"u*"uSsv&s1xQ~x[suff}us<sHP,( 6eff(r6*sxc~1v"t1uEz1uYs~"Euffs&xc~1v"tw"u"v&s}r~1uffrs|r~~1wQz](Vr~(E[s[z"ff "*~1vsvXXY zS|r~v&sw6~1zv~Usvr[stuffvrwVzVx6"|"wEusYs~x~1v~1wHxz1uVz}[sv]Y zS|r~v&sw6~1zvV"uffvswEusuffS|&uff x[sEuz1uffYyruff&uffv&yruffvrwzvs`xc~1v"t1uS~1v&y}~1~(yr&szsxc~1v"t1u{x6"|"wEus{[OzX~1v&x6wHsv& uRV"uffvstuffvrwHxsuS&}~1v"t~vNzE[sw6~1zv}~(s\w s}u T~1v"t(*Y zS|r~1v&sw6~1zv/HRuffuffEzv"u~xz1uffYyruff&uffv&yruffvrwzvw"uS1usy"u ~( z"wuff{*r&xffx6"zr(yw"uX1usy{ Hs}x6&s 6~1w6~(ffs5z1uXYs~1"uz"ff "Hxff]"us w6~1zvwHs}uffv~vffsx6uxz<s i~wi~ffsC<zuXYs~1"u_~(xVwusEu zvr&t"Hswi~z}v"wz[yruffwuffES~1v"uswusuffS|&uff/zx6"|"wus{/wzx6"|&x6w6~1w"wu_,zXw"u 6~1w6~(ffs*z1uXxXuffvw6~1zv"uyusiT~1uffawr~(xxc~1w&swi~z}v z}ux6zv&y"xXwzw"u "v"Eu zv&E~uyffsx6u~1v&suy"<(sv&xffy}~(x &xx6uy~vu w6~1zv":"*"ux6wEuff&xVwHsuffv~1v`V5~vwr~(xffs}x6ususxUNz1zxff]iEX16ff( Y6K ffi i6N,NPfffiffffff ! #"$ff#%&('fi)"+*+"+ff"+%,-ff % %.#%,ff ! /0 '1ff-%,2!ff /-&("+ff 3ff42"+/ '1ff%.5ff ! 67"+ff"8*(%,*+ :9;ff !"$'!02'1ff*+<3*+"+ %'>=1%?"$'A@B) 7"CD-EF'!%&(*$ G=10, :H(. %,2! IJ0 '1ff%2ff G/-ff ff ff2%.Kff"+ff"8*L%*$ M.B"+*$2! 5N''%ff( '=1"8=ff O.P%,2!ff"+ff2ff"+%,'QRKS6 TK ffE,(6 U&6ffN V?(i,11 W6X,EP7 HM' /';0, '1ff5=A ff/"+' M)%"$!*$ '=1"8=ffXP YI"$' *+2=1"+'0-"$ff*Z.[I!"+ff\ !EFO.P%,\7%,'1]"8 ff\&("+ff ;'=1"8=ff ,^ \ 7_A"+ff"+'0/ %//"+ff'1ffff%ff ffK`a.ff/ %,/"+ff- '1ff\ *+ G,=1<;"$ff"8*bIff '=1"8=ff"+# *+"+/"+'ff =c.P%d %,'"8=1 [ff"+%,'e%"$'!ff[' ,I"Z.ff -'=A"f=!ff g"$\-)ff"8 "+)'1ff\"+';-ff Gh%,) ff%\&( "8"+5'i#j\kO@l7%,"+'ff"+%,'mI"$ffJ)%,'!"+"+*+"$ff"+ Jff%ff\ffn *$,=A</ "+ff"8*op Nq, '"Z.m"+ff)%# *+ q,'Fff()"+*+"+ff"+ GI"$ff''!%,ff(ff[E, M%q, ff M%*$ M"+'?42ff"+%,&' rA"$"+*f*+<,IGff ! sN'=1"8=ff M"$2!*$ G=%,2!ffJ"Z.t*+*%,ff(ff G/ g%,*+ @=1 ) '=A '1ff\%,'"+Hffu#v*ff6QU w,iQ,,N(YPS6x#y('=A"f=!ff XP[YM'%ff#2*+ =%2ff#"+';ff)zQ'{2!ff"$ff2ff.P%,ff g%,*+ }|( "+~7%,2*8=/ '?'?"+'=A"$q1"8=12*q%,*+2'1ff N "+'0"+ff*Z.[I1%,\-ffn*+ ,=A (q,%*$2!'Fff"$'!0"$ffK2ff.P%,Kff ! 5"$ff"8*%,*+ Kr1"+' -)"$lP"+J#ff G%) N[ff%,GI'=g"+' M%*$ 7@B2ff"+ff2ff"$%'"$)*+"+ "+ff(,"+ q / '1ffGI'1</%,*+ @b2ff"+ff2!ff"+%,'"+~''%2' =6ff%/X,fi5\DDK{,DMD\DDgsN$7lO1[N+bP [P b81 --+BN1PDOPNJ$!\!JN>,+$-!(,7+1$b1#N$N,1(+1+1fA,(Gn/(1+!+(,8,+\/8/ //+13DNNz{8m,A;LA3b1+81D1m1DDG,DD,G1 8DbG7f7F518lF$8D, mN-8{8}8DDfi#DN~[fmG3:GD 8D DD,1D# m,N+m,KK1m;NDG8F1L1!(Pa a$7Nbb+1PbabG818,#1{c--G8m1 8A?DNGD 8DAf#8DD!DGDG 8 P18+8DDGDDD,A8D/N, A\D?Gm1{Pg8D1,:;L ,-ND?1m1++8 8,1ONGD 8Dm#D8,/A5P DD,A6fD, m1g8?118D87DD,1 b/GD 8DmAm1DDDmG,-PNm1D818ND?N, A\D,13:mg1\P DD,A DGfNGDPG 8DG8; 8b+8bm1 8bm8 8DGD,nPDF fiff,GDN, #8PDAf8D, 18mG? mNfiDN18/8D;A/GmD,fiN?ND8F~Gfiff#18m!8Pm,1 !m1NK1m8mG7{fiff+PN8 ND,Dgb/G 8 PsG!DGGDD#8, ;118mF~Pbfi,GsD\ 8\mFfDDG,D1m1\A8!,-8D#GNfiffA DD,11D}m1D{,1/fi P Nm8 #++m8!, / ,1p!m1N,O! b1+811 P/mFf{DDG,D#8 Pfi fim1+8D8m!8PmP:7DD DD,1 11\mA PGP1G 8 PJN18,\DDND;N1;m8G;DP1 8fiDN-g1DA P+", N PG,fi#88D;+8D{DD# +fi D,L,L%$'&P+# ,!" 38D18fimm1)(!P/!P18,b Afm bAmG* m,Am ;,+.-'/10 ,+324G657(!5m -8D11D!D16( 7m m1,+.-/10 !,+%89#18>Lmmfi+8D3GP 8183 DD,1:;8m , 1\1{8m!f!Pm=<J1m{ND/ DD,1sD1-8>AfiP7F~mFfl+fDNfi>mP{P?# +&a$# ,D1/L B! 818@<\N G1P 8m1AfP-8m1 8L#8 Dz7Dm 8D 8:P1+Afb;G 8 P\187 m8s8 G+DmN8F18A1fmG-DNm8\1BCEDB zP8 G+DmNf118m/G!;8#+fDN#P\7D;,K1mZG;8a+fDN PfiD1 8!,KD!{fm71mG-8DNFfGfN+fDNfi8;+8,{D8DDfim GF? 7 8D G!;8alF$8D3N,1 mA,O!m7D,Nm1,1n;mG#++DDJfiffD,GD# m;! P\G7f!m#8D!D~Gm7f7fD,11,}b(z DDN,1H 1fm!8!PmI(!mGDNG;8a+8DLD8B8m1++fJ:;m7BNDG8N18,M83D,AK)LC#Db!18DG 8!fJMONQPBRTSVUWKXAPZY,[\Y,]^@_a`7YbTcedfdhgjij_\]lkm^n_\ceiO! 1-G;DP1;{, A$P 1m:6fmA,1 L1GVo8DAD?L;1,1 L1G8 >m1P !8D;,MP;G;DP1 88+ 1/1D,p [q,G 8Grfi D1-;8 P+,G\77sm8L8 +8;8D3#DGbt(fG1,,NP8DbD! P;G;DP1 8 G8,G 88J5g1O!1!,L8GmPA 8?G?DP17f!6G 1m mDGmK#G+tD+vuF,+,aK@w# ,+%xmgPy& @#fiwbaGw@$>Nfi# z${wba$ N,+a%xV| +8NDA1 P;ADDN:, m!m ;D;Gm N8G#1\,8b# PFfmD8-PD!D,G,N1 + !fAA 81\DD,G7fD7f!m1D} 1887f!mb15! m1 PGP1,Dq} 18 f 8m BG1;#fi,sD{1mD1/G?DP17f!mDDG1D;G!;8;N1FffiDmFtLG+fG~g8,NP8DbND PfiG;DP1 8 G8,G 8!8>?O! 1N;D#{b1+81hD;G Nbfit,G7f!;DDfi1~A88DDmFtLG+fG#G8F1gf}[Af#87f!m@fi1lj@lV!l%Jfi;l)%\@'a@;l)%\@6fi@6VlV=@fiE;z,zJllV,J@*I"EB?B;l,QfiJfiIn6%@Jl%6Vl%{l@",zz,.=;lJ;V,>"V@fiJ@,'=lzfiz6Vlvn@,fiJ?@'>fi@6Vl@lfiI.a;l6@fiJ@TmJ;T@lfifi@6%'V,\"@qhl@,>y=mh@'fi@66z"l4Ap.@7,lT%nKV%a@VV,JlGEjhsl@,"JG1l;@%1@Al@ lee,,'lqVfi@z,J@"V,JlE=@,vJ@@fiz6) l@Q'A@,,.J?j7a@Evfi@fiz",nJ@e1l%,fi%;Ifi j 7Ol@fiJ@v!T@JlVlVfivn"Vfi@6VlJ@e,v leRewards(1NC)Cost: 0B(F unknown) B CmtDecision nodeChance node(F known)CCost: CcB1(F known)0(F unknown) B Cmt@l6Z'%\@'@fi@l"ze?6@lEfil,%fi%lJ"J*7@lJ@Tzv!Ifij)?j>6B7@lJ@*';?% ?6T.V)fil,%fi%lJ>@1{zfi@6Vl%sj6?>6z=@jqI?jj,ya@e,Jfi,fi@Vl;z @T.elq,zl;V"zz\>@@j@7l@"a@@ltz@6;.,B@lfiI@l@@\,fi)q7f\"z6 fillIfi@6@ l4"%zn, j A4am,.J,A;@%llQa@K@lm@llV{n '@lVzl@e\,fi4"l@l@v!4q7 j @eV;lTfi@l"zfiJIqfi@4{,,zl@l\,nJ@@;fi=O,%6V,'Q%Q,fi%,fia,fi%@fiz6VlvnJ@6OlEfiJ",fi%@J%'>%fi%@J%fiBlJllfi";%n@fiJz>@=%JJl@ze@T\l!n@7Z"fiaB*'%{V@,B,n,V,@l)fi@l"zl%fi%@Zm%fi%*lJT.""%nJ@v'.JQ,J%zEJfi%fiJ@J*lQav*zVaV%,l@fi=aGl*l@,nJG@ jJQfi@6V6?, ; l*m,.>a@fil%filJlsEh;l@l;J)fi@V6A@Hl6%{mlsnn@)fiz6Vlvn%sj6Ef?>6z=@jQjat.1 ) lfiffQ 1 llllEzl.%J@fi@6VlJ@A@%,,zl,fi.JQl)V,J@*fiJJzeJ"J@,j @B,Jfi,fi@,% 6VmqT.V,l,fi4"Q,;lV JlzlT,J% ,l"zalf*mTl,z4n" l6fi 'l%T.*l@m%fifil%Blz)fi@6VlJl{fi@,"z"J @V;l6%v>"zs)a@fi@6VlJ@vlfia@Vfil,%6,,elVl,fi4"J@ 'l%l>6J@f>@l!#",fis@VQ%lzl@,\Ga@ %6Tn%V",n%z,@lV,fifiJ?qv,fi%1$&%'fi(*)+-,/./02134576/8:9;45<(=57,/>-+?)/./@B(1)NCCost: 0CCost: Cc(11C0B(1B(Terminates)) (Not Terminate) 0(Terminates)BCmt(Not Terminate) 0)(1RewardsBB)(Terminates)B(Not Terminate)Cn[Irrelevant]EGFH7I/JLKMON-PRQ/SLKUT VKVVKWXFZY[F\7T]SLJXKUK?^_FSL`abc H;dFTe TfdgH7KUT;ShWi\7jkjlI/TFZWUd SLKYmFonpP-qsrLtkuRv<P-qsrxwytku&eiFzb{K7be|Fonpa}~}7-=vrL*W=firiUzauL-T2u&b*afF:YleFzb{K7be2dkSLKdgj\7KUJ&d SL\J` d7YSLKUJLjlFT SLKV2eSL`FZYK7I SF\T!JXKVI WiKYSL\l ~}7-=v_WYKUKUT/JLKUF\7I Y[7ba?eRFzb{K7beh`FH7`I/T WiKUJLS&dFTSxd \7I/SkSLKUJLjFT dgSF\7Te-T/\Wi\7jjfI/TFZWUd SF\TJLKYIS&YFok-TFZY`FH7`b_`/KUJXKi\7JXK7e-SL`/K]VKWXFZY[F\7TSLJLKUKFZYI/JLSL`/KUJkKiQ/SLKUT VKVSL\]FT WXI VK<dT/KU^jkKYLYXd H7KS;K SL`/JLKSlSL\x\ FTSlFT;SXKUT;SF\7T ^`/KUJLK]-TFZYUKUJL\ eh/I/S KUT/Ki SiYd7WUWiJXI/KVd JLK\ ^*KUJsrx_*u&b=_`FZYSL`/JXKS_jkKYLYLd HK?jdQFjFUKYKiQ/ KWiSLKVI/SFooFSx^`/KUT!a?7eFbK7beF=TF:Y`FH7`\7J_Wi\7jkjlI/TFZWUd SFT/HkSLKUJXjlFT SF\7Te/d?SLKdgjjkKUjl KUJWi\7jjfI/TFZWUd SXKY*dsSL`/JLKSbEO\7JhFT YSid WiK7ed]SL`/JXKSljkKYLYLd HKkFZYI YKVFod Tfid H7KUTSdFoZYFTFS&Yl\ ^TJL\ K7e-^`F:WX`FZYdSL`/JLKSkSX\!SX`/Klx\ FTSFT;SXKUT;SF\7Tb\ ^*KUKUJe*dYkKi\7JXK7e_SLKUJLjlFT SF\7TjkKYXYLd H7KYd JLKI YKV^`/KUTa7e_^`/KUJLK]SL`/KUjdQFjlFUKKiQ/ KWiSLKVI/SFooFS7bU</2;U/ Lh ~c Yd= J&YSRYSLKUe;P c? \7T?I YKYG7I doFS&d SFKr\ ^e`FH`ejkKVFI/ju2 J&dgjkKUSLKUJ dI/KYUb=;P c?KYSFjdgSLKYoF7KioF`/\;\/V\ _Zd7WX]\ hx\ FTSfWi\7jjlFSLjkKUTS&Y eF:dSLKjSLJ&d7WX7FT/HrxdgjfK7e-7u_VT jlFZWUdoFTKUJLJFT/HdSLKjYjKUT;S&d*YS&d SLKJL\7j\7 YKUJLd SF\T Y?\ _SLKjjKUjfKUJ&YUd7WiSF\T YUbE/\JLSLI/T SLKi7eJ&d SL`/KUJhSL` dgTkSLJ&d7WXFT/H?KdWL`kSXKjkjd SXKYKU J&d SLKi7ed Td H7KUTS-FWUd TkJXKi\7TFSiYh\ ^TSLKj\ KUJ&d SX\7JKiQ/KWiI/SF\7T]\7J?SLKdgjSLJ&d7WX7FT/H bzT JLSFZWiIZd JeRYI// \;YKF-` d7Y?YKiKWiSLKVdSLKj\7KUJ&d SL\7J#\JKiQ/KWiI/SF\7Te-d VyFSfT/KUKV/YSL\KYSFjd SXK \7J\ KUJ&d SX\7JlRedgT V]FS&YSLKjb\^e/FoF*YKiKWiSLKVdgSJ&dgT V\7jJX\7jdWX`/\ FZWiKk\ *Kdo]/JLKiKUJid KWUd VFZV/d SLKYUeGSL`/KUTFS&YSLKjjd SLKYsjdyVFonKUJlFTSL`FZYlYKiKWiSF\7Tb<`;I YUeSL`/KUJLKF:YWXKdgJd\ ^oF7KioF`/\;\/V\ dx\ FTSWi\7jkjFSXjkKUT;S=FKYSFjd SLKSL\K?`FH7`b-\^_KU7KUJe Fo-FZY=SL`/K\TWX`/\ FZWiKddFZd K7eSL`/KUTVKUKUT V/Y\T!SX`/Kk/JLKWiKVFT/Ho- SL` dgSF_KiQKWiI/SLKVy^_FSL`SL`/KlSLKjsbkrxjdK?I YSdY[FT/H KUSL\7TeFbK7be-?jdK?d TkFT VFF:VI d\7KUJ&d SL\J-SL` S_FKiQKWiI/SLKVd\T/K u&bh_`/KUJLK?d JLKSL`/JLKUKWUd7YKYSX\pWi\7T YxF:VKUJbkEGFJiYSeOF?rLFZY?YI//SLKdgj\ u_\7Jl?edo-jkKUjl KUJiY\ ^_KUJLK\ FT;SKiQKWiI/SFT/H]o= ZRbhE/I/JLSL`/KUJXjk\7JLK7e2o= Z]Wi\7IZV\7T K?SLKUJXjlFT SLKVF:djfI/SXI KioFKijk\T/Hlb`;I YUeF:YoFKiSL\Kh\ FT;SkWi\7jkjFSXSLKVSL\?KiQKWiI/SFT/HSL`/K\7TT/KiQS_WL`/\ FZWiK?yFZY_KYSFjd SLKV\^b_7KWi\7T V2eFo-eY\7jkKjkKUjl KUJ&Y*FT]^_KUJLKT/\7SR\ FT;S JLSFZWXF SFT/HFTSLKj\7 KUJ&dgSL\7JKiQKWiI/SF\7T]KJFKUJ`/KUT WiK F:YKYSFjd SLKV`FH`b_`FJ&V2eFo-T/\\7 KUJ&dgSL\7J/JLKWiKVKRe/K7b{H b:e FZY= J&YS_FT!dkYI//H\;dze/SL`/KUT FZYKYSFjd SLKV\ ^b`FoKd H7KUTS&Y=I YI doFTKUJjd S&WX`FT/HKYSFjd SLKY=\ eY\7jkKUSFjKYUe/KYSFjdgSLKY_V\fjF:Yjd S&WX`b_`/KUJLKi\7JLK7e;P c? FTSLKUH7J&d SXKYfY\7jkKKUJLJL\7JJLKWi\ 7KUJLJL\I/SFT/KYUbE/\7JFT YS&dgT WiK7ehFod Td H7KUTSkF&fi2/-gL_Lk/7ff/fii-L h&fiLih// ff/?Xfi&gLfiZ LfifiL ii 7k" ! fiR& oZ# $x % i7klL;&' &( fiL 7fi&R fLfifffiL)fiL*& oZ# +i7lLk&&,- .i ;/ fi&7 g0 !1lZ# *L_Ll% /LL2 fi0 3)&4 ! fihkLL2 75 ! fih&g Z# 6iklLk&&178 9:<; !fi&_# /?:= *):>fiL/ ! / ? iL kLX 7@g=ff /Ai i&-B; C /fiD/L6UgD ffAA/ LL&8GlXBEGFzff /fiL7 0 o# ff g>!z ihZH/Iikk )C / H7 J789:<;7L= /kK;L UfiffMU gN! filLkUlfi&' - &PQ&GN !7R!z ilZSZ[ L fi 7ff /Z?T ZAZ[ kLT 01i U L LL& U _7fi2fiL7 .C /ZkT ZVfiX W fiL L]k? 3 ! fiL k Z# fffiXfiiff 2 / :'=33 YE"&MZff /)fiL7 0 o# < !? <; [ ?ff fiLgfX!O$xg3 ;LRZlL ]\N !?A!z //# XN ^ LfiLl _ Mi&a`ff /fiff_Z)fiL k L fi3 Vi ff fi& & fiXR"R &P&mb`dcH*eif _ Z?Z 7fii .fiL fiL mXkff /X/lfi2 !LgkUlfi&' &f8H/Xfi&gkULfi&Qg%hjiff"g%hHklgf?2 fiL7L# /7 lC / H7 &mnRopq"res%qQtuev4w78 91:B;Z<fifffiX;# RUkL b_ff x77 fi :Ai_ 7!_ fifi&gL fi&&gL5 ]Uk2!Byz{lfiff&Y9-LZT0ff/AfiffS/i?ff/p3fiff/ |:*0A:}@7kL Rfiff*2fiLHfiL):d0G~&789:<; 7hUff/fffiLUX; /fi#ofij:L& /C"?84fi& = fiL lc_7 g%&H8 )\<fiL 7K7k!_ fiL /ff /kff fiXU67&lg-2 3/O\oZ&ff /k/ fiLU673 ' &.g= /RyOoZ&ff /kT ;S//lfi ! 7&>fiXffx73 &lg-2 3/O{# / ?ff /O;Lx2fiZ ]ff /f[ U!-/ /Ll& 8H ' / ]ff /X:L& /Cp2 .84fi& # fiL<7ff /lL[ U_T S2fiffk# / & ZT 0@O /f/*s3 .c7 gj&Hg- /R)k# / hff //lfi_ !4:]ff /Lg fi/;lfii fiD/aFz &P&Off /LgR*z# //L*3 Kfii fiD/Z?ff fiLU7fi& fiD/JD&jg-2 3/O6= / Rff /_T//lfih !# //Lh_ 7 2 /_k &7 ]; TLg[ U: L&/Cz84&fi # fiL\c 7g%_\\8g[U&fiy*ez{*ff\T\\2:Lg&fi 2fiDff{{;!;S/ /#/ /X8 )\8H/fi/;fi&fiff ff/?fffiXUX7&789:<;M[ oKUff/ffLfi UR 7 >Lfi 7K7kl7K-! &>7/&fi To#&,e b fiXK:2fi /7 //R7 <0fi3 ff/lL&7#C/fi#!fiLk"2/78R\ 003 ff&fi L'2 ff/ R 7 X 0fi #/ i; :N]ff/[U? ]fffi/i ffLfi &X8H/ SLfi!ff Z_i A/ |-// ffXfi UB 7 h . U&N!78 91:B; [ f// Bfi Lfi :_!&fi T0%fi#! Lfi 5LfiL 0oR Lg}_ fi/C) ; 0oZ#%i 7kS KU+X- 7_ 07_Xfi -?k 0!XS* _fiffC6U 0o&fif%")LTMj%<S"?TfTe"V"RbT#x#ff#bK</RDT0%ffffQ#_ff6SV_<ffff6)T3=3)ff< 1Bl=|Rff26SS#6#/-0R0K#ff)D#jHffffRx_3/RQffx+/#|M_DffMIL}LO_0+AffNGT0(ff/X6THjffDTff< /D/2AD2#/I_6THXO3.#/#KS00Dff?D/K#4Hffff52?/(5ffff/RffSff#%_6TffH6TffDl-?QffA)N6Vffb0Aff6'%SKff3_beD_#?D%ff)ffffQ1Bl#G03_<ff6HTX=S2d#ff-0Off}/T0bff#63 /MT.#/-0|2ff#K/ff|R_%A_.V#/|#/#KD/K#"ffff}_6T.ff T>L/#GT< #ffffbA/T(=/632#Rff<HQ%A6T_%KT%ff2S#f_Rff=3_3)T#jff6jQblff<ff=D/DH#KHKX<ffS#RSf =3=3lffK<ff#K/_<LTff-0RHjT#jff H%2/ ffeHQ%_XRQ##%f_T0ff6j#<ffSOff#D/DH#</XK)=K##Kff)ff26j <Rff=%T0%ffff6IVffX2ff/XKffSHQ%R/ffR<d/ ffff2#Tf%ffAd/#0/L ff00% DQd_2.#XTl<j"VaX1BYB3ffffe_6T2lffe6TYffff00#bK}2ffT6/3aR#ff3x5j%RVX2T)0L=DHffffffX_0ffd6Tj%<M f2NK=3_ %23ONK#)ff.ff_DT SQAB/3)Q.RA63] Kff]/Mfflff)ff6ffA63aHAff_3/aff_ 6TY?QffDX_<H0_ < ff003=ffD#VRb%/2HR=XHRS< < /3=.ff=X6TjKj0K#ff+3a%Rfij%RRR_#ffHQff#<H </3ffffS6T]bff#AKR=V<M <#R6Tj ffD/QDMH/)LGff#.#_ffePLSD_# _RSL2#AffHHff #ffff>6 #ffT_3Ob?_AffK6TdIjlDH#KTf#_HHff#ff"ffSHff13.=#KTff#_3R)/D/T0(/Xff_ffjff.jKTb bffR)ffNffePLV#)/DQR=3lffRff=}2fffffR_3/#.#ffTD'ff3X2Affff2Bff=3_]3/ARffb#=L ff_#b/D/4ff#R6TG3Off3YffSffff)jR)0K#D>ffRff_DTSffQDff#/0AQ6T_0N#/D#6-0jffe6T)ff# ff##KT0/Aff_D/Q <Yj=3/XffSHffR2N0#X2ff<ff ffSQ6T Tff/D/#_fffififiIj51Bfffifi"!< /#D=ff#fi<ff/0N#2D#%$&2ffDfffi'(")+*,-/.1032546798:8;48<%=>8@?BA+6CDFEHGJILKMONPQHRTSUWVYXN[Z\]\_^_\1`bac\def^1S dbN[^1acUWN[^P`fNgRY\1`Whi`Wh"N+QjNPdbk"UWNdSl"SmNffU%PL^_^ noNffUblpSUWQqPre[NYPrgsUWNffkdWPt]\u^1v\1`bawyx\re[Nzx M5{}|~ydNffr`b\1UWN`WNPtQRYSUfVeffPnP]\_^_\1`b\1NdPUWN]"UWSk"h`c`fS]oNPUi\1rN[ZNe[k"`b\1r"y`WNPQSnoNffU%P`WSU[d\1rPL^_^}Sl`fh"NgSQqP\rd"`Wh"NffUWNHPUWNcd\1r\_JeffPr`s\1Qjn"UWSmNffQjNffr`%d\1r `WNPQHRYSUWVHXN[Z\1]\_^u\1`baw"SU\1rdb`%Pre[N\ry]Nffrefh"QqPUfVFUWk"rdiSl5|5`W`%PeWV/PL^1QjS db`HPL^_^5Sl5`Wh"Nj`WNPQHRYSUWVl@P\u^1k"UWNdlpUWSQSk"UNPUb^_\1NffU\Qn^NffQNffr `%Pt`b\1SrFPUWNcPLmS\gNgwY+NffUf`%PL\1r^1aPL^_^9Sl}`Wh"NlPL\_^1k"UWNd\r O\1k"UWNcjPUfNcPg"gUWNdWdbNgW` NffQqdPrgPUfNPg"gUWNdWdbNg]NeffPkdNPNffr`%dHQHkdb`Hr"SRP`f`%PL\1rQHk"`WkPL^5]N[^_\1N[lH\r`Wh"NPeWh\1NffmNffQNffr `Ok"rPefh\NffmP]\_^_\`baSUs\1UWUfN[^NffmPre[aySlT`WNPtQSnNffU%Pt`WSU%dffwjMh kdff\1r \1`WNffQO`Wh"Ne[SQjQqPrgNffUYr"SR>P`W`%P\rdQHk"`WkPL^/]oN[^u\1N[lY`WhP`Y`Wh"Nsh"N[^u\e[Sn"`fNffUe[SQnPr ahPdYe[SQjn^1Nff`WNg\1`%dNffr" PNffQjNffr`HRY\1`Wh`Wh"NNffr"NffQHaJYR5h\_^1N\1ry\1`WNffQ}`Wh"N\UfUWN[^1NffmPre[aSln^Pr"r\1r"P]a nPdWdUWSk"`WN\de[SQQk"r\effP`fNg`WSH`Wh"NHe[SQjnPrawW` NffQqdPrgPUWNPg"gUWNdWdbNg]NeffPtkdbNFPNffr`%djr"SRPe[`HbS\1r `b^1a] ayU%d`qNffrdbk"U\r"`Wh"NNdb`%P]^_\dbh"QjNffr`YSl bS\1r `Ye[SQjQH\1`WQNffr `%d]N[lpSUWNsN[ZNe[k"`\r"H`Wh"N[\1UYUWS^1Ndffw}SU}\1rdb`%Ptre[NP`WNPQQjNffQH]NffUgSNdYr"S`5]oNff\1rN[Z"Ne[k"`b\1r"q`fh"NQH\dWd\1SrPd5dbSSrPd\1`n"UWS"e[NdWdbNdT\`[dYSU%gNffU%dp\1`WNffQ%U[P`Wh"NffUt\`5Pe[`[dbS\1r `b^1ajR\`fhq`Wh"Ns`WNPQ PLlp`WNffU+`fh"N`WNPtQNdb`%Pt]^u\dbh"NdS\1r`Te[SQQH\1`WQjNffr`%d`WSHN[ZNe[k"`WNi`Wh"NQH\dWd\1Sr/wW` NffQqds"oPtrgPUWNHPg"gUWNdWdNg]NeffPtkdbNj`Wh"Ni`WNPQSnNffU%Pt`WSUH};b ;ufpp_ffffp;[p%\ddnNef\_Ng`WS]NPr>|ssve[SQH]\rPt`b\1Sr>SlH`Wh"NFUWS^1NFStl`fh"Ndfe[Sk"`%dPtrg`Wh"Nr"Sr"vdWe[Sk"`%dwMYh kdk"rPeWh\1NffmPt]\u^_\1`baStl`WNPQSnNffU%P`fSU%d\dgNff`WNe[`fNgcd\1re[NN[\1`Wh"NffU`Wh"NdWe[Sk"`%dSUY`Wh"Nr"Sr"vdfe[Sk"`%dYeffPr"r"S`5noNffUblpSUWQ3`Wh"N[\1U5UWS^1N"SUT`fh"NcdWe[Sk"`b\1r"vpUWSt^NcPdWd\1r"QjNffr`\dk"rdbnNef\_Ngw rz\1`WNffQqdcPtrg r"SUWNffnP\U[dPUWNjnoS dWd\1]^1N]"k"`P``Wh"N^NPdb`c`Wh"Nje[SQnPr\rlpNffU%dP ffe[SQjn^1Nff`WNffv;lPL\_^1k"UWNPtrgUWNff`Wk"Ufrd5`WSh"SQjNi]PdbNo\1rdb`WNPgStl+RP\`\r"\1rgN[r\1`WN[^1awrz\`fNffQ9`fh"Nqk"rPdfd\1r"NgyUWS^1NP PL\1rz^NPg"dH`WSk"rPeWh\1NffmPt]\u^_\`baY]"k"`HUWNffnPL\1Ui\dinS dWd\]^1N]NeffPkdbNiSr"NSl}`Wh"NUWNffQqP\r\1r"dbk"]"`WNPQd5effPr`[PVNsSmNffU5`Wh"NUWS^1NSl}`Wh"NcdWe[Sk"`wW` NffQ\dPg"gUWNdWdbNgzd\1re[Nj`Wh"NHUWN[^1NffmPr`SnoNffU%P`WSUH\dr"SRN[Z"n^_\ef\1`b^1agN[r"NgFPdsP`WNPQSnNffU%Pt`WSUsRY\1`WhPrzYve[SQH]\1rP`b\1SrySlTQjNffQH]oNffU%dffoUWS^1NdffwHMYh kd]PdbNgSrFe[SQjQHk"vr\effPt`b\1SrlpUWSQ3`WNPQQjNffQH]NffU%dff`WNPQQjNffQH]oNffU%dff"effPr\1rlpNffU5\1`%dk"rPeWh\1NffmP]\_^u\;`awW` NffQ\djPg"gUWNdWdNgF]oNeffPkdbN\1r`Wh"NNdb`%Pt]^u\dbh"ve[SQjQH\1`WQjNffr`%dHn"UWS`WSe[St^@`Wh"Nj^1NPgNffURY\_^u^UWNffnNP`\1`%dQjNdWdWPN\_lPUWNdbnoSrdbNi\dsr"S`5h"NPU%gRY\1`Wh\1r `b\1QjNi^_\1QH\1`wcSRYNffmNffUL\1rNffr"NffU%PL^P`W`%PL\1r\1r"QHk"`WkPL^}]N[^_\1N[l\1mNffr `Wh"NHnSdWd\1]\_^u\1`baFSlYk"re[NffUW`%PL\1re[SQjQHk"r\effPt`b\1SrFeWhPr"r"N[^d\dPjr"S`fSUb\1Skd^1ag\_e[k^1`HeWhPL^_^1Nffr"NbPL^1noNffUWr3~S dbNdff%Prg`Wh\dsUWNffQqP\rdPtr\dWdk"NlSUlpk"`Wk"UWNRYSUWVw|dYPlk"UW`fh"NffU+\_^_^1kdb`WU%Pt`b\1SrSl`WNPQHRYSUWViXN[Z \1]\_^_\1`a\1r x M5{}|~y RYNe[UWNP`WNgd\_ZmPUb\P`\Srd\1r`Wh"NNffr m\1UWSr"QjNffr`%PL^e[Srg\`\SrdlPef\1r"`Wh"N|5`W`%PeWVe[SQjnPraSlh"N[^_\e[Sn"`WNffUn\_^S`%dffw}{+Pefhe[Srg\`\SrUWNk\1UWNg`Wh"NFn\_^1S``WNPQ`WSzXN[Z \1]^1a>QjS"g\_la\1`%de[SQjQHk"r\effP`b\1Sr>`WSyQqPL\1r`%PL\1re[Sh"NffUfNffre[N \1r`WNPQHRYSUWVw9Mh"Nd\_ZmPUb\P`\SrdPUfNwH+p;t+MYh\dY\d`Wh"N]PdbN[^_\1r"N[r"SUWQPL^je[Srg\1`b\1Sr/wwH+p;jO|5^1`Wh"Sk"hjd\1QH\_^PtU+`WSe[Srg\`\SrRYNTPdfdbk"QjN}\1rqPg"g\`\Sr`fhP`e[NffUf`%PL\1rHU%Pg\1SlUWNk"Nffref\1Nd[efhPr"r"N[^dHR5h\efhRYNffUWNjn"UfNffm\1Skd^1adbNffnPU%Pt`WNg9PUfNjr"SRe[SQjQSr/w rynPUW`b\e[vk^PtU/QjNdfdWPNdsn"UWNffm\1Skd^1aFPdWdbk"QNg `WS]Nn"Ub\1mP`WN[^1agN[^_\1mNffUWNgz`WSSr^1a `Wh"Nje[SQjQPrgNffUPNffr`+lpUWSQ\`[d5dbk"nNffU\SU%dffPUWNsr"SRPL^dbSjQqPgNcPLmPL\_^Pt]^NH`WS`Wh"NS`Wh"NffU5`fNPQQjNffQH]NffU[dffw%fiT+""/" L"+""H+; fffifi"!#$&% fi' $()fi*!#+$,!-.fi' $/!#,'fi01#2'*3%54687:9;fi< 6 +*3% "9"=oH+;?>@"fffiA."fi<?!#$&% fi' $ @)B70*'+*5 $A%% fi' $Cfi&fiDfi<*E*-FG!#Hfi<*-"fi*3I&$,JCK*3%LMHNL' fiOJP4+*-$&'' $Q ,Lfi#.$*-&5.fifiR!<ST$Qfi**-$*-DJUH+;WV.1Xff*-*)Y70*;$&!#*.Z2 $W'fiR.<fi170 fifi<*;[&'*#$*5.4\!#$&%LfiNL$C])^[fi_<'+*H&,0` [,fi'JE $%% fi' /$ 0a0Z&b)c*-$Zfi# 53JK$fid!-!#Rfi*#J"*3'fiNL5.fi*:fi*# _%'fiR$&!#*3ffeH+;Cf.5gh$C%%LfiNL$QfiW!#$&% fi' $iU)\*-*)Bfi*!#KH&.$ZJP&'+*Kj&*#kZ [,fiOJl $*3!<,L$5fi*[&.fifiNL*mH&ZOLfiNL/$ ;a0*+!#+H&.$,J51H<8`%,*3%70 finfi*Hfi' $4 &2fi' $/.fi!#*-fiR2 $ES*-JKc!-.fiNL$&-)&#.fi*-1fi&$!#$ZfiNL$,, $"fi<;j&J*D%,*3!< $Ffi*-<*-fi'!4R.+*-70<S+ $TpZa1qB rs*-$&.[,*3 .*-$,fiR1fi<+j&*#k, [,LJ*3NH&$&%nfi5fi*.[^8`*;!#$&% fi' $&ff0tuL*;vH,fiR0fi<* $Z[&*-ff.4wK*3.*3o*#k@!<&.$*3%E.K$fi*3.x+*-[^*-R4 *3!</4 fi*"ky!#$&%LfiNL$&ff +a0*+fifiR2z$,[&*-;4 +*3.*3ffL$Pfi*-*fi*3."ff{ [&2.$&!#*3%Y)!-.fi' &m.$&%*3!<SL*3< { .*"!#KH&.*3% +|02.$&!#*3%Q.*-$,fiRff4,LJP*#kcH,. fifi*"%,*3!< $Tfi*-J4R.+*-70SY).$&%Efi<Z&}&'fiRfi*5pZa1qB rT~}j&*#k,L[,fi'J ;0.fi' &:.*-$,fiR12712Jc1!#+$,!-fi*)$' $fi*"%,*3!< $Qfi<*-Jn4#.+*-70+0*3!<S*3+*-$Zfi# !#+$,!-.fi*5`*-JEfifi'*h$,LJn4, ')B 0-[ 504ff!#R'*)fi<,JW*3!<S*3m.*-$,fiR:70,%nLS*#LJT$fi;!#KD$,!-.fi<*".fi;2h)B'fi,;%,*#&$, fi' $P *#2k*3%*-* K1fi<*-*+fi*3.":70<SE70 fi%,*-$ZfiN!-8o!#Z'fi Kc%,*#-)}!.)\ ).$&%P 0 a0*$Z[^*-;.41.*-$,fiR170*-*mk*3%n $Wfi, *#kH&*-NLK*-$Zfimfi543)'2fi*-*Kfi*3."{ !-.fiNL&-)Y[&2.$&!#*3%T.$&%n*3!S*3:{ !#,%[^*+$Q'd%!#&<'*3% $Wfi<*D$*#kfi;'*3!#fi' $) fi:%!#,fi fi$fi<*;!-.fi' &fffi*3.70 fiE4fi*-oL$&!#<*3'* $nfi*3.x -*.%t@c!#&OL$y&R'fi;$Qfi*"[&8$&!#*3%Tfi*3.) fi71;[,L*Efi</H^*-'4 fiRm $Q$&%,*-"2dk!#$&% fi' $&-)[,Jnj&*#kZ [,J%,*3!#<*3 $: $&!#*3 $fi*+$,[&*-.4K*3.*3ff $T*3'H^$&'* Ea0*&R'fi0'*-fi0.4w!#$&% fi' $&_O!#$&% fi' $&0(mfiK=G&'fi#.fi* fi&.fi}fi*:[&2.$&!#*3%5fi*3.!-.$"<*3%,&!#*fiR1!#KD$,!-.fiNL$E $*3NH&$&'*mfi+fi*;OLfi<&.fi' $E4h!#*3%Y)*) $&!#*3'*L$!#+$,!-.fi' $!#Z'fiXff870*-`*-2)$&%,*-d!#$&% fi' $&:U;$&%Ee),fi*d[&8$&!#*3%5fi*3.x!-.$E2' $&!#*3'*: fiR0!#KD$,!-.fiNL$fi%%,*3fi*+$&!#*-fiR8L$,fi' *3ff t@ $&'fi#.$&!#*)70 fi!#$&%LfiNL$U)S,$.70*3%,*+.41H&,m` [,fi'J.fi".fi'!-2JQ*3%5fi*3+*-[^*-R5fiW*#kH,!< fi'J!#+$,!-.fi*W!<, *-`*-+*-$,fi".4713J,H&L$,fiR$Tfi*# fi* 5gh$C%%LfiNL$)B70 fiQ!#$&% fi' $Ce)fi*+fi*3&mfi!#+$,!-.fi*5fi*3'fi#.[,N!#+Lfi<+*-$Zfi#071*-$/%,*3!<% $Efi&2fi:0fij&JK4<7oR%ao*;!-.fi' &0fi*37102'5.[,*;fiH&*-N4<fi<* $$&%,*- 2wk!#$&% fi' $&-)^[fi0 fi*#*3:$5.$ZJEK* +*3<.*31.$&%*-"2 $&ff $&'*-$& fi' `*Kfi"!#$&% fi' $& (.F=Kfi&.fi ',%n*3',fi$Q4*-70*-DK*3.*3 ?g$&%,*-*3%Y)} fiR*#k&!&.$*E.4]2.Fh(4%TK*E+*3<.*3mfi&.$Qfi*E[&8$&!#*3%fi*3.fimH&*-'4x.$5%,*-$,fi'!-2zfiR'Smo$fi0$,Jm71'fi*ff.4zH*3!< &1!#+$,!-fi' $E*3'#!#*3-)[fi1!-.$E!#*3.fi*1NNSc}4}fi*dfi<*3. $EZ'fiNG*:*-$Z` $+*-$,fiRff oOa0*:$*#kcfi1'[&'*3!#fiNL$"70w%!#&fi*ff'* .4z!#+$,!-.fi' $5*#!< *-$&!#J5 $"K* %,*-fiR2Da0*:*3!<S*3}fi*3.x%,,*30!#+$,!-.fi*4*-7*-+*3<.*3-)}[fi fi4h2fiWH^*-'4Lfi#[&!E< /$ QqB`*-$T $Cfi<*5&R'fi$"8ff!-'*)fi,ff*#G!#Hfi<*-_!#KH&.$ZJ5*-fiRff'fi&!<S"$Efi<* 7o2J5fifi* [&.fifiNL*mH&ZOLfiNL$) $&!#*+*3* 70 fi+*3% }[fi, +ffu$fiz!#+$,!-fi*3% gh$,fi*-*3'fi' $.J)fi*B$Z[^*-z.4+*3<.*3^ $&!#*3N*$Wfi**3!<S*3fi*3.$&%,*-!#$&% fi' $&;(.Fo= Da0,ff [^*3!-.&'*"!#$&%LfiNL$(E2.7d:fi**3!<S*3fi*3.fi+2`.%*-fifiNL$+'fi<&!S+[^*#4*d<*3!, $fi*:[&.fifi'*:H&ZOLfiNL/$ 1hg$+4h!#fi3)fi,1!#$&% fi' $E71%,*3 $*3%fi<d*-fifi*}*3!S*3fi*3.$&'fi&!<p.L$&!#*fffi* *3!<SL*3<Bfi*3.!-.$$87TH&*-N4<+* .4R3fiY ,Number messages350300250200"balanced-u""cautious-u""reckless-u"15010050012345Types uncertainties6u <;0 &.:L#+,-.' n0 / ' &8z&#-R2 ,' 3-: K<3, R}&.' :&ZOLNL5+1+3<.3 1#&&.3Y 1,<&.#'K+-+33 ."N'G1m#@<&.3Yu 32 3.K-D^-R;NR.&,3y ?K&.'&, ';uC.3oC ^.KD,-.NL;#< -&#:z#NLN-8Z ;<3.#&.<'#,' 0 D-8L-m ;<3. -.#N#+,-.' T.-3 -?-.&'"OL,G-Z+,-R.' T3.&-N<".&#Eu3 .& -+:+3'0:#+,-.' +.-3 .Y3.0Y8.&mff&'#, 3.0Z1B T0,3< --NK#+,-.' /N#L3#NL '5L 80-' 5 .-3Y@&.'#,.' E "<-2 - 3. - }<;&3d#+&.m;R2z,&- .B+33-m3."o Z<c,&#3.^8:&2.&#3Y-.NL&d.&3< 3o 0 E &#3OL,D^-R:. .-,Rff&- 3.n0hm Z-<3'dh2 _#+&.''Y<;#2w#+#.' &23'R#3"2.2,LP33.I0-E-#&NR.,EOW . TZ:0 R . QA, W,R K"2,L3 -+<&.;#,&KY+3N,L# '.1&# ..+',E<L-,'L&NR.' <-"}. -2 -u < 3 c#&'3ffEm1R","2 :3< <--''# 3#' '-&,L3:< &2.&#353&-N<0#0 K-A+3<.3\<,o3.0<-,.' +&#,3LE',Z<-'#-R<'3-doD-.' &ff3.#&&.3 3 " .E1+m+330&.n;&8&#33.+'&NR.,'2w#+,-.' .-3YBh&,-3YY^-&/.-,R-, D,.NL0 C-.NL&+3#,l+^ET C32:' +03 35.-,RL,+-',P#&&.;.Z5+3<.31.:2u < c#&N3:+R&'&<_,52 &#+.Z8LW#K&.' E;^-'".&#.-.' &b&&2.&#3.&n3<L3<13"00 &#3 EZ&-#:.\-Z#} /<;3.n:1&#.Z8L1,3< <--''# 3#' 'C-&,L35<&2.&#3l3.IP&-'0#G:0 Q-+3<.3ff ,3.m-,.' n&#,3 Q'Z,-'#-R<'3-E0+-.NL& 3.&#.Z8LT &#RK/OL,G-Z5.-3P. 3 W .T+"K3.3m&?E&8&#3fiff ffff !"#%$ &(')ffff*+')-,."#*ff/ fi0#ff1fi324"35 fi1!fi*"#*!"6* 7981ff*(:ff;<#=6>?fiNumber messages@ACB/DFEFG)HJIKLNMFOQPRKSLT@LNDFU/B:AFEFV500450400350300250200150100500"balanced""cautious""reckless"234567Number agents team8WYX[ZN\F]^`_acbdfee6gNhfii jCkml%gSX[nb/o^#p[^h#eX[qN^:h#kNl`l+\FnCX<hgeX[kNnr/st^himp[^ooe^glu^#vhfiwgnFZN^o1nFkxl`^ogyZN^ognjzwF^nh#^xewge{Cp[kNe|kqN^]}pQgy{o~X[ewzewF^-v4gSvCX<ore^glrf^]^N(^Nkmnjo}^qN^ngZm^nRe6oewF^oX[l+\Cp<geX[kNn~X[ewF^hg\FeX[kN\oJe^glh#kN\Cp<jnFkme%^]\FnX[n]fi^gSp/eX[l`^Nr+nCe^]^o}eX[nFZp[NX[nefiwF^`e^oe9oh#^ngy]X[kJkN]:efiwCXQo-^#v4{^]X[l`^nCeewF^+]^himp[^ooxe^glX<ozgCp[^ek{^]kN]lefiwF^l+X<ooX[kNng{F{F]kN{F]X<gefi^#p.^qN^newFkm\FZNwewCX<oe^gl^#vchfiwgnFZN^ox\oe_l`^oofigZN^oCg]^~^]fewgnzefiwF^9gSp<gnh#^je^glr/Ykzg`h#^]e6gSX[n^#v4e^nCeFefiwCXQot]^o\Cp[efXpp[\oe]6gye^o3ewF^{kme^nRe}XQg5p/kN]:X[l`{F]kqmX[nFZefiwF^%jC^hfiX<oX[kNnFewF^kN]^e}XQho^#p[^h#eX[qNX[eX[newF^`g5pQgynh#^je^glrJfk~^qN^]~fwF^nzewF^:efi^oefoh#^ng]X[kxkm]efiwCXQot^#v4{^]X[l`^nRe3~fgNohwgynFZN^j)Fok+ewgeewF^:e]6gyno{kN]fie6o/g]fi]X[qN^jp<ge^gexewF^`]^njC^qNkm\o+{kX[nCeewF^JgSp<gnh#^jefi^gl~fgNoxgCp[^%ekh#kNnCeX[nR\F^Jek{^]kN]lefiwF^%l+X<ooX.kmng{F{F]km{F]X<ge^#p[Nr(k~^qN^]NefiwF^:]^himp[^ooe^gylnFk~{^]kN]l`^jX[ng{F{F]km{F]X<ge^#p[NwCX[ZNwCpX[ZNwCeX[nFZzewF^]X<oiJX[nefiwF^:]^himp[^oo3g{F{F]kRgNhfiwrNumber messages300250200150"balanced-m""cautious-m""reckless-m"10050034567Number agents team8WYX[ZN\F]fi^%_N_Nb1Y]6gno{kN]e|jCkml%gSX[nb/o^#p[^h#eX[qN^+h#kNl`l+\FnCX<hgeX[kNnrWYX[ZN\F]fi^ _-Xpp[\oe]6gefi^oewF^:jmX^]X[nFZ%h#kml`l+\FnCXQhgyeX[kNnz{gee^]fino1X[nzewF^:hg\FeX[kN\ognjJg5pQgynh#^je^glJokN]:ewF^+dfee#gNhijCkml%gSX[n)ekgeefi^l`{Fe|efik%\FnjC^]6o}e6gnjewF^`jmX^]^nh#^+X[newF^#X[]xekNe6gSp1h#kNl`6fi)F/C+FC<[N|Y[NFfi%C[N6(F9m[FCNfi y#<N6[NCSC<#tCF}.FmCFN4SC<#)[+Ff6Nfi9CN%5.13Nfi/#QyN6y[NxQ`NFfiF6#R#NN#N6[:C[NN6NC[66fiRfC<z#N<#/yfi[m[N<CS1NF6fiN6#6)[6#C6m[`C.[CNfiy#<m6[NzxN<#3N6cF|}Q [FC[N6F5m6SCNfy#<m6[N[`Ffy6m[F:[Rfi9N#NFCSm6fiN6F:FNF[F3[mQyF:CN:#<N6[Nzt.fiFNFf#NFR}.F+yuN6N#1#F#FRC</C[N|yNRS/FFfiF3m[F`y[%F3:[F<y`[m<[NF`m[FCNfi`FFyN#[N[Nx<#C<YF+[F9N[`3N<FF`6y%mF +NFx[`[m<[FF#R[C.S<C[zF}FFFN6SCN:y#<N6[NJ<t[5[zFNxm+NyRC`6mfF9mR6FRyN:FF+NTY[NFSTC[N#+FJ4S6Sm93N6Sf#N`+FC<[N`FNNmyF[NS<#zfi%1Fm/[##NCF9F[N#yFN:[6m6S`fiN[FN:NF/m`+FCQy[Nz6#C6mf<f#Nfi#<+FCm|y#<N#[Nz(FNN:F%F}.m:#R#fi[C FNC6FF9FN3N:FS<#fi#C#fi[RxFF#fiR}Q5[NFC.m9F:F[NfiCF3S<#zyCCFNf#N FC<fi|fC[9fiF#.#<m6[NF4#F3`CNC[N25Percentage messages90Degree Collaboration80706050403020"team""team-without-subteam"10"cautious""balanced"2015105000510 15 20 25Phase NumberC/3Nfi:#y<N6}.m30035510 15 20 25Phase Number3035)f#SNf#N`+FC<[NY[NF%SFf6Nfi%CNJS[1fiz#m`+FCQy[Nu-y)fiff Q/FSS[[N#}.fi<xF#NJF:#N[RNy.m.#4m[Fz`4mN[FzNC6+N`yC[[(#N`[F`fiF:#m1[R [S[}.m/F3NzS[[N3<fiF4Cfi[FzSRC[[3N<`fi<S[N`#Rm6m[[NzC<)N[NF-.C[<S[`C[`C6[N [TfiF`f6mCN%S[`[%fi`+#N:NC<mC[[NC CNFm[[NS3#4m[F#NFN+#`C[N"!`Ffi4C##R#[#[N%#m`+FCQy[NyC[[NF([C.}Q51.C.R6y[N#NC<NfiR<S[SNxmC.fi9CFCFfi<Sm/N6m61N<C1NFY.C[<S[`C[`R#[Nx[`F/(6NfiCN%5.%$fNmF9&ffiuN6m6Y['RfC<fi`NC<`mC.+f[m[N<CSN6yN6[`F[C[<S[`C[`C6[N)#NNC<+Nfi+NC[36fi#N`+FC<[NN6yN6N6N#/mz`[N5Y#m`+[`C63fiNFfz#m(zJmF:`[NSfi+[[N#N+[`C61Y<1S[NC (N#SR)F(6&cC#FFfiF`NfiN3FFC#|#[#[m[NNFm[[NS/fiQ5N}fNC<z9F#.#J [Fx#4fi`9NNNfi#N+C.y[N55.Fy+ *)N%,.-+S)N0 /1.,1N+S65#mCQxmC[f|}6/}fi<SNN#N2243fi576(8.9:;=<?>@ACBDFEG@AH5%AC9I.86:JK+LMNPORQCO4STVUWQCXZY([]\^S O_[]QC\^`baST]cRdSCe(f'XQCcgdhORi^S \SZi(j\^e(cRdelk4monpjcRORidqcRXrQCcRdCa^`_dqs^Stc4S ORduQCs^dqc4StORQCc4`XvSf?Y^dhcgdwCj([]cRdee(dqs^dq\^ex[]\yzQC\P{|idqOgidqc|ORid}UWQxXXZj\([FUqStO_[]QC\Q~UqUWjc4`{[]ORiORiddq\GO[ficgdhORdS XQCcQC\(T]fvSZ`_jYORdStXPm%UWQCjc4`_dCax[]O{QCj(Te'S ss^dS cORi^StO7ST TV`_j^Ugi`_sldUg[STVUqSC`_d`UWQCj(Te?Y^ddUWQC\QxXZ[]qde[]\QCjc[]\([]O_[ST[]Xs(T]dqXdq\GOWS O_[]QC\#YGfex[F`gUWQxdqc_[]\yPyCdq\dqc4ST[]S O[fiQx\^` YjOORidq\G|dq\^UWQ~e(d`scRdUg[`_dWT]f`j^URizyCdq\dqc4ST []S O_[]QC\^`ORQvSCQ [erORidhX?S \Gf?`_s^dUg[ST.UqSC`_d`qm\HSCeex[]O_[]QC\^ST7s^Qt[fi\(OhQt7dqSTfij^StO_[]QC\[`dSC`_fPQtXrQ~ex[ Y([ []O+fQ oS yCdq\(OORdS XY^dqi^Sx[]QCc4`qmZ\QCjc"dWNs^dqc_[]dq\^UWdCae(QCXvS[fi\rG\Q {T]de(yCdoSxUqwCj([]cRdeucRQCXdWNs^dqcRO4`[`\QCO.`_O4S O[FUc4S Ogidqc[fiO"j\^e(dqcgyCQGd`Sh`+TfiQ {dqCQ T]jO_[]QC\m"\vORid|OROWSCURZe(QCXvS[]\axQCc"[]\^`_O4St\^UWdCaGcgdST]{7Qxc_TeXZ[ []O4S cRf?e(Q~UWORc[fi\dUWQC\(O_[]\Gjd`ORQZdqCQ T]CdCa(cRdwxj([]c_[]\yXQex[ UqS O_[]QC\^`%[]\'QCjc|`_f(\GOgidqO_[Us([T]QCOORdS XY^dqi^Sx[fiQxc4`qm"\`_j^UgiP`[]ORj^S O[fiQx\^`qaG|Stss^dS c4`OgQ0SCUg[ [fiOWS ORdv`_j^UgiXQex[UqStO_[]QC\^`h`_jyxyCd`_ORdezY(fPe(QCXvS[]\dWN~sldqcRO4`qS OTfidSx`_Oal[]O[`|QtORdq\z\QCO|\dUWd`R`gS cRf'ORQvSxee'\dq{UWQGQCcWex[fi\^StO_[]QC\Ps(TS \^`qmnQCc[fi\^`O4S \^UWdCap[fi\ORidORO4SCUge(QxXvS[]\ae(QCXvS[fi\'dWNs^dqcgO4`%dS c_T []dqc`_jyxyCd`_ORde?SuXQ~ex[ UqS O[fiQx\aORi^S OORididWT [FUWQxsORdqcUWQxXs^S \(fv`_iQCj(Te?dqSxe(ddq\dqXZfHxdqi([FUgT]d`'`_dqdq\dq\cRQCjORdCa%c4S OgidqcORi^S \#^fx[]\yHQ CdqcmdqcRdCa|SCeex[]\ySP\dq{j\^SCUgi([]dqS Y([ T][]O_fUWQC\^ex[]O_[]QC\QxcoORidrORdS XQCs^dqc4StORQCc ^f([]yCiGOgs(TFSt\{Sx``_j(Ug[]dq\GO.G"ORidq\dq\^`_jcgdeORi^S OORids([ T]QCOoS yCdq\(O4`%UWQGQCcWex[fi\^StORde?ORidORdqcRX[fi\^StO_[]QC\vQt7 ^f([fiyxiGORs(TS \|a(dqCdq\r[=_j^`_OQC\dStcRY([]ORc4StcRfORdS XXdqXZYldqcoe(dqORdUWORde?ORiddq\dqXZf?Cdqi([UgT]d`qmKRUWQCjcW`_dCaORiddq SC`[]QC\'XvS \dqjxdqc4`qaYldW[fi\ye(QCXvS[fi\0`s^dUg[ U a=i^SCe'OgQ}Yld}SCee(de=mfikV^ltlx`Xdq\GO[fiQx\dehdStc_T [fidqcaCXQG`O[]Xs(T]dqXdq\(O4S O_[]QC\^`Q XZj(T]O_[]0S yCdq\(O.UWQ TS Y^Qxc4S O_[]QC\UWQC\(O_[]\GjdORQocgdWTfifuQC\e(QCXvS[fi\0`s^dUg[ UZUWQGQCcWex[fi\^StO_[]QC\?[]\`_dqcRx[UWdQ VORdStX}{QCcgvK_ dq\\([]\yG`qaMx ^a^MCCL(k4m"zQCcRdcRdUWdq\GOTfifCaiQ {dqCdqcaCSdq{dq\^UWQCjc4S []\ydWN^UWdqsO_[]QC\^`"i^SCddqXdqcgyCde?K+ dq\\([]\yG`ba^MCxLC%[URi? [e(\dqca=MC(CkWmd^c4`O|Yc_[]dW^f'cRdqx[fidq{ORid`_dZ`_f`_ORdqXv`S \^eORidq\PUWQC\(ORc4SC`_OORidqX{[]ORiG|#mtdq\\([fi\y(`q`KWMCCL(kl[]Xs(T]dqXdq\(O4S O_[]QC\?Q XZj(TfiO[fi0StyCdq\GOUWQ TS Y^QCcWS O_[]QC\Z[]\?ORidoe(QCXvS[fi\rQ dWT]dUWORc_[UW[]O_fhORc4St\^`_s^QCcgO4S O_[]QC\ZXvS \^StyCdqXdq\(O[F`%ST`_QY^SC`_deQC\_Q []\GO[]\(ORdq\GO[fiQx\^`[]O"[`T[]CdWT]fQx\d|Q Ogid.^cW`_O[]Xs(T]dqXdq\(O4S O_[]QC\^`[]\SUWQCXrs(TfidWNe(QxXvS[]\PY^SC`de?QC\PSZyCdq\dqc4STVXQe(dWTVQ "ORdS XZ{QCcR=mVdscRd`_dq\(O4`Szc4S Xdq{QCcgHUqST T]deqClh_q~xqb ZY^SC`_de#QC\S_Q []\(OvUWQCXXZ[]ORXrdq\GOOgQORid'ORdS Xz`+Q []\(OyCQGST#S \^eS_Q []\(OcRdUg[]s^dvUWQCXrXZ[]ORXdq\(OORQS'UWQxXXQC\zcRdUg[]s^d'omu{Qex[`_O_[]\^UWOuO+f(s^d`Qt+Q []\(OUWQCXX[fiOgXdq\GOW`" SuXQ~ex[ UqS O[fiQx\PORQZORid_Q []\GO[fi\(ORdq\(O_[]QC\^`%c4S Xdq{QCcgZS cRdUgTS[]Xdez\dUWd`R`RS cRfY^dUqStj^`_dex[ dqcRdq\(OSCUWO_[]QC\^`hStcRdZ[]\GxQCCde{|idq\P_Q []\(O}UWQCXX[fiOgXdq\GOW`hS cRd?e(cRQCss^de=mQ{dqCdqcaSC`SrcRd`_j(T]Oa(_Q []\GOcRd`s^QC\^`[]Y([ []O+f{7Qxj(TFeS ssldS cORQvYldZT []XZ[]ORdeORQ'SO_{QCT]dqCdWT"i([]dqc4S c4UgiGfzQ 7S+Q []\(OyCQGST7S \^eHS+Qt[fi\(OZs(TS \a"ST]ORiQCjyCi[]\^ex[fix[e(j^ST`'UWQCj(TedWNdUWjORd'UWQCXs(T]dWNSCUWO_[]C[]O_[]d`u[]\`_dqcRx[UWdvQORid_Q []\GOs(TFSt\m7id_Q []\(O|cRd`_slQC\^`[]Y([ T[]O_fzcWS Xdq{QCcRu[`[]Xs(T]dqXdq\(ORde[]\PORidZ.|}`_f`_ORdqXPa{|i([UgiS ssldS c4`ORQQ~UWj^`%QC\?SORdS XQtOgicRdqdoS yCdq\(O4`qm\P.|(aCORdS XZ{QCcRscgQ~UWdqde`%{[]ORi'S \CCx^F7S yxdq\GOoe(dqOgdUWO_[]\yvORidu\dqde?QCc"_Q []\GOSCUWO_[]QC\p[fiO[`|Ogidq\'cRd`_s^Qx\^`[]Y(TfidQCcd`_O4S Y(T [`_i([]\yPSORdS XS \^e'dq\^`_jc[fi\y'XrdqX}Yldqc4`q^UWQxXXZ[]ORXdq\(O4`|SC`cRdwCj([]cRdezY(f'ORid_Q []\GOcRd`_slQC\^`[]Y([ T[]O_fXdqORiQe=mi([ TfidZORidscgQ~UWde(jcRduQCc|d`_OWS Y(T [F`i([fi\yZ_Q []\(OoUWQCXXZ[]ORXrdq\GO4`7[fi\G|"[``[]XZ[ TFStcoORQ.|[fi\^UgT]j^ex[]\y#ORidv`[]XZ[ TS c_[]O_fHQt7ORidgT]dSCe(dqc4[fi\G|ORQzORidWQxcRyGS \([]qdqc4[fi\.|?G|e(Q(d`Y^dq\dW^OcRQCXSCe(QCsO[fi\y' `qaC{i([FUgiPscgQx[e(d`[]OSCeex[]O_[]QC\^ST^dWN([]Y([ T[]O_fCmG"[`ST`_Q?cRdWTS ORdeORQz|o=.K+7[FUgi [Fe(\dqca"MC(CkWa~SrscRQCOgQCO_fGsldhORQ(Q T]C[]OSs(T []deZORQ|Yj([ TeS|UWQ TS YlQCc4S O_[]Cd%[]\(ORdqc_0SCUWd7S yxdq\GO=QCcVStss(T[UqS O[fiQx\^`"`_j^URiSC`S[]cRORc4SCdWTGS cRcWS \yCdqXdq\(O4`qm|o%h`QCc_[]y []\^`"S cgd"[]\ORidCi^S cRdeTS \^`OgidqQCcRfCm|T]ORiQxjyCiZORid||o=%#[]Xs(T]dqXdq\O4S O[fiQx\e(Q(d`\QxOdWN~s(T [Ug[]O_T]fHcRdSx`_QC\zcgQCXOgidPll'GC.S OgO_[]ORj^e(du[fi\Ci^S cRdeTS \^`[]\(ORcRQe(j^UWde[]\KRocgQG`_oc4S j^`qa=MxC(k4a[]O|e(QGd`7[fi\^UWQxcRs^QCcWS ORdex[F`gUWQCjc4`_dyCdq\dqcWS O_[]QC\'S \^eZ[]\(ORdqcRscRdqOWS O_[]QC\'ST]yCQCfi=.(_]Rvg^ "C_] ]^ R%]v_gZRC_x(fi=R^ff fifig _]R(qC] Cq("Cl "!$#%&('*),+.-0/0 g1 ]4 RR2x3 Wx4_4lq 57qqZ(v P^qo 'g6F7 3^](R8 1]Cq( Cq(9 :C9 ;Cq4 $!<#%&('6)6+.-=/tRR> z]H_ g](Rq4 W_]C&_ gHCv](R9 ?^ Wu /Z_qxqGg@ ?]Ggq4 W_]C'(_Rx3:<+A'6BCWCGg4C_4D5figE!$#%"('6),+F-GH%> gEIG: > (q@ Dff@fifiJot K)6HL'.$+LMNO q(]G9ff@fifi7P] _9 ;CqW o]RQlCR4tGS5| ~T VU]4_@ *:$+A'6B (W >CYX+ ](?]GRq(_]C^NZ5fig C] [^q W /:C^ R@ \]Ft^8 4 gqvR^tR^:C^ g@ \ QQRG7 R#]_!$#%&('*),+.-xRX_ ]G%R Q^x^ (W P QQgG g /A),HL'.<+LMA\" R` W bfiWxGRWC_A5]RcX+tfi(R QlC^ (1 ]:$+d',Be W] 5oR5C3 f^C_@ Cg(q9 QfX_ ]GC( ih@Q P(]q4 8 R(]9 c:C@ WC ( :$+d',B ^CR%qjQ^ (1 ] /C"g ]9 ?C(]RC_]RWC^_g4]GW" ZR ]_ ^__]Rfix]?R9 Q^]_]ZR W_ ;x ?_]9 (C%R8 ]9 ; (]vgoCgq. 5} _RqvT k(] ( (:<+A'6B^C RRqRQg@ 3 q ]9 ? Q?]'Rlq(^9 d:$+A'6B^C](RR ( W@g@ R(> mx^CgRPg@ ( WvRt25C 'e ;xqR 9(@ g]C ?RqCgq_> SWCZ(> q _]C_8 ]@ W_ ;C] .C*578 1|CR(e n5]R?(]q4 g /|R v_ g v9 "xR8 ]9 ; (Z] v 1]q3 ?03 q ]Pg v9 o:$+A'6B _1 1fi^R4 RrRq^_P7 WRGR(Cvfi^T =Ch_qqz]RZCRq 57' _RqvT ,U]^ 1 4 RqR^ p(1 >x]SWjW lC4 fixCq"CR7 Q}j / 8 (__]R(Cv] ?q]9 ;C8 ~RqCAl@ Ssrfi(G_DWC Q fi u:$+A'6B^CQR QlG_@ _]CGgq%WC Q ]v;x x1 wxq _]C^Rv_ QQlCR|g57x3 Z]PRhtCqG g(fig@ WRR]4_8 1/3 5figv8 Q ` g]R CGe F% rR 4 R9 ( ? 9WCRQ^ xfiRWCrZ]Rq(49(qRqRfi(]p/0 WRxhqRf5C >H QQl ZRp^?R?_]CGgRu /%W1Fj ^C4t_]C&" ` N(q9 Q_R@ ( uG^ ` yX+tfi(|C( (fiqW gP_x `z/ ;Cx_]CGgq%WC Q ]{ vx.QR9 ;x]C^F57x3 R^ uff@fifiJ (k5$QR_q(R@ ? Z](]_ ]RQ]qq(4 _]C? /Vg R?5C3 # (8 | _^^C@ C}X+ ](](Rq(_]C^9 ~^57x3 ] bo> gPCRx 57x3 ^/C:$+d',BY Y(8 w^(fi#R Qlq4 Rx49 " #8 ^x4 _]C#RW]8 QRR ;Cqg9 K| 59 ;Cq@:$+d',B5|CFRq6(9 ;C8 ] Ql@l@ q ^_u /n |_9 ;CqW kQR ]qv]PR^t$5C3 rfipWC(_]G@ N(9 ?;C8 ] Qq( /VRt25C 2qQ^ (1 ]_]]'RD'|RW 3(Cv]&( "RDQR_q W /9 5V(xv]^_ gC<4t^ Q^Cg@ p o]C(1 wxq (3 qefi9 ? Qz]Pg lq9 D: ] Wf:$+A'6B^Cg'8 ~Rq?_ ^_4tG_ 1?R9 ;C_%R^t. ]q$5C3 ( ]%F^_RuRR <:$+A'6B C%Z_9 Q^ 4 go _Rq4 gqoR^tt8 Rq^]C /7R^to bp5C3 (c:$+A'6B _SQR ;C> (SWC W9Qg^ 7 ;t W]HS] RqZ ^ ~+FZ Ql@ g1wxq _]C /RDX+ ](q(4 7 Rfig (h]c(W >Z Qz]?R{YQ^ R` W &;xF 8 Q ` g]vt^ ]C RSQ^ RFe %:C^ R@ \] ^3)RG lRIG4 ^9 Fff@fifi =R(R` ]Z^C Q^8 1]@ Cog}g@ mC(]Rqq(D/C|R ?o _ g vRR(1 > Qr(fiqW g' /X_ ]G](Rq(_]C^9 (^8 ]8 /0 ^CCRqR qlq49 (](RqGfix^9 X_ ]G]GRq(_]C^y/x|RrWR@ WxgW]@ ^qx_@ t$( ^ _fi@ zR?CqqW b lt_]C /nWCZ(> q _]Cp^C_@ C] /xRv _]C ?Z(9 Qlq (q 8./ 1] 5]h 5KQR_q(4"6(q41 ]@ fWCRQ^ __xR^q 5qqS:$+d',B uR| ]qF57x3^ &ff fifiJ@("]zRqRvj /RW]6qQ^ (1 ]_]9 6Rlq ]p5]R&&:<+A'6B] ] (htP8 Q> g]@ g^ (_Rz_4 _}X+ ](RWCZ]Rq(4c^C_@ CE\dg'*)9 "5|(> RK5|Cu^ (Rg_@ ]QR9 ;x]C^65C3 _' ]q@ Cq(4D5C >z]RQ > gfia b zq W'_Cq_]] WCgR@ W "C ?_zR8 G_gq Wj /$X+ ](zWxZ]Rq(49 '<_ ]]qS5C3 ( .rC(]RC_] R9 Q^]5|C(]C Ql@ g b lq@ ( {Q^ R_> W @ %R?@ R^t(FQR ;C> (@ /x}rC(]RC_]p5|Cc^C_@CEWCQ^ _] 7 R(]9 ;Cqq(SWC x]_]C^j / Qlq4 Rx49 R(Z@ g^ (_5|CcRqvx3 W;Cqg@Rf^c]Z]R@ R?C(]RCfi' zR9 Q^] /&X_^_C4Qg9 ?Z(qRqRZ]@ # Q^@ g _hg ]2QlqRQlq4 RC %UgRqRCg RZR ]9 ?0_ ^_fig_]C^5|C$(8 w^@ p;xv'a Q^@ g .QR W@(RZ8 ~@ Wg@_9 Q^ W R8 4] x ;C> (^ 9 { vWC(R4C@ :<+A'6B^C"+fix(W wxqtG xqq4 lq@ ZC(]RCfiZR9 Q^]L;xF]4%8 Q> g]R ]9 ?C(]RCfiRWC^R4](49 (R^ %q^ ]ox(figC_]Z /Z gvxR Rq@fin.(f&@` F.6ej9SjkZ 13@9(`z9u@> 1`af>d<29a6^ 1k.36@N39iR3ab8 4872ab794393R$A6@jW>@*jbD9}3v@R 1Z 1b@939A3jR38RR@> &9$38@3@9FL>>FAR938R488986S393fL]f39j3@R3@3R9Lk39eb $L@ &9 8 &R1>9~37`7~7 c811_97@_3^8R3R939 3>F393R$A6YD39 4799 19@33@jv9&3@@63978>9 y87R3R99cL81<74eW93@o9NZK393f6%88>9 %88939d39n73K@ (& >@3L>3Dk8R>9f>f1D973R99na@3@v9>><9e ab7S 82>9ab7z8aAu989D998 x3u$@3>$>L<A6"1@f3LL3cb8.@>f3939>Fi9n7363AE8>9ejF893 @973in8@8487R`9jAL81 7A989R9FS8R>9&6<>u1b7$d,Y76@196n73z7>p7,@ AL3^8R8p3@RZ@9@9yR@3j`av$7>fL99 194a3@v9A" 1&<A6G>L@fL3v9 1@f89R9 (3@L7,q$]811>z39D833A7v 9 1`c3438u4A36397<n73x<A6_>ke`a$38>3@*3$887bj6iR9L(4Liqu$137n1uqL,yDi9n(@39 @ 8@N$@u@198$Liqu$137LW7qj3,y,yD@9k(@3a9@@7 (<bk97>$397@8jW>uab7&3@L877c8R9L3( >3ab743$Lveb99986Lc@196L3fgy,Yi8@$7gR39G.8u9K9*f8>39R393398K4Ni3^7>33@97R9n73Di9@39@ @ K$93$a7g9f@}8N38R7> 47 >N>6jy8&cD3@}94Z(S937>9Dv S3@89RD7b7>>D.71 9969LR8>zj3> k>Yy,L v9eW@pu@9RL6.7RR2pR9666@8@33aW^ 1yj986Zj3> 1gjb7 iL 937>8,}8RRY37 ZLy,_>RN`2>E87E8ab79$}v f43@f3R87bj3@Li$7`j84N8@8Nb77> n89<y,9987RR367W&939Lu@Lk@LFL81|bv6L,oD@9$(@3937`@D998 &9994877pRb@TxS9D]<`f@f8@v@a$3487f9@F *c973R9@366L,}3R9v1>93f839S4L, 3N6.c998 xR8&k3@j2Lx$d,9jv37>46@9ab7v8&33@aR.jb@7.RL(3$877vu@1@SL, j98&L>@81`a*$393$y3281@8R7 &^RL6xR`j338,82>9ab77`f@>i399>4@LLL>9uL,_98R1@D7R6A3497S3@NK$d,Ykjp3$d,C8>}3>v77bab7 L811bYK887bj&.9a`eW(L6N6L6K27ya93D$87fS3@L3ci3887bjbN99 FgL7>vf893 19@p887bj39d,D3@@u39fZ 1k3R8633@u11babSK8RbR984j%3@L3NK1`7KE8738>9DRN43p99 487~L,N,y,`f798@Ki$d,Yf986987v38>ab7%f$A6S6L6}`<f39@3g@SF3RL3(RL93>S1>R38>abY9L99K$d,Cjp3S$6%87YiR9Lnj38@E @7 Y$6%0 >N8@K799 $3,87ab7SR8b7v7vab7.jk1$jR2j989A$L99@jbL81`3@86R^j]4e`cf8R39TRZcL>^@j43*7b7>@fififf ffff! fi"#%$'&()(*+$-,fi"(*./0*fi$$1-23/4 5 fiff !2-*.ff'! fi12678 +ff (*9&": "12281! fi126;<--22*=12> /"($1?5?*.($+/4@281#;*=5/ fi(58/7A*.ff fi4BC*.($EDF<GIHJLK'2-*.ffN21?*fi6fi/4'OPFQ*.ff'&(fi9R-SfiS+TU?9VWKXfiK/9Y/ : 121Z4[2-*.ff]\^_5 .//5/ fi(V9fi28!`712-23/afi-2: 2-*.ffb fi7(1?*=2 fi1?<8(*fic&(d`e7#/ ./2-$K f< .ga+1-9%2Z"- : -5*.&#h;Z84B_5 ./i+ff ff'/2ff ?9fiff ff'"%*.5/ fij9Qff + fi15/4k*.($l127(*Y/1m*.1 fii*fi$$12-5-$K0F!8 : fi1ff0*Y#g*.7712 *fi28E2 @-*.ff n! fi126/oODfi fi&p124E-Kq*r#WK;9gRYSfiS.sU21*.( : fi12ff0c2-*=fft7#%*.(u/2 k57(*=1?*.2B12 .#/nv7#%*.( : +1i`n"5/ fiC&>w/($+a+%$"(*Y#x9y!/28A1Z4=;$+#/>Aff'&p-$$-$zfiff ff'"%*.5/ fi(KwDFGIHJ{7"127( 5#/>L*Yafi .%$5"(8]21*.( : fi12ff0*.Z +(9(5 0*=4fi*.@|(`/&#/>k1-*fi5 fi!/28AOvvU!`e7#h%/i2-*=ff}4fi *Y#%~-7#%*.(*.($OvhvU5#/-5/afi@fiff ff'"%*.5/ fiOP5E2 &('/ff 7p fi12?*=c/C71?*fi5%.U?K zO2ff'>21?*fiP);fi9Qc"12n: fi9bA8fi9cR-SfiSR.U9q$-%3/ fio8 fi12>E% *.77#h/-$ : +1iff -2*.4fiB715/ fi15/5/-*.5/ fiofi1?$+/(*.Z +&(*fi5-$l fiE28 *.4fi?\p12-"1?3/afi ff e$#h/4E : -*fi8E fi281?V\j*fi5/ fi(KDFGIHJ{*.77#h-'$-%3/ fi28 fi1> : fi1fiffffm"%*.Z +k5#/-5/a+5>E*.($@8(*.(ff?V9(&"!/A*'afi1>$+hj12fi2`!71?*fiZ;*r#( fi7(1?*=5/ fi(*Y#h/-*.5/ fiB : 4fi1*Y#9$ fiff0*rn/($7p($-2-*.ff'! fi126ff $#(&(*fi5-$ fic_P .//5/ fi(VKIBI.IIfiyfiC}jfiF -*.ff'g +126'%!&(-+ff'/4B(1-*fi3/4.#/>k15/5%*Y#E*'ar*=15/P>B : ff'"#Zn*=4fi<a+/12 fiff ?91*.4fin/4 : 12 fiffafi/122"(*r#afi/12 +ff: +1 21?*Y//4o*.($-$"(*.5/ fij9!2 E/2122nv&(*+5-$ : fi12ffB*.5/ fi/4fi1?*.5/ fij92 '7p fi25%*Y#jffm"#/5/nv12 +&( fi5%[57(*ficff'%23/ fi(cOPFQ*.ff'&(c*Y#K/9R-S+Sfi<*. ')*r#WK;9RYSfiSfi/ff 2#Fh`e/1?*9QR-SfiS=s(h##h%*.ff0Z fiE*Y#K/9R-SfiSfiT</?*. B*Y#K/9jR-SfiSe(fc*->+-5n! fi28@c*Y#K/9R-SfiS+fi!h#h#>fi9R-SfiSfiTUK 712afi/ fi"(/ff 7#/ff*.5/ fi(y : ff'"#/5/n*.4figZ>e5ff09Y/(#/"($+4B fi"1I .j92-*.ff'! fi126[8(*fiy : 2 &(@&(*+5-$B fi 712n$(-$9$ fiff0*rnZ7(-h7#%*.( : fi1!fi1$+(*=5/ fijKg<n: fi122"(*.#>fi98-5i7#%*.([*.12/|(`/&#@*.($28"(c 0ffB*.?8 : fi18m"(1?*Y/Z-c :fiff 7#/`9$>(*.ff'%Ba+/12 fiff ?KwH'*@1-5"#/-9*.4fi?\Qfi812i2-*=ffm! fi16k*.z,fi"%6fi#/>z$+%25 .#/afiB/2ff'%2fi1?$+/(*.2-$[ff'%5&p8(*Yafi/ fi1-Ky"12281ff fi12fi9Y28gfi1?$+/(*.Z +m7#%*.(I*= fiq&p!12"(5-$u/m +281$ fiff0*r(VK!Dfi"(2812"(5c%y/ff 7p fi12?*.!8 .ga+1-9&( fi28@ *-a+/ff 7#/ff ?*.5/ fij fi12*.($B : fi1?fi(3%5(>]*fi12 2<*.77#h;*=5/ fi(KJ fiZa.*.2-$w&>2815/5%*Y#g-$ : fi12-*.ff'! fi126|(`/&h#h/P>C*.($12"(2*.&h#h/P>fi9Q28%*.15%#8(*fi712-52-$dDFGHJC9*B4fi1?*Y#Iff $# : 2-*.ff'! fi126K!8#/DFGIHJC\c$afi#/ fi7ff c;$1Za+&>i71?*fiZ;*r#(-$I : 2-*.ff'! fi126*.77#h;*=5/ fi(9+/?fi1%Q&(*fiZ-$' fi'715/(/7#-$B8 fi15/-I : -*.ff n! fi126KIDFGHJ%! fic : _P"(5* : z/ff 7#/ff 2-$]5>52ffB8(*.8(*Yafi&p4fi"@2 [&15%$4fi28c4*.7&(5!k=##%*.&p fi1?*.Z +k8 fi15/-*.($@71*fi5%fiKDFGHJfiff'&-c5afi1*Y#6+>0 .afi# : -*=2"12-OvvU"(5' : _5 ./</5/ fi(*+* &"h#%$+/4k&#/ 26 : fi1* 2-*=ff]\_P ./ff?*r#*.5/2"($ OPafi-2,+"*Y#K/9!R-SfiSfiy fi8bafi-,fi"fi9RYSfiSR&U< 28@*.12Z;#/h##/"(51?*.2-'8(*. DFGHJ&"h#;$"7*'8/1?*.128%*Y#g512"(2"12 : _5 ./!/25/ fi(*.($/($+a+%$"(*Y#/25/ fi(9*.(*Y#/ fi4fi fi"()2 28[7(*.12n5%*Y#iDfi8(*=12-$ #%*.(wO21 5@c1?*."(V9R-S+SfiTU?<OvhvU/24+1?*.5/ fi : .afi#2-8%,fi"- : fi1`7#%/-5?*=&#%58ffB : _5 ./25/ fi(wO2Dfiff'/28o fi8j9cR-SfiS+TU?!OvhhvUm71Z(/7#/-$fiffffm"%*.Z +&(*fi5-$l fiLfiff ffffc/]_5 ./c25/ fi(!OWapU"(Z :`e7#h%/ 12 .#/nvff + fi15/4kfi(Z21?*Y/?*fi[!#h#*fi[127(*Y/1 ff 8 e$'&(*+5-$C fiE_5 ./[/5/ fi(VcOa(Ui*.77#h%*.5/ fi : $-;P +nv28 fi125%2-8%,fi"- : fi1!fiff ff'"%*.5/ fi@5#/-5/afi/5>*=($ 8(*.(ff?V9)8@8fi2`ey : 28y_P .//5/ fi( : 1?*.ff ! fi16KBFj E*-a.*Yh# : 28 7( .!1i : *wff $#<Z"(28z*fi'DF<GIHJL9j* : "($*.ff ?*Y#8(*.4fi<E*.4fig*.128/2-2"1-y%!-255%*Y#*.1?8/2-2"12-!ff'"(5!712 .a+%$`7#h;/i5"77p fi12 : fi112712-Z?*=5/ fiL : *.($C12-*fiZ fi/4k)8z2-*.ff4fi *Y#%9yO1-*fi5/afi.U2-*.ff7#%*.( *.($d2-*.ff5*.2-KDFGHJ8(*fic&(C*.77#h-$C*.($ar*r#"(*=2-$/A2812fiff7#`L$ fiffB*Y/(KiF!! B : 28 $ fiffB*Y/(9-2figBj-fi;YLyfi2fi2@.(j?=(5(fi-(.2[(fi5-wfik2-Y/v!fi5%E3/';=5/fiE+/2fi vfi?Y//(j.(2+qh/fig=fiI-.0(-+g(=25%/(.2-[%.2+2Y/55%!e;Z-I!/2'(2-I.fi2!52Z;=fij3@20fiBY/je)fi(yjfi%Yfi.fi-.;y.o(fi/fi <xfi!(.5%(=5/fi@/]cxfi2(fi'/05Z-<.!P3/'%.2-pg52+2(. ?(=/].<Pce!fi?5fi!<I;mW.[v2fik+ /20e.-.'g+2Q.(C5fi?Y0=P+c;Z5-'0Y/ofipCx+'x2@!fi2z]+E%25@%/fi-Z5/.5/zCm2?+5/fi(!/2C/-.2/(C3Z;rep5/ ? )+/o5!h-+fii5@vfi2.ce%.(.Z+(fi5-/-.2/o5@/?hch/-c-.25g.ph'-fi+2/ 2fi-Y(.0.fi?fi%z.2+0.5 B2fi5/B2-.'!fi2k+5/fi/5/-y?.2[2(.zY/--fi5fi/L.pfii]fi(- Yh/fiyv2fiCfiBY/(p( 2-fiZfi/l=(fi[2-.'!fi2.+?</-.3/2(.Z+5(- Bfi+(=5/fiA2/-fi<(Z?.(fiE2[vfi20.Z+@/-fii?fiZ-j.fi2Q.fi/-.2(Q3/2(.5/fi5p- !2/-j?.fiI.fijfivfi20.Z+/-fi'.(fim%.fiq!hvfi5%-B2-. 'pgfi%'2(I55/ifi[-=2- -x+2fi5/ [fi5/fi/5/-<WYhI(fi@fiCI2/-<y/(fi?=@(.5%/(.2-E3/2(.Z+(c+/5/fi(Yh/fiC'.!/-fi/(3/fiE2-=2/o.2fiofi%o+ / @22'/((5/fi/-.2/@.2fi-yvfi'/5/.fifi?+/(.5/fid2fijqYfifi?pYh/22-5/fi0.([2-.fic;Ir;Zifi[2fi%x+jv22!!fi2-(=25%%.5/['fi/2+?y!/2B2h;=fim%.Z+j!.fi.fi0/./?.fi?fifi/BPQ.'()5fi]-fifffiQ.'(fijYfifiI2'/v-. 0.-fi/fi/fifiY%.(B/25/fi(!vfifi (=5%5fiB!/2 . fiY%g=([/25/fi(< j2(-/@fir;y.(25/fi(y0Y/(+%.2fi?+/(.5/fiwWYh/2-jP('2-= 0.2-y.v2E.22Bfi!%5%Yfi2%.-@?fiZe.!fi-./fiC2 .fi2-+.5(L.L=2fij/'(fi](@.2vh/A(Y%.(-d!/2=L.fi?fi2y2fi5/fi5/+Z-VI/5%Yj2-5/?y.j2%y.2fi0.2(+22-P..'q=mpfi-fiefi?5%2/CCfim%.Z+L.(.hh/5/-'/Lw5/(/-WfiZ+E%fii.+2fi fi%<xfix2!fi2Ifi(@5%2-fi '%.5/fi@0Y[x+2 2(+3%!.q'/5/.fi.h%.(+?.5/fifi+5%.5/fi25g.22=jg.2p22fip-fifiI25/fi<Ib2h-<fiB22-. fi!52-. -+B2-5./+@+%2.fi(.25%%.5/B]-%+@fi5/fijh/c-+?5/B/ 2-.'!fi2u;[/?5h='/2-55/'fi (=/fi-55/=5/fij(.h/o.fi?'2dfifi5%.2@B%.(B!/2fiB/-fi@!fi%oY%5E/ r+AC(hh/5fiA@fip]2(=+2-23/z5(2%25-g+;C/5/0=2/z/-fi<I r./ 2.fi-(/h%5w2-.'!fi2ff!#"%$'&()$'*$+-,ff.!%<2-5-.?]fi!5pfi22-Efi)(.2.fi2?ficfi+fiff=5fi /xfi 10p2-i);.2Z;/;Q.2(-+?3/fi.(!2+/fi(q+x2(y(.(yPQ.'(fifiYfir(2(..fijQ.fi43c?.?jj.(5)h.(50I.!5/+vfic2/mfi.(A5pfi2vfi2[g+2 2pfi22-E2%c.25%/fi1<%2(23/fi(<!/2E!%]./(Yfi/(-w/ 2.fi[26 (Yh5E.!2 .25%/fi r;Z]2(.2fic2-. 'p?c!fi2+fiE2 !fipA7 jfi2cvfi2/]5pfi2B.i2]!fiL2pfi22-/ ;@=25%/fi8cfi0rep25%5Evfi ;B!fiLfi2.+;-d9Y+%Cfih/..o.(:32]fi+25fiA=<;!3(./I.(LY@fi [.1= fi=;+j> >@?fiACB DEGFHII1J'KLMON8HQPSR5J TffUCM%VWJ+LYXZ\[]H^X_I1J'` MOab` U'TffM%c-KdSe fSg+hifkj+lGmffn%o7m lGfplGf hqo7risut+f lt+f7vumxw4yOmxvvumzw{h|qe f1lGf hqo7risug |isumff}~mxy)d1pg rqmxffslGf lsu}|qeGshxrq|isovufff%|sht+hif l5m}5f7f o7j |sm}mxy1eGsufkr@xr7oqeGsokv1mffg'fkr@x|qmffr7hkCmffrrf ffo7|isufffgGvx}+hk1vv1mffg+fkr7x|qmffr@hsu}Q|qe feGsufkr@xr@oeG#f7 f o7j |qfs}g+xr7vvf7v%x}+le fk}+o7f]|qe f#su}g+xr@vvuf7vo7mff}+hi|qrj+o7| dSe fo7mfffk}|7hSsu}|qe fg+hifkj+lGmo7mlGfxrfpfk}+ovmGhif lsu}5ff~ffSdSe f|qfkrq]su} mxvumffff~sh<+r@hi|plGf hqo7risut+f l9t+f7vumxw+|m\ovxrisy|qe fg+hifkj+lGmffn%o7m lGfffz7 GOk+@7Offqimffg+fkr@|qmffr{\ CffS!uuuu}CffplGfk} mff|qf h|qe ff7f o7j |isumff}mxyQ|qf xtG|qf !xsufffk}|qe fo7mff}G|qf7 |bmy|qe fo7j rqrqfk}G|su}|qfk}G|isumff}eGsfkr7xr@oe\ x}+lwSsu|qeg+xr@xfk|qfkr@hSCffG!uuG})d)fkrq~hS CSox+C'xrfvvf7!o7|ivu#ffhsu}5fff o7|isumff})lGfk} mff|f hS|qe fp|qf xhimxsu}|Ssu}G|qfk}G|isumff}#|qmf7f o7j |qfC4kk x)x@-lGfk} mff|qf h|qe fh|@x|qj+hmxy|qe f1imxsu}|su}|fk}|isumff}@SO-+we fk|qe fkrs|<sh]j |qj+vvut+f7vsufkfff l|qmt'fffoeGsufkfff lC j }+ffoeGsufkzxtGvufmffr<srrqf7vufkzx}G|4k 7 oeGsufkfffkfk}G|qn%o7mff}+lsu|isumff}+hfk}|So7mff}+lsu|isumff}+hSmxy)|qe f{|qf xmffg+fkr7x|qmffr@G7blGfk} mff|f h1|qe+|1|qe fpy%ffo7|hx|ishW+f hS|qe f]ffoeGsfkfknhWsu]svxrivuwSsu|qe~rqf hig'f o7|b|mj }+ffoeGsufkzxtGsvs|i#x}+lsrrqf7vufkzx}+o7o7mff}+lsu|isumff}+hkYff]]'7ffOk |qfkrq]su}+x|qfknig4gCl x|qfkn%hi|@|qf@7kp_lGfk} m|qf hSo7mff]j }Gsokx|isumff}~|qm|qe f|qf x|qm|qfkrq]sun}+x|qf]himxsu}G|o7mff]su|qfk}|1|m+lGj f|qm|qe f{y%ffo7|Syq%kCQqkk k' p@@lGfk} mff|f hp|qe f]j gl |isu} myb|qe f]|qf xh|@x|qf]mxy{wSsu|qe|qe f{yo7|Sy4gCl x|qfkn%hi|@|qj+h @-]lGfk} mff|qf h]|qe fj gCl x|isu} Qmxy|e f|qf xmffg'fkr@x|qmrwSsu|qe:s|7ho7j rqrqfk}G|hi|@x|qj+hmxyffoeGsufkfffkfk}G| j }+ffoeGsufkzxtGsvs|i#mffr<srrqf7vufkzx}+o7ff4~+'+xQ+x u-sh|qe f{su}+lsuffslGj+vbxfk}|1mrb|f xf7 f o7j |isu} \mffg'fkr@x|qmr<lGfk} mff|fp|qe fffo7|isumff}+hmxy|qe fmffg+fkr7x|qmffrCsh{]|qf hi|Smxyw1e fk|qe fkr1|e fxfffk}G|QkC57'4k u)sh|qf hi|1mxyw1e fk|qe fkr{|qe fxfffk}G|Q +'+kqkk x)kqCC+'%mffr1hij |qf xz7 GOkish]|qf xmrj+h|bm} fpsu}+lsuffslGj+v%lGfk} m|qf h1hif7vyq<lGfk} m|qf h1oe+x} fffs}|qe fprqmxvufpg'fkriymrq\x}+o7fpokxg+xtGsvsu|myxfk}|7Offqis}+lsuslGj+vmffg+fkr7x|qmffrhif7vyq1~ffuuu}CfflGfk} mff|qf h|qe ff7 f o7j |isumff}myx}thif7vyq xsufffk}#|e fo7mff}|f7|1my_|qe fo7j rrqfk}|<s}G|qfk}G|isumff}#eGsufkr@r@oqeG\x}+l~wSsu|qe#g+r@xfk|qfkr7hCffG uuG})!mffrf7 g+mGhWsu|qmffrq5g j rg+mhif h k f o7j |qfknO|qf nOmffg+fkr7x|qmffr@x}+lk f o7j |qfknsu}+lsuffslGjzvnOmg+f r7x|qmffr@xrqflGf7+} f l5hhifkg+r@x|qf]g rqm o7f lGj rqf hkpW}5rqf vsu|iffd1p|iwSm+fifflGmf h{} mff|pls)fkrqfk}|s|qft+fk|iwSfkfk}|qe ffi"!#$% &'()*&+#,-/.102+3$,4657398;:+<=74>"5?@ABDCFE$GHBDIfiJBDK6L;IFMNOBQPRKSGUTVPDWYX2Z\[]Z_^`Z_afibcZ\bedZfgffZ bhi6jcf&kFlHmongprq6moksutvwyx\kFk]x\k{zDmHn|h}fwvdf&n~s#w(2zkDkfizDmHkBDGUK$FD1CDT6LyL]GYL(BFOGo|mo|Oz|vw;lHkFk]xOkfizDmHn|$hfc~|$kDq6h#qVmHn|hf7w$vf&kFlHmDq6nlHD|$ngh\mUYnh\mHkFh\mong|$hXt#f&nk&WYQfifiVWRX_"Ze{\OjQfifiVWRX_"Z#{e\j7F{{VWRX_Z\F66\e\Sjoj&|Wqjn~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfiojQ{YWYh#qzonkFqVnngm$HzD|h\nmHn|hlQWYXjFZHjQfiWHokFkFq6hzDkDHzD|h#Ongmon|hlQWYXjFZ$HjHjvwynlnlmok]zFqVlHkkQHk;~YqzDm~ngl2~|h#mo|lRqVmHnl~mHkmHkFopnh#qVmHn|hrzD|h#Ongmon|hr|6~X2f2kzFq6lokkFok~7nl|hgq;mHHkfiqVmmH|XWlHkFk(x\kfizmHn|h}fc{jnlq6hq6|$|l{f7w$vnf&kFlHmongprq6moktv$wlokFk]lokfizDmong|$h}fwvnnf&n~w22z;o||lHkY|$#kFDq6mo|TVL]LyE\CDK{GHBDWmHkFopnh#qVmHkDDWYXjFZ\FZu[j&nmHnHn|onmtvwyx\kFk]x\k{zDmHn|h}(qVh#(fgc{wvnnnYfn~h|y|mHkFn$kFong|$Hnm(|kFDq6mH|$fiZngh#q6Dq6kF@AVBDCQE$GUBIH#Vfi6EK6IRTDNBFPDK{GHT6PDW{T6LyL]E\CDKSGUBWmokFHpnghq6mHkDWYXjQZeQZ7[jFZfiBF FZuX^`ZafibcZbedZfffiSjFtnfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFtfq6mokDYlomRqVmHlQWRX_jFtW#jn~efiDF{{FD{u#WujFZ{kFok[nfq6#qVmHko|kDp|$hnmH|onhzD|hlomHDq6nh\mHlfitvw(x\kQkxOkfizDmHn|$h#fdfwvnnf&n~\H|$gkYp|hnmH|$Hnhz|hlomHRqVnhem~q6nHk{lHzH;mH#qVmWYQfiWYhqzonkFq6ngnm$Uz|h#\nmong|$hlFWXjFZ{RjmHkFhq6mHkYlomRq6molFWDX jQtWYzQjn~HkfizkFnk]zD|$pp(hnzQq6mHn|6hy|6~mHkQHpnh#qVmHkDDWYXjqVh#~YqzDmn~WFfiDWzonkF$kFpkFh\mUUzD|$h#\nmHn|$hlFWX7jQZfiojQ{YWYh#qzonkFqVnngm$HzD|h\nmHn|hlQWYXjFZHjQfiWHokFkFq6hzDkDHzD|h#Ongmon|hlQWYXjFZ$HjHjnfq6mokDYlomRqVmHk(Wfi\9DF{{#W[jFZ{HjFtnnfq6mokDYlomRqVmHlQWRX_jFtWjq6mokDYlomRqVmHk6Wfi\9DF{{#W[jFZ6{6WX7jojFtvw;kDkfizDmok`\|$pqVnghOYlo#kfiznzqzmHn|hlmo|]p|\n~]mokfiq6plHmDq6mok|V~[wvccfifi6ffofififfQ6#\VH ff{oOHFrFD6H$ffHQg{D#ffH {!"$#&%'($H*) $+-,.#&%'($HooF#6D6F/0214357681:96814;2<=9?>:@A1B?;C68>2B +DE GF'HI'JE JK6$2 !"$#&%'($ H ) $#L%E($ o4MN+ 2HQ#VR6F/G0214356P1:96814;fi<Q9?>4@1B?;6P>fiB #&%'($ GF'HI'JE JK6V $HWHD6\PffXR TS UHff RV\H6oo4Y&Z []F\ $#L%E($ ouoF#6D6F/G0214356P1:9P^`_Eafi^]bX^a25;ficd9?>:@A1B?;C68>2B fe 1c g GF'HIUJEV $HWHD6\PffXR TS UHff RV\H6oo4&&2ih7j&k#mlnffHD6o VF\popj7hV #6otDs $e2\HF\H$ ud fv]wGq &HFrx &Z y6Z 4u fvw*zm(*E{|*}~*[2$ d, 1@;fi^`B hjQGff $PHff QF6njh/0214357681:96814;2<=9?>:@A1B?;C68>2B P 18@;fi^`B +D'H&fiQfiffo4YV`#2gShjnF#Vg7ff :O Vfi;gy\FRVeO fiDH$&oEd2Hff :Y V`$ #2 gD#fiffrffHfi(2ff#VRfiVFHQHF#VgV m# yH$4$VH(W D$Hff oR6\T\Y g$6H$12ff gFfioff &o $o\rV 6Hff fiD#2 g(D$#\HUffX*jhFoff &/0214357681:96814;2<=9?>:@A1B?;C68>2B X >2<n@'c1:681:9f;2^`cK5B41 +D'HIfC FfiUHff 4 6` #$ofi K6hjQSQ#6ff PHff Q* #$Hgfi D7V Fo4 Y6 H&H ffr Pff# fiff \ fiHoEdDjh=hyj Q#HDfiA Hy4 fi4 o4 Hfi2V&FRVHTjh7]*D7fitQ'*`G/0143 576P149P^`_'afi^`b^afi5;2cd9 *@A1B?;C68>2B $Hff Q4'HIfXJE7JU J6& Hff Dfi Hff fiff V#O\Y # V#\HQeo$ZXy6Z #p{|*}~' Z yVZ $Ezm(*E{|*}~*[Z yZ6' fifi[~(6HZ UX}Z4Z $YV Qe8U#\og$Fff gZX}Z:&Z#$Hgfi H D$#\HUFff $Z HoF6D4H#OgoQff $ g HgZX}Z:6o4$off RVH(Z # Hff FF gXfi'n*]E7Nn&Tfir4$r?2P$Efir4$r?2Pfi EP 'fi'fiP4X4rI72A$rEX:Kn:PrmUPfirnP4fir$K* rAP ' 4fiP7= 2P7E7PXP4EPQfiff ffff fi4$ ! #"$& %Ei7 EmnP4fir p '& 7*m*E ,*+ - .0/( K )fi+K$214365#ffPfiff ffff fi47 5#8ff9 P ? $&fiEfir4$2`Er 2K;: E2 4`fiTI?fi7=<X:P?>'4 &A @2P4fi]$'r fiUn =fiP'X4Er 2&47EP BEfirPX2nDEfi4fim P P&r E2 7r&fiff ffff fi4 CDEFGfi 8HAffIJr ? $IfC' fiUP4fi`E7r fiKLK : EfiPPK*E7PUfi47p r4$fiPP rPEfi'<X:PM>E4 &Emr4Xr:A4P:$E`E2K' 4fiP7NPO;O?QSR;TFU8VXWPYLZ#[]\MN_^Za`cbdO;efiQgf_hFefiQSijlknm=opJq'r smutv smwolx mwoytz{Amwx]{Sms}|J~8|Jss}|J~6knmx mwoytzrnz||Jaj?a=rnt|Jz9x mwxzk zolpJtzysmpJAx]mwoomzpssknmsrmAy|x mknmps|tzknqx mwoytz{AmwxzurnrAmAxz_MAjlknm=tv s}mwocpoF~lzkknmps|tz}knqzMrnrSmAxzJpJtmF{Apomwx|mnmwyvnz|'|JAk zmtptyk zypsA|rAmtpJ|to|tDtmwpyzmlr s9pAo6k zs}mknmopq'r smtv s}mwou{Sms|+~ptmx mwoytz}{Smwxzo7zq'r szGAmwxz8knm8|tqnknm'pyvApstv smwo=pJtmmAy|nx mwxzg|pJtwnpJAxpJtmpwJpzspJ{ smpo?pJ| sznmMrnrSmAxzG?lG * l $ FLa $u*M$ l $? ;BP4r n77 4firp47p&UfiP7D7fiKfi PfirTP?2P=474finD' 4PE24fiP8EP=r 7 p47EP2QPX2 7E 4fir4lS< TPX:P'>'KfiaU P2PTP4fiP=47?finQ4;$4 fi4PU nfir 7 p47EP;@fiDrXfi ' ?2Pu4c;$4 7n4rP P&rEfi=' X;47p&UfiP7D7 fi' n2PX7= U ?2PXB;;fi0n;fifi? w7fi?w=fiwwJAa7w=fiw;fi=7fiufififi=4lSD?lG=Ml?FLauM?ll'MMafilafi0fi= lw?ww+ fiwfilfifi?J;L8w;fffiw;]M ;M ww J7G Fu7dw fiwu4c9=}fiD+w;]a;7fiJfi M=7 ? Gw=wfiwaaw;fififi? w7fi?w=fiwwJAa7w=fiw;fi=7fiufififi=4lSD!?lG=MlG l?a7Ma a====M ll=afilfi770waw=GfiwwwM=w=fi D+ Jfiu lwfi=}7w7Ga;? w7fi?w=fiwwJnfiw=7;7=fifiufififi=4lS" $#&%(+*)ff'#&% D7fifi,.-0/," afi77210354=fi7GM7=wG;0w6'=}fi?7986:;-0<.7>=A@+*?lG=Ml Mlln=uM?llfiGaM 0 lw=7w J7G=fiL fi=fifiwa;? w7fi?w=fiwwJnfiw=7;7=fifiufififi=4lS?ff)CB " $ #$%=afi7GM7=wG;0w6'=}filw;a7986:;-0<.7fi7GM7=wG;w=fiwLwaa&10354fi;a ;=w=fiawJ fi=fiafi=7fiufififi=4lSECFG=HLMll?lG=MlG=uMM L G uafi? Jaaw wG u0fiG wfifiw7fiJfiaJwwJ=7wA ?fifiwI@? 'LNJ')GK LfiOPRQSUTUV.WYX[Z\5]U^`_Z\aO?\5SUbQ2PUTUcdfeg h!j5kfkIlnmoqp!rsmto$smoflnmofsrmvuxwCy;z|{9sm}r~}lnmGgfh!r2s>mRAofsrmgsRsln2lk&Rlnk0rkfsm5kfr~loIr2l!5lh!j5oIlfjrlkAoIrk?rgm5rrof5lkEl2lnk ps>A~Ir2lnk|rkIEsm5kIr~lCofr2l!5lhJj5oflIj5rRlnkofrkrgsUhnAmm5roRlnk0rkfkfr~l$j5kfkIlnmoqp!rs>mo[smoflmtoIsrm9uxwyqz { s&j5mRhI5sln}A~>l5j5loIrEh!kIsofshnA~;kfr~>lAs~j5kIlrA sRs>mGRlnk0rkfsm5rUnU;CnUR[Ga`U[E255RCUi6nRnUna65ARUR|UJU>fI6`RJ`R5qRA.U&G;5.U;|5[C50;5Gn[A!AE0 |5;;0>E5;A[5UJUAnA!|.|RA$AnY5|RAC2CC5Gn[U? 5UnAvU5?UC6UCC` AUC|5G&5 qUUn&;A55IGR|!56v5Rnn6fC 5|Rff2 fi55qR[5!A25fi05!5Cffq!505RU n$U[ nAn5$55R 5!U|RAnJ nJU!5a6>|;5J"R`6URU;iIiR|R!|R55RAUC&6;5C!UAC|5C;05Rn [!225E|92 C05;|5E5A 5U!U5AnA!|.`R;AnAnv655UA[$#&;2&%.5('U5qU 5UR 5!)nvJ+*6R25!5[I,!|Rfffi;5|5$-U5|;.A!;2592 05.0>;5UA[$#&;2/%.('5U5.U.5UA.$[6C510q?255A[32655RnR?5!4+ R|I5H+R|! En5J" 56na65AA9[[nA[U65 7%q805RU:9R;5AI!5ff%;|A!|CUI|<105A3=G`>%.n!A 55R?<I5RU 6G &56!5t5!nUvA.I@C!|R2ffE fiG;505;5A5A!25CBR>`CAD?EEA<U!A5F%.!ACG5UG#nJ`tD6R|URUHR5!5 +AC5(05`Jn!UUn9R|URU1IJIJI !5UA505 5CD?EAKB55LENM|$O P5RnR55URQ745535J!!52n5!;5CR|URU+5 RvR5YAUfC 5|RffE fiG25055R5A!2592 |0>;S0UT6GRn5AD`5$#&.U$<U!A5; AU5V<G$=G.5 $R|I5nUA5nA!|UUn5n+55!UYGRJf65AA5!5A?fW!506ff2;505;5$- 505E592 05;;0>5!5U.5R `656!U!U!nAYA22G5YXA0[U PZR[\[fi]?^8_J`!abdc1e3fffghKikj;hAlnmkcoYpfhJqjRrs6ttu!vjwJeYxyxzoY{$ecoY|ff};~!xzoYfec e!x; Gc(ep8Go |}"efjU zUzyy hYhut78jbdc1e3fffghdikj.8jh.lqY}z!8c6hwdjjr s6tt!v jxzoYfec@}f1 ep8cfffj/wJe8hAj.j;hk@ec(3oYh8j;hdlAeYxyxzo1Vhkj.rPL8fjyvh U Uz 8 / z U h8j$sY3!8jJCPRc(6f(fhwoY{8cff}z!h8Cjox;c(h8jj;hl@e!fff6fh?jArs6tt7vjmk8eYx;6!oY, ee38eYx;6!};Go}zfff|(cff};{8p8|(63~};c(e8!|6j8! ff 3 h?rP!v h7N3t773jo66fffe|(h8ikj;hiLc(eY.f|(eh8j;hl&bkhj8j?rstt!vjACp!x"|}oN3|k eYxyxoN{ecoN|ff};e};};c(6 |16}"8c(eY~}zf(oY|}"ej3ff ff. 3 U U 6ff 3yU $V U66R 1Nj}xyxhKj;h?wJ8h8jh?bdcoN|(h$8j;h?e3fff!{!x;e3eChVAj;h?lAoY{h?j?rs6tt7vj3|( xyxy};!|oY!|fUec|(8:f3!|(8|ff}z{oY|(|x" xz?@o eoY3WeYdc(e| oYc(};8Go};c co|6jff6 ff@ !6U 6kVyz U 8 ffU z U6 6jY8!};83fhkjrs6ttY8vjwJe};|(!|foY e3~3|ff};ef@|(8Uep88oY|}"eeY e!ec};oY|ff};e};p!x;|ff};oY3|df7fff|1fj+3+ 6+ 6 +6 6hKNjY8!};83fh+jkrs6tt7vjwJe!|(c(eNxxy};8 e!e$coY|ff};~,8c1e{!x;fffeYx;~};8};};!pfff|(cff}zoxp!x;|ff};oY!|fff7f|(fLpf};8ffeY};!|};3|(!|ff};efj U 6 Uzyy 6h6YjmoY};8Yo8h?bj!j;h8l/KoN{$h8Gj$rstt!vjAqe81}zox eoYcff}zfffeUecLo}x;p8c(+e!};|(ec}"8oYc16 e~!c(C}"p!x;|ff};oY!|fff|(|}"8!fjff6 ff !U 6ff U zUzyy hYj?r(q|(p!!|doY{f|(co |v jm};83hj;h.7Pp88{$c(hkGjh..oYehj;hkqe8!{c($hd.jh.L}z!oYc?hbj;h.l,c(8c6h.j.r s6tt!v jAxzoY886|(6oYo |}"~};|ffj,wofff|( xyUcoY1!}hwdj;hAl,c(8c6hL.jLrPJ8fjyvhJ U 6 RV6zV U U3ff U Yj?q8c}"8c6hVjm};|oY8eh j;hf(o8o8h8Gjh7mkp8!};e!fff!}h?j;h8e78oh8j;h$l&df(ooh7j?rs6tt!vjAe{e8 p88c(e{e|ecffxzG p8}"!};|ff}zoY|}"~jff6 (1 3 UU6jm};|oY8eh jhKAoY{hKj;hAq|1e8hKAj;h x"e!fffehKj;he88o8h j;hdf(o.o8hj;hKlf(o8ohGjAr s6tt!v j8c1e{e8 p8fff!3|(8|}oN3| f K1oxyx;8jff ff 3 U6 U 86ff U z U6 Njo};c?h.jJ.j;hLYe86fhjJj;hJl}; xzfffhdAjJjJr s6ttY8v jwJe!ec};oY|(6{$o~};eceN e8p8|(c8coY|(6WUec 6f };|oo};c(fffe!oYc6j ff ff 3! ff @ +V3U. 6ffUff3zffLffVff UU jR.cffxzoY!eh x"ecff}z8o8fff|ff};|(p8|1eckqY};p!xzoY|ff};e,oYco};!};8fih ff!};~cf};|ffeYwJ!|(co x x;ecff}z8o8j?~6f p8h j8j;hwJe8hAj?j;hl.p886fh8jr s6tt!v j.,o |ff};8|(e|(8cjdff6 ff3+U ff U 6 U6 6jC!x;eoYc(?hwoxy}(j;kkd8c(6f(fj?e8(!{oYp8@hmj.jLrs6ttY8vj zy 1ffU 6 Vy 8 U6 3@ U U U !6U!Pff3 6jj j!|(86fP}fh oYc(~YoYcff!}"~cf};|ffjfi!!"$#&%(')+*!,.-'/)01)+!23!!457698:<;!=?>@>A(B3C$5DC9A!EF=?>G>9=HAJI3C$50C.ALKMEF=N!OPHQSROPTL=?>@>@6AVULC$B3C$WX/Y+Z+[\C1]J^!_>.Oa`LOP8S69b+`!QcTLO+dS=Nfe+=`!=H?O/>9Q6hgOa8S69b+`(iVjlk!`6@monp69`!erqp69=stCvuxw+y{z|~}?w+?}L|}pAL$WXa\A!!!Z+!Cv=s=?>@>AjC$W?XY+Y+\?CtJ}L| ?(z?+?|~{S&p}L|c|~p}LC FOPH<qPOPHNv`69qfiC$VH<=ddA$ROPT!HS6~Ne+=+A!5O+d<d{CJ69=`8<=?>ArEC.AKB=?6G^!=?69HO!A&ECWXY+Ya!\CJ|~?cw+?w+@|ca(zpazz}@a|}D+@wP?C69`LN!:?H<=d85:/HO/sQ6@>@>A$>9k!=I16~Ne+=U+k!698A$LjCJbP>@>~O+:fiAL5DC$W?XY+Y+\?C B;!=3kLdS=dbPm_>~OP`Ld{C3?c| y|w+}cG|@+/}Ly?AL!{AL[+Z!CIOa_!k!8ApULC9APKE3OPHHA+RFCI3CpWXYpY+\CpRbb+_L=HOa8S69q+=T=;LOqp69b+HJ69`bN!dO/mC+B=:;(CH<=_(C/<UBQSRIQY+PQp!A`LdS8S698<k!8=Fmob+HFd69k>~OP86hbp`xOP`LN78<HO/69`69`!eLALv`69q+=Hd698SnbPmR=`8HO/> >9b+HS6~N!O!CIOPbAVjC1ULC9A1$kL:O+dA1jC.A5fb+HS>9=n+AC9AU+=?>9q+=d8<H<=?>A5DC9A1K5k!HHO/n+AC1WXY+Y+\CjFe+=`8<Qcb+HS69=`8<=NOPH:;6h8=:?8<k!H<=Fmcb+HO/69H<Q:?b+TLOP8d69k>~OP8S69b+`(CB=:;(CLH<=_(C!B=:<;!`6~:O/>vb+8<=3!A!B;!=3jFkLdS8<H?O/>@6.Oa`jH<86Gfi:6~O/>J`8<=?>@>G69e+=`L:?=`LdS8S698<k!8=+C=?6@>@>9n+AtlCULCFWX/Y+Y+[\C/G|/w@f+c|+}w+wp}LDfi/y|w+p}C;(CC8;!=d6~dA3U:;!bba>bPmRb+_!k!8<=HFU:69=`L:?=+AJROPH`!=eP69=5f=?>@>hbp`xv`6hqp=Hd698Sn+CI16~:;(A3RC9AVKUP6.N`!=H/AFRCWXYpY+\CR(j3]1tiV;!=`OPe+=`8d:?bP>@>~OPTLbpHOP8<=fs698<;_L=b+_>9=+C`Sy??+|}az}c?}Lw+c|+}Lwp 1+}S}y+}3c+}L++p+/}L~+/}L! aCbd=`T>9bb+AJCpULC9A+(O/69HN$A+C+]C9AP=s=?>@>A+jC9A!A+K5:/ROPHS>API3CWXY+YXP\CPj_!H=?>G6969`LOPHnOa`LO/>9nd6~dJbPm8<;!=dSbOPHOPH?:<;698<=:?8<k!H=OpdVOFTLO+d6~dJmcb+HVe+=`!=HO>!6h`8<=?>@>@69e+=`L:?=+C 3?c| y|w+}c@|Gp}Ly?A/(!W?XQ\A+Z+Y/p+!CU+=`(AULCWXYpY+[\CpSy??+|}aSzpfi|}fiPvP|~l+}F+w?ficw+c|+}1/+@c|+}wp}L3(?w+?}!|~}+CJj=HS6~:OP`j3d<dSb!:6~OP8S69b+`mcb+HjFH<8S6@fi:6~O/>`8=?>G>@69e+=`L:?=+AJ5=`>9brVOaH<fiARjCUP6~N`!=HARC!W?XY+YP!\?CjF`OPH<8S6@fi:6~O/>Np6~d<:?bpk!HdS=v>.Oa`!e+kLOPe+=mcb+H:?bP>@>~OPTb+HOP8S69q+=F`!=e+b+86.Oa8S69b+`(C$`Sy??P|~}P3Stz3w+c|+}Lw++}S/}Ly?3+}3c| y/|~wpL?}Lc@|Gp}yFcaCU+698<;(AJC.A KRb+;!=`(AVJCVWXYpY+[\CBbPsOaHN!d3dS=rOP`8S6~:dFmcb+HOP`0OPe+=`8:?bpk!`6.:Oa8S69b+`>~OP`!epkLOPe+=TLO+dS=N&b+`dS_==:<;O+:?8dCJ`S/y?p|~}PStzwpc|~+}w+Vp}S}y3+}3?c| y|w+}cG|.+}y&~FF3c+CU+b+`!=`TL=H<eA]C.AB16~N;LOPHN$A3C9A=H<`!=H/A]C.AEv6h`!`n+AC.Ak!`!epTL=H<eLAF5DC9AKIOPbLAjCW?XY+YP!\?CJ>~OP`!`!=N8=OPO+:?8S69qp698n+C1B(=:;(C!H<=_(CLp[!AjkLdS8HO/>@6~OP`jF`LdS8S698<k!8=+CU+8<b+`!=+AJC9AKV=?>hbdSbLA5DC1WXY+Y+[\CB(bPsOPHN!d:?bP>@>~OPTLbpHOP8S69q+=OP`LNO+Nqp=Hd<OPHS6~O/>>9=OPH<`69`!eLiO:O+dS=dS8<kLNnf69`0H<bpTLb+8S6~:&dSb!::?=HC&`U+=`(AULCW]N$Ch\A Ftpfi?|~}ffiPvP|~p}pw?ficw+c|+}!/+@c|~+}fw+}L&(?w+?}L|}|}x@c|9Sw+/}LV/c/CBJOPTL=+A 5DCJWX/Y+Y+\CI=:?k!Hd6hqp=OPep=`8tOP`LNOPe+=`8<Qce+H<b+k!_8<H?O+:<p69`!e69`O&H<=O/>9Qc8S69=Nn`LOP6.:=`!Qq+69H<b+`!=`8CD`S/y?p|~}PSzf}c?}Lw+c|+}Lwp1+}S}yp}ux@c|9Sw+/}L/ccu++CBJOPTL=+A(5DCJWXY+Yp[\C3B(H?O+:<p69`!eNn`LOa6~:8<=OPO+:?86hqp698Sn+Ct`Sy??+|}atSz&3w+c|~p}Lw+1+}//}Ly?t+}3?c| y|w+}cG|@+/}Ly?~FF3c+Cfi$!JPL+LD++fiff <ff < L99+ ff!"ff#$<P&%' ($)*,+.-!/#0fi11fi243"56879/!:;=< 1?>A@ ; 3=/5B@CEDF/5G:H1#-!15I01J/5LKJ- ; 3 M'03=@CNfi5 ; 1C=CO3P6415I01&Q"KK9KRNS+JPL+!DL?+?)T9!8+F<aUVW,XYLa&"ffFZ![8p\4W !fiEK']B^]_CO3"12ZKR- ; 3 M.0#3"@CBNfi5 ; 1C=CO3P6415I01J`8L8 GJPL+3D9Ja8 I!(Rbc 9Ja8!fe 9Jg fh .9(c # fi$X ?!9v9Je'S+ ffJj Lk 9flkff %P(mgVpnJ)`PO+8+fiop4 W< 4ff!\+U`9&~8!D\4 !fiqKJNrs@64@8tH3=5I/1 mu$v ?8JPL+!D9lwe'SpIjJkLpnedi'kxy8 ff zp <#[!9+IXYLP&"ff38pff(L#)*z+.-!/011fi23=567{/!: ;=< 1'Nfi5 ; 1-5I@ ; 3=/5I@4C8|}/43"5 ; DF/5G:H1#-!15I01F/45fKJ- ; 3 M'03=@C8Nfi5 ; 1C=CP3O61#5I01QN|D{KRNS+JPL+3D9kff %P(9g9Jl~e'+fjJkLFpnOX4PO+Ofiq`9Z~8X 8 YL%WW ff #d)`+.-!/011fi23=567A/: ;=< 1TF3 : ;=< D/5:1-!15B0fi1&/5DF/o]_ ; 1 15I1#-!@ ; 1fi2/4-017J@5B2Td1 < @3=/-!@C.1!]-1G7H1#5 ; @ ; 3=/5"X L8 ?9Jk+\+! <tD99lv+TxF/+nX PU&8IX< P? ff!"ffz%d 89# 3&"`TXOL(ff ( <((ff "ff#.o<T(' !&9I! #O~8,9 P_ff~#)*< OP+ I?ff z)*I!! +bOPO~PU(D9'kYff8 !Fg.FlFff(p Fg1+4,i$!ff!Xff"`[ !4 <!"ff.I?Z![ 8p\ !fi{ {)`,+.-!/011fi23=567d/!: ;=< 19KKKJNdm@C=C8d]/873"/5+.CO@5L1G^0 ; 3"/5o+.-!/GCP1#?7A@5B2TN7fi71G7fifiJournal Artificial Intelligence Research 7 (1997) 283-317Submitted 8/97; published 12/97Bidirectional Heuristic Search ReconsideredHermann KaindlGerhard Kainzhermann.kaindl@siemens.atgerhard.kainz@siemens.atSiemens AG Osterreich,PSEGeusaugasse 17A{1030 Vienna, AustriaAbstractassessment bidirectional heuristic search incorrect since firstpublished quarter century ago. quite long time, search strategyachieve expected results, major misunderstandingreasons behind it. Although still wide-spread belief bidirectional heuristicsearch aicted problem search frontiers passing other, demonstrateconjecture wrong. Based finding, present new generic approachbidirectional heuristic search new approach dynamically improving heuristicvalues feasible bidirectional search only. approaches put perspectivetraditional recently proposed approaches order facilitatebetter overall understanding. Empirical results experiments new approachesshow bidirectional heuristic search performed eciently alsolimited memory. results suggest bidirectional heuristic search appearsbetter solving certain dicult problems corresponding unidirectional search.provides evidence usefulness search strategy long neglected.summary, show bidirectional heuristic search viable consequently proposereconsidered.1. Background Introductionproblem represented state space graph, solutions problempaths given start node goal/target node t. Finding solutionattempted searching graph. search guided heuristic information,called heuristic search. work heuristic search problem solving dealsunidirectional approaches, start heading towards node (see, e.g.,Pearl, 1984).one goal node explicitly given search operators reversible,bidirectional search possible, proceeds forward directionbackward direction (see, e.g., Nilsson, 1980). Strictly speaking,even required operators inverses. necessary given node nset parent nodes pi determined exist operators lead pin. Searching backwards means generating parent nodes successively goal node(see, e.g., Russell & Norvig, 1995). words, backward search implements reasoningoperators backward direction.illustrating example class problems bidirectional searchusefully applied, consider finding find shortest path two given placesusing given map city. case one-way streets, bidirectional search implementsc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiKaindl & Kainzreasoning like following: \in order arrive t, one-way street leading towardsmay used". slightly adapted problem class, cost driving street maydifferent, depending driving direction. steep street top mountainmay serve example. Bidirectional search works also correctly case:backward search implements reasoning backward direction takes accountcost driving forward direction. formally, k1(m; n) = k2(n; m) costoptimal path n. k2 used notational convenience only.1 bidirectionalsearch algorithms dealt paper work correctly conditionsrequire operators reversible cost path eitherdirection.Bidirectional search shown ecient unidirectional counterpartheuristic knowledge unavailable, inverse result originally foundexperiments bidirectional heuristic search Pohl (1971). Since kind searchwork expected, consensus conjecture bidirectional heuristicsearch aicted problem search frontiers passing without intersecting.situation metaphorically compared Pohl missiles pass other,illustrated figure reprinted Nilsson (1980, Fig. 2.11). Nilsson conjecturedcase bidirectional search may expand twice many nodes wouldunidirectional one.original algorithm BHPA proposed Pohl (1971) may actually showinecient performance, missile metaphor wrong misleading. demonstratebidirectional heuristic search actually aicted problem search frontierspassing other. performance BHPA much worse originally expectedtwo different reasons:1. BHPA's search frontiers typically go other.2. major effort spent search frontiers already met: findingbetter solutions one found first meeting search frontiersoptimal one; finally proving indeed better solution possible.first reason specific BHPA incidentally resolved technical improvements introduced related algorithm BS* Kwa (1989). secondissue, however, also major obstacle eciency BS* actually bidirectional search algorithm performs heuristic front-to-end evaluations, i.e., evaluationsestimate minimal cost path evaluated node search frontt. Note, kind evaluations also performed typical unidirectional search.common belief missile metaphor, however, so-called wave-shapingalgorithms developed de Champeaux (1983), de Champeaux Sint (1977),Politowski Pohl (1984), idea steer search \wave-fronts" together.contrast BHPA BS*, algorithms perform front-to-front evaluations, i.e., evaluations estimate minimal cost path evaluated node one searchfront nodes opposing front. fact, algorithms achieve large reductionsnumber nodes searched compared algorithms perform front-to-end evaluations. However, either excessively computationally demanding,1. notation explained Appendix.284fiBidirectional Heuristic Search Reconsideredrestriction solution quality. Still, reductions number nodessearched using front-to-front evaluations come from? all, algorithms performingfront-to-end evaluations suffer problem search frontiers passingother.order answer important question, let us shortly focus common propertyheuristic evaluation functions estimate minimal cost path applyingheuristic knowledge static information encoded state information nodeevaluated. static evaluation functions typically evaluate error, i.e.,difference minimal cost path heuristic estimate casesgreater zero. approach improve accuracy given static evaluation functionperform search utilize results. Since involves dynamic changes, calldynamic evaluation function. Dynamic evaluations bounded look-ahead searchstudied various contexts Kaindl Scheucher (1992).static evaluation errors typically smaller paths smaller cost, alsoobserved Pearl (1984). Front-to-front evaluations therefore typically accuratefront-to-end evaluations. addition, costs paths nodesopposing search frontier (or s, respectively) known, overall evaluationsfront-to-front algorithms much accurate front-to-end evaluations. Sinceformer utilize results search opposing direction, may viewapproach dynamically improving heuristic values static evaluation function. Dueasset, wave-shaping algorithms achieve large reductions terms nodes generatedsince perform front-to-front evaluations. However, quite expensive termsrunning time (per node examined), calls finding appropriate balance.fact, Dillenburg Nelson (1994) well Manzini (1995) developed recent nontraditional approach bidirectional search called perimeter search achieves exactlythis.devised new computationally much cheaper approach dynamic improvements call difference approach. utilizes differences known costsheuristic estimates given evaluation function improve heuristic estimatesfunction. difference approach applied bidirectional heuristic searchalgorithms perform heuristic front-to-end evaluations. exemplified two newmethods dynamic improvements heuristic evaluations search.also devised new approach bidirectional heuristic search performs heuristicfront-to-end evaluations, dynamic improvements heuristic evaluationssearch embedded eciently effectively. approach generic senseencompasses whole class (non-traditional) bidirectional search algorithms.show paper, instantiated case availability sucientmemory well case limited memory.results experiments suggest bidirectional heuristic search improveunidirectional heuristic search respect generated nodes running time(for certain problems finding optimal solutions). Since missile metaphor wrong,bidirectional heuristic search using approach without time-consumingfront-to-front evaluations. So, bidirectional heuristic search viable proposereconsidered.285fiKaindl & Kainzpaper organized following manner. First, discuss previous workpresent new theoretical empirical results existing approaches bidirectionalheuristic search. describe new generic approach non-traditional bidirectionalsearch two instantiations. Thereafter propose new approach dynamicallyimproving heuristic values based differences known costs heuristicestimates. presentation experimental results applying approaches,discuss context various approaches bidirectional heuristic searchpreviously proposed.2. Previous Workorder make paper self-contained, sketch essentials previous workheuristic search algorithms focus bidirectional heuristic search, without goingdetail necessary understand new results previous worknew approaches.2.1 Unidirectional Heuristic Search AlgorithmsMany unidirectional search algorithms presented, would prohibitivereview here. Rather, focus unidirectional algorithms formbasis bidirectional search discussed paper. First, review traditionalbest-first search algorithm A* (Hart, Nilsson, & Raphael, 1968). Then, shortly explainlinear-space algorithm IDA* (iterative-deepening-A*) proposed Korf (1985). Finally,review algorithm called Trans (Reinefeld & Marsland, 1994) implements formenhanced iterative-deepening search.A* maintains set Open so-called open nodes generatedyet expanded, i.e., frontier nodes. Much best-first search algorithm, alwaysselects node Open minimum estimated cost, one considers \best".node expanded moved Open Closed. A* specifically estimatescost node n evaluation function form f (n) = g (n)+ h(n), g (n)(sum) cost path found n, h(n) heuristic estimate costreaching goal n, i.e., cost optimal path goal t. h(n)never overestimates cost (it said admissible) solution exists, A*guaranteed return optimal (minimum-cost) solution (it also said admissible).certain conditions, A* optimal admissible unidirectional heuristic searchalgorithms using information, sense never expands nodes(Dechter & Pearl, 1985). emphasize optimality resultA* compares unidirectional competitors, bidirectional approach may wellimprove performance A*. major limitation A* memory requirement,proportional number nodes stored therefore practical casesexponential.IDA* designed address memory problem, using heuristicevaluation function f (n) A*. IDA* performs iterations depth-first searches. Consequently, linear-space requirements only. Although performing depth-first searchesiteratively deeper deeper heavily used computer chess programscontext alpha-beta minimax search since sixties still use (see Kaindl, 1990),286fiBidirectional Heuristic Search ReconsideredB1k1(A,B1)k1(A,B2) B2h1(B2)g1(A)h1(B1)k1(A,B3)h1(A)B3h1(B3)H1(A) = max( h1(A), min( k1(A,Bi) + h1(Bi) ) )Figure 1: illustration back-up idea.application approach problem-solving searches marked breakthroughsolving dicult problems. IDA*'s depth-first searches guided thresholdinitially set estimated cost s; threshold succeeding iterationminimum f -value exceeded threshold previous iteration.IDA* shows best performance trees, one major problemspure form cannot deal duplicate nodes sense transpositions. transpositionarises, several paths lead node, search space representeddirected acyclic graph (DAG). disadvantage IDA* relates advantagerequiring linear space.Fortunately, computers memory available needed IDA*.memory utilized recognizing duplicate nodes two ways, using finite state machine (Taylor & Korf, 1993), transposition table implemented hash table (Reinefeld& Marsland, 1994). Due general applicability wider variety domains,since bidirectional algorithms partly make use it, focus latter technique.algorithm Trans proposed Reinefeld Marsland (1994) uses transpositiontable IDA*. Since size table deliberately parameterized,approach utilizing limited memory. Analogously earlier applications transpositiontables computer chess programs, Trans utilizes table actually two purposes:recognizing transpositions;caching best heuristic values acquired dynamically.Since latter use dicult understand, explain underlying ideadepth. back-up idea illustrated Fig. 1. normal searchnodes Bi statically evaluated stored, values still used backingnode stored | case Trans transposition table.dynamic value minimum estimated costs best paths foundnodes Bi . Unless static evaluator consistent, useful store maximumdynamic static value node. cached node re-searched,improved value often used instead value assigned directly staticevaluation function.Apart use Trans, back-up idea actually widely applied many algorithms like MA* (Chakrabarti, Ghose, Acharya, & DeSarkar, 1989), MREC (Sen & Bagchi,1989), RTA* (Korf, 1990), SMA* (Russell, 1992) (Ghosh, Mahanti, & Nau, 1994).287fiKaindl & Kainzadvantages little overhead steady (though often modest) improvementincreasing memory size. addition, idea also works goal condition insteadgoal node specified, i.e., require goal node explicitly given. However,applicable re-searched cached nodes, cannot see could makesense context traditional best-first search like A*.2.2 Traditional Approach Bidirectional Heuristic SearchFirst, look older approach bidirectional heuristic search forwardbackward searches alternate. call traditional approach. encompassesalgorithms performing front-to-end others performing front-to-front evaluations.2.2.1 Front-to-end EvaluationsSince first proposed algorithm bidirectional heuristic search called BHPA (Pohl, 1971)performed front-to-end evaluations, let us begin approach. employs heuristicevaluation functions hd (n) estimate cost optimal path evaluatednode n s, respectively, depending search direction d. precisely, h1 (n)estimates cost optimal path n forward search, h2 (n)n backward search. Note, always optimal pathfound (i.e., s) therefore also cost path estimatedevaluation function fd uses hd heuristic component. viewpointbackward search targets node s, however, may seem cost frontierestimated heuristically, precisely cost frontier.issue matters cost path either direction.view BHPA search essentially two A*-type searches opposite directions,i.e., traditional best-first searches.2 performed quasi-simultaneously, i.e.,sequential machine one node expanded another, search direction changed(at least) time time. decision searching forward backward directionmade anew node expansion according cardinality criterion (Pohl, 1971):jOpen1j jOpen2j 1 else 2Whenever search frontiers meet node n, solution found. costg1(n) + g2(n), i.e., cost path found forward search n, pluscost path found backward search n t. Even two partssolution forward backward search optimal, however, concatenatedsolution path necessarily optimal. Therefore, algorithm requires specialtermination condition guaranteeing optimal solutions. termination condition2. precisely, BHPA viewed consist two HPA searches (Pohl, 1970) opposing directions.long heuristic function used consistent values weighted equally gd -values,relevant difference check whether Open become empty. admissible consistentheuristic functions, option move nodes back Closed Open important, new bettergd -value found. heuristic function consistent hd (m) hd (n) + kd (m; n) nodes n.implies hd admissible, i.e., heuristic function never overestimates real cost.288fiBidirectional Heuristic Search ReconsideredBHPA follows:Lmin max[ min f1(x); min f2 (x)]x2Open1x2Open2(1)condition essentially means cost Lmin best (least costly) completepath found far larger estimate computed fd -valuessearch frontiers. heuristic used estimates admissible, pathmust already optimal solution order satisfy termination condition. Sinceunderstanding condition important paper, elaborate depthbelow.Implicitly also condition successful termination improved algorithmBS* (Kwa, 1989), removes nodes n whose fd -values Lmin terminatesOpen1 Open2 empty. technique removing nodes called trimmingBS*, newly generated nodes placed sets open nodes all,called screening. techniques improve BHPA \just" respectsaving memory, BS* additionally includes improvements reduce number nodesgenerated. major improvements following:nipping: node selected expansion already Closed opposite search tree, put Closed current search tree withoutexpansion;pruning: situation, descendants node Open oppositesearch tree removed.BHPA BS* admissible fd consistent. However, BHPA's resultsclearly less ecient A* finding optimal solutions, also BS* nevershown really ecient A*.Koll Kaindl (1993) first conjecture missile metaphor misleading explanation provided (preliminary) evidence finding. Basedrealizing fulfilling termination condition (1) key issue, developedecient "-admissible search algorithms, typically find solutions known errorbound faster generate fewer nodes corresponding derivative A* guarantees error bound. algorithms provided, however, improvementsfinding optimal solutions, require exponential space like BHPA, BS* A*.Based approach, Kaindl Khorsand (1994) showed bidirectionalheuristic search using limited memory possible using unidirectional searchalgorithm cope limited memory | SMA* (Russell, 1992). However,runtime eciency insucient.2.2.2 Front-to-front EvaluationsSince long time consensus belief search frontiers wouldpass other, research focused algorithms would force \wavefronts" meet\wave-shaping" techniques: BHFFA (de Champeaux & Sint, 1977), BHFFA2(de Champeaux, 1983), d-node retargeting (Politowski & Pohl, 1984) generalizedalgorithm (encompassing BHPA BHFFA2) (Davis, Pollack, & Sudkamp, 1984).289fiKaindl & Kainzh(A,B1)g1(A)B1h1(A)k2(t,B1)h(A,B2)h(A,B3)B2 k2(t,B2)k2(t,B3)H1(A) = max( h1(A), min( h(A,Bi) + k2(t,Bi) ) )B3Figure 2: illustration front-to-front idea.algorithms perform front-to-front evaluations show bidirectional heuristicsearch ecient terms number nodes generated.Since basic idea front-to-front evaluations important understandingpaper, illustrate using Fig. 2. evaluation node nodes Biopposite search front available storage, costs optimal pathsevery Bi estimated. Adding known costs paths Bi goal nodet, normally accurate dynamic estimates gained static front-to-endevaluator directly estimates cost t.However, algorithms performing front-to-front evaluations either excessively computationally demanding, restriction solution quality.compute heuristic estimates nodes one search frontier nodesother, order estimate paths going nodes opposite frontiervice versa. So, effort evaluations needed single node selectionexpansion may even seem proportional cross product numbers nodesfrontiers. use appropriate data structures, effort reduced become proportional number descendants expanded node timessize opposite search frontier.3 Still, excessively computationally demanding frontiers may contain order millions nodes. keeping effortpractical non-trivial problems, algorithm may either restrict computationcertain (small) number nodes promising values keep search directionfocused single target node opposing frontier several steps retargetingit. approaches typically terminate non-optimal solutions therefore obviouslylose admissibility, i.e, guarantee finding optimal solutions.2.3 Non-traditional Approach Bidirectional Heuristic SearchSo, traditional approaches succeed improve unidirectional searchfinding guaranteeing optimal solutions. particular, algorithms basedtraditional best-first search exponential storage requirements. may seembidirectional search needs store nodes least one frontier searchopposing side recognize meeting frontier (typically implementedhashing scheme). Instead storing frontiers forward backwardsearches alternate, possible search one direction first storing nodes,3. According personal communication Dennis de Champeaux.290fiBidirectional Heuristic Search Reconsideredsearch direction. call non-traditional approach bidirectionalheuristic search.approach perimeter search (Dillenburg & Nelson, 1994; Manzini, 1995).perimeter search, breadth-first search generates stores nodes aroundpredetermined (and fixed) perimeter depth. final frontier breadth-first searchcalled perimeter. search finished nodes stored, forward searchstarts s, targeting perimeter nodes. Depending given problemavailable storage, forward search performed A* IDA* fashion.former implemented PS* (Dillenburg & Nelson, 1994), latter IDPS*(Dillenburg & Nelson, 1994) BIDA* (Manzini, 1995). perimeter depth,IDPS* BIDA* search exactly nodes. However, BIDA* temporarily removesperimeter nodes cannot affect computation evaluation functionconsequently reduces number heuristic front-to-front evaluations comparedIDPS*. Due improvement, BIDA* far ecient terms running timeIDPS*.BIDA* achieves good results (sliding-tile) Fifteen Puzzle domain. investigate case contrast traditional approaches bidirectionalheuristic search. particular, show results experiments varying perimeterdepth, i.e., varying perimeter size storage use.3. New Results Previous ApproachesStill, seems previous approaches bidirectional heuristic search understood properly. Therefore, present new results proposenew approaches.3.1 Theoretical Resultspresent new theoretical results bounds number nodes expandedtraditional bidirectional heuristic search front-to-end evaluations. Since runtimeperformance proportional number nodes expanded, boundspotential eciency. assume availability consistent heuristic evaluation functionhd directions.First make explicit principally known result form lemma, since needparticular result proving new results. addition, understanding importantunderstanding results. Note, however, termination condition bidirectional search significantly different termination conditions unidirectional searchlike A* given Pearl (1984).Lemma 3.1 (a sucient condition successful termination BHPA BS*):solution path t, BHPA BS* terminate successfully (i.e.,finding path) iff following conditions satisfied:(i) least one search frontiers BHPA BS* minimum f -value mustraised least value optimal solution C , is, minx2Opend fd (x)C ;(ii) optimal solution must found, is, Lmin = C .291fiKaindl & KainzProof: need concerned whether algorithms indeed find optimalsolutions, since corresponding proofs given Pohl (1971) Kwa (1989), respectively. focus exactly termination condition Formula (1)fulfilled | BHPA explicit termination condition, BS* implicitexplained above. minimum f -values Opend first values f1 (s) f2 (t),respectively. Since fd consistent exceed C . minimum f -values Opendincreases gradually nodes f -values < C least one search frontierexpanded (or nipped pruned BS*). Since maximum minimum f -valuesOpend used, one least one must become C . search,Lmin C always holds, optimal solution found, Lmin = C .2order establish bounds number node expansions, let us first focusupper bound number nodes expanded BHPA.Theorem 3.1 number node expansions BHPA bounded#(BHPA) < #(A )1 + #(A)2Proof: worst case, BHPA may perform A*-type searchesdirections completely, exception least one node expansion. Even Lmin =C achieved last node expansion one direction, immediately thereaftertermination condition fulfilled according Lemma 1. Therefore, opposite directionleast one node expansion saved.2sense, bound may look quite weak, actually Nilsson (1980) conjectured bidirectional heuristic search may expand twice many nodes wouldcorresponding unidirectional one. conjecture based assumption originallypublished Pohl (1971) search frontiers may pass without intersecting.recently, however, empirical evidence found Koll Kaindl (1993)assumption invalid, i.e., frontiers typically meet rather early even withoutusing wave-shaping techniques. So, question may arise whetherconditions result Theorem 3.1 reasonable useful. order show conditions, define strong symmetry property search spaces. Although may seemcompletely unrealistic assumption, dicult imagine search spaceproperty. Searches optimal solutions TSP (traveling salesman problem)instances need generate nodes represent visiting neighboring citiesstart city. Since city also final city visited, reverse searchopposing direction needs generate nodes exactly cities, etc. So, leaststraight-forward implementation bidirectional search TSP works symmetricspace. symmetric TSP instances (where arc costs independentdirection) usual heuristic evaluations functions TSP (like minimumspanning tree heuristic), turns perfectly A*-symmetric search space.Definition 3.1 Let f11 = h1(s); f12; : : :; f1k,1; f1k = C different f -values expandednodes forward direction analogously f21 = h2 (t); f22; : : :; f2k,1; f2k = Cbackward direction. search space perfectly A*-symmetric iff A* expandsnumber nodes f -value forward direction backward direction,is, #j (A)1 = #j (A )2 j = 1 : : :k.2292fiBidirectional Heuristic Search ReconsideredTheorem 3.2 search space perfectly A*-symmetric f -values distinctdirection,#(BHPA) = 2 #(A) , 1 3Proof: perfectly A*-symmetric search space, numbers nodes expandeddirections A*-type searches within BHPA strictly last 2f -values, termination possible point; since distinctdirection, amounts 2 nodes remaining 2 f -values:#(A )1 , 2 = #(A)2 , 2Depending Lmin = C achieved, 1 3 nodes must expandedfulfill termination condition. Summing proves theorem.2Since practice f -values normally distinct (in direction), showconsequence realistic assumption | occurrence many different f -values.meant sense number nodes f -value small comparednumber nodes expanded.Corollary 3.1 search space perfectly symmetric many different f values,#(BHPA) 2 #(A)Proof: Since several nodes f -value, expansion3 nodes may saved optimal solution already found.number nodes f -value small compared number nodes expanded,however, #(BHPA).2So, strong assumption symmetry BHPA expands close twice manynodes A*. possible conjecture Nilsson (1980) supported althoughoriginal assumption appears valid?point search frontiers BHPA meet early, i.e., passwithout intersecting, go other! So, possibly largeregion search space explored twice (as illustrated Fig. 3).BS* avoids double exploration (see Fig. 3). Unfortunately, appearsdicult quantify size region. So, cannot determine tighter upper boundnumber nodes expanded BS* without assumptions.Fig. 3 also illustrates search frontiers BS* typically \ragged".means meetings occur \middle" well near (as observedexperiments).let us look lower bounds number nodes expanded BHPA.need assumption symmetry show general results.Theorem 3.3 numbers nodes expanded BHPA boundedmin(X1; X2) + 1 #(BHPA)293fiKaindl & KainzA*BHPAregion search space explored twiceBS*nippingpruningFigure 3: illustration traditional bidirectional heuristic search front-to-end evaluations.Xd = #d (A ) , #kd (A) number nodes would expand searchdirection minus number nodes value fdk = C .Proof: lower bound represents case earliest termination according Lemma1. (At least 1 node expanded direction.)2Corollary 3.2 f -values distinct direction, number nodesexpanded BHPA boundedmin(#1 (A); #2(A)) #(BHPA)Proof: Xd = #d (A) , 1 since 1 node n fd(n) = C .2Corollary 3.3 maximal improvement BHPA given#(A) , min(X1; X2) , 1:Proof: min(X1; X2) + 1 minimum number nodes expanded BHPA.2essence, shown certain conditions traditional bidirectional heuristic search front-to-end evaluations exemplified BHPA expand close twicemany nodes A*. original conjecture result basedapparently wrong assumption, found another | even obvious | effect(partly) responsible.addition, shown BHPA cannot much ecient A*respect node expansions even best case. variant BS* without pruningtechnique, lower bound number nodes expanded applies. general,major problem traditional bidirectional heuristic search front-to-end evaluationscost satisfying termination condition.294fiBidirectional Heuristic Search Reconsidered3.2 Empirical Resultsorder provide evidence missile metaphor misleading, present newempirical data performance BS*. Since perimeter search seems becomeecient increasing perimeter depth (Manzini, 1995), investigatedbehavior experiments two different domains. present new empirical resultsexperiments provide explanation perimeter search works wellFifteen Puzzle domain.3.2.1 BS*BS* classical best-first search algorithm requires exponential memory. So,aware BS* implementation yet able solve dicult problem instancesFifteen Puzzle, given domain-specific knowledge puzzleManhattan distance heuristic. experiments, BS* able solve 59 100instances used Korf (1985), available 256 Mbytes main storage (onConvex C3220).gathered data runs BS* provide empirical evidencemissile metaphor misleading (in addition data already given Koll Kaindl(1993)). average, BS* found first solution generation 7.2 percenttotal number nodes generated. quality solution average 6.3percent worse optimal solution. continuing searches, BS* foundoptimal solutions generation 22.4 percent total number nodes generated(again average). is, search effort BS* spent verify optimality.means search frontiers BS* meet relatively early without usewave-shaping techniques, even optimal solutions found rather quickly. However,even BS* already found optimal solution problem instance,\know" solution optimal. So, must continue search generateremaining nodes order prove fact better solution available.Relatively overall higher effort, BHPA would find first solution even \earlier"BS*. course, BHPA needs exactly number nodes BS*search frontiers meet. first meeting, however, would generatenodes BS* search frontiers go other. search frontierswould, however, pass illustrated missile metaphor, solutions couldfound early.3.2.2 Perimeter SearchPerimeter search achieved good results Fifteen Puzzle domain, solveFifteen Puzzle problem instance relatively fast limited memory. However,approach bidirectional heuristic search also seems understood suciently yet.So, made experiments increasing perimeter depth two different domains.results may seem quite surprising. cannot yet explain theoretically,important right, try explain intuitively.experiments, feasible use complete set 100 Fifteen Puzzleproblem instances used Korf (1985). Fig. 4 shows domain BIDA* workswell, especially terms number nodes generated. data normalized295fiResults relative Korfs IDA* %Kaindl & Kainz50Nodes generated45Running time4035.342.034.23532.730.729.73028.027.829.127.42520151054.13.22.51.91.51.10.90.70.50.4010111213141516171819BIDA* Perimeter DepthFigure 4: Comparison BIDA* different perimeter depths Fifteen Puzzle (100instances) | time optimum.respective search effort IDA* (in Korf's implementation), since firstalgorithm able solve random instances Fifteen Puzzle.4 Also running timesgood.5Consistently (Manzini, 1995, Table 1), Fig. 4 shows steady decreasenumber nodes generated required running time increasing perimeter depthreaches 16. perimeter depth, however, BIDA* achieves minimum runningtime. exact perimeter depth optimum occurs may depend severalfactors machine used eciency implementation. newimportant finding is, however, optimum actually exists BIDA*.optimum perimeter depth shown exist PS* Dillenburg Nelson (1994),data presented Manzini (1995) suggested increasing perimeter depthnumber evaluations performed BIDA* even decreases. larger perimeter depths,however, savings terms node generation obviously outweighed larger costfront-to-front evaluations. Note, data presented Manzini (1995)show optimum amount memory required storing perimeterdepths greater 14 exhausted resources available experiments reportedthere.4. give idea overall diculty given problem set, note IDA* generates 363million nodes average, needs slightly less half hour Convex C3220.5. BIDA*'s result worse data reported Manzini (1995). primarily due usedifferent machine different implementation based ecient code IDA*puzzle provided us Korf using. implementation overhead especiallywave shaping shows clearly even using runtime optimizations described Manzini(1995). access implementation Manzini, E-mail communicationgiven hints it, agreement overall effect relativerunning times due different implementations IDA*.296fiBidirectional Heuristic Search ReconsideredKnowing existence optimum helps us better understand improvement perimeter search traditional approach bidirectional heuristic searchbased front-to-front evaluations exemplified, e.g., BHFFA. advantage improved evaluation accuracy balanced large overhead time consumptionnode evaluations. BIDA* tuned towards optimum, algorithm likeBHFFA typically balance regard. BHFFA reasonfind optimal solutions quite easy problems, perimeter search comparably much cheaperper node searched, since much smaller frontier \targeted".Although performance perimeter search cannot improved deliberatelyusing memory, optimum running time BIDA* Fifteen Puzzleproblems good. So, wanted see whether results alsoachieved another domain used experimenting algorithms.made experiments finding optimal solutions set maze problems.6problems, BIDA* based IDA* inecient due high number iterations. So,used PS* (Dillenburg & Nelson, 1994) implements common underlying idea| perimeter search | based A*. A* works well maze problems,seems runtime optimization BIDA* cannot practically used A*-basedalgorithm due excessive storage requirements, since every node Open informationevery perimeter node would stored may affect computationfront-to-front evaluations. fact, Manzini (1995) states techniqueapplied depth-first search algorithm.Based experiments, perimeter search approach appears work satisfactorily illustrated Fig. 5 | neither terms generated nodes termsrunning time. data normalized respective search effort A*, since seemsecient algorithm problem instances fit memory (see alsooptimality result A* unidirectional competitors Dechter & Pearl, 1985).7Even comparably larger perimeter depths (50, 100, : : : , 250), numbers generatednodes marginally improve (up 93.9 percent number nodes generated A*shown figure), running time becomes quite high (up 358.7 percent).running time reduced perimeter depths smaller 25,real savings number nodes generated therefore improvement A*observed.considering different performances perimeter search domains, question arises, works well Fifteen Puzzle satisfactorily maze. Let us consider reason good results first, closer lookcase perimeter depth 1. minimal perimeter around node Fifteen6. use domain inspired use Rao et al. (1991). Problem instancesdomain model task navigation presence obstacles. 100 instances drawn randomlyusing approach behind Xwindows demo package Xmaze. heuristic evaluator, useManhattan distance like Rao et al. (1991).experiments, made following adaptations. order allow transpositions,\install" wall three percent cases. leads roughly \density" transpositionsFifteen Puzzle. Moreover, use much larger mazes | 2000 2000, order focusdicult instances these, use instances h1 (s) 2000.7. give idea overall diculty given problem set, note A* generates 2.7million nodes average, needs less two minutes Convex C3220.297fiKaindl & Kainz358.7350Nodes generatedResults relative A* %303.0Running time300244.0250185.1200150100139.0119.899.398.797.496.295.093.95002550100150200250PS* Perimeter DepthFigure 5: Comparison PS* different perimeter depths maze problems (100instances).Puzzle contains two nodes. Still, perimeter approach saves half nodegenerations IDA*.major improvement explained quite simply looking approachimproving heuristic evaluation function. Perimeter search \discovers"search analogous improvement Manhattan distance heuristic presentedKorf Taylor (1996, p. 1203) name \last moves heuristic" (more preciselypart dealing exactly last move).8 precisely, cases dynamicvalues increase h1 (n) two units, i.e., twice (unit) cost either arcstwo perimeter nodes.9 improved evaluations, many node generationssaved even using perimeter nodes.Still, question remains improvements observed maze domain.domains arcs unit costs, found major differences help usexplain phenomenon. Fifteen Puzzle problems relatively short (optimal) solutions,due unit costs arcs overall cost solution also relatively small (53.1average). comparison, maze problems (in mazes size used) relativelylong (optimal) solutions relatively high cost solution (5262 average).8. heuristic based last move solution, must return blank goal position.order allow blank position, tiles next blank goal position mustcertain places. Manhattan distance accommodate corresponding paththerefore increased two units.9. also relates property Manhattan distance heuristic itself. cases, increasecost known arc (with cost 1) added increase heuristic estimateevaluated node perimeter node (also 1) compared estimate t. remaining cases,heuristic estimate evaluated node perimeter node reduces (by 1) comparedestimate t, cancels cost known arc.298fiBidirectional Heuristic Search Reconsidereddifferences also ected differences heuristic values (although useddomains less heuristic). given set Fifteen Puzzle probleminstances, h1 (s) = 37:1 average much smaller h1 (s) = 2361 given setproblem instances maze domain. data heuristic values\Think-A-Dot" problems used Dillenburg Nelson (1994), note meanpath length given 18.4, i.e., even much smaller Fifteen Puzzle.Let us assume Fifteen Puzzle maze domainnumber perimeter nodes twice cost arc (i.e., two units) added.means resulting dynamic evaluation improves static evaluationabsolute amount, quite different relative amount: 5.4 percent FifteenPuzzle compared 0.08 percent maze domain. So, dynamic improvementheuristic effect much higher Fifteen Puzzle, leads much larger savingsterms node generations effort front-to-front evaluations.summary, Fifteen Puzzle perimeter nodes improve staticevaluation, since twice (unit) costs arcs even cases simplyadded. large effect domain heuristic values typically smaller40. maze instances size experimented with, heuristic valuestwo orders magnitude larger, therefore many perimeter nodes wouldrequired achieve much effect. These, however, make perimeter search expensiveterms running time probably also storage requirement.considerations, clear effect front-to-front evaluationsmuch steering frontiers together, rather improve heuristic evaluationsdynamically. particular, example two perimeter nodes illustrates\wave shaping" real effect, rather improvement evaluation accuracy.4. Generic Approach Non-Traditional Bidirectional Searchdeveloped new generic approach bidirectional heuristic search integrates varioussearch algorithms typically leads hybrid combinations. Since approachallow changing search direction once, viewed non-traditionalform bidirectional search.major steps generic approach are:101. Assign search direction even nearly available memorytraditional best-first search.2. Perform traditional best-first search assigned direction using given memory.3. Unless best-first search already found optimal solution, perform searchreverse direction. Use memory structure built previous best-firstsearch, possibly together additional memory still available, computeuse front-to-end evaluations.would dicult perceive even general approach subsumesperimeter search. expensive front-to-front evaluations, however, wanted10. approach different one proposed earlier (Kaindl, Kainz, Leeb, & Smetana, 1995).299fiKaindl & Kainztranspositionslinear-space searchbest-first searchFigure 6: specialization generic approach.devise approach avoids need find balance costevaluations beneficial effect.useful specialization generic approach uses memory sidessearch space illustrated Fig. 6. traditional best-first search uses assignedmemory usual, e.g., A*, linear-space search uses much memory stillavailable transposition table (Reinefeld & Marsland, 1994). former first orderssequence node generations finds transpositions. latter uses memoryfinding transpositions another part search space, caching accurateheuristic evaluations closer t.limited memory available, approach exible. instance,memory transposition table assigned, approach combines linear-space searchconventional best-first search bidirectional style. may look quite similarBIDA*, note approach contrast performs front-to-end evaluations.memory best-first search used find solutions earlier meeting frontier(rather t).sucient memory available even solving dicult problem instancesdomain, also search reverse direction may performed traditional bestfirst search like A*. all, A* certain conditions certain sense optimalrespect node expansions (Dechter & Pearl, 1985).4.1 Instantiating Limited MemoryFirst show generic approach instantiated limited memoryavailable. course, instantiation make use available domain-specificinformation. particular, combine unidirectional search algorithmsbest suit properties domain (see, e.g., Rao et al., 1991; Zhang & Korf, 1993).example, domains IDA* choice, others depth-first branch-and-bound(Lawler & Wood, 1966) much better. case limited memory, eitherpreferred A*.present experimental results Fifteen Puzzle, domaincharacterized distinct cost values. condition, reasonableselect IDA* linear-space search algorithm, since dicult problem instancesFifteen Puzzle require much memory using A*, Manhattan distanceheuristic used. Since A* makes good use consistent heuristics like one (Dechter &Pearl, 1985), select part best-first search.300fiBidirectional Heuristic Search ReconsideredBased key idea bidirectional search, let A* IDA* search oppositedirections steps 2 3 generic approach, respectively. instantiationgeneric approach leads BAI (Bidirectional A* { IDA*).Optionally, may also give IDA* search part available memorytransposition table. Fig. 6 illustrates instantiation. call variant BAI dueuse table BAI-Trans.A* cannot find solution using given memory, IDA* searches reversedirection towards frontier prior search. Since consider case findingoptimal solutions, search cannot always terminate immediately solution found.better solution may exist, algorithm must find optimal one subsequentlyprove optimal.technically, IDA* part must changed slightly. Instead findgoal node, solution found whenever depth-first search meets frontieropposing A* search. cost solution smaller cost best solutionfound far (or first solution found) value stored. course, costbest solution found far may sub-optimal, algorithm yet knowalready optimal. However, stored value exceed non-overestimatingthreshold IDA* part, depth-first search exited successfully optimalsolution.addition necessary changes, IDA* part advantage startincreased initial threshold based admissible estimate optimal solution costdetermined A* part. Since assume consistent heuristic h, minimumf = g + h nodes Open always admissible estimate. Therefore, estimatehigher usual initial threshold IDA*, used instead.Moreover, necessary IDA* part search space alreadyexplored A*. technically, depth-first search invoked IDA* meetsclosed node opposing A* search frontier, branch cut (meeting opennode general insucient). call nipping according analogous methoddescribed Kwa (1989).ecient implementation Fifteen Puzzle even effort hashing everynode causes overhead cannot ignored. Therefore, implemented BAIway avoids hashing nodes | based heuristic estimate |knows frontier opposing A* search still reach.According step 1 generic approach, search directions must assignedA* IDA* part, respectively. traditional bidirectional search, Pohl (1971)proposed used cardinality criterion problem determining frontierselect node expansion: continue searching frontier fewer opennodes. utilized node expansion traditional bidirectional searchalgorithms, BAI decide issue beginning whole search.search space suciently symmetric, initial search directiondetermined random. search space least slightly asymmetricspecific knowledge determining search direction available, seems reasonablemake shallow probes search space sides use idea behindcardinality criterion. Since BAI incorporates IDA*, using algorithm also probingconsistent overall approach. example Fifteen Puzzle, first301fiKaindl & Kainziterations IDA* searched sides, direction fewer generatednodes assigned IDA* part overall search, since especially dicult problemssearch much deeper A* part.Let us shortly discuss behavior BAI. best case, would seemA*. fact, BAI even better pure A*. BAI assigns search directiondynamically, lead better results systematically going one direction.worst case, BAI perform part A*, without savings IDA* part(except effect nipping).key question BAI saves effort without enough memory availablecompleting A* search. Primarily, save one IDA*'s iterations. Duebetter initial threshold, early iterations saved. Since earlieriterations comparably cheap, helps much less saving last iteration.search also terminated complete iteration IDA* cost bestsolution already found larger new increased threshold. Therefore, largesavings possible BAI terminates earlier pure IDA*.4.2 Instantiating Sucient Memorylet us sketch generic approach instantiated case sucientmemory available sense even solving dicult problem instancesdomain, traditional best-first search terminate successfully given memory.case interest order see whether bidirectional search better A*,sense optimal unidirectional algorithms.sucient memory available, instead IDA* (or depth-first branch-and-bound)reverse search employ A*. fact, easy construct algorithm analogously BAI described above, using A* instead IDA*. instantiationgeneric approach leads BAA (Bidirectional A* { A*). algorithm changessearch direction contrast BS*. better utilization approachdynamically improving heuristic values based differences, introduce slightvariation algorithm below.5. Approach Dynamically Improving Heuristic Values basedDifferencesnew approach dynamic improvements heuristic evaluations search baseddifferences known costs heuristic estimates. differences utilizedtwo concrete methods presented below. basic idea common methodsmany nodes search, actual cost pathalready known. Since static heuristic values normally gained rather cheaply,differences computed signify error made evaluation comparedcost known path. differences utilized improve heuristic estimatessearch.order able compute differences, search must bidirectional.focus context non-traditional approach bidirectional heuristic searchdescribed above. Actually, application also possible context traditional bidirec302fiBidirectional Heuristic Search ReconsideredB1h1(A)g1(A)Searchfrontierg2*(B1)Diff1*(B1)h1(B1)B2 Diff1*(B2)Diff1*(Bi) = g2*(Bi) - h1(Bi)Diff1*(B3)Mindiff1 = min( Diff1*(Bi) )B3H1(A) = h1(A) + Mindiff1Figure 7: illustration Add idea.tional search like BS*. involves, however, intricacies beyond scopepaper. So, interested reader referred (Kainz, 1996).5.1 Add Methodfirst method instantiates approach adding constant derived differences heuristic values static evaluation function. Therefore, call Addmethod.Note, adding constant evaluations change order nodeexpansions unidirectional search algorithm like A*. So, benefit approachmay immediately obvious. However, bidirectional search algorithms using frontto-end evaluations, estimates compared cost best solution found far(which necessarily already optimal one), better estimates availablecomparisons improves eciency due earlier termination. explaindetail apply approach context non-traditional approachbidirectional heuristic search.See Fig. 7 key idea method. assume consistency static heuristicevaluator hd . Around goal node t, search examined part graph storedoptimal paths nodes Bi closed fringe t. node Bi , heuristicvalue h1 (Bi ) computed subtracted optimal path cost g2(Bi ) = g2(Bi ) =h1 (Bi ), resulting Diff1 (Bi ). actually error made heuristic evaluationnode Bi . minimum Diff1(Bi ) nodes Bi fringe computed |call Mindiff1 .point Add method consistent heuristic value h1 (A)node outside stored graph underestimates h1 (A) least Mindiff1 . proveprecisely below, first need show result Diff1.Lemma 5.1 heuristic h1 consistent, optimal path node nintermediary nodeDiff1(m) Diff1(n)holds, i.e., Diff1 decrease optimal path decreasing distance goalnode t.303fiKaindl & KainzProof: heuristic h1 consistent,h1 (n) h1 (m) + k1 (n; m)simply obtaing2(m) , h1 (m) g2(m) + k1(n; m) , h1 (n)Since n one optimal path t, knowg2(n) = g2(m) + k1 (n; m)substitutions obtaing2(m) , h1 (m) g2(n) , h1 (n)equivalentlyDiff1(m) Diff1(n)2proves lemma.Theorem 5.1 heuristic h1 consistent, possible compute admissibleheuristic H1 node outside search frontier aroundH1(A) = h1(A) + Mindiff1 h1 (A)Proof: path exists node t, also optimal path must exist,let go frontier node Bj . (If path exists, h1 (A) infinitetheorem holds.) Lemma 1 definition Mindiff1 knowMindiff1 Diff1(Bj ) Diff1 (A)Since Diff1 error made heuristic h1 , writeh1 (A) + Diff1(A) = h1 (A)substitution obtainh1(A) + Mindiff1 h1 (A)2proves theorem.Corollary 5.1 H1(A) also admissible estimate frontier node.Proof: replace Bj proof Theorem 3.1 without changing validity.2304fiBidirectional Heuristic Search ReconsideredTheorem 5.2 heuristic h1 consistent, H1 consistent.Proof: heuristic h1 consistent,h1 (n) h1 (m) + k1 (n; m)Adding constant Mindiff1 sides leadsh1 (n) + Mindiff1 h1 (m) + Mindiff1 + k1(n; m)meansH1(n) H1(m) + k1(n; m)proves theorem.2let us sketch Add method utilized context nontraditional approach bidirectional heuristic search. using BAA, example,first A* search must used compute value Mindiff1 (we assume startsnode t). Optimal paths nodes within search frontier guaranteedfrontier nodes themselves. suboptimal path found frontier node,however, known optimal path leads another frontier nodeoptimal path t. So, change fmin, since costs suboptimal pathscannot uence minimum. Mindiff1 reverse A* search constantadded h1 . call resulting algorithm Add-BAA.course, larger value Mindiff1 preferred given amount search.So, search starting around better guided expanding always onenodes n minimal Diff1 (n). call variant Add-BDA.11also necessary check, whether node evaluated outside fringegraph around t. simply achieved Add-BAA Add-BDA hashing,done anyway. node fringe first A* search matched,solution already found, first node path inside stored graph aroundmatched, path need pursued further, since optimal continuationalready known. So, evaluator H1 actually used, consistent, thereforeA* re-open nodes (Pearl, 1984). search terminates selectsnode n expansion f1 (n) = g1 (n) + H1 (n) smaller costbest solution found far, proven way optimal one.details method theoretical properties refer interestedreader (Kainz, 1994).5.2 Max Methodsecond method computes estimate based differences usesmaximum static estimate. Therefore, call Max method.See Fig. 8 key idea method. assume consistency static heuristicevaluator hd , path cost g1(A) known. knowevaluation node A: h2 (A) g1(A). difference Diff2 (A) = g1 (A) , h2 (A).use difference construction admissible estimate F1 (A) cost11. Earlier called Add-A* (Kainz & Kaindl, 1996).305fiKaindl & Kainzk1(A,B1)g1(A)h1(A)Diff2(A)h2(A)B1h2(B1)g*2(B1)h2(B2)h2(B3)Diff2(A) = g1(A) - h2(A)fmin2 = min( g*2 (Bi) + h2(Bi) )*B2 g2(B2)g*2(B3)B3H1(A) = max( h1(A), fmin2 - h2(A) )F1(A) = max( f1(A), fmin2 + Diff2(A) )Figure 8: illustration Max idea.optimal path constrained go A. Note, g1(A) = g1(A)necessary, call difference used Diff2(A) instead Diff2 (A).addition, assume search performed reverse direction.search, assume nodes Bi closed fringe optimal pathsknown, cost g2(Bi ). Therefore, possible computefmin2 = min(g (B ) + h2 (Bi ))2Based assumptions, construct dynamic evaluation functionfollows.Theorem 5.3 heuristic h1 consistent, possible compute admissibleheuristic h01 node outside search frontier aroundh01(A) = fmin2 , h2(A) h1 (A)Proof: Every path must go frontier node Bj . cost Cjpath bounded follows:Cj k1(A; Bj ) + g2(Bj )h1 consistent, possible estimate optimal cost path two nodesk1(A; Bj ) h2 (Bj ) , h2 (A)Therefore, writeCj h2(Bj ) , h2 (A) + g2(Bj )Since fmin2 = min(g (B ) + h2 (Bi )), also write2Cj fmin2 , h2 (A)valid cost path including optimal one,concludeproves theorem.h1(A) fmin2 , h2 (A)3062fiBidirectional Heuristic Search ReconsideredCorollary 5.2 h01(A) also admissible estimate frontier node.Proof: replace Bj proof Theorem 3.3 without changing validity.2dynamic evaluation function necessarily better nodes staticfunction, useful combine functions:H1(A) = max(h1(A); fmin2 , h2 (A))Since admissible resulting function also admissible. value fmin2changes search, however, H1 consistent.Since formula computing H1 originally derived difference Diff2 (A) =g1(A) , h2 (A) included, also derive overall evaluation functionF1 (A) = max(f1(A); fmin2 + Diff2 (A))let us sketch Max method utilized context nontraditional approach bidirectional heuristic search. using BAI, example,A* search starting first must used compute value fmin2 (we assumestarts node t). Again, like Add method, necessary optimalpaths frontier nodes known. getting values fmin2 largepossible given amount search, usual strategy selecting node minimalf2 appropriate here.subsequent IDA* search within BAI must perform hashing graph storedaround order check, whether node evaluated outside fringegraph around t. latter case new solution found. call resulting algorithmMax-BAI. transposition table (Reinefeld & Marsland, 1994) used additionBAI-Trans, call Max-BAI-Trans.interestingly, IDA* also utilize Max method without additional storagerequirements. Let us sketch basic approach linear-space applicationmethod here. IDA* normally searches one direction only, let alternatesearch direction iteration solution found. Actually, procedureoutside generic approach bidirectional search presented above. includesince linear-space approach special interest. fmini computed one iterationused subsequent iteration, must search alternate directionuse value. example, iteration searching s, adapted IDA*computes hmax1 = max(h1 (Bi )) nodes Bi . value used estimatesubsequent iteration checking, whether node evaluated \outside":h1 (A) > hmax1 true, node cannot \inside" H1(A) safely used.check substitutes hashing stored graph. Since static heuristic function normallyunderestimates, however, nodes heuristic H1 used although wouldtheoretically correct use it. call resulting algorithm based ideaMax-IDA*.details method theoretical properties refer interestedreader (Kainz, 1996).307fiKaindl & KainzResults relative Korf's IDA* %100.0 100.0Nodes generated100Running time76.18067.166.7 66.754.46050.84030.127.627.424.515.413.9204.30.90MaxIDA*IDA*IDA*ProbingIDPS*Depth=2TransBIDA*Depth=16BAITransMax-BAITransFigure 9: Comparison Fifteen Puzzle (100 instances).6. Results Experiments New Approachesorder provide empirical evidence effectiveness eciencynew approaches, made experiments two different domains: Fifteen Puzzle mazes.6.1 Fifteen PuzzleFirst let us look specific experimental results finding optimal solutionsset Fifteen Puzzle problems, complete set 100 instances used Korf(1985). compare algorithms achieve previously best results domainnew algorithms. compared algorithms use domain-specific knowledgepuzzle Manhattan distance heuristic.12 main storage availableConvex C3220 used 256 Mbytes.Fig. 9 shows comparison several algorithms terms average number nodegenerations running times. data normalized respective searcheffort IDA* (in Korf's implementation). already noted above, IDA* needs averageslightly less half hour machine used find optimal solutionone problem instance. So, even slight improvements mean notable savings time.IDA*, Max-IDA* IDA*-Probing linear-space algorithms use additionalstorage, performance cannot compete algorithms use 256Mbytes. Max-IDA* generates 54.4 percent number nodes generated IDA*due dynamic improvements heuristic evaluations according differenceapproach. Since these, however, imply overhead per node searched, needs 76.1percent IDA*'s running time. IDA*-Probing variant IDA* usesprobing idea selecting search direction. Although search space sliding-tilepuzzle appears quite symmetric, interesting see much gainedselecting search direction dynamically. Since IDA*-Probing overheadrunning time, even faster Max-IDA*. order see well probing via threeiterations already indicates better search direction, compared result12. much improved heuristic functions, much ecient searches result (Culberson & Schaeffer,1996) even solving Twenty-Four Puzzle instances become feasible (Korf & Taylor, 1996).308fiBidirectional Heuristic Search Reconsideredperfect oracle. Using would still generate 64 percent IDA*'s nodes, i.e., IDA*Probing overhead generated nodes determining search directionless 0.1 percent overall 3 percent worse this. Systematically searchingbackward direction, however, significantly better systematically searchingforward direction due high standard deviations, although saves 17 percent.IDPS* uses nodes additional storage perimeter. Duerelated overhead front-to-front evaluations, needs running timeIDA*-Probing, although generates much fewer nodes.13Trans (using 256 Mbytes memory) achieves savings half running timecompared IDA*. saves even much node generations amount memory,effort hashing slows down.14Another technique prune duplicate nodes proposed Taylor Korf (1993),using finite state machine. results included Fig. 9, since lack datarunning time (no data given Taylor Korf (1993), reimplement technique). IDA* employing pruning technique generated 100.7 millionnodes set instances reported Taylor Korf (1993), means27.7 percent number nodes generated pure IDA*. finite state machineachieved result contained 55,441 states, requiring modest amount storage.course, finite state machine must built pre-processing stage first.use search involves small constant overhead running time. So,sliding-tile puzzles, approach seems better transposition tableseliminating duplicates. actually appears represent successful approach yetsolving Fifteen Puzzle problems using unidirectional search.principle, provided available storage BIDA* (Manzini, 1995),ecient algorithm perimeter approach. given 256 Mbytes storage,BIDA* store maximum 1 million perimeter nodes. would correspondperimeter depth 19, BIDA* generates 0.4 percent number nodesgenerated IDA*, needs 42 percent IDA*'s running time. So, shown Fig.4 use memory savings number nodes generated,optimum running time smaller perimeter size (16), showFig. 9. Also reduced perimeter, BIDA* achieves best result terms nodes13. results reported Dillenburg Nelson (1994) based runs using different sample setFifteen Puzzle, different perimeter depth. Using perimeter depth (4), resultsKorf's set re-implementation even better terms number node generations,much slower terms running time (even slower IDA*). personal communicationJohn Dillenburg turned implementation IDA* slower Korf's one (whichusing) factor 60 per generated node. implementation overhead especiallywave shaping show clearly ecient one. Since smaller perimeterdepth means fewer stored nodes therefore less overhead wave shaping, perimeter depth2 results better running time, consequently show data figure.14. data figure gained using re-implementation Trans based ecient code providedJonathan Shaeffer. Note different way presenting results: absolute data figure vs.relative problem diculty Reinefeld Marsland (1994). re-implement Trans, sincedata performance Trans amount memory used available, sinceintegrate technique algorithms. Actually, Trans+Move best algorithmdescribed Reinefeld Marsland (1994), absolute results less one percent betterTrans. Therefore, re-implement Trans+Move cannot includefigure.309fiKaindl & Kainzgenerated | 0.9 percent number nodes generated IDA*. BIDA*'soverhead computing front-to-front evaluations smaller IDPS*, BIDA*needs 27.4 percent IDA*'s running time.15algorithms BAI-Trans Max-BAI-Trans store maximum 5 million nodesimplementation algorithms given 256 Mbytes storage. BAI-Transgenerates clearly nodes (13.9 percent IDA*) BIDA*, since overheadper node much smaller, running time even slightly better (24.5 percent). Max-BAITrans | additionally utilizing new difference approach | achieves fastest searches,needing 15.4 percent time needed IDA*. achieving result, uses4 million nodes Max method (and BAI) 1 million nodes Trans. ordersee uence Trans, compare result Max-BAI (not shownFig. 9 order clutter it) uses 4 million nodes Max method(and BAI). Needing 19.2 percent time used IDA*, slightly slowerMax-BAI-Trans, shows comparably modest uence Trans.summary, new approach bidirectional heuristic search enhanced Maxmethod achieves fastest searches finding optimal solutions Fifteen Puzzleusing Manhattan distance heuristic knowledge source. superiority Max-BAI-Trans terms running time previous algorithms statisticallysignificant. example, probability improvement running timeBIDA* due chance uctuation smaller 0.15 percent according testcompares means paired samples absolute running times, even muchsmaller according test data relative diculty instancewell according sign test.16 using less ecient implementations IDA*basis, difference would become smaller, since approach less overhead pernode searched therefore \gains" less compared pure IDA*. However, prefercompare algorithms using ecient implementation available.details results see (Kainz, 1996).6.2 Mazesorder get better understanding usefulness new approach, madealso experiments second domain | finding shortest paths maze.maze problems described Subsection 3.2. addition 2000 2000mazes, also made experiments much smaller 1000 1000 mazes, order seewhether size uences relative performance various algorithms. compareknown algorithms achieve best results domain (as far found)algorithms Add-BAA Add-BDA. traditional shortest-path algorithm Dijkstra(1959) corresponds A* without using heuristic knowledge, need explicitlyinclude experiments. Also experiments, compared algorithms usedomain-specific knowledge Manhattan distance heuristic, mainstorage available Convex C3220 used 256 Mbytes.15. noted already Subsection 3.2, BIDA*'s result worse data reported Manzini(1995), primarily due using different machine different implementation basedecient code IDA* puzzle provided us Korf using.16. details statistic tests used refer interested reader (Kaindl, Leeb, & Smetana,1994; Kaindl & Smetana, 1994).310fiBidirectional Heuristic Search ReconsideredResults relative A* %160Nodes generated144.2Running time140120119.8103.599.3100 10099.387.510070.7 71.7806040200BS*PS*Depth=25A*Add-BAAAdd-BDAFigure 10: Comparison maze problems (100 instances).Fig. 10 shows comparison several algorithms terms average numbernode generations running times. data normalized respective searcheffort A*. already noted above, A* needs average less two minutesmachine used find optimal solution one problem instance.BS* generates slightly nodes solving problems A* (103.5 percent),running time even worse. may seem implementation BS*could optimized, clear overhead compared A*. So,BS* certainly improve A* here.PS* (Dillenburg & Nelson, 1994) | using perimeter search, i.e., front-to-frontmethod | generates 99.3 percent number nodes A*, needs 119.8 percenttime used A*. data correspond perimeter depth 25,best results shown Fig. 5 terms running time (see also discussionSubsection 3.2). So, also PS* cannot really improve A* here.algorithms Add-BAA Add-BDA generate clearly fewer nodes A* (87.570.7 percent, respectively). better performance Add-BDA ects higherMindiff1 value achieved guiding first two best-first searchesexpanding always one nodes n minimal Diff1(n). precisely, Add-BDAachieved Mindiff1 = 1174 (from reverse search 750k nodes), Add-BAA achievedMindiff1 = 811 (from reverse search even 1000k nodes). performance AddBAA terms running time is, however, still much A* (at leastimplementation derived BS*). Add-BDA achieves fastest searches, needing71.7 percent time needed A*. So, application approach dynamicallyimproving heuristic values feasible little overhead.superiority Add-BDA previous algorithms statistically significant.example, probability improvement terms running time A* duechance uctuation smaller 0.005 percent according three statistic testsmade analogously Fifteen Puzzle data. significance resultholds improvement respect number node generations. Add-BDAA* well algorithms compared generate child nodesnode expansions, superiority Add-BDA algorithms statistically311fiKaindl & KainzTable 1: Overview approaches bidirectional heuristic search.front-to-frontfront-to-endtraditionalBHFFA, BHFFA2 BHPA, BS*non-traditional PS*, IDPS*, BIDA* Max-BAI-Trans, Add-BDAsignificant also respect. particularly interesting, since optimality resultA* unidirectional algorithms stated sense A* never expands nodecould skipped (unidirectional) algorithm (Dechter & Pearl, 1985).Since relative results 1000 1000 mazes similar, showexplicitly (see, however, Kainz, 1996). provide empirical evidenceperformance algorithms peculiar certain size mazes.7. Discussionpresentation new approach bidirectional heuristic search experimental results, let us put perspective. Table 1 provides overview existingapproaches according way evaluating way organizing change(s)search direction. algorithms instantiate new generic approach fallcategory non-traditional bidirectional heuristic search algorithms (that change searchdirection once) perform front-to-end evaluations. approach allowscoping limited memory (e.g., Max-BAI Max-BAI-Trans), also usefulcase sucient memory (e.g., Add-BDA).Due avoiding expensive front-to-front evaluations, approach dynamically improving heuristic evaluations less effective perimeter search saving node generations (at least Fifteen Puzzle domain). However, less overhead thereforeecient per node searched terms running time.viewpoint Table 1, approach somehow \completes" picture bidirectional heuristic search. (Note, however, non-traditional approach foundindependently work perimeter search.) Still, ample opportunityresearch bidirectional search, especially looking perspectives. Another issue is, e.g., whether linear-space search involved not. proposepaper Max-IDA*, algorithm alternates search direction everyiteration order able use information previous iteration improvingheuristic evaluations dynamically. Yet another perspective whether algorithmdesigned find optimal solutions not. paper, focused admissiblesearch algorithms. discussed above, however, also exist "-admissible bidirectionalsearch algorithms guarantee solutions known error bound, well othersfind solutions without guarantee quality (e.g., d-node retargeting).contrasting traditional non-traditional approaches bidirectionalheuristic search, may appear strange less exible approach deliversbetter results. \better" change search direction once?dicult provide generally convincing answer question, let us summarizeobservations:312fiBidirectional Heuristic Search ReconsideredTraditional bidirectional search typically requires exponential space. KaindlKhorsand (1994) showed search possible using limited memory,complexity algorithms runtime eciency insucient.perimeter depths perimeter search successful, perimetersmuch smaller frontiers traditional front-to-front algorithms.parameterizing perimeter depth possible balance effort front-tofront evaluations effect improving heuristic evaluations dynamically.runtime optimizations BIDA* IDPS* feasible perimeterstays constant (at least iteration).Mindiff value Add method becomes higher search computinggenerates nodes. So, context traditional bidirectional searchinitially small.Applying Max idea becomes much complex, e.g., BS* searchfrontiers change (Kainz, 1996).general, one major problems heuristic search use availablelimited memory effectively. Pure unidirectional approaches utilizing limited memory ledless convincing results (Chakrabarti et al., 1989; Sen & Bagchi, 1989; Russell, 1992;Ghosh et al., 1994; Reinefeld & Marsland, 1994) non-traditional approachesbidirectional search shown Table 1. particular, generic approach allowsexible effective use available memory. is, however, partly due integrationvarious unidirectional strategies. Future work may investigate direct use unidirectional approaches utilizing limited memory instantiations generic approachbidirectional search.addition, bidirectional search allows use memory dynamically improvingheuristic evaluations ways infeasible strictly unidirectional search.demonstrated front-to-front approach well difference method.following simple idea implicitly behind approaches may illustrate this. Givenbreadth-first (uniform-cost) search depth d, node outside frontier mustleast + 1 steps away start s. reverse search towards may usefact compute estimate node outside frontier least + 1.idea cannot used strictly unidirectional search. Note, however, approachesdiscussed much complex useful simple idea. Since takeknown costs heuristic estimates well differences account,provide much better estimates especially nodes far outside already givenopposite search frontier.sense, also possible view difference approach learning, since alsodifferences predicted actual outcomes important. Usual machinelearning research, however, strives using results one problem instance solvingsubsequent instances, attempt. in-depth discussion relationshipoutside scope paper. Note, however, also approaches using front-tofront evaluations could considered viewpoint.313fiKaindl & Kainz8. ConclusionBased new insights previous approaches bidirectional heuristic search, propose papernew generic approach non-traditional bidirectional search front-to-end evaluations,new approach dynamically improving heuristic values context.showed successfully instantiate generic approach importantcase available memory limited. memory also utilized ecientlyimproving heuristic values. certain problems sucient memory available,proposed instantiation form algorithm challenges A*,certain sense optimal unidirectional search algorithms. optimality result A*unidirectional competitors Dechter Pearl (1985) imply bidirectionalsearch cannot ecient, experiments found empirical evidencenew algorithm ecient A* terms node expansionsrunning time. also showed approach ecient terms running timebidirectional unidirectional search approach using informationtwo different domains. results statistically significant.traditional bidirectional search yet achieve improvements admissible unidirectional search, non-traditional way performing opposing searchessequence | exemplified perimeter search approach | seemsgreat potential. sense, show bidirectional heuristic search viableconsequently propose search strategy reconsidered.Acknowledgementsyears, several people cooperated first author research heuristicsearch particular bidirectional search: Aliasghar Khorsand, Andreas Koll, AngelikaLeeb, Harald Smetana Roland Steiner. work served basis workpresented paper. experiments Convex C3220 computingcenter TU Vienna available. implementations based ecientcode IDA* A* puzzle made available Richard Korf ecient hashingschema Jonathan Shaeffer. Finally, acknowledge useful comments earlier draftsAndreas Auer, Dennis de Champeaux, Stefan Kramer, Giovanni Manzini, Ira PohlRoland Steiner. Parts paper already appeared Proc. Fourteenth InternationalJoint Conference Artificial Intelligence (IJCAI-95) Proc. Thirteenth NationalConference Artificial Intelligence (AAAI-96).Appendix. Glossary Notations;CStart node goal/target node, respectively.Current search direction index; search forwarddirection = 1, backward direction = 2.Cost optimal path t.314fiBidirectional Heuristic Search Reconsideredkd (m; n)gd(n)hd (n)gd(n); hd(n)fd (n)fdjHd(n)Fd (n)LminOpendCloseddjOpendj#(a)#d (a)#jd (a)Cost optimal path n = 1, n = 2.Cost optimal path n = 1, n = 2.Cost optimal path n = 1, n = 2.Estimates gd(n) hd (n), respectively.Static evaluation function: gd (n) + hd (n).One f -values expanded nodes search direction d.Dynamic estimate hd (n).Dynamic evaluation function: gd (n) + Hd (n).Cost best (least costly) complete path found far t.set open nodes search direction d.set closed nodes search direction d.Number nodes Opend .Number nodes expanded algorithm a.Number nodes expanded algorithm search direction d.Number nodes value fdj expanded algorithmsearch direction d.ReferencesChakrabarti, P., Ghose, S., Acharya, A., & DeSarkar, S. (1989). Heuristic search restricted memory. Artificial Intelligence, 41 (2), 197{221.Culberson, J., & Schaeffer, J. (1996). Searching pattern databases. McCalla, G.(Ed.), Advances Artificial Intelligence, pp. 402{416. Springer-Verlag, Berlin.Davis, H., Pollack, R., & Sudkamp, T. (1984). Towards better understanding bidirectional search. Proc. Fourth National Conference Artificial Intelligence (AAAI84), pp. 68{72. Menlo Park, CA: AAAI Press / MIT Press.de Champeaux, D. (1983). Bidirectional heuristic search again. J. ACM, 30 (1), 22{32.de Champeaux, D., & Sint, L. (1977). improved bidirectional heuristic search algorithm.J. ACM, 24 (2), 177{191.Dechter, R., & Pearl, J. (1985). Generalized best-first strategies optimality A.J. ACM, 32 (3), 505{536.Dijkstra, E. (1959). note two problems connexion graphs. NumerischeMathematik 1, pp. 269{271.Dillenburg, J., & Nelson, P. (1994). Perimeter search. Artificial Intelligence, 65 (1), 165{178.Ghosh, S., Mahanti, A., & Nau, D. (1994). ITS: ecient limited-memory heuristictree search algorithm. Proc. Twelfth National Conference Artificial Intelligence(AAAI-94), pp. 1353{1358. Menlo Park, CA: AAAI Press / MIT Press.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics (SSC),SSC-4 (2), 100{107.315fiKaindl & KainzKaindl, H. (1990). Tree searching algorithms. Marsland, T., & Schaeffer, J. (Eds.),Computers, Chess, Cognition, pp. 133{158. Springer-Verlag, New York.Kaindl, H., Kainz, G., Leeb, A., & Smetana, H. (1995). use limited memoryheuristic search. Proc. Fourteenth International Joint Conference Artificial Intelligence (IJCAI-95), pp. 236{242. San Francisco, CA: Morgan Kaufmann Publishers.Kaindl, H., & Khorsand, A. (1994). Memory-bounded bidirectional search. Proc. TwelfthNational Conference Artificial Intelligence (AAAI-94), pp. 1359{1364. Menlo Park,CA: AAAI Press / MIT Press.Kaindl, H., Leeb, A., & Smetana, H. (1994). Improvements linear-space search algorithms. Proc. Eleventh European Conference Artificial Intelligence (ECAI-94),pp. 155{159. Chichester, England: Wiley.Kaindl, H., & Scheucher, A. (1992). Reasons effects bounded look-ahead search.IEEE Transactions Systems, Man, Cybernetics (SMC), 22 (5), 992{1007.Kaindl, H., & Smetana, H. (1994). Experimental comparison heuristic search algorithms.AAAI-94 Workshop Experimental Evaluation Reasoning Search Methods,pp. 11{14.Kainz, G. (1994). Heuristische Suche Graphen mit der Differenz-Methode. Diplomarbeit,Technische Universitat Wien, Vienna, Austria.Kainz, G. (1996). Neue Algorithmen fur die bidirektionale heuristische Suche. Doctoraldissertation, Technische Universitat Wien, Vienna, Austria.Kainz, G., & Kaindl, H. (1996). Dynamic improvements heuristic evaluationssearch. Proc. Thirteenth National Conference Artificial Intelligence (AAAI-96),pp. 311{317. Menlo Park, CA: AAAI Press / MIT Press.Koll, A., & Kaindl, H. (1993). Bidirectional best-first search bounded error: Summaryresults. Proc. Thirteenth International Joint Conference Artificial Intelligence(IJCAI-93), pp. 217{223. San Francisco, CA: Morgan Kaufmann Publishers.Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27 (1), 97{109.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2{3), 189{212.Korf, R., & Taylor, L. (1996). Finding optimal solutions Twenty-Four Puzzle. Proc.Thirteenth National Conference Artificial Intelligence (AAAI-96), pp. 1202{1207.Menlo Park, CA: AAAI Press / MIT Press.Kwa, J. (1989). BS : Admissible Bidirectional Staged Heuristic Search Algorithm.Artificial Intelligence, 38 (2), 95{109.Lawler, E., & Wood, D. (1966). Branch-and-bound methods: survey. Operations Research,14 (4), 699{719.316fiBidirectional Heuristic Search ReconsideredManzini, G. (1995). BIDA*: improved perimeter search algorithm. Artificial Intelligence,75 (2), 347{360.Nilsson, N. (1980). Principles Artificial Intelligence. Tioga, Palo Alto, CA.Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving.Addison-Wesley, Reading, MA.Pohl, I. (1970). First results effect error heuristic search. Meltzer, B., &Michie, D. (Eds.), Machine Intelligence 5, pp. 219{236. Edinburgh University Press,Edinburgh.Pohl, I. (1971). Bi-directional search. Machine Intelligence 6, pp. 127{140 Edinburgh.Edinburgh University Press.Politowski, G., & Pohl, I. (1984). D-node retargeting bidirectional heuristic search.Proc. Fourth National Conference Artificial Intelligence (AAAI-84), pp. 274{277.Menlo Park, CA: AAAI Press / MIT Press.Rao, V., Kumar, V., & Korf, R. (1991). Depth-first vs best-first search. Proc. NinthNational Conference Artificial Intelligence (AAAI-91), pp. 434{440. Menlo Park,CA: AAAI Press / MIT Press.Reinefeld, A., & Marsland, T. (1994). Enhanced iterative-deepening search. IEEE Transactions Pattern Analysis Machine Intelligence (PAMI), 16 (12), 701{709.Russell, S. (1992). Ecient memory-bounded search methods. Proc. Tenth EuropeanConference Artificial Intelligence (ECAI-92), pp. 1{5. Chichester, England: Wiley.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,Englewood Cliffs, NJ.Sen, A., & Bagchi, A. (1989). Fast recursive formulations best-first search allowcontrolled use memory. Proc. Eleventh International Joint Conference Artificial Intelligence (IJCAI-89), pp. 297{302. San Francisco, CA: Morgan KaufmannPublishers.Taylor, L., & Korf, R. (1993). Pruning duplicate nodes depth-first search. Proc.Eleventh National Conference Artificial Intelligence (AAAI-93), pp. 756{761.Menlo Park, CA: AAAI Press / MIT Press.Zhang, W., & Korf, R. (1993). Depth-first vs. best-first search: new results. Proc.Eleventh National Conference Artificial Intelligence (AAAI-93), pp. 769{775.Menlo Park, CA: AAAI Press / MIT Press.317fiJournal Artificial Intelligence Research 7 (1997) 249-281Submitted 7/1997; published 12/1997Gravity Fails: Local Search TopologyJeremy Frankfrank@tiziano.arc.nasa.govCaelum Research Corp.NASA Ames Research CenterMail Stop N269-1Moffett Field, CA 94035-1000Peter Cheesemancheesem@ptolemy.arc.nasa.govRIACSNASA Ames Research CenterMail Stop N269-1Moffett Field, CA 94035-1000John Stutzstutz@ptolemy.arc.nasa.govNASA Ames Research CenterMail Stop N269-1Moffett Field, CA 94035-1000AbstractLocal search algorithms combinatorial search problems frequently encounter sequence states impossible improve value objective function;moves regions, called plateau moves, dominate time spent local search.analyze characterize plateaus three different classes randomly generatedBoolean Satisfiability problems. identify several interesting features plateausimpact performance local search algorithms. show local minima tendsmall occasionally may large. also show local minima escapedwithout unsatisfying large number clauses, systematically searchingescape route may computationally expensive local minimum large. showplateaus exits, called benches, tend much larger minima,benches exit states local search use escape. showsolutions (i.e., global minima) randomly generated problem instances form clusters,behave similarly local minima. revisit several enhancements local search algorithms explain performance light results. Finally discuss strategiescreating next generation local search algorithms.1. IntroductionLocal search algorithms heavily studied alternative complete searchNP -Hard problems. typical local search algorithm, gradient descentgreedy search, employs objective function rank states, picks \neighboring"state maximizing improvement objective function. compelling (if inexact)analogy dropping marble smooth surface observing roll downhilllocal valley. typical greedy objective function acts like gravity, pulling currentstate downhill. procedure result algorithm becoming trapped localminimum. Local search algorithms tend find solutions satisfiable decision problemsquickly complete search algorithms. However, algorithms may terminatec 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiFrank, Cheeseman, & Stutzprocedure GSAT(,MaxFlips, MaxTries)# problem instance solved# current variable assignmenti=1 MaxTries= N -bit string selected uniformly randomj = 1 MaxFlipssolved problem(A; )returnelsePossFlips = neighbors minimizing number unsatisfied clauses= one element Poss ips selected uniformly randomend elseendendreturn FAILendFigure 1: GSAT Algorithm Sketcheither without finding solution one exists guaranteeing problem instancesolution.GSAT local search procedure Boolean Satisfiability problems (Selman,Levesque, & Mitchell, 1992) proven effective quickly finding solutionssatisfiable problem instances. sketch GSAT appears Figure 1. figure,refers problem instance GSAT solve. GSAT's search space spacecomplete assignments values variables. GSAT algorithm typically given fixednumber tries (denoted figure MaxTries) fixed number moves per try(denoted MaxFlips) solve problem instance. move, GSAT examinesstates reachable changing value single variable, selects moves minimizenumber unsatisfied clauses. GSAT typically encounters sequence statesbest move available state leaves number unsatisfied clauses unchanged.moves referred plateau moves sideways moves, studied (Gent & Walsh,1993a) (Hampson & Kibler, 1995). Plateau moves dominate time GSAT spends search (Gent & Walsh, 1993a). believed combinatorial search problemsdiscrete objective functions plateaus cause plateau moves local search,unlikely search problems real-valued objective functions plateaus.GSAT encounters plateau, randomly searches either runs ips findsneighboring state fewer unsatisfied clauses, thereby exiting plateau. Returningmarble analogy, gravity plateaus, hence marble simply rollsrandom finds exit runs momentum. Numerous variants GSATdeveloped avoid random plateau search improve GSAT performance (Gent &Walsh, 1993b; Selman & Kautz, 1993; Gent & Walsh, 1995).nature plateau behavior local search algorithms well understood.researchers suggest algorithms like GSAT become trapped local minima, i.e., parts250fiWhen Gravity Fails: Local Search Topologysearch space escape better part search space.true, local minima detection avoidance important problem local searchalgorithm development. researchers suggested local search could becometrapped \ at" regions search space exits better states, callbenches. may happen benches large, contain exitsrandom plateau search small probability finding exit. Rather designingalgorithms testing problem classes, undertook empirical examinationnature plateaus variety 3-SAT problems.paper presents several surprising discoveries concerning topological structuresleading plateau behavior impact local search. define plateaus featuresearch space break plateaus two classes: local minima benches. Plateausdefined maximally connected region local search spaceobjective function constant. Local minima plateaus surrounded regionssearch space objective function takes values exceeding plateau,result purely greedy local search cannot escape finding statelocal minimum. Benches defined plateaus exits regions search spacelower values objective function. results show local minimacommon benches number unsatisfied clauses close 1, local minimaalso occur frequently higher numbers unsatisfied clauses. local minima tendsmall, size exhibits high variability; often largest local minima exceeds 10,000states problem instance containing 100 variables. Also surprising behaviorsolutions: solutions grouped together global minima highly variable size.results also show benches tended much larger local minima.benches large number exits, small fraction exits,result local search spend large amount time trying escape them. Plateaucharacteristics dependent many features problem instance; found differencesplateau characteristics based ratio clauses variables, solvability probleminstances, problem classes. results plateau characteristics allowed us reinterpret success many modifications local search, including history lists (Gent &Walsh, 1993b), random walk (Kautz & Selman, 1996) tabu search (Glover, 1989).paper organized follows: Section 2 present definitions used throughout rest paper. Next Sections 3 4 present empirical analysisproperties plateaus several problem spaces. Section 5 present analysisprevious results light findings. suggest apply workcreation new local search algorithms Section 6, finally Section 7 concludediscuss ideas future work.2. Definitionssection define terms used throughout paper. restrict discussion Boolean Satisfiability problems conjunctive normal form three distinctliterals per clause, abbreviated 3-SAT, many concepts presented translatediscrete combinatorial search problems. first present informal definitions,provide formal definitions end section.251fiFrank, Cheeseman, & Stutzway visualizing local search space 3-SAT mapping full variableassignment node N dimensional hypercube, N number variablesproblem instance. two assignments differ one variable assignmentadjacent nodes hypercube. problem instance defines function nodeshypercube, mapping node number unsatisfied clauses instanceassignment values corresponding node. refer number unsatisfiedclauses assignment level assignment. plateau maximal connectedregion assignment space states level, levelplateau level states plateau. Even single state plateau,neighbors different level state itself. define border plateauset nodes hypercube neighbors state plateaudifferent level plateau. plateau minimum states borderhigher level plateau. plateau minimum,state border lower level states plateau; states plateauadjacent lower level states called exits. Plateaus exits calledbenches. benches consist entirely exits; local search algorithm may exploreone state bench moving it. call benches contours.3-SAT, plateau global minimum level 0, unsatisfiable problem instancesglobal minima levels higher 0.PlateauexitsExitsMinimaBenchLowest LevelGlobal MinimaHigher LevelLocal MinimaStates ExitsContourFigure 2: Taxonomy Plateaussummary: plateau part space \ at" perspectiveobjective function. states neighboring plateau different levelplateau. neighboring states higher level, plateau local globalminimum, otherwise bench. every state plateau neighbor statelower level, bench contour. Figure 2 shows taxonomy different types plateaus.illustration definitions using simple problem instance presentedAppendix A.realize different ways defining topological structures local searchspaces. definition plateaus includes structures lead plateau behavior;local search exhibit plateau behavior passes contour, example.definitions show observed plateau behavior local search caused varietystructures local search topology. retrospect, clear definition benchesspecifically excludes contours would better serve characterize plateau behaviorgreedy algorithms. caution reader results benches contingentupon current definition benches, least one reasonable alternate252fiWhen Gravity Fails: Local Search Topologydefinition expected give somewhat different results. discussedSection 7.end section providing formal definitions ideas. Throughoutfollowing definitions, let H N dimensional hypercube representing possibleassignments 3-SAT problem instance . Two vertices hypercube h1 ; h2neighbors, i.e., edge them, correspond assignments differingexactly 1 variable.Definition 2.1 (Level) Let : H ! Z + function mapping assignments integers(h) = z assignment corresponding h results z unsatisfiedclauses problem instance . z defined level assignment.Definition 2.2 (Plateau) Let P connected subgraph H let z 2 Z + constant. P plateau P maximal connected subgraph H (p) = zp 2 P . Further, z defined level plateau.Definition 2.3 (Border) Let P plateau hypercube H . Let N (p) setneighboring vertices vertex p hypercube. Let V (P ) function returnsvertex set graph P . Define B (P ) = ([p2P N (p)) , V (P ), i.e., set B (P ) contains bb neighbor vertex p 2 P b P itself. B (P ) borderplateau.Definition 2.4 (Minimum, Local Minimum, Global Minimum) Let P plateauhypercube H . P minimum vertices B (P ) higher levellevel P . Also, P local minimum P minimum another minimumQ level Q smaller level P . P minimumlocal minimum P global minimum.Definition 2.5 (Bench, Exit, Contour) Let P plateau hypercube H . Pbench P minimum, hence exists b 2 B (P ) levelb smaller level P . Also, p exit bench p 2 P pneighbor b 2 B (P ) level b smaller level P . Finally, Pcontour every state P exit P .3. Probabilistically Painting PlateausArmed definitions previous section examined landscape plateausrandomly generated 3-SAT problem instances. generated problem instancesratio number clauses C number variables N ranged3.8 4.6 according Uniform3-SAT problem generation model (Selman et al., 1992;Crawford & Auton, 1993); algorithm generating instances presentedAppendix B. Problems region straddle \phase transition" satisfiability,satisfiability randomly generated problems exhibits rapid transitionrespect ratio clauses variables, complete search GSAT requirelongest time average find solutions (Cheeseman, Kanefsky, & Taylor, 1991;Crawford & Auton, 1993; Clark, Frank, Gent, MacIntyre, Tomov, & Walsh, 1996). Problem253fiFrank, Cheeseman, & Stutzinstances NC < 4:3 referred \under-constrained" since lieobserved transition satisfiability, problem instances NC > 4:3 called \overconstrained." guaranteed problem instance used set experimentssatisfiable finding solution using complete search algorithm.Local search seems diculty level assignment becomesclose 0; consequently, decided analyze plateaus levels. quite dicultrandomly sample plateaus fixed level problem instance; probability randomlygenerating assignment one unsatisfied clause, instance, small probleminstances 100 variables. used GSAT find plateaus analyzed paper.biases investigation plateaus found one local search method,hopefully provides first picture plateau structure local search spaces. Dueclumsiness language, remind reader throughout text findingsdependent plateau sampling methodology. Further, GSAT employsrandom starting points, bias results depends gradient followingprocedure. sample plateaus first used GSAT find state pre-determined level.is, generated initial state ran single try GSAT encounteredstate specified number unsatisfied clauses. used Breadth-First Searchfind states plateau found GSAT. Naturally Breadth-First Search recordsstate found redundant states double-counted. recordedsize plateau (i.e., number states plateau), number exitsplateau contained.3.1 Characterizing Plateausfirst analyzed relative proportions benches minima satisfiable probleminstances plateaus whose level close 0. generated problem instances 100variables 380-460 clauses increments 10 clauses. problem size generated1000 problem instances guaranteed instance solution using complete searchalgorithm. Using procedure described above, problem instance generatedfound one plateau level 0 5 measured proportion plateauslocal minima benches. analysis provide idea numberbenches local minima problem instances. Note plateaus level 0global minima satisfiable problem instances.Figure 3 shows proportion plateaus local minima graphednumber clauses problem instances. described above, used GSAT findplateaus Breadth-First Search determine whether plateaus local minimabenches. see proportion plateaus minima growsnumber clauses problem instance plateaus levels 2-5; hencelocal minima identical levels over-constrained problems under-constrainedproblems. rate growth diminishes plateau level decreases, roughlyplateaus level 1. 85% plateaus level 1 minima 100 variableproblem instances numbers clauses investigated.Figures 4 shows data, except case graphed levelplateau. level grows proportion local minima declines probleminstances numbers clauses. However, plateaus level 5 may still local minima254fiWhen Gravity Fails: Local Search Topology10.9Proportion Plateaus Minima0.80.70.60.50.40.3Level 1 PlateausLevel 2 PlateausLevel 3 PlateausLevel 4 PlateausLevel 5 Plateaus0.20.10380390400410420430Number Clauses440450460Figure 3: Proportion Plateaus Local Minima vs. Number Clauses Randomly Generated 100 Variable Problem Instances1Proportion Plateaus Minima0.9460 Clauses450 Clauses440 Clauses430 Clauses420 Clauses410 Clauses400 Clauses390 Clauses380 Clauses0.80.70.60.50.40.30.20.10012345Plateau LevelFigure 4: Proportion Plateaus Local Minima vs. Plateau Level 100 RandomlyGenerated Variable Problem Instances Varying Numbers Clauses255fiFrank, Cheeseman, & Stutzeven problems 100 variables 380 clauses. Hence local minima fact lifeeven under-constrained problems, become likely over-constrained problems.Finally, note plateaus level 1 2 reordering proportionlocal minima. example, problems 450 clauses lowest proportion localminima level 1, highest proportion local minima level 2.explanation result.10.9Proportion Plateaus Minima0.80.70.60.50.4Level 0 PlateausLevel 1 PlateausLevel 2 PlateausLevel 3 PlateausLevel 4 PlateausLevel 5 Plateaus0.30.20.10255075100Problem Size125150175Figure 5: Proportion Plateaus Local Minima vs. Plateau Level VariableSized Randomly Generated Problem Instances C/N=4.3also analyzed relative proportions benches minima changed problemsgrew larger. found one plateau levels 1-5 1000 problem instances25 175 variables increments 25, NC = 4:3. Figure 5 shows proportionplateaus levels 1-5 local minima NC = 4:3 graphed problemsize. see that, level, proportion minima grows problem size,bodes ill performance local search larger problem instances. seeproportion local minima higher level decreases less rapidly largerproblems. conjecture that, larger problems, proportion local minima decreasessignificantly plateaus levels higher 5, cannot predict exact behaviordata hand.cost detecting local minima proportional size local minima,understanding size distribution local minima important. cost escapingbenches dependent size bench proportion states benchexits, understanding properties also important. next twosections analyze characteristics benches minima. so, generatedstatistics plateaus found experiment used generate Figure 4.instance, 60% plateaus level 2 problem instances 380 clauses local256fiWhen Gravity Fails: Local Search Topologyminima, 600 local minima 400 benches analyze characteristicsplateaus. cases 100 data points available analysis.3.2 Minima Characteristics300100 variables, 430 clauses250Number Minima2001501005000100200300400500600Size Minima7008009001000Figure 6: Histogram Sizes Level 1 Minima Randomly Generated Problem Instances100 Variables, 430 Clauses. Note minima exceeded 1000 states.section analyze size distribution local minima. Figure 6 showsdistribution size level 1 minima problem instances 100 variables430 clauses. median minima size 48, yet tail shows minima larger1000 states. fact, 35 900 minima larger 1000 statesmany 10,000 states. examined distribution minima sizes levels1 found similar results; main differences lengths tailshistograms. consequence discovery escaping local minima explicit localminima detection normally easy, occasionally expensive. Figure 7shows distribution sizes minima smaller 100 states. seefewer minima size 0-5 size 5-10; detailed analysis revealsthree minima size 1, fifteen minima size 2.Due long tails distribution minima size, median providesstable summary statistic mean. therefore examined median size localminima levels 0-5 different numbers clauses determine size localminima varies. Figure 8 shows median size local minima plotted numberclauses problem instances. striking feature resultsminima tend quite small. suggests possible devise local search algorithmsdetect local minima using exhaustive search propelfruitful part search space. distribution shown Figure 6 indicates257fiFrank, Cheeseman, & Stutz100100 variables, 430 clauses9080Number Minima706050403020100051015202530354045 50 55 60Size Minima65707580859095 100Figure 7: Histogram Sizes Level 1 Minima Smaller 100 States RandomlyGenerated Problem Instances 100 Variables, 430 Clauses150Level 0 MinimaLevel 1 MinimaLevel 2 MinimaLevel 3 MinimaLevel 4 MinimaLevel 5 Minima125Median Minima Size1007550250380390400410420430Number Clauses440450460Figure 8: Median Size Minima vs. Problem Size 100 Variable Randomly GeneratedProblem Instances Varying Numbers Clauses258fiWhen Gravity Fails: Local Search Topologylocal minima large, explicit detection minima fixed size (themedian, instance) may successful addition local search. second featurenote median size level 0 minima (i.e., solutions) follows patternlocal minima, level 0 minima tend smaller local minima. lastfeature note median size local minima decreases minima level 0-3number clauses problem instances increases. median size local minimalevel 4 5 increases problems 450-460 clauses. One possible explanationsampled problem instances guaranteed solutions, meansadded clauses must contribute larger minima benches higher levels.true clear minima levels 0-3 increase size. Anotherpossible explanation small amount data plateaus levels 4 5 relativeamount available plateau sizes indicated Figure 4.120Level 1 MinimaLevel 2 MinimaLevel 3 MinimaLevel 4 MinimaLevel 5 Minima100Median Minima Size806040200255075100Problem Size125150175Figure 9: Median Size Minima vs. Plateau Level Variable Sized Randomly GeneratedProblem Instances C/N=4.3also examined median size local minima levels 1-5 number variablesproblem instances increases. Figure 9 shows median minima size variouslevels minima graphed problem size problem sizes 25 175 variablesCN = 4:3. observe that, problem sizes grow large (beyond 100 variables), mediansize minima lower levels appears smaller minima higher levels.also observe fixed minima level, appears problem instance sizemaximizes median minima size. explanation large numberminima level 1 problem instances 50 variables.Recall global minima satisfiable problem instance plateaustates solutions. many global minima satisfiable problem instances?one, solutions broken multiple global minima?259fiFrank, Cheeseman, & Stutzsingle global minima, size global minima tell us anythinglikely local search encounter particular solution? answer questionsused GSAT find 1000 global minima single problem instance 100 variables430 clauses, determined minima distinct. found 4361000 minima unique, global minima instance ranged size1 2880 states. Furthermore, found vast majority minima small,median size around 48. repeated experiment 20 probleminstances found solutions problem instances typically dividedseparate global minima global minima vary widely size. Due spaceconsiderations present data paper.Assuming could detect local minima, dicult local search escapeminima order explore new part search space? local search localminimum must temporarily move states higher level order find promisingpart search space. Two sources computational complexity contribute costescaping minima: cost detecting minimum, cost finding pathbetter part search space. size minimum measure detectioncost; chose minimum increase level measure diculty escaping localminima. understand idea, consider sequences neighboring statesminimum level increases, decreases. interested minimumincrease required level decreases again. determine generated 1000problem instances 50 variables 215 clauses each, generated initial state,ran GSAT 1000 ips. sucient reach local global minimum. 1 orderfind minimum level required escape, used Breadth-First Search. beginstates local minimum. explore state border, queuingstates explored increasing order level. ensures states lowerlevel explored first. encounter state lower level neighbor,found path local minimum; level state neighbor lowerlevel minimum level required escape local minimum. results indicatelocal minima usually escaped increasing level 1, is,unsatisfying one additional clause. However, obvious border state useescape; Breadth-First Search may expand tens thousands states findingescape route, may always effective escape strategy.summary, data presented Figures 6 9 shows local minima tendsmall much time, therefore may easily detectable escaped. Localminima typically escaped unsatisfying single additional clause,still clear escape local minima effectively. Further, size distribution globalminima behaves much like size distribution local minima. Instances tendmany global minima highly variable size, evidence local searchlikely encounter small sized local minima global minima large ones.3.3 Bench Characteristics1. local minima ranged level 1 6; measure level required escapebenches global minima.260fiWhen Gravity Fails: Local Search Topology80100 variables, 430 clauses70Number Benches60504030201000100020003000400050006000Size Benches70008000900010000Figure 10: Histogram Bench Sizes Level 1 Randomly Generated Problem Instances100 Variables, 430 ClausesRecall bench plateau exits states lower level. Twoimportant characteristics benches impact performance local searchsize benches number exits. first analyzed distribution sizebenches; Figure 10 shows distribution bench sizes level 1 problem instances100 variables 430 clauses. found long tails, implying benchessmall, large. distributions tend much atterminima.next analyzed median bench size varies number clausesproblem. appearance long tails distribution bench sizes indicatesmedian stable measure mean. Figure 11 shows mediansize benches varies number clauses problems different levels benches.interesting feature large median size benches comparedsize local minima. Benches typically 10-30 times large local minima,depending level number clauses problem instance. Problem instancesclauses tend smaller benches, under-constrainedinstances median bench size begins growing rapidly bench level even smallrange plateau levels analyzed here.also examined bench size depends problem size. small problems, i.e., 2550 variables, benches tended much larger problems variables.explanation clauses adequately distinguishassignments examine states low enough levels. Problems 100261fiFrank, Cheeseman, & Stutz7000Level 1 BenchesLevel 2 BenchesLevel 3 BenchesLevel 4 BenchesLevel 5 Benches6000Median Bench Size500040003000200010000380390400410420430Number Clauses440450460Figure 11: Median Size Benches vs. Problem Size 100 Variable Randomly GeneratedProblem Instancesvariables benches 10,000 states; exclude benchesanalysis. 2Large benches may dicult escape number exits small, exitsclustered together. benches exits, others many exits.used ratio exits benches bench size measure dicultyescaping benches. investigate whether exits benches closetogether, may also impact diculty escaping benches.Figure 12 shows distribution proportion exits bench size benches level1 problems 100 variables 430 clauses. distribution proportionsindicates plateaus highly variable numbers exits. note benchesfact contours; Figure 12 contours show benches whose ratio exits benchsize 1. observed six benches ratio exits bench size least0.95 Figure 12 fact contours. Figure 13 shows distribution proportionexits benches level 5; proportionally contours (65 78 benchesrightmost column histogram contours), mean ratio exits benchsize increased. difference two plots indicates benches lowerlevels tend fewer exits benches higher level, even exclude contoursmeasurements.understand escape benches different levels, next present plotsmean proportion number exits bench size graphed problem size2. Breadth-First Search stores enormous number states, terminated programbench size exceeded 10,000 states. Since large benches used median statistic,caused diculties analysis.262fiWhen Gravity Fails: Local Search Topology15100 Variables, 430 Clauses, Level 1 BenchesNumber Occurences105000.10.20.30.40.50.6Proportion Exits Bench Size0.70.80.91Figure 12: Exits Level 1 Benches Randomly Generated Problem Instances 100Variable, 430 Clauses80100 Variables, 430 Clauses, Level 5 Benches75706560Number Occurences555045403530252015105000.10.20.30.40.50.6Proportion Exits Bench Size0.70.80.91Figure 13: Exits Level 5 Benches Randomly Generated Problem Instances 100Variables, 430 Clauses263fiFrank, Cheeseman, & StutzFigure 14. taken consideration histograms Figure 12, hopecreate accurate picture benches tend look.see Figure 14 proportion exits benches increases levelbenches. problems 430 460 clauses mean number exits bencheslevel 1 increases sharply, indicating over-constrained solvable problems bencheslevel 1 less obstacle finding solutions. point inclusioncontours definition benches may artificially ate proportions,cases considerably.0.8Level 1 BenchesLevel 2 BenchesLevel 3 BenchesLevel 4 BenchesLevel 5 BenchesMean Proportion Exits Bench Size0.70.60.50.40.30.2380390400410420430Number Clauses440450460Figure 14: Mean Proportion Exits Benches vs Problem Size Randomly Generated Problem Instances 100 Variablesanalyzed benches determine whether relationshipnumber exits bench size, found relationship clausesizes benches levels investigated. lack relationship unfortunate, sincetells us little escape large benches.summary, data presented figures 10 14 shows benches occasionallylarge, often many exits benches. result, occasionallylocal search become trapped large bench little chanceescape. also found benches higher level exits bencheslower level. showed contours common benches level 5 may also occurlevel 1. Finally, found obvious relationship bench size numberexits. conclude local minima often problem local searchbenches since benches seem easy escape.264fiWhen Gravity Fails: Local Search Topology4. Plateau Characteristics Across Problem Classesprevious section analyzed plateaus satisfiable 3-SAT problem instancesone problem instance class. little reason suspect plateaus behave similarlyacross problem instance classes. may also differences satisfiableunsatisfiable instances class. recent years numerous algorithm designersbegun testing algorithms random problem classes pre-specified desirableproperties. Among problem instances guaranteed solutions (Tsuji &Gelder, 1993), problems structure hidden algorithm.class \cluster" problems presented Kask Dechter (1995); problemsconsist number satisfiability problems independent sets variablesnumber clauses connecting clusters. repeated experiments problemdistributions determine plateaus instances exhibit different propertiesUniform3-SAT class, might alter effectiveness local search. alsorepeated experiments unsatisfiable instances Uniform3-SAT distribution. Duespace considerations repeat full analysis performed above, discussdifferences characteristics classes investigated.4.1 Unsatisfiable Problems1Satisfiable ProblemsUnsatisfiable ProblemsProportion Plateaus Minima0.90.80.70.60.50.40.30.20.100123456Plateau Level78910Figure 15: Proportion Plateaus Local Minima Randomly Generated Satisfiable Unsatisfiable Problems 100 Variables, 430 Clausesmajor drawback local search inability distinguish satisfiable problem instances unsatisfiable problems. analyzed plateau structure unsatisfiableproblem instances Uniform3-SAT instance distribution determine whetherdifferences would allow local search determine problem instance unsatisfiable. repeated previous empirical studies collected data proportion265fiFrank, Cheeseman, & Stutzsize plateaus limited investigation problems 100 variables 430clauses. first present data proportion plateaus local minima unsatisfiable problem instances 100 variables 430 clauses. generated 1000 unsatisfiableinstances using problem generation technique used previous set experiments guaranteed problem instances unsatisfiable using complete searchalgorithm. used GSAT find states level 1-10, generated correspondingplateaus. contrast data data satisfiable problem instances 100variables 430 clauses Figure 15.Figure 15 shows proportion plateaus local minima similarsatisfiable unsatisfiable problems plateau level decreases, except plateauslevels 0 5 proportion shifted right ome level. possible interpretationresult comes noting frequently adding single randomly generated clauseturn random satisfiable instance unsatisfiable instance. Hence local searchmay become trapped higher level local minima unsatisfiable problemssatisfiable problems.7060Satisfiable ProblemsUnsatisfiable ProblemsMedian Minima Size50403020100012345Plateau LevelFigure 16: Median Size Local Minima Randomly Generated Satisfiable Unsatisfiable Problems 100 Variables, 430 ClausesNext analyzed median size local minima unsatisfiable problem instancesminima levels 1 5. analyzed data plateaus found generateFigure 15. Since number minima small minima levels 6-10, couldgather sucient data analysis reasonable amount time. However, Figure16 shows, local minima unsatisfiable problems tend much smaller local minima satisfiable problems. Figure 17 shows median size benches unsatisfiableproblem instances. found median bench size unsatisfiable instances tendedsmaller benches satisfiable problems. conjecture local search mayconverge local minima faster unsatisfiable problems minima tend266fiWhen Gravity Fails: Local Search Topologyhigher level; since minima benches smaller minima higherlevels, local search able descend faster average become stuck earlier.Unfortunately, differences slight enough seems little hope usingresults improve ability local search identify unsatisfiable problem instances.1000Satisfiable ProblemsUnsatisfiable ProblemsMedian Bench Size8006004002000123Plateau Level45Figure 17: Median Size Benches Randomly Generated Satisfiable UnsatisfiableProblems 100 Variables, 430 Clauses4.2 Instances Guaranteed Solutionsnext present data problems guaranteed solutions described (Tsuji &Gelder, 1993). generator HardSolvable3-SAT generator presented AppendixB. Brie y, generator selects assignment guaranteed solution,generation rejects clauses satisfied assignment set additional clauses enforce even distribution signs variable. before,generated 1000 problem instances, 100 variables 380-460 clauses.problem instance used GSAT find state 1-5 unsatisfied clauses, determinedwhether corresponding plateau bench local minimum. Figure 18 showsproportion plateaus minima graphed number clauses probleminstances 100 variables. proportion local minima problems similaridentical proportions local minima Uniform3-SAT class shownFigure 3. One difference local minima appear prevalent over-constrainedproblems HardSolvable3-SAT class Uniform3-SAT class. seconddifference data plateaus level 1. proportion minima rises slightly380 clauses 430 clauses, dips sharply; hence benches level 1Figure 18 Figure 3. detailed analysis reasons differences beyondscope paper, generation process seems eliminate clause combinations267fiFrank, Cheeseman, & Stutz10.9Proportion Plateaus Minima0.80.70.60.50.40.3Level 1 PlateausLevel 2 PlateausLevel 3 PlateausLevel 4 PlateausLevel 5 Plateaus0.20.10380390400410420430Number Clauses440450460Figure 18: Proportion Plateaus Local Minima vs. Number Clauses 100Variable Problem Instances Guaranteed Solutionsmake level 1 local minima expense making minima higher levels.higher percentages local minima over-constrained problem instances indicatelocal search may harder time solving problems.analyzed median size local minima different levels HardSolvable3SAT class found results similar reported Uniform3-SAT class Figure8. median minima size levels HardSolvable3-SAT class largerUniform3-SAT class under-constrained instances somewhat smallerover-constrained instances. also found bench size distributionHardSolvable3-SAT class matched Uniform3-SAT class. median bench sizesomewhat smaller HardSolvable3-SAT instances Uniform3-SAT instancesnumber clauses problem instances grows. also found problemsguaranteed solutions higher proportion exits bench sizerandomly generated problems. surprising problem classsimilar previously investigated class since problem generation algorithmssimilar.4.3 Cluster Problem Instancesnext present analysis plateaus cluster problem instances; generationprocedure Cluster3-SAT presented Appendix B. instances created generating 10 clusters 10 variables 34-40 clauses variables sharedclusters. clusters linked 20 connecting clauses linkingclause contains variables distinct clusters. total number clauses instances ranges 360 420. earlier experiments, guaranteed instance268fiWhen Gravity Fails: Local Search Topology10.9Proportion Plateaus Minima0.80.70.60.50.40.30.2Level 1 PlateausLevel 2 PlateausLevel 3 PlateausLevel 4 PlateausLevel 5 Plateaus0.10360370380390Number Clauses400410420Figure 19: Proportion Plateaus Local Minima vs. Number Clauses 100Variable Cluster Problem Instancessolution using complete search. number clauses clusters, generated 1000 instances used GSAT find plateaus different levels. foundinstances took considerably longer solve previous classes, similarresults reported Kask Dechter (1995) (CPU times shown paper).Figure 19 shows proportion plateaus local minima graphedtotal number clauses cluster problem instances 100 variables. proportionplateaus local minima less dependent number clauses comparisonFigures 3 18. result tend proportionally fewer local minima overconstrained cluster problem instances comparison Uniform3-SAT instances. Figure 20shows median local minima size plotted number clauses probleminstances. local minima problem instances larger minimaUniform3-SAT instances analyzed factor 5-10, seen Figure 8.unable collect data level 0 minima due excessive CPU requirements.Figure 21 shows median bench sizes plotted number clausesproblem instances. compared median bench size Uniform3-SAT instancesFigure 11, see median size benches cluster problems dramaticallydifferent. Cluster problem instances fewer clauses per cluster resulted enormousbenches, cases larger benches Uniform3-SAT instances factor 10.increase size benches cluster problem instances randomly generatedinstances accompanied decrease proportion exits bench size. Figure 22shows mean proportion exits bench size versus total number clauses clusterproblem instances. comparison measure Uniform3-SAT instances, shownFigure 14, see benches cluster problems fewer exits benchesUniform3-SAT instances bench sizes 1 5. increase bench size coupled269fiFrank, Cheeseman, & Stutz1500Level 1 MinimaLevel 2 MinimaLevel 3 MinimaLevel 4 MinimaLevel 5 Minima1250Median Minima Size10007505002500360370380390Number Clauses400410420Figure 20: Median Size Local Minima vs. Total Number Clauses 100 VariableCluster Problem Instances10000Level 1 BenchesLevel 2 BenchesLevel 3 BenchesLevel 4 BenchesLevel 5 Benches90008000Median Bench Size70006000500040003000200010000360370380390Number Clauses400410420Figure 21: Size Benches vs. Total Number Clauses 100 Variable Cluster ProblemInstances270fiWhen Gravity Fails: Local Search Topologydecrease exits means local search likely much harder timeescaping benches cluster problems problem classes. countersgood news fewer minima problems.0.8Level 1 BenchesLevel 2 BenchesLevel 3 BenchesLevel 4 BenchesLevel 5 BenchesMean Proportion Exits Bench Size0.70.60.50.40.30.2360370380390Number Clauses400410420Figure 22: Mean Proportion Exits Bench Size vs. Size Benches 100 VariableCluster Problem Instances4.4 Summarysummary, see behavior plateaus unsatisfiable Uniform3-SAT probleminstances differs behavior satisfiable instances class. Unsatisfiable instances proportionally local minima, smaller minima smaller benchessatisfiable instances. Problems HardSolvable3-SAT class minimaUniform3-SAT class, benches HardSolvable3-SAT class instances exits benches Uniform3-SAT instances. result expectproblems HardSolvable3-SAT class harder local search local searchalgorithms frequently trapped local minima. Cluster problem instancesfewer local minima Uniform3-SAT instances, tend larger benchesfewer exits. expect problems harder local searchtrouble escaping benches.5. Previous WorkNumerous researchers studied local search techniques NP -Hard problems, addressing plateau behavior local minima escape them. However, researchlargely centered analyzing performance algorithms less structureproblem. Hence, improvements algorithms credited mechanism without271fiFrank, Cheeseman, & Stutzclear understanding properties problem make mechanism work.section review previous analysis algorithms properties localsearch spaces light new discoveries. discussion focuses GSATsimilar local search algorithms 3-SAT problem, discuss potential impactwork local search algorithms next section.5.1 Analyzing Properties Problem SpacesClark et al. (1996) studied number solutions affected local search algorithm performance 3-SAT problems Constraint Satisfaction Problems. showednumber solutions number constraints play role determiningwell GSAT works. work complements study adding understandinglocal search affected problem instance structure. also add resultsshowing solutions tend occur disconnected subgraphs variable size.Hampson Kibler (1995) studied plateaus affect local search's ability solve3-SAT problem instances showed local search algorithm could modifiedperforming complete search plateau encountered. analyzed rationumber exits benches versus size benches randomly generated probleminstances NC =4.25. found benches higher levels easier escapeaverage, consistent findings. However, failed mention highvariance proportion exits benches, also failed report existence localminima. also report local search, augmented complete search plateaus,generally performed worse original local search. believe large plateaus,rare, contributed large CPU times reported paper.Gent Walsh (1993a) investigated GSAT solved problem instances aggregating statistics GSAT performance. collected information number satisfiedclauses function GSAT's ip number, number best ips function ipnumber, statistics averaged many runs problem instances. studyindicates GSAT satisfies average 99% clauses 2N ips instancesNC = 4:3. works 425 clauses instances 100 variables. evidence local minima hard-to-escape benches level 5 (i.e., 425 satisfiedclauses) consistent results. Gent Walsh also report numberips GSAT spends benches escaping highly variable second halfsearch, number satisfied clauses high (Gent & Walsh, 1993a).consistent finding benches either easy hard escape.5.2 Revisiting Local Search AlgorithmsGSAT encounters plateau randomly searches plateau. plateaubench, GSAT escape; however may take long time benchexits relative size, exits highly clustered one region bench.GSAT encounters local minimum never escape; even made moveminimum state higher level, GSAT simply move back minimum,every state minimum looks better every state leading away it.point GSAT escape local minimum size 1 forced makemove. However, either GSAT return immediately minimum another272fiWhen Gravity Fails: Local Search Topologyadjacent neighbor; found minima size 1 since GSAT doesn'texhibit cycling behavior minor consideration.HSAT (Gent & Walsh, 1993b) augments GSAT heuristic designed break ties.HSAT several ips equally good terms number satisfied clauses,ips variable ipped longest ago. HSAT explore benches effectivelyGSAT ensuring variables ipped \fairly"; long HSAT remainsbench ip variable keeps HSAT bench variablesipped. Therefore, HSAT's improved performance may due ability escapebenches faster GSAT. However, HSAT still unable escape local minima.Tabu search (Glover, 1989; Mazure, Sais, & Gregoire, 1997) augments local searchfixed length list previously made moves. algorithm allowed reverse movetabu list. Local search augmented tabu lists may escape local minima.memory structure either explicitly implicitly store states plateauforce local search make moves away part space. However, duenature tabu list, possible local search one variants ignoremove reduces objective function simply Tabu list.Tabu search frequently stores moves, states. result, different tabu searchimplementations allow moves states fewer unsatisfied clauses ever detecteddate, even required move tabu list, thus avoid problem.result tabu search missing exits benches; whether results poor performanceunknown.GSAT random walk (Gent & Walsh, 1995) ips randomly selected variableprobability p uses standard criteria select ips probability 1 , p. featureallow GSAT escape either local minima benches, guaranteenext move simply bring GSAT back minima escapedhappen multiple, equivalently good moves available. Gent Walsh (1993a)report that, number unsatisfied clauses small, number availablemoves leading reduction level GSAT tends 1. However, effectivenessrandom walk suggests random ip move GSAT placeproceed solution. Also, p large, two random walk steps followsuccession, improving chances escaping local minima. fact variantresults substantial improvements even used modifications GSATtie-breaking heuristics (Gent & Walsh, 1995) complements discovery Section 3local minima tend shallow; random walk may effectively promote escapelocal minima parts search space.WalkSAT (Kautz & Selman, 1996) examine possible neighbors moving. Instead, WalkSAT randomly selects unsatisfied clause investigates statesreachable ipping variables selected clause. result neighborhood examined changes ip ip, reverse move may next neighborhoodexamined. WalkSAT performs much search blind features uncovered.WalkSAT escape local minima simply choosing neighborhood containing movesback onto minima, may take series worse moves escape bench manyexits simply neighborhood contain them.Simulated annealing (Kirkpatrick, Gelatt, & Vecchi, 1983) examines single neighbor current assignment. Moves leading improvements objective function273fiFrank, Cheeseman, & Stutzalways accepted, moves worsen objective function accepted probabilistically; probability based much worse move long searchprogressed. Like WalkSAT, simulated annealing conducts much search blindplateau features. Simulated annealing make backwards move bench minimumeven neighboring state results forward move; help escape minimalarge benches, may sub-optimal strategy early search.6. Next Generation Local Search Algorithmsidentified analyzed number features local search topology mayuence success local search. results used improve local searchalgorithms? One contribution study identify features local search spaceworth investigating beginning construction local search algorithmsolve new problem. rapid exploration properties benches local minimaundertaken determine local search tactics likely work bestsearch problem class. instance, examination might reveal one problemlocal minima prevalent uniformly small, indicating explicit local minimadetection avoidance likely effective tactic. Also, possible use resultsFigure 3 determine adaptive schedule resetting probabilityrandom walk optimizing size tabu list, done Mazure et. al. (1997).also possible new classes local search algorithms could learn tactics work bestmanner similar MultiTac (Minton, 1996). study provides first step towardsidentifying features tracked self-modifying local search algorithms.local search algorithm starts exhibiting plateau behavior, may smallminima, large minima, bench many exits, bench exits. (We ignorecase small bench, since hard escape cases.) problemidentify case search process stuck in, choose proper tactichandle it. Standard tactics include continuing search normal, invoking specialdetection procedure, randomly ipping one variable random walk, randomly ippingsmall number variables Jump-SAT (Gent & Walsh, 1995) randomly generatingnew values variables randomly restarting.Small minima detected easily using algorithm Breadth-First Search,done Hampson Kibler (1995). local search algorithm detectedescaped local minima, desirable prevent revisiting minimaescaped. Local search could proceed \filling in" local minima foundorder prevent revisiting them. approximately tabu search works,schemes used well. small size local minima indicatesmemory requirements scheme small long small numbers minimaencountered. algorithm using mechanism could explore numerous localminima close together solution space without restarting.Large benches minima dicult recognize escape. questionbecomes one determining utility continuing search versus changing tactics.studies done provide algorithm designers information required implementutility computation local search algorithm intelligently choose amongtactics. instance, knowing problem instance cluster problem indicative274fiWhen Gravity Fails: Local Search Topologylarge benches exits likely inhibit local search local minima.Hence explicit local minima detection good strategy problem class; jumpingrandom restart might better strategy.point many enhancements like proposedplace local search algorithms solve 3-SAT problems, enhancementsapplied problem classes Graph k-Coloring. expect extensionssuccessful improving performance local search algorithms solve problems.One way approach new problems spend time gathering information topologysearch space, done paper. second option, mentionedabove, use knowledge local search topology learn best tacticssolving instances. Detailed information appearance local minima, distributionlocal minima size, bench size, prevalence exits benches usedconstruct good local search procedures explicitly take factors account.7. Conclusions Future Workpresented analysis important properties plateau structures local searchspaces used local search algorithm designers construct better local searchalgorithms. defined set topological structures local search spaces shownaffect local search. provided conclusive evidence existence localminima search spaces, shown become prevalent numberunsatisfied clauses becomes close 0. also shown plateau behavior localsearch caused local minima benches. results show local minimabenches vary widely size; often small, large local minimabenches may defy detection avoidance local search algorithms. also showcharacteristics structures change different problem classes. analysismade possible interpret previous work improving local search termssearch space structure, illuminating importance escaping benches early searchdetecting local minima later search.made suggestions previous section might used create newversions local search better current crop algorithms. obviousnext step implement algorithms analyze performance, especiallycomparison existing algorithms already attempt escape plateaus.barely begun analyzing topology plateaus. empiricalevidence local minima low level (i.e., near 0) escaped unsatisfyingone additional clause, may true structured problem classes.evidence benches may many exits always imply easy escape;highly clustered exits may make benches hard escape. analysis topologyplateaus variety problem instances lead concrete resultsuence local search algorithm development.clear nature plateaus highly dependent problem classtested. Extending form analysis problem classes might reveal differencesplateau structure motivate substantially different GSAT variants. Furthermore,plateaus Graph Coloring Problem Traveling Salesperson Problem may manifestdifferent ways 3-SAT, local search algorithms275fiFrank, Cheeseman, & Stutzproblems explore plateaus differently. differences must studied orderdetermine best apply new understanding local search topology. also unclearstudy extend problems Traveling Salesperson Problemsearch space may much \smoother."collected large amount data local search spaces,much success modeling features defined. possible computeprobability individual state search space local minima benchexits, dicult compute expected size bench minimum withoutmaking horrendous independence assumptions. work modeling may resultbetter understanding local search topology.mentioned Section 2, possible alter definition benches specificallyexclude contours type bench. rationale contours provide impedimentgreedy local search, little impediment semi-greedy variations. Onepossibility change definition plateau include states without neighborshigher lower level. several predictable effects change. First,know reported benches pure contour regions. would eliminatedconsideration reporting proportions plateaus benches. Second, sizebenches would exclude states, expect find smaller benchesexclusive bench definition. Third, measurements mean proportion statesbenches exits would also change, excluding contours reduces mean.Fourth, states provide potential means linking bench regions would disjointexclusive definition. Thus possible use exclusive definitioncause dramatic reduction average bench size, accompanied increase benchnumbers. might even eliminate large size tails bench size distributionsobserved using inclusive definition. would significantly alter conclusionsregarding benches impede local greedy search, recommendations regardingdeal benches. Exploring impact revised definitionsexplanation plateau behavior worth investigating.Finally, analysis topological structures geared towards analyzing local searchalgorithms greedy objective functions based number unsatisfied constraints.Many local search algorithm designers experimenting new objective functionsmodified continuously throughout search, clause weighting schemes (Selman &Kautz, 1993). Work type may lead innovations design objectivefunctions. Since plateau behavior rooted objective function used, analysissuitable analyzing methods, may provide insight conductsimilar study self-modifying algorithms type.Acknowledgementsgratefully acknowledge comments JAIR reviewers editors; also acknowledge comments Phil Rogaway Chip Martel, U.C. Davis.276fiWhen Gravity Fails: Local Search TopologyAppendix A. Sample Problemsection illustrates terms defined Section 2. Consider following 4variable, 14 clause 3-SAT problem instance:(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^(A _ B _ C )^ (A _ B _ C )^ (A _ B _ C )^(A _ B _ C )^ (A _ B _ D)^ (A _ B _ D)^(A _ C _ D)^ (A _ B _ D)^ (A _ B _ D)^(A _ C _ D)^ (A _ C _ D)duration section abbreviate assignments values variablesfollowing way: 0 False, 1 True, hence string 0s 1s length 4 encodesassignment variables ABCD order.problem instance global minimum comprised single solution 1111.single state 0000 local minimum size 1 level 1, i.e., one unsatisfied clause.border local minimum consists states 1000,0100,0010,0001; states 00011000 level 3 two states level 2.following states constitute bench level 1: 1001, 1101 1011. 1101 exitsince ipping C results 1111, solution. Similarly, 1011 also exit since ipping Bresults solution. neighbors 1001 bench 0001 1000;level three, 1001 exit.State CommentLevel Unsatisfied Clauses1111 Solution00000 Local Minimum1(A _ B _ C )0010 Border Minimum 2(A _ B _ C ); (A _ C _ D)0100 Border Minimum 2(A _ B _ C ); (A _ B _ D)0001 Border Minimum 3(A _ B _ C ); (A _ B _ D); (A _ C _ D)1000 Border Minimum 2(A _ B _ C ); (A _ B _ D)1001 Bench1(A _ B _ C )1011 Bench1(A _ B _ C )1101 Bench1(A _ B _ C )1111 Border Bench00001 Border Bench3(A _ B _ C ); (A _ B _ D); (A _ C _ D)1000 Border Bench2(A _ B _ C ); (A _ B _ D)0010 Contour2(A _ B _ C ); (A _ C _ D)1010 Contour2(A _ B _ D); (A _ B _ C )0011 Contour2(A _ B _ C ); (A _ B _ D)0000 Border Contour 1(A _ B _ C )1110 Border Contour 1(A _ B _ D)0111 Border Contour 1(A _ B _ C )Figure 23: Topological Structures Sample Problem Instancestates 0010, 1010 0011 form level 2 bench also contour. 0010neighbor local minimum level 1, 1010 adjacent 1110 level 1,0011 adjacent 0111 level 1.277fiFrank, Cheeseman, & Stutzstates 1000 1100 form bench level 3 contour. states0110, 0001 also contours level 3 themselves. Since states unsatisfyingthree clauses contours fact local maxima.features summarized Figure 23.Appendix B. Random Problem Generationappendix contains pseudo-code random problem classes studied paper.First present Uniform3-SAT class. Parameters generator C numberclauses N number variables. class procedure selects three literalswithout replacement N assigns negative sign probability 21 .procedure first presented Crawford Auton (1993) appears Figure 24.procedure Uniform3-SAT(C ,N )=;(i=1 C )Clause= 3 distinct variables selected uniformly 1..NNegate variable Clause probability 12= [ ClauseendreturnendFigure 24: Random Problem Generation Algorithm SketchNext present Cluster3-SAT problem generator. parameters numberclauses C , number variables N per cluster, number clusters , numberlinking clauses L. generator builds instances first creating independent subproblems C clauses N variables each, using Uniform3-SAT generation proceduredescribed above. variables sub-problems relabeled sub-problemshares variables sub-problem; sub-problems linked generatingL linking clauses. linking clause contains variables three distinct sub-problems.Kask Dechter generate problems using HardSolvable3-SAT procedure defineddescribed Kask Dechter (1995). procedure appears Figure 25.Finally present HardSolvable3-SAT generator. parameters numberclauses C number variables N . Instances generated first selectingassignment guaranteed solution. Clauses generated Uniform3-SAT,however clause either zero two satisfied literals selected assignmentrejected. instance, clause (A _ B _ C ) would rejected assignment 110since two satisfied literals assignment. preserves uniform balancesigns variable limit, resulting little information solutionpresent sign balances problem instance. method discussed TsujiVan Gelder (1993) algorithm given Figure 26.278fiWhen Gravity Fails: Local Search Topologyprocedure Cluster3-SAT(C ,N ,M ,L)# First generate sub-problems distinct variablesi=1,i =Uniform3-SAT(,,C ,N )Re-label literals ,i sub-problem shares variables= [Mi=1 ,iend# Next generate linking clauses= 1 LRandomly select 3 distinct sub-problems ,a ; ,b ; ,c ,iClause= one variable randomly selected ,a ; ,b ; ,cNegate variable Clause probability 21= [ ClauseendreturnendFigure 25: Cluster Problem Generation Algorithm Sketchprocedure HardSolvable3-SAT(C ,N )=;= randomly generated assignment variables(i < C )Clause= 3 distinct variables selected uniformly 1..NNegate variable Clause probability 21# Check make sure Clause allowed formula(1 3 literals Clause true )= [ Clausei++endendreturnendFigure 26: \Hard" Guaranteed Satisfiable Problem Generation Algorithm Sketch279fiFrank, Cheeseman, & Stutzfinal note random problem instance generation order. None proceduresguarantees resulting problem instance contain variables. largenumber variables small number clauses used parameters, resultingproblem may contain variables. However, ranges clauses variables usedwork problem instances full range variables.ReferencesCheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.12th International Joint Conference Artificial Intelligence, 163{169.Clark, D., Frank, J., Gent, I., MacIntyre, E., Tomov, N., & Walsh, T. (1996). Localsearch number solutions. Proceedings 2d International ConferencePrinciples Practices Constraint Programming, 119{133.Crawford, J., & Auton, L. (1993). Experimental results crossover point satisfiability problems. Proceedings 11th National Conference Artificial Intelligence,21{27.Gent, I., & Walsh, T. (1993a). empirical analysis search GSAT. Journal ArtificialIntelligence Research, 1, 47{59.Gent, I., & Walsh, T. (1993b). Towards understanding hill-climbing proceduresSAT. Proceedings 11th National Conference Artificial Intelligence, 28{33.Gent, I., & Walsh, T. (1995). Unsatisfied variables local search. Hallam, J. (Ed.),Hybrid Problems, Hybrid Solutions, pp. 73{85. IOS Press.Glover, F. (1989). Tabu search part I. ORSA Journal Computing, 1 (3), 190{206.Hampson, D., & Kibler, S. (1995). Large plateaus plateau search boolean satisfiability problems: give searching start again. Johnson, D., & Trick,M. (Eds.), DIMACS Series Discrete Mathematics Theoretical Computer Science: Cliques, Colors Satisfiability, Vol. 26, pp. 437{456. American MathematicalSociety.Kask, K., & Dechter, R. (1995). GSAT local consistency. Proceedings 14thInternational Conference Artificial Intelligence, 616{622.Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logicstochastic search. Proceedings 13th National Conference Artificial Intelligence, 1194{1201.Kirkpatrick, S., Gelatt, C., & Vecchi, M. (1983). Optimization simulated annealing.Science, 220 (4598), 671{680.Mazure, B., Sais, L., & Gregoire, E. (1997). Tabu search GSAT. Proceedings 14thNational Conference Artificial Intelligence, 281{286.280fiWhen Gravity Fails: Local Search TopologyMinton, S. (1996). Automatically configuring constraint satisfaction programs: casestudy. Constraints, 1 (2), 7{43.Selman, B., & Kautz, H. (1993). Domain independent versions GSAT: Solving largestructured satisfiability problems. 13th International Joint Conference ArtificialIntelligence, 290{295.Selman, B., Levesque, H., & Mitchell, D. (1992). new method solving hard satisfiabilityproblems. Proceedings 11th National Conference Artificial Intelligence, 440{446.Tsuji, Y., & Gelder, A. V. (1993). Incomplete thoughts incomplete satisfiabilityprocedures. Proceedings 2d DIMACS Challenge.281fiJournal Artificial Intelligence Research 7 (1997) 161-198Submitted 5/97; published 11/97Storing Indexing Plan DerivationsExplanation-based Analysis Retrieval FailuresLaurie H. IhrigSubbarao KambhampatiDepartment Computer Science EngineeringArizona State UniversityTempe, AZ 85287-5406ihrig@asu.edurao@asu.eduAbstractCase-Based Planning (CBP) provides way scaling domain-independent planningsolve large problems complex domains. replaces detailed lengthy searchsolution retrieval adaptation previous planning experiences. general, CBP demonstrated improve performance generative (from-scratch)planning. However, performance improvements provides dependent adequatejudgements problem similarity. particular, although CBP may substantially reduce planning effort overall, subject mis-retrieval problem. success CBPdepends retrieval errors relatively rare. paper describes designimplementation replay framework case-based planner dersnlp+ebl. dersnlp+ebl extends current CBP methodology incorporating explanation-based learningtechniques allow explain learn retrieval failures encounters.techniques used refine judgements case similarity response feedbackwrong decision made. failure analysis used building caselibrary, addition repairing cases. Large problems split storedsingle goal subproblems. Multi-goal problems stored smaller cases failmerged full solution. empirical evaluation approach demonstratesadvantage learning experienced retrieval failure.1. IntroductionCase-Based Planning improves eciency plan generation taking advantage previous problem-solving experiences. shown effective method scalingdomain-independent planning solve large problems complex domains (Kambhampati & Hendler, 1992; Veloso, 1994). CBP involves storing information particularplanning episodes problems successfully solved. information may includegoals achieved, world state conditions found relevantachievement, final plan decisions taken arrivingplan. Whenever new problem encountered, judgment made similarityprevious experiences. Similar cases reused extended searchsolution new problem. example, previous plan may transformedskeletal plan refined new solution (Friedland & Iwasaki, 1985;Kambhampati & Hendler, 1992; Hanks & Weld, 1995). Multiple cases, correspondingsmall subproblem, may combined extended solving single larger problem(Redmond, 1990; Ram & Francis, 1996). Alternatively, plan derivations may replayedc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiIhrig & Kambhampatiprovide guidance new search process (Veloso, 1994; Ihrig & Kambhampati, 1994a).CBP improves problem-solving problems solved less time comparisongenerative planning.One challenging tasks CBP determining cases storematch cases new problem-solving context. complex domain, unlikelyproblem seen once. Moreover, every problem solvedstored, library large cost associated retrieval may overshadowgains provides (Koehler, 1994; Francis & Ram, 1995). Ultimately, wouldlike retain library minimum number cases new problemssolved ecient retrieval adaptation cases stored (Smyth &Keane, 1995). However, complex domains, planner's theory problem similarityincomplete (Barletta & Mark, 1988). information relevantfeatures new situation determine stored case applicable. Sometimesnew problem contain extra goals and/or changed initial state conditions.changes may mean solution cannot found consistent earlierplanning decisions made stored episode. planner cannot predict ahead timeprevious choices wrong current situation, experience retrievalerror.paper, introduce dersnlp+ebl (DERivational Systematic NonLinear Planner+ Explanation-Based Learning), CBP system like priar (Kambhampati & Hendler,1992) spa (Hanks & Weld, 1995) based sound complete domain-independentplanner. dersnlp+ebl deals mis-retrieval problem allowing plannerlearn planning failures may anticipate future errors. Failure explanationsautomatically generated search process used extending casenew problem-solving situation. used building case libraryaddition repairing cases.Although earlier systems chef (Hammond, 1990) exploited EBL techniques, use restricted reasoning correctness plans generatedcase-based planner. contrast, dersnlp+ebl starts sound complete plansynthesis strategy. emphasis improving performance base-levelplanner guidance retrieved cases. guidance considered succeedleads planner search path leading solution new problem.retrieval error occurs planner directed wrong path searchsolution, is, path lead solution. dersnlp+ebl extends currentCBP methodology EBL techniques employed automatic generation reasons retrieval failure. Analytical failures occur leaf nodessearch tree explained terms subsets con icting plan constraints. leafnode failure explanations regressed failing search paths form reasonretrieval failure.dersnlp+ebl builds indexes case library based failure analysis.failure reason used construction new repairing case. example, retrievedcase fails due presence extra interacting goal covered retrievedepisodes, explanation failure formed identifies subset new inputgoals negatively interacting. failure reason used construct new casesolves goals alone. failure analysis also employed refining162fiStoring Indexing Plan DerivationsRetrieverLibraryCases ProblemPlanningProblemStorerPlan DerivationCase Failure ReasonCase-Based PlannerReplay/Extension[Recovery]ProblemSolutionDomain OperatorsFigure 1: schematic diagram illustrating approach dersnlp+ebl.indexing case library censor retrieval failing case wheneverinteracting goals present again, direct retriever new repairing caseavoids failure.dersnlp+ebl's failure-based storage strategy limits size case library. Librarysize reduced splitting problems single goal subproblems, storing separately. Large problems solved retrieval adaptation multipleinstances smaller cases. Multi-goal problems stored retrievedcases fail merged extended full solution. describe empirical studiesdemonstrate substantial improvements performance novel approachmulti-case adaptation.remainder paper organized follows: Section 2 describes dersnlp+ebl learns case failure improve case retrieval. also reportspreliminary experiments testing learning component. Section 3 provides ecient techniques used store, retrieve adapt multiple cases. describes experiments testdersnlp+ebl's method plan merging. Section 4 describes evaluation full dersnlp+ebl system solving large problems drawn complex domain. Section 5relates work previous case-based planners, including chef prodigy/analogy.Section 6 provides summary.2. Learning Case Failurestated earlier, dersnlp+ebl based complete correct domain-independentplanning strategy. Like priar (Kambhampati & Hendler, 1992) spa (Hanks & Weld,1995), implemented partial-order planner. aspect differs statespace systems prodigy/analogy (Veloso & Carbonell, 1993a; Veloso, 1994)paris (Bergmann & Wilke, 1995). Like prodigy/analogy, employs case adaptationstrategy, derivational replay stores planning experience form successful planderivations. Previous decisions made earlier planning episodes become instructionsguide search process solving new problem. Derivational replay includesfollowing elements, illustrated Figure 1 (Veloso, 1994; Veloso & Carbonell, 1993a):facility within underlying planner generate trace derivation plan,163fiIhrig & Kambhampatinullplanskeletalplane1finalplanXe2 X e3 X- - - - - - - - - - - - - - - - - - - -depth limitXFigure 2: Multiple derivation traces (each sequence decisions shown figurerectangles) used guide new search process. figure, solutioncould reached backtracking skeletal plan, liesoutside new plan derivation (shown filled circles).indexing storage derivation trace library previous cases, retrievalmultiple cases preparation solving new problem, finally, replay mechanismplanner employs retrieved plan derivations sequence instructionsguide new search process.dersnlp+ebl's methodology depends aspects common molgen(Friedland & Iwasaki, 1985) priar (Kambhampati & Hendler, 1992). requireseager case adaptation strategy, skeletal plan constructed containsconstraints added advice retrieved cases, constraints.separate failure resulting previous guidance subsequentplanning effort. eager case adaptation, planning decisions encapsulatedretrieved cases greedily adopted decisions extended solveextra goals covered. Multiple retrieved plan derivations replayed sequenceproduce skeletal plan contains recommended plan constraints.planner returns from-scratch planning previous decisionsretrieved cases visited. skeletal plan refined achievegoals left open. Previous work demonstrated effectiveness approachplan-space replay well advantage state-space replay (Ihrig & Kambhampati,1994a, 1994b).Eager case adaptation also described extension-first. skeletal planfirst extended search solution, and, extension fails, planbacktracked over, discarding plan constraints added advice previousepisodes. general approach case adaptation therefore involves three distinct phases:case replay, case extension, and, extension fails, recovery. search processemployed extending skeletal plan, planner constructs explanationplan's failure becomes reason case retrieval failure. Explanations formedanalytical failures occur leaf nodes directly skeletal plan (SeeFigure 2). analytical failure explained set inconsistent plan constraints.failure explanations immediately regressed search paths encountered.regressed explanations collected root tree form reason164fiStoring Indexing Plan Derivationsl1l1OB1ldldlplpl2OB2l2(b) New Problem ExtraGoal(a) Previous PlanFigure 3: (a) plan accomplish transport single package, ob1, destinationairport ld . (b) new problem contains extra goal involves additionaltransport ld second package, ob2.retrieval error. dersnlp+ebl detects retrieval error occurred waysrefining skeletal plan tried, planner forced backtrackplan. point failure reason fully constructed. Performing skeletal planextension separate process prior recovery allows planner identify retrievalerror terms failure skeletal plan, construct reason failure.reason communicated Storer used augmenting librarynew repairing case.Consider simple example illustrated Figure 3 taken LogisticsTransportation domain shown Figure 4. goal package ob1 locateddestination location ld. package initially location l1 . plane locatedlp used transport package. Figure 3a illustrates previous plancontains steps determine plane's route destination airport well stepsaccomplish loading package right place along route. Eagerlyreplaying earlier step addition decisions new problem extrapackage transport produces skeletal plan may readily extended includeloading unloading extra package long package lies alongroute. However, new package old route, planner may ablesolve extra goal without backtracking previous step addition decisions.(See Figure 3b).case failure reason shown Figure 5. gives conditions futurereplay case result failure. conditions refer presencenew problem set, C , negatively interacting goals, well initial stateconditions, contained E . summary information content failure reason is:extra package transport destination location, packagedestination location, inside plane, located plane'sroute.165fiIhrig & Kambhampatiactionprecondadddelete(LOAD-TRUCK ?O ?T ?L)(AT-OB ?O ?L)(AT-TR ?T ?L)(INSIDE-TR ?O ?T)(AT-OB ?O ?L)actionprecondadddelete(LOAD-PLANE ?O ?P ?L)(AT-OB ?O ?L)(AT-PL ?P ?L)(INSIDE-PL ?O ?P)(AT-OB ?O ?L)actionprecondadddelete(UNLOAD-TRUCK ?O ?T ?L)(INSIDE-TR ?O ?T)(AT-TR ?T ?L)(AT-OB ?O ?L)(INSIDE-TR ?O ?T)actionprecondadddelete(UNLOAD-PLANE ?O ?P ?Li)(INSIDE-PL ?O ?A)(AT-PL ?P ?Li)(AT-OB ?O ?Li)(INSIDE-PL ?O ?A)actionprecondadddeleteequals(DRIVE-TRUCK ?T ?Li ?Lg)(AT-TR ?T ?Li)(SAME-CITY ?Li ?Lg)(AT-TR ?T ?Lg)(AT-TR ?T ?Li)(NOT (?Li ?Lg))actionprecondadddeleteequals(FLY-PLANE ?P ?Li ?Lg)(IS-A AIRPORT ?Lg)(AT-PL ?P ?Li))(AT-PL ?P ?Lg)(AT-PL ?P ?Li)(NOT (?Li ?Lg))Figure 4: specification Logistics Transportation Domain adapted experimentsSubsequent backtracking skeletal plan, planner continues search,go find solution full problem one exists. new solution achievesnegatively interacting goals identified failure reason. Moreover, sincegoals represent subset problem goals, new derivation may used constructcase covering goals alone. dersnlp+ebl stores new case directly beneathfailing case censor retrieval. ensure whenever failure reasonholds (for example, whenever extra package plane's route),retriever directed away failing case toward case repairs failure.position describe detail dersnlp+ebl's eager derivationreplay strategy, well learns reasons underlying case failure.2.1 Eager Derivation Replayderivation trace contains sequence instructions representing choices liealong derivation path leading root search tree final plan leafnode. trace fitted context new search process validating choicenew context, replaying decision valid. order understand validationprocess, must first describe decision steps planner takes arrivingsolution planning problem. planning problem 3-tuple hI; G; Ai,complete description initial state, G description goal state,set operators strips representation (Fikes & Nilsson, 1971). ground operatorsequence said solution planning problem executed initialstate, resulting state world satisfies goal.dersnlp+ebl refinement planner solves planning problem navigatingspace potential solutions, represented partly constructed plan1 . Syntactically,1. formal development refinement search semantics partial plans, refer readerwork Kambhampati, Knoblock, Yang (1995).166fiStoring Indexing Plan DerivationsCase Failure Explanation:C = f h(AT-OB OB1 ld); tG i; h(AT-OB OB2 ld); tG gE = f htI ; (:AT-OB OB2 ld)i; htI ; (:INSIDE-PL OB2 ?PL )i;htI ; (:AT-OB OB2 l1)i; htI ; (:AT-OB OB2 lp)i gFigure 5: Example case failure reasonplan space P seen set constraints (see below). Semantically, partialplan shorthand notation set ground operator sequences consistentconstraints. latter called candidate set partial plan, denotedhhPii. particular, partial plan represented 6-tuple, hS ; O; B; L; E ; Ci,1. set actions (step names) plan, mapped ontooperator domain theory. contains two dummy steps: tI whose effectsinitial state conditions, tG whose preconditions input goals, G.2. B set codesignation (binding) non-codesignation (prohibited binding) constraints variables appearing preconditions post-conditionsoperators represented plan steps, .3. partial ordering relation , representing ordering constraintssteps .4. L set causal links form hs; p; s0 s; s0 2 .5. E contains step effects, represented hs; ei, 2 .6. C set open conditions partial plan, tuple hp; sip precondition step link supporting p L.Planning consists starting null plan (denoted P;) , whose candidate setcorresponds possible ground operator sequences, successively refining planadding constraints solution reached. planning decision represents choiceresolve existing aw plan, either open condition (unachievedgoal) threat causal link. understand choices validatedreplay process useful think planning decision operator actingpartly-constructed plan. possible choices available dersnlp+ebl shownFigure 6.Planning decisions preconditions based existence awcurrent active plan effects alter constraints eliminateaw. example, precondition establishment choice specified termsexistence unachieved subgoal. effect addition causal link achievesopen condition. precondition resolution decision threat one stepclobbering existing causal link. threat resolved adding step orderingeither promotes demotes clobberer relative causal link.167fiIhrig & KambhampatiType : ESTABLISHMENTKind : NEW STEPPreconditions:hp0 ; s0 2 CEffects:00 = [ fsg 0O0 = [ fs g 0B 0 = B [ unify(p;0 p )L = L [ fhs; p;s igE 0= E [ effects(s)C = C , fhp0 ; s0 ig[ preconditions(s)Type : ESTABLISHMENTKind : NEW LINKPreconditions:hp0 ; s0 2 CEffects:O00 = [ fs s0 g 0B 0 = B [ unify(p;0 p )L0 = L [ fhs;p;igC = C , fhp0 ; s0 igType : RESOLUTIONKind : PROMOTIONPreconditions:00hs; p ; 2 Lht; :p 2 Eft sg; fs tg 62Effects := [ ft sg000Type : RESOLUTIONKind : DEMOTIONPreconditions:00hs; p ; 2 Lht; :p 2 Eft sg; fs tg 62Effects := [ fs tg0000Figure 6: Planning decisions based active plan hS ; O; B; L; E ; Ci effects alter constraints produce new current active planhS 0 ; O0 ; B0 ; L0 ; E 0 ; C 0 i.decision replayed, first compared current active plan determine whether precondition holds new context. Invalid decisions, whosepreconditions don't match, skipped. Establishment decisions ignored goalsachieve present open conditions current active plan. Threat resolutions skipped threat present. Previous choices justifiedcurrent situation used guidance direct new search process. Replaying validdecision involves selecting match decision children current activeplan, making child next plan refinement.dersnlp+ebl's eager derivation replay strategy replays applicable decisionstrace sequence. replay strategy contrastedprodigy/analogy (Veloso, 1994) replay alternated from-scratch planningextra goals covered case. eager derivation replay previous decisioneagerly adopted justified current context. Since invalid instructionsskipped, skeletal plan end result replay comparable productfitting phase plan reuse (Kambhampati & Hendler, 1992; Hanks & Weld, 1995).contrast plan reuse, derivation replay alter underlying planning strategy.Replay merely provides search control, directing search node visit next.means dersnlp+ebl inherits properties snlp, including soundness,completeness, systematicity.sample trace snlp's decision process shown Figure 7. trace correspondssimple problem logistics transportation domain (Veloso, 1994) adaptedsnlp Figure 4. problem contains goal getting single package, ob1,designated airport, ld . derivation trace contains choices made alongpath root search tree final plan leaf node. Instructions containdescription decision taken basis justification new context.2.2 Eager Case Extension Recoverydecisions trace skipped replay knownpriori unjustified. guarantee skeletal plan left168fiStoring Indexing Plan DerivationsGoal : (AT-OB OB1 ld )Initial : ((IS-A AIRPORT ld ) (IS-A AIRPORT li ))(IS-A AIRPORT lp ) (AT-PL PL1 lp )(AT-OB OB1 li ) ...Name : G1Name : G7Type : START-NODEType : ESTABLISHMENTName : G2Kind : NEW LINKType : ESTABLISHMENTNew Link: (0 (IS-A AIRPORT ld ) 2)Kind : NEW STEPOpen Cond: ((IS-A AIRPORT ld ) 2)New Step: (UNLOAD-PL OB1 ?P1 ld )Name : G8New Link: (1 (AT-OB OB1 ld ) GOAL)Type : ESTABLISHMENTOpen Cond: ((AT-OB OB1 ld ) GOAL)Kind : NEW STEPName : G3New Step: (LOAD-PL OB1 PL1 ?A4)Type : ESTABLISHMENTNew Link: (4 (INSIDE-PL OB1 PL1) 1)Kind : NEW STEPOpen Cond: ((INSIDE-PL OB1 PL1) 1)New Step: (FLY-PL ?P1 ?A2 ld )Name : G9New Link: (2 (AT-PL ?P1 ld ) 1)Type : ESTABLISHMENTOpen Cond: ((AT-PL ?P1 ld ) 1)Kind : NEW LINKName : G4New Link: (3 (AT-PL PL1 li ) 4)Type : ESTABLISHMENTOpen Cond: ((AT-PL PL1 ?A4) 4)Kind : NEW STEPName : G10New Step: (FLY-PL ?P1 ?A3 ?A2)Type : RESOLUTIONNew Link: (3 (AT-PL ?P1 ?A2) 2)Kind : PROMOTIONOpen Cond: ((AT-PL ?P1 ?A2) 2)Unsafe-link : ((3 (AT-PL PL1 li ) 4)Name : G5Effect : 2 :(AT-PL PL1 li ))Type : ESTABLISHMENTName : G11Kind : NEW LINKType : ESTABLISHMENTNew Link: (0 (AT-PL PL1 lp ) 3)Kind : NEW LINKOpen Cond: ((AT-PL ?P1 ?A3) 3)New Link: (0 (AT-OB OB1 li ) 4)Name : G6Open Cond: ((AT-OB OB1 li ) 4)Type : ESTABLISHMENTKey Abbreviations:Kind : NEW LINKPL = PLANENew Link: (0 (IS-A AIRPORT li ) 3)OB = OBJECTOpen Cond: ((IS-A AIRPORT ?A2) 3)Final Plan: (FLY-PL PL1 lp li ) Created 3(LOAD-PL OB1 PL1 li ) Created 4(FLY-PL PL1 li ld ) Created 2(UNLOAD-PL OB1 PL1 ld ) Created 1Ordering Steps: ((4 < 2) (3 < 4) (4 < 1) (3 < 2) (2 < 1))Figure 7: Example solution trace dersnlp+ebl169fiIhrig & Kambhampati2 DmS 1 :(Affi precond : fIi; Pff g add : fgig delete : fIj jj < ig)(Afii precond : fIi Pfi g add : fgig delete : fIj jj < ig)(Aff precond : fg add : fgff g delete : fPfi g [ fgij8ig)Figure 8: specification Barrett Weld's Transformed Dm 1Domainultimately refined solution current problem. Without actually completingsearch way predicting whether constraints left skeletalplan consistent complete solution. Whenever skeletal plan complete(whenever extra goals unsatisfied initial state conditions) planner mustundergo planning effort extend plan possibility effortmay fail, necessitating recovery phase.dersnlp+ebl, skeletal plan extended first, prior recovery. planbacktracked search process fails refine full solution newproblem. strategy requires depth limit placed search tree2 . Otherwiseskeletal plan extension may continue indefinitely, planning algorithm becomes incomplete. eager extension strategy not, however, linked particular search method.example, may used best-first, depth-first iterative deepening search.different search methods used exploration subtree skeletal plan,prior backtracking plan. skeletal plan found fail, recoveryphase initiated merely involves exploring siblings replayed path. Likeextension, recovery linked particular search strategy.2.3 Analyzing Failure Case Extensionorder skeletal plan successfully extended achieve conditions left open,sequence decisions adopted guidance previous trace mustconcatenated choices arrive solution. occur, replayedpath must decision-sequencable respect new problem, definedfollows:Definition 1 (Decision-Sequencable Search Path) search path contains sequence decisions decision-sequencable respect new problem, hI 0 ; G0 ; Ai ,exist two decision sequences E E 0 E E 0 (where \"decision sequencing operator) produce plan correct hI 0 ; G0 ; Ai.One primary reasons replayed path may decision sequencable goalinteractions occur input goals new problem. particular, extragoals achieved case may interact covered, making retrievedcase inapplicable. long recognized relative diculty problem-solvinglinked level interaction various input goals problem (Korf,1987; Joslin & Roach, 1990; Barrett & Weld, 1994; Veloso & Blythe, 1994; Kambhampati,2. practice, limit actually bound placed number steps contained plan.170fiStoring Indexing Plan DerivationsIhrig, & Srivastava, 1996a). Goal interaction formalized Korf (1987) termsproblem search space. Barrett Weld (1994) extend Korf's analysis planspace. plan-space planner, order goals achieved crucial.Goals laboriously serializable state-space planner (in exist goalorderings goals may solved sequence) may trivially serializableplan-space planner (meaning goals solved order).However, goals always trivially serializable plan-space planner (Veloso &Blythe, 1994). example, consider 2Dm 1 domain (Barrett & Weld, 1994) shownFigure 8. Notice gff one set problem goals, true initially,goal, gi , present set must achieved operator Affi,Afii . means time case replayed previously solved goal, gi ,action Afii , gff extra goal covered case, replay fail.CBP, however, much concerned general propertiesdomain, properties particular search paths storedcase library. required input goals every problem trivially serializableCBP beneficial planning performance. were, woulddomains CBP effective. Trivial serializability requirement sincenecessary every plan every subset input goals consistentsolution full problem. particular plans retrievedlibrary concerned with.Even goals problem trivially serializable, replay may decisionsequencable, depending cases actually retrieved library.2 Dm 1 domain, single-goal cases retrieved solve gi action Afii ,decision-sequencable new multi-goal problem containsgoal gff . However stored cases solved Affi , replay casessequencable. fact, aim dersnlp+ebl's learning component achieveindexing within case library new problems encounteredplanner may solved sequenced replay cases retrieved library.next section describes dersnlp+ebl able work towards objectivelearning component learns replay failures.2.4 Constructing Reasons Retrieval Failuredersnlp+ebl constructs explanations retrieval failures use explanationbased learning techniques allow planner explain failures individual plansplanner's search space. leaf node plan represents analytical failurecontains set inconsistent constraints prevent plan refinedsolution. analytical failure explained terms constraints (Kambhampati, Katukam, & Qu, 1996b). Leaf node failure explanations identify minimal setconstraints plan together inconsistent. dersnlp+ebl forms explanationsanalytical failures occur subtree directly skeletal plan.regressed failing search paths collected root treeform reason retrieval failure (See Figure 9a). regressed explanation termsnew problem specification. contains subset interacting goals, well initialstate conditions relevant goals.171fiIhrig & Kambhampatinullplane11< (AT-OB OB2 ld), tG ><tI , (AT-OB OB2 ld ) >e1f-1df-1e1fdfe1nullplan< (AT-OB OB2 ld), tG ><tI , (AT-OB OB2 ld) >skeletalplandf-1dfskeletalplanXXe2Xe3X< tI , (AT-OB OB2 ld ), tG >< tI , (AT-OB OB2 ld) >(a) Regression Process(b) Detailed ExampleFigure 9: path failure explanation root tree computed e11 = d,1 1 (d,2 1(d,f 1(e1 )) ).Since plan failure explained subset constraints, failure explanationsrepresented manner plan itself. Recall dersnlp+ebl representsplans 6-tuple, hS ; O; B; L; E ; Ci (See Section 2). explanation failureoccurring leaf node contains constraints contribute inconsistency.inconsistencies appear new constraints added con ict existingconstraints. discussed Section 2, dersnlp+ebl makes two types decisions, establishment resolution. type decision may result plan failure. establishmentdecision represents choice method achieving open condition, eithernew/existing step, adding causal link initial state. attemptmade achieve condition linking initial state effect, conditionsatisfied initial state, plan contains contradiction. explanationfailure constructed identifies two con icting constraints:h;; ;; ;; fhtI ; p; sig; fhtI ; :pig; ;iprecondition resolution decision threat causal link. dersnlp+ebluses two methods resolving threat, promotion demotion, adds stepordering plan. either decision adds ordering con icts existingordering, explanation failure identifies con ict:h;; fs s0 ; s0 sg; ;; ;; ;; ;icon icting constraints failure explanation regressed finaldecision, results sorted according type form new regressed explanation.process illustrated graphically Figure 9b. example, new linkinitial state results failure. explanation, e1 is:h;; ;; ;; fhtI ; (AT,OB OB 2 ld ); tG ig; fhtI ; :(AT,OB OB 2 ld)ig; ;i172fiStoring Indexing Plan Derivationse1 regressed final decision, df , obtain new explanation, initialstate effect regresses itself. However, since link explanation addeddecision, df , link regresses open condition precondition addinglink. new explanation, ef1 , thereforeh;; ;; ;; ;; fhtI ; :(AT,OB OB 2 ld)ig; fh(AT,OB OB 2 ld ); tG igiregression process continues failing path reaches root searchtree. paths subtree underneath skeletal plan failed,failure reason root tree provides reason failure retrievedcases. represents combined explanation path failures. case failurereason contains aspects new problem responsible failure.may contain subset problem goals. Also, initial state effectspresent leaf node explanation, also present reason case failure3 .2.5 Empirical Evaluation Utility Case Failure Analysispreliminary study conducted aim demonstrating advantage storingretrieving cases basis experienced retrieval failure. Domains chosenrandomly generated problems contained negatively interacting goals, planningperformance tested dersnlp+ebl solving multi-goal problems scratchreplay single cases covering smaller subset goals. Replay performancetested without case failure information.2.5.1 DomainsExperiments run problems drawn two domains. first artificialdomain, 2 DmS 1, originally described (Barrett & Weld, 1994) shown Figure 8.Testing done problems randomly generated domainrestriction always contain goal gff . Logistics Transportation domain(Veloso, 1994) adopted second set experiments. Eight packages oneairplane randomly distributed four cities. Problem goals represented taskgetting one packages single destination airport4. fly operator augmented delete condition prevented planes visiting airportonce. meant replay failed extra package transportedprevious route taken plane.2.5.2 Retrieval StrategyCases initially retrieved basis static similarity metric takesaccount goals covered case well relevant initial stateconditions (Kambhampati, 1994; Veloso, 1994). Prior studies show reasonably3. dersnlp+ebl's EBL component explains analytical failures. Depth limit failures ignored.means failure explanations formed sound case depth limit failure,retriever may reject case applicable. Rejecting applicable case may leadstorage duplicate cases larger library size. However, empirical work shownpractical importance reasons outlined Section 3.2.2.4. comprehensive evaluation unbiased problem set see Section 4.173fiIhrig & Kambhampatieffective metric. learning mode, cases also retrieved basis. However,mode, failure reasons attached case used censor retrieval.time case retrieved learning mode, failure conditions alsotested. failure reason satisfied new problem specification, retrievalmechanism returned case replay. If, hand, failure reason foundtrue new problem context, case repaired failure retrieved.Following retrieval, problem solved replay retrieved case wellplanning scratch.2.5.3 Experimental Setupexperiment consisted three phases, phase corresponding increaseproblem size. Goals randomly selected problem, and, caselogistics domain, initial state also randomly varied problems. initialtraining session took place start phase n, 30 n-goal problems solvedscratch, derivation trace stored library. Following training,testing session consisted generating problems manner additionalgoal. time new (n +1) goal problem tried, attempt made retrievesimilar n-goal problem library. testing session, casesimilar new problem found previously failed, problemsolved learning, static from-scratch modes, became part 30-problemset. method, able evaluate improvements provided failurebased retrieval retrieval static metric alone ineffective, failureconditions available.2.5.4 Experimental Resultsresults experiments shown Tables 1 2. table entry representscumulative results obtained sequence 30 problems corresponding one phaseexperiment. first row Table 1 shows percentage problems correctly solvedwithin time limit (550 seconds). average solution length shown parentheseslogistics domain (solution length omitted 2 DmS 1 since problemsgenerated within phase solution length). second third rowsTable 1 contain respectively total number search nodes visited 30 testproblems, total CPU time (including case retrieval time).results also summarized Figure 10. dersnlp+ebl learning modeable solve many multi-goal problems two modessubstantially less time. Case retrieval based case failure resulted performanceimprovements increased problem size. Comparable improvementsfound retrieval based static similarity metric alone.surprising since cases retrieved experienced least one earlier failure.meant testing done cases likelihood failing retrievalbased static metric.Table 2 records three different measures ect effectiveness replay. firstpercentage sequenced replay. Recall replay trace consideredsequenced skeletal plan refined reach solution new problem.174fiStoring Indexing Plan Derivations2 DmS 1StaticScratchLearningLogisticsStaticScratch100%901100%2404100%3002100% (6.0)177330100% (6.0)177334100% (6.0)273556% Solvednodestime(sec)100%1202100%81015100%9908100% (8.2)6924146100% (8.2)13842290100% (8.2)20677402% Solvednodestime(sec)100%1503100%234041100%253321100% (10.3)29032100% (10.3)38456916100% (10.3)1272372967PhaseLearning%Solvednodestime(sec)(1) Two Goal(2) Three Goal(3) Four GoalTable 1: Performance statistics 2 DmS 1 Logistics Transportation Domain (Averagesolution length shown parentheses next %Solved logistics domainonly)(a) 2Dm 1(b) LogisticsFigure 10: Replay performance 2 DmS 1and Logistics Transportation domain.175fiIhrig & Kambhampati2 DmS 1LogisticsLearningStaticPhaseLearningStatic% Seq% Der% Rep100%60%100%0%0%0%53%48%85%53%48%85%% Seq% Der% Rep100%70%100%0%0%0%80%63%89%47%50%72%% Seq% Der% Rep100%94%100%0%0%0%100%79%100%70%62%81%Two GoalThree GoalFour GoalTable 2: Measures effectiveness replay.results point greater eciency replay learning mode. 2 Dm 1 domain,replay entirely sequenced mode. transportation domain, retrieval basedfailure always result sequenced replay, often staticmode.greater effectiveness replay learning mode also indicated twomeasures contained subsequent two rows Table 2. respectively, percentage plan refinements final derivation path formed guidancereplay (% Der), percentage total number plans created replay remain final derivation path (% Rep). case-based planner learningmode showed much greater improvements according measures, demonstrating relative effectiveness guiding retrieval learning component basedreplay failures. results indicate dersnlp+ebl's integration CBP EBLpromising approach extra interacting goals hinder success replay.Section 4 report thorough evaluation dersnlp+ebl's learning component. conducted purpose investigating learning case failurebenefit planner solving random problems complex domain. evaluation implemented full case-based planning system along novel case storageadaptation strategies. next section, describe storage strategydeveloped evaluation.3. Improving Case Storage Adaptationaim case-based planning eciently solve large problems complex domains.complex domain means great variety problems encountered. problem size(measured terms number goals, n) large, unlikely n-goalproblem seen before. therefore advantage able store casescovering smaller subsets goals, retrieve adapt multiple cases solving singlelarge problem.176fiStoring Indexing Plan Derivationsimplementing strategy, decisions made goal combinations store. previous work within state-space planning Veloso (1994) developedapproach reducing size library first transforming totally ordered planpartially ordered graph, separating connected components graph, storingsubplans individually. Goals interact respective plans mustinterleaved order form complete solution stored together single case.replay based plan-space planner snlp, component subplan maysubdivided, since planner ability first piece plans together, later add steporderings interleave subplans (Kambhampati & Chen, 1993; Ihrig & Kambhampati,1994a). Replay smaller cases sequenced long individual subplansmay interleaved addition step orderings form full solution. plan-spaceplanner therefore greater capability reducing size problems storedlibrary, and, consequence, number cases stored.dersnlp+ebl's storage strategy makes use plan-space planners' ability piecesmall plans together, add step orderings interleave plans. earlier approaches, priar (Kambhampati & Hendler, 1992), prodigy/analogy (Veloso,1994) caplan (Munoz-Avilla & Weberskirch, 1996), cases stored coversmaller subsets original set input goals achieved successful problem-solvingepisode. dersnlp+ebl differs earlier approaches division goalsubsets based structure final plan alone, sequence eventsmaking problem-solving episode. new repairing case stored casesretrieved library solving new problem fail extended newsolution. storer constructs new case based failure explanation obtained extension phase well new successful plan derivation obtainedrecovery.failure explanation identifies set negatively interacting goals responsiblefailure. goals form subset input goals achieved newsolution. repairing case stored, new plan derivation strippeddecisions irrelevant achievement interacting goals. new casecovers negatively interacting goals.Note define negative interaction based failure skeletal plan.interaction occurs set input goals cannot solved refining skeletal plan,causing planner backtrack plan. Moreover, cannot determinewhether two goals negatively interacting merely analyzing final solution.include information planning failures encountered generatingsolution. particular, final solution tell us whether additional goalachieved extending replayed path, backtracking path. Approachescase storage determine goal interaction final plan alone (Veloso, 1994;Munoz-Avilla & Weberskirch, 1996) therefore ignore retrieval failuresencountered planning episode.Retrieval failures provide important guidance library may improvedavoid similar failures. dersnlp+ebl, used dynamically improve storagelibrary addition new goal combinations. Multi-goal problemsstored retrieved cases corresponding single-goal subproblems fail merged177fiIhrig & KambhampatiCase Failure Explanation:C = fhgff; tG i; hg8 ; tG igE = fhtI ; i8 i; htI ; Pfi igFigure 11: Example case failure reasonextended new solution. Repairing cases constructed achieve negativelyinteracting goals responsible identified failure explanation.3.1 Example Negative InteractionFigure 11 provides example explanation failure encountered solvingproblem Barrett Weld's 2Dm 1 domain shown figure 8. problem containsthree goals, gff , g6 g8 , attempted replay case solvestwo goals, gff g6 , second case, achieves g8 . latter,goal achieved action Afi8 represents incorrect operator choiceinput goals problem include goal gff .failure explanation shown Figure 11 identifies subset interacting goals, madeg8 gff . Note interaction evident final plan shown Figure 12.plan, three input goals problem achieved connectedcomponent. base storage solely plan graph represented successful plan,three input goals stored single case. Moreover, new problemrepresenting novel combination goals stored library, causing librarysize increase exponentially problem size. example, suppose domain includesgoals, fgi j1 < < ng gff . number problems size threenumber 3-goal subsets n + 1 goals. dersnlp+ebl's strategy storing casesbased explanations retrieval failure result maximum 2n + 1 cases stored.goal fgi j1 < < ng appears two cases, one representing single-goal problemone representing two goal problem also achieves gff .Storing negatively interacting goals multi-goal problems may therefore resultsubstantial reduction size case library. also represents tradeoff,replayed cases must extended from-scratch planning solve con ictsindividual plans recommended separate cases. Moreover, complex domains,may goals interact positively may solved commonsteps (Ihrig & Kambhampati, 1996; Munoz-Avilla & Weberskirch, 1997). goalsstored separate cases, replay may result unnecessary redundancy plan.dersnlp+ebl, positive interactions handled replay process itself,merges subplans provided multiple cases. Section 3.3 describemerging accomplished. next section provides detail case storagestrategy implemented empirical study.178fiStoring Indexing Plan DerivationstI1:2:3:tGFigure 12: Solution example problem.3.2 Building Case Libraryfollowing deliberative strategy adopted building case library. newproblem contains n goals, first goal attempted, and, solved, case coveringgoal alone stored library. Problem-solving continues increasing problem sizeone goal time. example, problem attempted contained goal set,G = hg1 ; g2 ; :::; gi solved decision sequence Di second decisionsequence, Di+1 , stored whenever Di cannot replayed extended achieve nextgoal gi+1 . Whenever replayed derivation path fails, recovery phase successfulproducing new solution, explanation case retrieval failure used identifysubset negatively interacting input goals, N = hgj :::gj +m i, responsiblefailure. replayed path fails extended, backtracked reach solutionnew problem, new successful derivation passed storer alongfailure explanation. explanation used delete derivation decisionsrelevant set negatively interacting goals, N . reduced derivationstored library repairing case. Alternatively, whenever next goalset solved simple extension previous decision sequence, casestored includes goal.storage strategy entails two important properties. (1) new case correspondseither new single-goal problem multi-goal problem containing negatively interactinggoals. (2) plan derivations arising single problem-solving episodedifferent decision sequence stored library prefix another stored case.case added library new problem solved extendingretrieved case. New cases stored previous decisions needbacktracked search new solution.dersnlp+ebl's strategy restricting multi-goal cases goalsnegatively interacting serves ameliorate mis-retrieval problem. experienceplanner problem-solving, interactions discovered,less likely planner backtrack replayed paths. aimeventually library minimal number cases problemsencountered may achieved successfully merging multiple instances stored cases.approach therefore retain cases based competence well performance(Smyth & Keane, 1995).3.2.1 Example dersnlp+ebl's Storage Strategyexample multi-goal problem stored, consider problem containedFigure 13 three packages, ob1, ob2 ob3, transporteddestination location, ld . Initially goal set contains goal transporting ob1 alone,represented (at-ob ob1 ld ), successful derivation stored Case A.second goal added set. Since problem attempted achieves first179fiIhrig & KambhampatiOB1OB3BBldBlpOB2l2Figure 13: logistics transportation example illustrating multi-case storage. figureshows two plans produced two stored derivations. Case achieves goalsingle packages, ob1, transported destination airport, ld . CaseB achieves goal ob1 ob2 located airport.goal decision sequence backtracked order solveadditional goal, second derivation, Case B , stored. new derivation solvesmutually interacting goals, (at-ob ob1 ld ) (at-ob ob2 ld ). Problem-solvingcontinues addition third goal. goal solved simple extensionprevious decision sequence. case stored includes goal. meanstwo cases stored library: Case corresponding single-goal problemCase B corresponding multi-goal problem containing two negatively interacting goals.Multi-goal problems stored problem goals mutually interacting,is, individual derivations cannot sequenced extended solvefull problem.dersnlp+ebl's storage strategy, size library limited amountinteraction domain. example, negative interaction, singlegoal cases stored. logistics transportation domain, potentialproblem goals interact negatively. However, since also significant percentagenon-interacting goals, strategy reduces size library comparison onemulti-goal problems successfully solved stored. storagestrategy also represents tradeoff since effort must expended merging retrievedcases full solution (See Section 3.3).3.2.2 Indexing Basis Replay FailureMulti-goal cases stored library censor retrieval correspondingsingle-goal subproblems. library organization differs earlier work storescases common fashion single level, first indexing case goals,success conditions relevant goals (Veloso, 1994; Munoz-Avilla &Weberskirch, 1996). contrast, dersnlp+ebl indexes cases discriminationnet similar one depicted Figure 14. figure shows one fragment caselibrary includes cases solve single input goal. Individual planningepisodes achieve goal represented one level lower net. labeled180fiStoring Indexing Plan DerivationsG0input goals:initial conditions:(AT-OB OB1 ld )(AT-PL PL1 lp)(AT-OB OB1 l1)G1G2derivation 1r1failure reasons:(AT-PL PL1 lq)derivation 2r2G3G4derivation 3derivation 4Figure 14: Library fragment indexing stored cases solve single input goal, (at-obob1 ld ).relevant initial state conditions, otherwise known footprinted initial state (Veloso,1994). Together, goal initial state conditions make static success conditionscases first retrieved. one cases retrieved replay replayfails, derivation corresponding extra interacting goals added libraryindexed directly failing case. future retrievals case, failureconditions checked see whether extra goals responsible failure presentconditions. so, retrieval process returns repairing caseachieves con icting goals. case failure reason thus used direct retrieval awaycase repeat known failure, towards case avoids it.One might question hierarchical organization instances failures dueinteracting goals alone. store cases single level first indexingcase goals, conditions relevant goals? answerlies need censor cases failure conditions satisfied. type errorfound retrieving multiple cases. example, consider new problemcontains three goals, g1 , g2 g3 . Suppose goal g2 negatively interactsg1 g3 . case retrieved library achieves g1 g2 ,one goal, g3 , left open. However, case retrieved solves g3 alone,fail presence g2 . type retrieval error handled prioritizingcases. repairing case stored subclass case failed. Failing casesannotated failure reason directs retriever case avoidsfailure.Prioritizing cases basis negatively interacting goals alone sucientcapture retrieval failures may encountered. cases retrievedbasis partial match relevant initial state conditions, retrieval errors mayoccur unmatched conditions (Veloso, 1994). example, failure mightoccur logistics transportation example extra package plane'sroute, similar failure occur package moved plane's route. strategyadopted deal types failure information annotate case181fiIhrig & KambhampatiOB1OB3l1ldB BBBBlpOB2Bl2Figure 15: logistics transportation example illustrating multi-case retrieval.failure reason (whether extra goal unmatched initial state condition)use failure reasons prioritize cases. EBL techniques employedconstruction failure explanations may used types failures.dersnlp+ebl's method storing multi-goal cases goals negatively interacting limits size case library. aspects dersnlp+ebl's storage strategyalso serve lower library size. planner always uses current library solving newproblems. New derivations stored applicable case,retrieved cases fail. strategy avoids storage duplicate cases, mayentirely effective since soundness failure explanations guaranteed. failureexplanations sound, pointers repairing cases may eventually lead duplicatecase, causing library continue grow indefinitely. However, easily checkedputting depth limit number repairing cases discrimination net. Also,failures due interacting goals result unchecked growth librarysince number interacting goals limited maximum problem size.3.2.3 Detailed Example Case Retrievalexample case retrieval illustrated Figure 15. figure contains three subplanscorresponding two separate cases stored library. Case achieves goalsingle package, ob1, located destination ld . Case B achieves goalob1 ob2 located ld.Assume new problem attempted replay contains threegoals, (at-ob ob1 ld), (at-ob ob2 ld ), (at-ob ob3 ld ). second goal negativelyinteracts goals. retriever first attempt find casesolves first goal alone. Case solves goal. However, case annotatedfailure reason satisfied new problem situation, therefore censoredfavor repairing case, Case B . retriever returns Case B ,one open goal covered, is, (at-ob ob3 ld ). seek case solvesgoal alone, find Case A. However, A's failure reason satisfiednew problem state rejected favor second copy B (whichcall Case B 0), solves problem transporting ob3 ob2.two instances Case B retrieved solve three goal problem,Case B Case B 0 . Together cover new problem goals. dersnlp+ebl replays182fiStoring Indexing Plan DerivationsFigure 16: New linking opportunities indicated increase number siblingsstep addition decision.copies B sequence obtain solution full problem, thereby mergingrespective subplans. Notice, however, union plans contain redundantsteps. example, plans plane location l1 . Section 3.3 describesdersnlp+ebl deals positive goal interactions.3.3 Multi-case Mergingsay two plans mergeable respect problem, hI 0; G0 ; Ai, existssolution problem contains combined constraints.Definition 2 (Mergeability) plan P1 achieving goal g1 mergeable plan P2goal g2 respect problem, hI 0 ; G0 ; Ai , plan P 0 correcthI 0; G0 ; Ai hhP 0ii hhP1ii\hhP2 ii. (Thus syntactically, P 0 contains constraintsP1 P2 ).Multi-case replay accomplishes plan merging, may result lower quality planscare taken avoid redundant step additions (Ihrig & Kambhampati, 1996; MunozAvilla & Weberskirch, 1997). occur goals covered separate cases positivelyinteract may solved common steps. Replaying case sequenceresults unneeded steps plan5 .multi-case replay, open condition justification adding new step,steps may added already exist plan due earlier replay anothercase. first retrieved derivation replayed, none replayed step additionsresult redundancy. However, subsequent goals solved replayadditional cases, step additions may unnecessary opportunitieslinking open conditions achieve earlier established steps. plannerway determining priori steps may represented single stepplan6 .dersnlp+ebl's replay framework handles redundant step additions skippingstep addition establishments whenever open condition may achieved new link.thus strengthens increases justification replaying step addition decisionsopen condition longer basis validating decision. justification replay strengthened add condition new linking opportunities5. analogous decrease plan quality occurs state-space plan reuse, sequencing macro-operatorsresults state loops (Minton, 1990a).6. Consider, example, domain plane may transport two packages one trip, not,depending capacity.183fiIhrig & Kambhampatidersnlp+ebldersnlp+ebl-ij87%(6) 67%(5)2465579687%(7) 67% (5)21985810replay%Solvedtime(sec)scratchreplayscratchTable 3: Percentage problems solved, total CPU time seconds 30 problemsproblems Logistics Transportation Domain. Average solution lengthshown parentheses next %Solved.present. may detected increase number siblings prescribedstep addition choice (See Figure 16). siblings stored step addition decisionrecorded annotations derivation trace. new links availablecontained within siblings, step addition decision skipped. replay,alternative new links explored normal course plan refinement.means step may eventually added new links fail.Increasing justification step addition decisions improves quality plansterms number steps contain. example, Case B B 0 would normallyproduce subplans shown Figure 15. cases replayed sequencesolving single problem, plans merged plane moves cityonce. Plan merging increasing justification replay accomplishesretracting redundant action sequences, may cause planning failure. thusdeals action-merging interactions defined (Yang, Nau, & Hendler, 1992).next section describe empirical study testing effectiveness mergingstrategy.3.3.1 Empirical Test dersnlp+ebl's Plan Merging Strategypreliminary study conducted test effectiveness dersnlp+ebl's methodplan merging replay. experiment compared dersnlp+eblwithout increasing justification replay. experimental setup consisted trainingdersnlp+ebl set 20 randomly generated 4-goal training problems, testingdifferent set 30 4-goal test problems. initial state problem contained 12locations (6 post oces 6 airports) 12 transport devices (6 planes 6 trucks).training phase, planner solved problems stored successful plan derivationscase library. testing phase, planner retrieved multiple stored planderivations used guidance solving test problems. dersnlp+ebltested 30 problems replay from-scratch modes. Replay either(dersnlp+ebl) without (dersnlp+ebl-ij) increased justification. resultsshown Table 3.Although overall performance poorer, quality plans terms numbersteps improved dersnlp+ebl's strategy increasing justification step addition. result suggests dersnlp+ebl's method plan merging serves reduce184fiStoring Indexing Plan Derivationsredundancy plans produced multi-case replay. Recently, Munoz-AvillaWeberskirch (1997) tested non-redundant merging strategy process planning domain found similar improvements plan size. next section describesevaluation full dersnlp+ebl system.4. Experimental Evaluation Complete Systemexperiments reported section tested full dersnlp+ebl system usingdynamic multi-case storage retrieval strategy described Section 3. aimevaluate replay system complex domain. hypothesis performancewould improve problem solving experience negative interactions discoveredstored. addition, predicted dersnlp+ebl's method storage would resultlow library size low retrieval costs.Logistics Transportation domain (Veloso, 1994) become somewhat benchmark CBP literature. scaled version therefore chosen purpose.tested large multi-goal problems drawn domain shown Figure 4 scaledfirst 6 15 cities. size domain unusual current literature.4.1 Experimental Setupexperiment run phases, phase corresponding increase problemsize. Thirty test problems size randomly generated. Since possibleobtain truly random distribution within nonartificial domain, following strategyadopted problem generation. First, initial state constructed fixingnumber objects type contained domain description. example, firstexperiment, six cities (12 locations within cities), six planes, six trucks.initial state problem constructed first including filter conditions (nonachievable conditions). defined layout cities. example, condition (is-aairport ap1) identified ap1 airport. condition (same-city ap1 po1) indicatedap1 po1 located city. Second, achievable (non-filter) conditions present add clauses domain operators variedproblem choosing object constants randomly available restrictiontwo initial state conditions inconsistent. example, plane packageassigned single randomly-chosen location. Goals chosen amongachievable conditions manner. Although attempt made create interacting goals, goal interaction common multi-goal problems.limit imposed number steps plan. meant multi-goal problems often could solved concatenating subplans individual subgoals.instances, planner could take advantage linking opportunities achieve multiplegoals common steps. also meant often planner backtrackderivation one goal order solve additional goal.first experiment used 6-city domain run 6 phases. sizetest problems (which ranged 1 6 goals) increased phase. Priorphase n experiment, case library emptied planner retrainedrandomly generated problems size n. Training problems solved attemptingsingle-goal subproblems scratch, storing trace derivation solution185fiIhrig & KambhampatiPhase020%Solvedtime(sec)100%(3)15% Solvedtime(sec)Logistics (Best-firstCPU limit: 500sec)801004060100%(3)14(.1)100%(3)13(.1)100%(3)4(.0)100%(3)5(.10)100%(3)3(.13)100%(3)3(.13)90%(4)154893%(4)1069(.2)100%(5)22(1.0)100%(5)23(.2)100%(5)25(.28)100%(5)15(.28)100%(5)11(.26)% Solvedtime(sec)53%(5)703887%(7)93%(7)93%(7)93%(7) 100%(8)2214(.55) 1209(.49) 1203(.54) 1222(.52) 250(.54)100%(8)134(.58)% Solvedtime(sec)43%(5)8525100%(8)563(.99)100%(8)395(.79)100%(8)452(.91)100%(9)24(.97)100%(9)22(.89)100%(9)22(.88)% Solvedtime(sec)0%1500070%(11)5269(2)90%(11)2450(1)93%(11)1425(2)93%(11)1479(1)93%(11) 100%(12)1501(1) 375(1)% Solvedtime(sec)0%1500050%(12)7748(3)70%(13)4578(5)87%(14)2191(5)93%(14)1299(3)93%(14)1319(3)One GoalTwo GoalThree GoalFour GoalFive GoalSix Goal12093%(14)1244(3)Table 4: Performance statistics Logistics Transportation Domain. Average solutionlength shown parentheses next %Solved. Case retrieval time shownparentheses next CPU time.problem one already present library, successively adding extragoal. Multi-goal problems stored retrieved cases used solving problemfailed. Whenever problem could solved sequenced replay previous cases,negatively interacting goals contained failure reason identified newcase achieving goals alone stored library. phase experiment,planner tested 30 randomly generated test problems varyingamounts training. problems solved from-scratch mode replaymultiple cases retrieved library constructed training.second experiment tested planner complex 15 city domain employed stable case library formed dersnlp+ebl trained 120 (6 city, 6 goal)logistics transportation problems. library smaller problems usedplanner tested larger (15 city) problems ranging 6 10 goals.4.2 Experimental Resultsfirst experiment 6 city domain dersnlp+ebl showed substantial improvements multi-case replay evident results Table 4. Moreover, replayperformance improved problem-solving experience. plans producedshowed slight increase number steps solutions obtainedfrom-scratch mode. results plotted Figure 17 graphs cumulativeCPU time test problems six experiments. figure illustrates CPUtime decreased number training problems solved. insert shows total CPU186fiStoring Indexing Plan DerivationsFigure 17: Replay performance Logistics Transportation Domain increasingamounts training. Thirty problems tested problem size (16 goals). amount time needed solve test problems size(including case retrieval time) shown problems solved scratch(level 0) replay increasing levels training (after solving 20 ...120 randomly generated problems). insert shows amount time takensolve test problems increasing amounts training. time limit500 seconds placed problem solving.187fiIhrig & KambhampatiFigure 18: Replay performance Logistics Transportation Domain scaled 15cities. case library formed 120 training problems (6 cities, 6 goals)solved. library used solving test sets containing largerproblems (15 cities, 6 10 goals). None problems solved withintime limit (500 sec) from-scratch mode. replay mode, average solutionlength shown parentheses next problem size.Figure 19: Replay performance logistics transportation. percentage test problems solved within time limit (500 sec) plotted number trainingproblems solved. Percentage solved shown problems increasing size (1,3, 5 goals).188fiStoring Indexing Plan DerivationsFigure 20: Figure shows size case library increased number trainingproblems solved. Library size increases training problem size (1, 3, 5goals). 5' shows number single-goal subproblems contained 5-goaltraining problems.time (including case retrieval time) test problems six experiments.evident insert, planning performance improves increased experience randomproblems. However, relatively little experience (20 problems solved) enough showsignificant performance improvements.Replay raised problem-solving horizon, illustrated Figure 19. effectivelarger problem size, from-scratch planning tends exceed time limit imposedproblem-solving. Figure 20 shows increase size library increasingamounts training. figure also indicates library size determinedamount interaction domain, opposed number training problems solved.rate case library grows tapers higher planner trainedlarger problems7 .second experiment, library formed course training 6-goal problemsused solve larger problems (6 10 goals) complex domain (15 cities) (SeeFigure 18). None larger problems solved from-scratch mode within timelimit 500 sec 8 . planner continued maximum time problems, indicatedfigure linear increase CPU time. performance substantially betterreplay, however. Since library size relatively small, improvements planningperformance offset cost retrieving adapting previous cases. findingsuggests replay strategy employed experiments represents effectivemethod improving planning performance complex domains.7. opportunity interaction larger problems. example, 6-goal problem couldcontain 6 goals mutually interact, whereas 5-goal problem maximum 5 interacting goals.8. dersnlp+ebl from-scratch mode used best-first strategy. replay, best-first strategy biasedsubtree replayed path explored first, siblings path.189fiIhrig & Kambhampatiaction (Put-On ?X ?Y ?Z)precond (On ?X ?Z)(Clear ?X)(Clear ?Y)add(On ?X ?Y)(Clear ?Z)delete (On ?X ?Z)(Clear ?Y)action (New-Tower ?X ?Z)precond (On ?X ?Z)(Clear ?X)adddelete(On ?X Table)(Clear ?Z)(on ?X ?Z)Figure 21: specification Blocks World Domain adapted experiments.4.3 Empirical Comparison dersnlp+ebl Rule-Based EBLCase-based planning explanation-based learning offer two differing approaches improving performance planner. Prior research (Kambhampati, 1992) analyzedtradeoffs. hybrid learning approach dersnlp+ebl designed alleviatedrawbacks associated pure case-based planning, rule-based EBL. Priorwork, EBL used construct generalized search control rules mayapplied new problem-solving situation. rules matched choicepoint search process (DeJong & Mooney, 1986; Minton, 1990b; Mostow & Bhatnagar,1987; Kambhampati et al., 1996b). approach known exhibit utility problem sincerule base grows rapidly increasing problem-solving experience even smallnumber rules may result high total match cost (Minton, 1990b; Tambe, Newell, &Rosenbloom, 1990; Kambhampati, 1992; Francis & Ram, 1995). contrast, empiricalresults discussed (see Table 4) indicate dersnlp+ebl low case retrievalmatch cost.demonstrate dersnlp+ebl reduces match cost, conducted empirical studycompared performance ucpop+ebl, rule-based search control learningframework (Kambhampati et al., 1996b). framework constructs reasons planningfailures manner similar dersnlp+ebl. However, approach similarMinton (1990b) employs explanations construction search controlrules matched node search tree. planners testedset problems ranging 2 6 goals randomly generated blocksdomain shown Figure 21. Testing performed set thirty problemsincreasing amounts training.illustrated Figure 22, dersnlp+ebl improved performance 10 training problems solved. ucpop+ebl failed improve significantly. reason evidentucpop+ebl's match time (ucpop-match) also graphed Figure 22. ucpop+ebl,time spent matching rules increases training, wiping improvementsmay gained use rules. rules matchedchoice point search tree, small number rules sucient substantially increasetotal match cost.190fiStoring Indexing Plan DerivationsFigure 22: Total CPU Time 30 blocks world problems increased amounts training.also possible improve performance rule-based EBL reducing numberrules use utility monitoring strategies (Gratch & DeJong, 1992),using sophisticated match algorithm (Doorenbos, 1995). example, Doorenbos(1995) employs improved rule matcher based Rete algorithm. dersnlp+ebl,hand, aims alleviating utility problem reducing number times rulesmatched. Similar rule-based EBL, learning component employed generaterules. However, rules generated govern retrieval cases storedlibrary. compiled indexing structure. dersnlp+ebl exhibits lowmatch cost applying retrieval rules one point search process. Specifically,retrieves cases start problem-solving. case represents sequencechoices (a derivation path) thus providing global control opposed local. resultsshown Table 4 indicate cost retrieving cases significantly lower comparisontime spent problem-solving.5. Related Work Discussiondersnlp+ebl's storage strategy relies capability case-based planner replaymultiple cases, covering small subset goals, add step orderings interleave respective plans. strategy differs earlier approaches priar(Kambhampati & Hendler, 1992), prodigy/analogy (Veloso, 1994), paris (Bergmann& Wilke, 1995), caplan (Munoz-Avilla & Weberskirch, 1996), divisiongoal subsets based structure final plan alone, sequenceevents making problem-solving episode. Retrieval failures treated opportunity planner stores new repairing case. aspect similarHammond's chef (Hammond, 1990) also learns improve retrieval strategybased failures. Despite surface similarity, important differences191fiIhrig & KambhampatiTransformationalPRIARSPAMPAPlan-SpaceState-SpaceDERSNLPPRODIGY/ANALOGYPARISDerivationalFigure 23: different approaches case-based planning case adaptation accomplished underlying generative planner.approach. dersnlp+ebl learns case extension failures, whereas chef concentrateslearning execution failures. Specifically, chef assumes incomplete domain model,consisting stored cases, domain-specific modification theory patches. Givennew problem, chef retrieves previous case, modifies retrieved plan using domainspecific modification rules generate candidate solution current problem.correctness solution tested respect external causal simulatordomain. solution found incorrect, explanation incorrectness (suppliedsimulator) used modify case-library censor retrieval casesimilar situations future. effect improves correctness chef's domaintheory. contrast, dersnlp+ebl assumes complete knowledge domain, formdomain operators. also access sound complete plan synthesis strategy.aim case-based reasoning dersnlp+ebl improve performancebase-level planner. end, dersnlp+ebl analyzes case extension failures predictcase cannot extended solve new problem.Fox Leake (1995) taken approach similar chef, use introspective reasoning explain failures find repairing cases. Similar chef, introspectivereasoning used revise indexing case library (Fox & Leake, 1995; Ram & Cox,1994). approaches employ domain-specific techniques improve storage retrieval case library (Munoz-Avilla & Weberskirch, 1996; Smyth & Keane, 1995).dersnlp+ebl differs automatically generates new indices well defineddomain-independent methodology (Kambhampati et al., 1996b) incorporatedunderlying planning strategy.Since EBL employed explaining case failure well success, dersnlp+ebl complements extends earlier approaches case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Hendler, Stoffel, & Mulvehill, 1996; Veloso, 1994; Bergmann& Wilke, 1995; Munoz-Avilla & Weberskirch, 1996; Ram & Francis, 1996). Although192fiStoring Indexing Plan Derivationsexhibits low retrieval match cost, CBP system, eciency may degrade larger domain size. dersnlp+ebl's approach compatible others aimedimproving match cost (Doorenbos, 1995; Ram & Francis, 1996; Hendler et al., 1996).example, mpa (Ram & Francis, 1996) built around retrieval engine performsasynchronous memory retrieval. caper (Hendler et al., 1996) uses structure matchingalgorithm parallelizes process plan's success conditions representedretrieval probe matched large knowledge base world facts. processexpands binary predicates match success conditions larger structure containing implicitly specified relations knowledge base. structure acts filter,eliminating matches fail line probe.dersnlp+ebl similar case-based systems employ complete correctdomain-independent planner generate cases stored (Hanks & Weld, 1995; Kambhampati & Hendler, 1992; Koehler, 1994; Veloso, 1994; Ram & Francis, 1996). surveyingliterature, possible distinguish approaches two orthogonal scalesshown Figure 23. horizontal direction, CBP frameworks rankedunderlying planning strategy falls continuum whose end extremes representstate-space vs plan-space dichotomy. Towards state-space end spectrumprodigy/analogy, employs means-ends analysis (MEA) planner, nolimit,extend previous case. nolimit classed state-space planner since appliesactions plan based current world state thereby advances world state.priar framework (Kambhampati & Hendler, 1992; Kambhampati, 1994) basedwithin nonlin (Tate, 1977). nonlin creates plans hierarchical task reduction.also partial-order (plan-space) planner constructs plans protecting underlying causal structure. Like dersnlp+ebl, extends case normal courseplan refinement defined underlying plan-space strategy. However, dersnlp+eblimplemented within partial-order, causal-link planner, snlp (McAllester & Rosenblitt,1991; Barrett & Weld, 1994). aspect similar spa system developedHanks Weld (1995).different CBP systems may also distinguished according case adaptation strategy. roughly categorized either transformational derivational(Carbonell, 1983; Veloso & Carbonell, 1993b), according whether transform previous plan replay previous plan derivation. transformational strategies priarspa, final plan product planning episode stored caselibrary. case retrieved plan fitted adapt new problem-solving situation retracting irrelevant redundant subparts. Early CBP systems (Carbonell,1983; Hammond, 1990) also employ transformational techniques adapt previous solution. Causal-link planners snlp ready-made plan reuse since causalstructure employed plan adaptation part plan itself. priar spause plan's causal structure fitting plan new problem context,extending fitted plan solve new problem. priar differs spaemploys extension-first strategy. skeletal plan first refined additionplan constraints undertaking retraction constraints. spa,hand, alternates retraction plan constraints additionnew constraints. mpa (Ram & Francis, 1996) extends spa's transformational strategyaccomplish multi-case retrieval adaptation.193fiIhrig & Kambhampatimentioned earlier, derivational analogy case-based planning techniqueintroduced Carbonell (Veloso & Carbonell, 1993b). model developedVeloso prodigy/analogy (Veloso, 1994), employed case fitting strategy calledderivational replay. Case fitting based replay similar fitting plan reuse,based plan's underlying causal structure. justification planningdecision stored derivation trace ects causal dependencies plansteps. justified choices replayed solving new problem. Replay thus servespurpose retraction plan reuse. Replay may advantage multi-casereuse since allows planner readily merge small subplans solve large problems.dersnlp contrasted prodigy/analogy employs case fittingmethodology called eager derivation replay (Ihrig & Kambhampati, 1994a, 1996).replay strategy, applicable cases replayed sequence returning fromscratch planning. Eager replay simplifies replay process avoiding decisionalternate replay multiple cases. effectiveness approach dependentunderlying plan-space planning strategy (Ihrig & Kambhampati, 1994a). dersnlp'seager case adaptation strategy allows case failure defined terms failuresingle node search tree. particular, case failure defined failureskeletal plan, contains constraints adopted adviceprevious cases. Eager case adaptation means explanations case failure mayconstructed use EBL techniques developed explainanalytical failures occurring planner's search space.6. Summary Conclusionpaper described design implementation case-based planner,dersnlp+ebl. dersnlp+ebl framework represents integration eager case adaptation failure-based EBL. EBL techniques employed building case librarybasis experienced retrieval failures. approach improves earlier treatments case retrieval (Barletta & Mark, 1988; Kambhampati & Hendler, 1992; Ihrig &Kambhampati, 1994a; Veloso & Carbonell, 1993a). partial-order case-based planner,dersnlp ability solve large problems retrieving multiple instances smallersubproblems merging cases sequenced replay (Ihrig & Kambhampati,1994a). dersnlp+ebl framework extends approach use new EBLtechniques employed construction case library. techniquesused explain plan merging failure identify set negatively interacting goals.library augmented new repairing case covering interacting goals.dersnlp+ebl's method storing multi-goal cases goals negatively interacting results small library size low retrieval costs. However, multi-case adaptationalso involves tradeoff since effort expended merging multiple instances stored cases.dersnlp+ebl accomplishes merging increasing justification replay step addition decisions. strategy avoids addition redundant steps goals positivelyinteract. dersnlp+ebl therefore aimed domains Logistics Transportationdomain significant amount positive interaction. also aimed domainsnegative interaction. course futile spend effort explaining casefailure none encountered.194fiStoring Indexing Plan DerivationsSection 4 describes evaluation overall eciency storage retrievalstrategy solving large problems complex domain. dersnlp+ebl shows improvement planning performance offsets added cost entailedretrieving failure conditions. amount improvement provided replay shownexperiments seen lower bound since random problem distributionmay mean less problem similarity found real world problems.conclusion, paper described novel approach integrating explanationbased learning techniques case-based planning. approach aimed issuesassociated pure case-based planning, rule-based EBL. particular,addresses mis-retrieval problem CBP, well utility problem. resultsdemonstrate eager case adaptation combined dersnlp+ebl's dynamic caseretrieval effective method improving planning performance.Acknowledgementsauthors wish thank Amol D. Mali, Eric Lambrecht, Eric Parker, anonymousreviewers helpful comments earlier versions paper. Thanks dueTerry Zimmerman providing insight ucpop+ebl. research supportedpart NSF Research Initiation Award IRI-9210997, NSF Young Investigator awardIRI-9457634, ARPA Planning Initiative grants F30602093-C-0039 (phase II)F30602-95-C-0247 (phase III).ReferencesBarletta, R., & Mark, W. (1988). Explanation-based indexing cases. ProceedingsAAAI-88.Barrett, A., & Weld, D. (1994). Partial order planning: evaluating possible eciency gains.Artificial Intelligence, 67, 71{112.Bergmann, R., & Wilke, W. (1995). Building refining abstract planning cases changerepresentation language.. Journal Artificial Intelligence Research, 3, 53{118.Carbonell, J. (1983). Learning analogy: Formulating generalizing plans pastexperience. Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine Learning:Artificial Intelligence approach, Vol. 1. Palo Alto, CA: Tioga Press.DeJong, G., & Mooney, R. (1986). Explanation-based learning: alternative view. Machine Learning, 1 (2), 145{176.Doorenbos, R. (1995). Production Matching Large Learning Systems. Ph.D. thesis,Computer Science Department, Carnegie Mellon University.Fikes, R., & Nilsson, N. (1971). new approach application theorem provingproblem solving. Artificial Intelligence, 2, 189{208.Fox, S., & Leake, D. (1995). Using introspective reasoning refine indexing. ProceedingsIJCAI-95.195fiIhrig & KambhampatiFrancis, A., & Ram, S. (1995). comparative utility analysis case-based reasoningcontrol-rule learning systems. Proceedings 8th European ConferenceMachine Learning, ECML-95.Friedland, P., & Iwasaki, Y. (1985). concept implementation skeletal plans.Journal Automated Reasoning, 1 (2), 161{208.Gratch, J., & DeJong, G. (1992). Composer: probabilistic solution utility problemspeed-up learning. Proceedings AAAI-92.Hammond, K. (1990). Explaining repairing plans fail. Artificial Intelligence, 45,173{228.Hanks, S., & Weld, D. (1995). domain-independent algorithm plan adaptation. JournalArtificial Intelligence Research, 2, 319{360.Hendler, J., Stoffel, K., & Mulvehill, A. (1996). High performance support case-basedplanning applications. Technological Achievements Arpa/Rome LaboratoryPlanning Initiative: Advanced Planning Technology. AAAI Press.Ihrig, L., & Kambhampati, S. (1994a). Derivation replay partial-order planning.Proceedings AAAI-94.Ihrig, L., & Kambhampati, S. (1994b). Plan-space vs state-space planning reusereplay. Tech. rep. 94-006, Department Computer Science Engineering. ArizonaState University. Also available http://rakaposhi.eas.asu.edu/yochan.html.Ihrig, L., & Kambhampati, S. (1996). Design implementation replay frameworkbased partial order planner. Proceedings AAAI-96.Joslin, D., & Roach, J. (1990). theoretical analysis conjunctive goal problems. ArtificialIntelligence, 41, 97{106.Kambhampati, S. (1992). Utility tradeoffs incremental modification reuse plans.Proceedings AAAI Spring Symposium Computational Considerations SupportingIncremental Modification Reuse.Kambhampati, S. (1994). Exploiting causal structure control retrieval refittingplan reuse. Computational Intelligence, 10.Kambhampati, S., & Chen, J. (1993). Relative utility ebg based plan reuse partial ordering vs total ordering planning. Proceedings AAAI-93, pp. 514{519. Washington,D.C.Kambhampati, S., & Hendler, J. A. (1992). validation structure based theory planmodification reuse. Artificial Intelligence, 55, 193{258.Kambhampati, S., Ihrig, L., & Srivastava, B. (1996a). candidate set based analysissubgoal interactions conjunctive goal planning. Proceedings 3rd Intl. Conf.AI Planning Systems.196fiStoring Indexing Plan DerivationsKambhampati, S., Katukam, S., & Qu, Y. (1996b). Failure driven dynamic search controlpartial order planners: explanation-based approach. Artificial Intelligence, 88,253{315.Kambhampati, S., Knoblock, C., & Yang, Q. (1995). Planning refinement search:unified framework evaluating design tradeoffs partial-order planning. ArtificialIntelligence, 76, 167{238.Koehler, J. (1994). Avoiding pitfalls case-based planning. Proceedings 2nd Intl.Conf. AI Planning Systems.Korf, R. (1987). Planning search: qualitative approach. Artificial Intelligence, 33,65{68.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsAAAI-91.Minton, S. (1990a). Issues design operator composition systems. ProceedingsInternational conference Machine Learning.Minton, S. (1990b). Quantitative results concerning utility explanation-based learning. Artificial Intelligence, 42, 363{392.Mostow, J., & Bhatnagar, N. (1987). Failsafe: oor planner uses ebg learnfailures. Proceedings IJCAI-87.Munoz-Avilla, H., & Weberskirch, F. (1996). Planning manufacturing workpiecesstoring, indexing replaying planning decisions. Proceedings 3rd Intl.Conf. AI Planning Systems. AAAI-Press.Munoz-Avilla, H., & Weberskirch, F. (1997). case study mergeability casespartial-order planner. Proceedings 4th European Conf. Planning.Ram, A., & Cox, M. (1994). Introspecive reasoning using meta-explanations multistrategy learning. Michalski, R., & Tecuci, G. (Eds.), Machine Learning: multistrategyapproach Vol. IV. Morgan Kaufmann.Ram, S., & Francis, A. (1996). Multi-plan retrieval adaptation experience-basedagent. Leake, D. B. (Ed.), Case-Based Reasoning: experiences, lessons, futuredirections. AAAI Press/The MIT Press.Redmond, M. (1990). Distributed cases case-based reasoning:facilitating use multiplecases. Proceedings AAAI-90.Smyth, B., & Keane, M. (1995). Remembering forget: competence-preserving deletionpolicy cbr. Proceedings IJCAI-95.Tambe, N., Newell, A., & Rosenbloom, P. (1990). problem expensive chunkssolution restricting expressiveness. Machine Learning, 5, 299{349.Tate, A. (1977). Generating project networks. Proceedings IJCAI-77.197fiIhrig & KambhampatiVeloso, M. (1994). Planning learning analogical reasoning. Springer Verlag. Number886 Lecture Notes Artificial Intelligence.Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Proceedings 2nd Intl. Conf. AI Planning Systems.Veloso, M., & Carbonell, J. (1993a). Derivational analogy prodigy: Automating caseacquisition, storage utilization. Machine Learning, 10, 249{278.Veloso, M., & Carbonell, J. (1993b). Toward scaling machine learning: case studyderivational analogy prodigy. Minton, S. (Ed.), Machine Learning methodsplanning. Morgan Kaufmann.Yang, Q., Nau, D., & Hendler, J. (1992). Merging separately generated plans restrictedinteractions. Computational Intelligence, 8 (2), 648{676.198fiJournal Artificial Intelligence Research 7 (1997) 1{24Submitted 2/97; published 7/97Defining Relative Likelihood Partially-OrderedPreferential StructuresJoseph Y. HalpernCornell University, Computer Science DepartmentIthaca, NY 14853http://www.cs.cornell.edu/home/halpernhalpern@cs.cornell.eduAbstractStarting likelihood preference order worlds, extend likelihoodordering sets worlds natural way, examine resulting logic. Lewis earlierconsidered notion relative likelihood context studying counterfactuals,assumed total preference order worlds. Complications arise examiningpartial orders present total orders. subtleties involving exactapproach lifting order worlds order sets worlds. addition,axiomatization logic relative likelihood case partial orders gives insightconnection relative likelihood default reasoning.1. Introductionpreference order set W worlds exive, transitive relation W . Variousreadings given relation literature; u v interpreted \uleast preferred desirable v" (Kraus, Lehmann, & Magidor, 1990; Doyle, Shoham,& Wellman, 1991) (it reading leads term \preferential structure"), \uleast normal (or typical) v" (Boutilier, 1994), \u remote actualityv" (Lewis, 1973). paper, focus one interpretation, essentially alsoconsidered Lewis (1973). interpret u v meaning \u least likely v".1Interestingly, readings seem lead much properties.literature, preference orders mainly used give semantics conditional logics (Lewis, 1973) and, recently, nonmonotonic logic (Kraus et al., 1990).basic modal operator papers conditional !, p ! q interpreted \in preferred/normal/likely worlds satisfying p, q case". However,view representing likelihood, seems natural define binary operatorformulas ' interpreted \' likely ". Lewis (1973)fact define operator, showed related !. However, assumedtotal; is, assumed worlds w; w0 2 W , either w w0w0 w. many cases preferential likelihood reasoning, seems appropriate allow preference order partial. may well agent finds two1. tradition, starting Lewis (1973), taking u v, rather u v, mean upreferred desirable v. last reading historically comes interpretationpreferred world less far actuality. Since seems split readingliterature, traditionally taken mean \at least likely" literature qualitativeprobability (Fine, 1973; Gardenfors, 1975), take reading here.c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHalpernsituations incomparable far normality likelihood goes. example, one situationmay better one dimension worse another.show paper, subtleties involved starting partialpreference order worlds. ultimately interested ordering worlds,ordering sets worlds. make sense statement like ' , needcompare relative likelihood set worlds satisfying ' set satisfying. Unfortunately, many possible ways extending preference order worldsone sets worlds. focus two particular choices, agreedefinition given Lewis case preference order worlds total, differgeneral. define using definition allows us make interestingwork default reasoning.turn attention axiomatizing likelihood operator. Lewis providedaxiomatization case preference order partial. key axioms usedLewis transitivity:('1 '2 ) ^ ('2 '3 ) ) ('1 '3 );union property:('1 '2 ) ^ ('1 '3 ) ) ('1 ('2 _ '3 )):latter property characteristic possibility logic (Dubois & Prade, 1990).partially ordered case, axioms suce. need following axiom:(('1 _ '2 ) '3 ) ^ (('1 _ '3 ) '2 ) ) ('1 ('2 _ '3 )):hard show axiom implies transitivity union property (inpresence axioms), equivalent them. Interestingly,property captured axiom isolated (Friedman & Halpern, 1997)key feature needed likelihood ordering sets appropriate defaultreasoning spirit (Kraus et al., 1990). Thus, considering preference orderspartial, able clarify connections , !, default reasoning.rest paper organized follows. Section 2, consider goordering worlds one sets worlds, focusing differences totalpartial preference orders. Section 3, present logic reasoning relativelikelihood provide natural complete axiomatization it. Section 4, relateresults work relative likelihood, well work conditional logicnonmonotonic reasoning. conclude Section 5. Proofs technical resultsfound Appendix A.2. Preorders Worlds Preorders Sets Worldscapture likelihood ordering set W possible worlds partial preorder |thatis, exive transitive relation| W .2 typically write w0 w rather2. partial order R typically assumed exive, transitive, anti-symmetric (so (a; b) 2 R(b; a) 2 R, = b). assuming anti-symmetric here,preorder.2fiRelative Likelihood Partially-Ordered Preferential Structures(w0 ; w) 2 . usual, often write u v rather v u, take u vabbreviation u v not(v u), u v abbreviation v u.relation strict partial order , is, irre exive (for w, casew w) transitive relation W . say strict partial order determined.said introduction, think providing likelihood, preferential, order worlds W . Thus, w w0 holds w least likely/preferred/normal/closeactuality w0 . Given interpretation, fact assumed partialpreorder easy justify. example, transitivity says u least likelyv, v least likely w, u least likely w. Notice sincepartial preorder, may pairs worlds w w0 incomparableaccording . Intuitively, may prepared say either one likelierother. say total preorder (or connected, linear preorder)worlds w w0 , either w w0 w0 w.Since added likelihood worlds, seems reasonable also add likelihoodlanguage, allow us say \' likely ", example.exactly mean? Although semantic model allows us sayone world likely another, immediately tell us say setworlds likely another set. But, observed introduction,need make sense \' likely ".extend likelihood ordering worlds one sets worlds? Clearlywant way preserves ordering worlds. is, using >denote ordering sets, would certainly expect u v would imply fug > fvg.could impose minimal requirements, certainly would enoughuniquely determine ordering sets. example, two general approaches;distinguish them, put subscripts >.1. Define >1 U >1 V u 2 U v 2 V , u v.define strict partial order spirit two distinct ways.(a) considering analogous procedure used get : define>2 U >2 V U >1 V not(V >1 U ). call standard methodbelow.(b) replacing definition >1 : define >3 U >3 Vu 2 U v 2 V , u v. call alternative method.2. Define >4 U >4 V v 2 V , U , u 2 U , Vu v. Note approach focuses symmetric difference UV . two ways getting strict partial order.(a) standard method gives us U >5 V U >4 V not(V >4 U ).(b) alternative method gives us U >6 V v 2 V , Uu 2 U , V u v.first approach ( >1 ) used Doyle, Shoham, Wellman (1991) defininglogic relative desire, starting preference order worlds. Unfortunately,3fiHalpernpoint out, relations weak allow us make importantdistinctions. go define notions comparison, tunedapplications, spirit notions considering here.second approach (typically >4 >5 ) widely used various applicationsliterature. example,Dershowitz Manna (1979) use define ordering multisets,used provide technique proving program termination.Przymusinski (1987) uses order models database.Brass (1991), Cayrol, Royer, Saurel (1992), Delgrande (1994), Geffner (1992)use help model various aspects default reasoning.paper, focus variant second approach, essentially due Lewis(1973), interesting connections default reasoning. Roughly speaking, takeU likely V every world V , likely world U .make precise, U; V W , write U V every world v 2 V ,world u 2 U u v. easy check partial preorder, is,exive transitive. (The superscript \set".) Moreover, total preorder,. Finally, would expect, u v iff fug fvg, relationsets worlds viewed generalization relation worlds.apply standard method alternative method definestrict partial order. standard method gives us relation 0 , U 0 V holdsU V not(V U ). alternative method gives us relation definedfinite sets taking U V hold U nonempty, every world v 2 V ,world u 2 U u v. (The reasons U taken nonemptydefinition restricted finite sets discussed below.)various approaches compare? Clearly U >1 V implies U V , althoughconverse hold general; >1 weak ordering. consequence, >20 incomparable, >3 s. Similar remarks apply >4 . Again, easysee U >4 V implies U V . hand, two notions equivalent.example, suppose v v0 . fvg fv; v0 g, fvg >4 fv; v0 g.focusing , 0 , here, rather >1 { >6 (or notion)? likelihood viewpoint, seem reasonable; intuitions regardingextending likelihood worlds sets worlds seem well developed.may possible motivate finest relation extending certain properties, fact motivation here. Rather, interest motivateddeep connections 0 certain approaches nonmonotonic reasoning.said that, many questions consider could perfectly well explored using >1 { >6 . apology, discuss >1 { >6 paper,except odd remark.explained two methods getting strict partial order setsworlds partial order worlds. standard method alternativemethod really different? easy see u v iff fug fvg iff fug 0 fvg. (Thistrue >2 , >3 , >5 , >6 well.) Thus, 0 agree singleton setsextend relation worlds. Moreover, 0 strict partial orders4fiRelative Likelihood Partially-Ordered Preferential Structuresfinite sets. (The requirement U must nonempty definition U Vensure ; ;; strictly speaking, also addeddefinitions >3 >6 ensure strict partial orders.) shownLemma 2.9, 0 fact identical underlying preorder worlds totalpreorder. However, following example shows, 0 identical general.Example 2.1: Suppose W = fw1 ; w2 g, w1 w2 incomparable.easy see fw1 ; w2 g 0 fw1 g. However, case fw1 ; w2 gfw1 g, since element fw1 ; w2 g strictly likely w1 .3Notice careful define finite sets. followingexample illustrates why:Example 2.2: Let W1 = fw0 ; w1 ; w2 ; : : :g, supposew0 w1 w2 : : :easy see apply definition infinite sets,would W1 W1 , would irre exive.4approach extending definition infinite sets essentially dueLewis (1973) (who case total preorders). idea say orderU V , enough every element v V element uU likely v. definition allows W1 W1 Example 2.2.Notice finite case, easy see U V , every element vV , must u 2 U that, u v, u dominates Vv0 2 V v0 u. precisely domination conditionhold Example 2.2. observation provides motivation ocial definitions, applies finite infinite domains.Definition 2.3: Suppose partial preorder W , U; V W , w 2 W . sayw dominates V v 2 V case v w. (Notice totalpreorder, equivalent saying w v v 2 V .) write U V Unonempty and, v 2 V , exists u 2 U u v u dominates V .easy see definition agrees earlier definitions U Vfinite.collect properties , 0 , . this, need definitions.say relation > 2W (not necessarily preorder) qualitative (V1 [ V2 ) > V3(V1 [ V3 ) > V2 implies V1 > (V2 [ V3 ). say > satisfies union propertyV1 > V2 V1 > V3 implies V1 > (V2 [ V3). say > orderly U > V , U 0 U ,V 0 V implies U 0 > V 0 . provide intuition properties followingProposition 2.5, showing help us characterize , 0 , .3. remark similar results hold >5 >6 . identical underlying order worldstotal preorder, example also used show differ underlying orderpartial.4. Similar problems arise >6 dealing infinite sets, solution describedDefinition 2.3 applied >6 well.5fiHalpernLemma 2.4: > orderly qualitative relation 2W , > transitive satisfiesunion property.Proof: See Appendix A.converse Lemma 2.4 hold. Indeed, orderly strict partial order2W may satisfy union property still qualitative. example, supposeW = fa; b; cg, fa; bg > fcg, fa; cg > fbg, fa; b; cg > fbg, fa; b; cg > fcg,fa; b; cg > fb; cg. easily checked > orderly strict partial ordersatisfies union property, qualitative.definitions hand, state key properties relationsinterested here.Proposition 2.5:(a) partial preorder W , orderly partial preorder 2Wsatisfies union property.(b) partial preorder W , 0 orderly strict partial order 2W .(c) strict partial order W , orderly qualitative strict partialorder 2W .Proof: See Appendix A.discuss interpret properties considering lightresult.extent think > meaning \more likely than", orderlinessnatural property require. U likely V , certainly superset Ulikely subset V . thus surprising threerelations defined orderly.Clearly union property generalizes arbitrary finite unions. is, > satisfiesunion property > Bi , = 1; : : : ; n, > B1 [ : : : [ Bn . particular,u vj j = 1; : : : ; N , fug fv1 ; : : : ; vN g, matter large N is, similarlyreplace (since fact qualitative means satisfies unionproperty, Lemma 2.4). different probability, suciently many\small" probabilities eventually dominate \large" probability. suggestsu v perhaps interpreted \u much likely v". generally,> satisfies union property, U > V interpreted meaning Umuch likely V . sense, notion likelihood correspondingcloser possibility (Dubois & Prade, 1990) probability, since relation \morepossible than" satisfies union property.Note that, general, 0 satisfy union property. Example 2.1,fw1 ; w2 g 0 fw1 g fw1 ; w2 g 0 fw2 g, fw1 ; w2 g 0 fw1 ; w2 g.qualitative property somewhat dicult explain intuitively. threerelations considering, relation satisfies it. fact 0satisfy follows Lemma 2.4, together observation 0 satisfyunion property. Example 2.1 also shows qualitative, since were,6fiRelative Likelihood Partially-Ordered Preferential Structurescould conclude fw1 ; w2 g fw2 g (taking V1 = fw1 g V2 = V3 = fw2 gdefinition qualitative) fw1 g fw2 g, contradiction. interest qualitativeproperty stems fact that, precise sense, property characterizess. first arose (Friedman & Halpern, 1997), shown key propertyrequired generalization probability called plausibility capture default reasoning.discussed detail Section 4.total preorder, get connections notions.discuss details, need define analogue total preorders strict case.relation > arbitrary set W 0 (not necessarily form 2W ) modular w1 >w2implies that, w3 , either w3 > w2 w1 > w3 . Modularity \footprint" totalpreorder strict order determined it. made precise following lemma.Lemma 2.6: total preorder, strict partial order determinedmodular. Moreover, > modular, strict partial order W , totalpreorder W > strict partial order determined .Proof: See Appendix A.Modularity preserved lift preorder W 2W .Lemma 2.7: modular relation W , modular relation 2W .Proof: See Appendix A.Although showed converse Lemma 2.4 hold general strictpartial orders, hold orders modular.Lemma 2.8: > modular strict partial order satisfies union property,> qualitative.Proof: See Appendix A.shown (Friedman & Halpern, 1997), connection nonmonotonicreasoning, conditional logic, qualitative property. (This discussed Section 4.)relationship best understood considering s, rather 0 ,focus here. Lewis (1973) able use 0 focused total preorders.following lemma makes precise.Lemma 2.9: total preorder, 0 agree. general, U V impliesU 0 V , converse hold.Proof: See Appendix A.close section considering preorder 2W viewedgenerated preorder W . result turns play key role completenessproof, emphasizes role qualitative property.Theorem 2.10: Let F finite algebra subsets W (that is, F set subsetsW closed union complementation contains W itself) let >orderly qualitative relation F .7fiHalpern(a) > total preorder F , total preorder W >agree F (that is, U; V 2 F , U > V iff U V ).(b) > strict partial order nonempty set F least 2log(jFj)elements, partial preorder W > agree F .log(jF j)Proof: atom F minimal nonempty element F . Since F finite, easysee every element F written union atoms, atoms disjoint.Part (a) easy: w 2 W , let Aw unique atom F containing w. DefineW v w iff Av > Aw . easy see > total preorder F ,total preorder W > agrees F . proof (b) considerablydicult; see Appendix details.clear requirement sets F least 2log(jFj)elementsnecessary. However, shown Theorem 2.10(b) hold withoutassumptions cardinality elements F . example, suppose atomsF A, B , C . Let > defined (B [ C ) >A, W >A, X > ; nonemptyX 2 F , pairs sets > relation. easy see> orderly, qualitative, strict partial order. However, W = fa; b; cg, = fag,B = fbg, C = fcg, ordering W > agree F :easy see ordering must make a, b, c incomparable.incomparable, cannot fb; cg fag. hand, allow C twoelements, taking W = fa; b; c; dg, = fag, B = fbg, C = fc; dg,ordering = >: simply take c b d.log(jF j)3. Logic Relative Likelihoodconsider logic reasoning relative likelihood. Let set primitivepropositions. basic likelihood formula (over ) one form ' , 'propositional formulas . read ' \' likely ". Let Lconsist Boolean combinations basic likelihood formulas. Notice allownesting likelihood L, allow purely propositional formulas. woulddiculty extending syntax semantics deal them, would obscureissues interest here.preferential structure (over ) tuple = (W; ;), W (possiblyinfinite) set possible worlds, partial preorder W , associatesworld W truth assignment primitive propositions . Notice maytwo worlds truth assignment. shall see, general, needthis, although case total preorders, assume without loss generalityone world associated truth assignment.give semantics formulas L preferential structures straightforwardway. propositional formula ', let [ '] consist worlds whose truthassignment satisfies '. definej= ' [ '] [ ] .extend j= Boolean combinations basic formulas obvious way.8fiRelative Likelihood Partially-Ordered Preferential StructuresNotice j= :(:' false) iff [ :'] = ; iff [ '] = W . Let K' abbreviation :(:' false). follows j= K' iff ' true possible worlds.5definitions, provide sound complete axiomatizationlogic relative likelihood. Let AX consist following axioms inference rules.L1.L2.L3.L4.Gen.MP.substitution instances tautologies propositional calculus:(' ')(('1 _ '2 ) '3 ) ^ (('1 _ '3 ) '2 ) ) ('1 ('2 _ '3 ))(K (' ) '0 ) ^ K ( 0 ) ) ^ (' )) ) '0 0K', propositional tautologies ' (Generalization)' ' ) infer (Modus ponens)L2, L3, L4 express fact irre exive, qualitative, orderly,respectively; made precise proof following result. axiom Genanalogue inference rule \From ' infer K'", typically known generalization.inference rule here, since language allow nested occurrences. Thus, arbitrary formula ', formula K' language.language ' propositional; axiom takes care case.Theorem 3.1: AX sound complete axiomatization language L respectpreferential structures.Proof: validity L1 immediate. clear fact irre exivequalitative, shown Proposition 2.5, implies L2 L3 valid. see L4corresponds orderliness, note j= K (' ) '0 ) ^ K ( 0 ) ) ' ,[ '] [ '0 ] , [ 0 ] [ ] , [ '] [ ] . Since orderly, follows[ '0 ] [ 0 ] , j= '0 0 . Thus, L4 valid. also clear MP Genpreserve validity. Thus, axiomatization sound.completeness proof starts out, standard completeness proofs modal logic,observation suces show consistent formula satisfiable.is, must show every formula ' case :' provableAX satisfiable preferential structure . However, standard modallogic techniques constructing canonical model (see, example, (Hughes & Cresswell,1968)) seem work case. Finding appropriate partial preorder worldsnontrivial. use (part (b) of) Theorem 2.10. See Appendix details.happens start total preorder? Let AXM consist AX togetherobvious axiom expressing modularity:L5. ('1 '2 ) ) (('1 '3 ) _ ('3 '2 ))say preferential structure totally preordered form (W; ; ),total preorder W .5. K defined Lewis (1973), although wrote 2 rather K .9fiHalpernTheorem 3.2: AXM sound complete axiomatization language L respecttotally preordered preferential structures.Proof: soundness, check L5 valid totally ordered preferentialstructures. straightforward left reader. completeness proof usesTheorem 2.10 again, simpler proof completeness Theorem 3.1.leave details Appendix A.remark light Proposition 2.8, replace L4 AXM axioms sayingtransitive satisfies union property, namely:L6. ('1 '2 ) ^ ('2 '3 ) ) ('1 '3 )L7. (('1 '2 ) _ ('1 '3 )) ) ('1 ('1 _ '2 ))result axiomatization similar given Lewis (1973).proof Theorem 3.1, showing consistent formula ' satisfiable,structure constructed may one world truth assignment.necessary, following example shows. (We remark observation closelyrelated cardinality requirements Theorem 2.10(b).)Example 3.3: Suppose = fp; qg. Let ' formula (p (:p ^ q)) ^ :((p ^ q)(:p ^ q)) ^:((p ^:q) (:p ^ q)). easy see ' satisfied structure consistingfour worlds, w1 ; w2 ; w3 ; w4 , w1 w3 , w2 w4 , p ^ q true w1 , p ^:q truew2 , :p ^ q true w3 w4 . However, ' satisfiable structureone world satisfying :p ^ q. suppose structure,let w world satisfying :p ^ q. Since j= p (:p ^ q), mustcase [ p] fwg. Thus, must world w0 2 [ p] w0 w. w0must satisfy one p ^ q p ^ :q, j= ((p ^ q) (:p ^ q)) _ ((p ^ :q) (:p ^ q)),contradicting assumption j= '.hard see formula ' Example 3.3 satisfiable totallypreordered preferential structure. accident.Proposition 3.4: formula satisfiable totally preordered preferential structure,satisfiable totally preordered preferential structure one world pertruth assignment.Proof: See Appendix A.results previous section help emphasize differencestotally preordered partially preordered structures.4. Related Workrelated literature basically divides two groups (with connections them):(a) approaches relative likelihood (b) work conditional nonmonotoniclogic.10fiRelative Likelihood Partially-Ordered Preferential Structuresfirst consider relative likelihood. Gardenfors (1975) considered logic relativelikelihood, took primitive total preorder sets 2W , focusedconnections probability. particular, added axioms ensure that, given preorder2W , probability function Pr property (in notation)U V iff Pr(U ) Pr(V ). Fine (1973) defines qualitative notion comparativeprobability, like Gardenfors, assumes preorder sets primitive,largely concerned connections probability.Halpern Rabin (1987) consider logic likelihood absolute statementslikelihood made (' likely, somewhat likely, on), notionrelative likelihood.course, many quantitative notions likelihood, probability,possibility (Dubois & Prade, 1990), ordinal conditional functions (OCFs) (Spohn, 1988),Dempster-Shafer belief functions (Shafer, 1976). ones closest relative likelihood considered possibility OCFs. Recall possibility measure PossW associates world possibility, number [0; 1], V W ,Poss(V ) = supfPoss(v) : v 2 V g, requirement Poss(W ) = 1. Clearlypossibility measure places total preorder sets, satisfies union property, sincePoss(A [ B ) = max(Poss(A); Poss(B )). true OCFs; refer reader(Spohn, 1988) details. Fari~nas del Cerro Herzig (1991) define logic QPL(Qualitative Possibilistic Logic) modal operator , ' interpretedPoss([['] ) Poss([[ ] ). Clearly, ' essentially corresponds '. providecomplete axiomatization logic, prove equivalent Lewis' logic.6surprisingly, analogue AX also complete logic. discussionlogic found (Bendova & Hajek, 1993). discuss connectionspossibility measures, OCFs, logic below, context conditionals.turn attention conditional logic. Lewis's main goal considering preferential structures capture counterfactual conditional !, ! ' read\if case, ' would true" \if kangaroos tails,would topple over". takes true world w if, worlds \closest"w (where closeness defined preorder ) kangaroos don't tails,case kangaroos topple over.7abstractly, case W finite, subset V W , let best(V ) = fv 2V : v0 v implies v0 2= V g. Thus, best(V ) consists worlds v 2 V worldv0 2 V considered likely v. (We take best(;) = ;.)W finite, define(M; w) j= ! ' best([[ ] ) [ '] .Thus,true.! ' true exactly ' true likely (or closest) worlds '6. Actually, axiomatization given (Fari~nas del Cerro & Herzig, 1991) quite complete stated;get completeness, must replace axiom QPL4|true '|by axiom ' false [Luis Fari~nasdel Cerro, private communication, 1996].7. really deal appropriately counterfactuals, require one preorder , possibly differentpreorder w world w, since notion closeness general depends actual world.ignore issue here, since somewhat tangential concerns.11fiHalperninfinite domains, definition quite capture intentions. example,Example 2.2, best(W1 ) = ;. follows = (W1 ; ; ), j=true ! :p even makes p true every world W1 . certainly would wantsay \if true case, p would false" true p true worldsW1 ! solution generalization Lewis's definition case totallyordered worlds, much like infinite domains. say j= ! 'u 2 [ :' ^ ] , exists world v 2 [ ' ^ ] v u v dominates[ :' ^ ] . definition agrees definition given case finite W .Lemma 4.1: W finite, best([[ ] ) [ '] iff u 2 [ :' ^ ] , existsworld v 2 [ ' ^ ] v u v dominates [ :' ^ ] .Proof: See Appendix A.Lewis (1973) argues definition ! captures many intuitions counterfactual reasoning. give ! another interpretation, perhaps naturalthinking terms likelihood. often want say ' likely not|in L,expressed ' :'. generally, might want say relative ,conditional case, ' likely not. meanrestrict worlds true, ' likely not, is, worlds ' ^true likely worlds :' ^ true.Let us define !0 ' abbreviation K : _ (' ^ :' ^ ). is,!0 ' true vacuously structure hold world ; otherwise,holds ' likely worlds satisfying .Although intuition !0 seems, surface, quite different !,especially finite domains, almost immediate formal definitionsequivalent. (This connection ! !0 already observed Lewis (1973)case total proeorders.)Lemma 4.2: structures , j= ! ' iff j= !0 '.Proof: almost immediate definitions. See Appendix details.Given Lemma 4.2, write ! ! !0 . lemma also allows usapply known results conditional logic logic relative likelihood defined here.particular, results (Friedman & Halpern, 1994) show validity problemlogic Section 3 co-NP complete, harder propositional logic,case partial total preorders.8recently, ! used capture nonmonotonic default reasoning (Kraus et al.,1990; Boutilier, 1994). case, statement like Bird ! Fly interpreted \birdstypically y", \by default, birds y". semantics change: Bird ! Flytrue likely worlds satisfying Bird , Fly holds well. Dubois Prade (1991)shown possibility used give semantics defaults well, ! '8. remark also well known axiomatizations various conditional logics (Burgess, 1981;Friedman & Halpern, 1994; Lewis, 1973). immediately give us complete axiomatizationlogic relative likelihood considered here, since must find axioms language ,language !.12fiRelative Likelihood Partially-Ordered Preferential Structuresinterpreted Poss( ) = 0 Poss(' ^ ) > Poss(' ^ : ). course,analogue definition ! terms s. Goldszmidt Pearl (1992) shownsimilar approach works use Spohn's OCFs.results clarified unified (Friedman & Halpern, 1997). Suppose startmapping Pl sets partially ordered space minimal element ? (suchmapping called plausibility measure (Friedman & Halpern, 1997)). Define ! 'Pl(') = ? Pl( ^ ') > Pl( ^ :'). shown ! satisfies KLMproperties|the properties isolated Kraus, Lehmann, Magidor (1990) formingcore default reasoning|if Pl qualitative, least restricted disjointsets.9 Since s, Poss, OCFs give rise qualitative orders 2W , surpriselead logics satisfy KLM properties.remark also start !, define terms !. are,fact, three related ways so. Define ' 0 abbreviation ((' _ ) ! (' ^: )) ^:((' _ ) ! ); define ' 00 abbreviation :(' ! ) ^ ((' _ ) ! : );define ' 000 abbreviation :(' ! false) ^ ((' _ ) ! (' ^ : )).Proposition 4.3: structures , following equivalent:(a) j= '(b) j= ' 0(c) j= ' 00 .(d) j= ' 000 .first translation essentially due Kraus, Lehmann, Magidor (1990), second essentially due Freund (1993), third due Lewis (1973). Sinceequivalences close already literature, omit proof resulthere. Using equivalences results (Kraus et al., 1990), Daniel Lehmann [privatecorrespondence, 1996] provided alternate proof Theorem 3.1. See remarksproof theorem Appendix details.5. Conclusioninvestigated notion relative likelihood starting preferential orderingworlds. notion earlier studied Lewis (1973) case preferentialorder total preorder; focus paper case preferential orderpartial preorder. results show significant differences totallyordered partially ordered case. focusing partially ordered case, bringkey role qualitative property (Axiom L3), whose connections conditional logicalready observed (Friedman & Halpern, 1997).9. is, V1 , V2 , V3 disjoint sets, require Pl(V1 [V2 ) > Pl(V3 ) Pl(V1 [V3 ) > Pl(V2 ),Pl(V1 ) > Pl(V2 [ V3 ). result also requires assumption Pl(U ) = Pl(V ) = ?,Pl(U [ V ) = ?.13fiHalpernAcknowledgementsMany interesting useful discussions plausibility Nir Friedman formed basispaper; Nir also pointed reference (Doyle et al., 1991). Daniel Lehmann,Emil Weydert, referees paper also provided useful comments. preliminaryversion paper appears Uncertainty Artificial Intelligence, ProceedingsTwelfth Conference, 1996, edited E. Horvitz F. Jensen. workcarried author IBM Almaden Research Center. IBM's supportgratefully acknowledged. work also supported part NSF grantsIRI-93-03109 IRI-96-25901, Air Force Oce Scientific Researchcontract F49620-96-1-0323.Appendix A. Proofsrepeat statements results proving conveniencereader.Lemma 2.4: > orderly qualitative relation 2W , > transitivesatisfies union property.Proof: Suppose > orderly qualitative relation. see > transitive, supposeV1 > V2 V2 > V3. Since > orderly, follows (V1 [ V3 ) > V2 (V1 [ V2 ) > V3 .Since > qualitative, follows V1 > (V2 [ V3 ). fact > orderly,get V1 > V3 . Thus, > transitive, desired.see > satisfies union property, suppose V1 > V2 V1 > V3 . Since >orderly, (V1 [ V3) >V2 (V1 [ V2) >V3 . Using fact > qualitative,get V1 > (V2 [ V3 ). Hence, > satisfies union property.Proposition 2.5:(a) partial preorder W , orderly partial preorder 2Wsatisfies union property.(b) partial preorder W , 0 orderly strict partial order 2W .(c) strict partial order W , orderly qualitative strict partialorder 2W .Proof: prove part (c) here; proof parts (a) (b) similar spirit,left reader. fact orderly strict partial order straightforward,also left reader. see qualitative, suppose V1 [ V2 V3V1 [ V3 V2 . Let v 2 V2 [ V3 . must show v0 2 V1 dominatesV2 [ V3 v0 v. Suppose without loss generality v 2 V2 (an identicalargument works v 2 V3 ). Since V1 [ V3 V2 , u 2 V1 [ V3 dominatesV2 u v. u dominates V3 , clearly dominates V2 [ V3 mustV1 , done. Thus, assume u dominate V3 ,element u0 2 V3 u0 u. Since V1 [ V2 V3 , must v0 2 V1 [ V214fiRelative Likelihood Partially-Ordered Preferential Structuresv0 dominates V3 v0 u0 . Since u dominates V2 u0 u, follows udominates V2 . Since v0 u0 , v0 dominates V2 . Hence, v0 dominates V2 [ V3 .follows v0 cannot V2 , must V1 . Thus, element V1 ,namely v0 , v0 v v0 dominates V2 [ V3 , desired.Lemma 2.6: total preorder, strict partial order determinedmodular. Moreover, > modular, strict partial order W , totalpreorder W > strict partial order determined .Proof: Suppose total preorder. see modular, suppose w1 w2 .Given arbitrary w3 , w3 w1 , follows transitivity w3 w2 .hand, case w3 w1 , w1 w3 . Thus, eitherw3 w2 w1 w3 , modular.suppose > modular strict partial order W . Define w veither w > v neither w > v v > w hold. Clearly, exive. seetransitive, suppose v1 v2 v2 v3 . three cases: (1) v1 > v2 ,since > modular, either v1 > v3 v3 > v2 . cannot v3 > v2 ,would v2 v3 . Thus, must v1 > v3 , hence v1 v3 . (2)v2 > v3 , using modularity again, get either v1 > v3 v2 > v1. Again,cannot v2 > v1 , must v1 > v3 , also v1 v3 . (3) neitherv1 >v2 v2 >v3 hold, claim neither v1 >v3 v3 >v1 hold. v1 >v3 ,modularity, must either v1 > v2 v2 > v3 . v3 > v1 , eitherv3 > v2 v2 > v1 , contradicts assumption v1 v2 v2 v3 . Thus,conclude v1 v3 . Thus, transitive. Finally, almost immediatedefinition > strict partial order determined .Lemma 2.7: modular relation W , modular relation 2W .Proof: Suppose modular. want show modular. supposeV1 V2 , case V1 V3. must show V3 V2 . Sincecase V1 V3 , must v 2 V3 u 2 V1 ,u v . suppose v 2 V2. claim v v. see this, note since V1 V2 ,must u 2 V1 u v. Since modular, eitheru v v v. Since, choice v , u v , must v v.follows V3 V2 .Lemma 2.8: > modular strict partial order satisfies union property,> qualitative.Proof: Suppose > modular strict partial order satisfies union property.see > qualitative, suppose (V1 [ V2 ) > V3 (V1 [ V3 ) > V2 . Since >modular, follows either (V1 [ V2 ) > V1 V1 > V3 . (V1 [ V2 ) > V1 , then, usingfact > satisfies union property (V1 [ V2 ) >V3 , get (V1 [ V2 ) > (V1 [ V3 ).Using transitivity, follows (V1 [ V2 ) > V2 . Using union property again, get(V1 [ V2 ) > (V1 [ V2 ). contradicts assumption > irre exive. Thus,15fiHalpernmust V1 >V3 . similar argument shows V1 >V2 . Using union property,get V1 > (V2 [ V3 ), desired.Lemma 2.9: total preorder, 0 agree. general, U V impliesU 0 V , converse hold.Proof: immediate definitions U V implies U 0 V , factconverse hold shown Example 2.1. show 0 equivalenttotal preorder, suppose U 0 V . Clearly U nonempty, since V ; V .want show U V , must show v 2 V , u 2 Udominates V u v. actually show u 2 Uu v0 v0 2 V . Suppose not. every u 2 U , vuu vu . Since total order, means vu u. this, turn, meansV U , contradicting assumption U V . Since u 2 Uu v v 2 V , easily follows u dominates V U V , desired.Theorem 2.10: Let F finite algebra subsets W (that is, F set subsetsW closed union complementation contains W itself) let >orderly qualitative relation F .(a) > total preorder F , total preorder W >agree F (that is, U; V 2 F , U > V iff U V ).(b) > strict partial order nonempty set F least 2log(jFj)elements, partial preorder W > agree F .log(jF j)Proof: Part (a) already proved main text, prove part (b) here.proceed follows. say pair (A; X ) minimal pair > X >X 0 X (\" used denote strict subset) X 0 > A.minimal pairs ordered relation determine it. Indeed, following stronger resultholds.Lemma A.1: > >0 two orderly qualitative relations Fminimal pair (A; X ) > X > A, minimal pair (A0 ; X 0 ) >0X 0 >0 A0 , > = >0 .Proof: Suppose assumptions lemma holds X > ; must showX >0 . Suppose atom . Since > orderly, must X >A.Let X 0 minimal subset X X 0 > A. Since F finite, X 0 mustexist. Thus, (A; X 0 ) minimal pair >. assumption, X 0 >0 A. Since >0orderly, also X >0 A. Thus, X >0 atom . Since>0 qualitative, also satisfies union property, hence X >0 desired.symmetry, follows > = >0 .minimal-pair tree > rooted tree whose nodes labeled atomsfollowing conditions satisfied:16fiRelative Likelihood Partially-Ordered Preferential Structures1. node tree labeled B immediate successor node labeled A,must minimal pair (A; X ) > B X .2. node tree labeled minimal pair > form (A; X ),must atom B X node labeled B immediatesuccessor t.3. exist path tree two nodes pathlabel.4. node two distinct successors label.minimal-pair tree rooted root tree labeled atom A.Since subset F written unique way union atoms,1-1 correspondence subsets F sets atoms. Thus, exactlylog(jFj) atoms. third condition, path tree lengthlog(jFj). Since atoms path must distinct, followslog(jFj)! log(jFj)log(jFj) (= jFjlog log(jFj) ) possible paths tree rootedA. identify tree set paths, means2log(jFj)! 2log(jFj)possible trees rooted atom A.label element W minimal-pair tree way everyelement atom labeled tree rooted A, every minimal-pair tree rootedlabel element A. Since assumed least 2log(jFj)elements, labeling. Let L(w) label node w. define Ww0 w iff L(w0 ) proper subtree L(w). Clearly strict partial order.claim > agrees s. Lemma A.1, suces show (A; X )minimal pair >, X A, (A; X ) minimal pair , X > A.suppose (A; X ) minimal pair >. want show X A. Let w 2 A,suppose L(w) = . Thus, minimal-pair tree rooted A. constructionminimal-pair trees guarantees successor root tree labeled Batom B X . Consider subtree rooted B . minimal-pair treerooted B , hence must label w0 2 B X . Thus, w0 w. followsX A.suppose (A; X ) minimal pair . want show X > A.Suppose not. show below, means exists minimal-pair tree rootednode labeled atom contained X . Let w elementL(w) = . construction, element w0 X w0 w. Thus,X A, contradicting initial assumption.remains show exists minimal-pair tree rootednode labeled atom contained X . Clearly, cannot X 0 >X 0 X , then, preceding argument, would X 0 A, (A; X ) wouldminimal pair s. follows (A; ) minimal pair >, must, X 6= ;.Two general fact orderly, qualitative relations useful construction:log(jF j)log(jF j)Lemma A.2: >0 qualitative relation F >0 X , (Y , X ) >0 X .17fiHalpernProof: Notice (Y , X ) [ X >0 X . Since >0 qualitative, follows (Y , X ) >0 X(take V2 V3 definition qualitative X ).Lemma A.3: >0 orderly, qualitative relation (X1 [ X2 ) >0 X3X 0 >0 X2 , (X1 [ X 0 ) >0 X3 .Proof: Since >0 orderly, assumptions imply (X1 [ X 0 [ X2 ) >0 X3(X1 [ X 0 [ X3 ) >0 X2 . Since >0 qualitative, follows (X1 [ X 0 ) > (X2 [ X3 ).result follows using fact >0 orderly again.start constructing tree whose nodes labeled atoms whose rootlabeled A. proceed log(jFj) + 1 stages. stage, tree whose nodeslabeled atoms. stage 0, take single node labeled A. Supposeconstructed tree whose nodes labeled atoms whose root labeledstage k < log(jFj). stage k + 1, leaf stage-k tree, labeledB , atom C , minimal pair (B; ) > C , addsuccessor labeled C . call tree constructed end stage log(jFj) fulltree A.next mark nodes full tree stages. kth stage, atom B ,mark unmarked node labeled B one following three conditions holds: (1)B X , (2) ancestor tree also labeled B , (3) minimal pair(B; ) > successors label contained marked earlierstage. unmarked nodes satisfying one three conditions stage k,marking process stops. Otherwise, continue stage k +1. Sincefinitely many nodes, marking process guaranteed terminate.goal show that, end marking process, root full treeunmarked. case, let subtree full tree consistingunmarked nodes whose ancestors unmarked. easy checkminimal-pair tree marking procedure guarantees node labeledatom contained X , done.see root full tree unmarked, proceed follows: Define 0-covernode full tree itself. Suppose defined k-cover t.set Z nodes (k + 1)-cover exists k-cover Z 0node t0 Z 0 labeled B minimal pair (B; ) >, Z consistsnodes Z 0 except t0 , together successors t0 labeledatom contained . easy argument induction k shows following.Lemma A.4: Z k-cover node labeled C k > 0, exist set(C; ) minimal pair >, successors t1 ; : : : ; tm full tree, atomsD1 ; : : : ; Dm = [mi=1Di Di label ti , = 1; : : : ; m, partitionZ1 ; : : : ; Zm Z disjoint subsets Zi ki -cover ti, = 1; : : : ; m,ki < k.Given set Z , let UZn consist union atoms labeling nodes Z stillunmarked nth stage (we take UZ0 union atoms labeling nodesZ ); given node t, let Vt consist union atoms labeling ancestorsdescendent label D.key fact following result.18fiRelative Likelihood Partially-Ordered Preferential StructuresLemma A.5: Z k-cover node labeled C k > 0, (UZn [ Vt [ X ) > C .Proof: proceed induction k, subinduction n. k = 1,set (C; ) minimal pair > nodes Z labeledatoms contained . Since (C; ) minimal pair >, > C . Since >orderly, (Y [ Vt [ X ) > C . definition, UZ0 = , takes care case n = 0.Suppose n > 0 (UZn,1 [ Vt [ X ) > C . inductive step, suces show(Y 0 [ V [ X ) > C(1)label node t0 Z marked stage n,((Y 0 , D) [ Vt [ X ) > C:(2)suppose (1) holds label t0 . must consider t0 marked.X (2) immediate. ancestor t0 also labeled D, Vt ,and, since k = 1, Vt Vt [ C . Thus, since > orderly, follows00((Y 0 , D) [ Vt [ X [ C ) > C;(3)(2) follows Lemma A.2. Finally, suppose minimal pair (D; 00 )> successors t0 labeled atom 00 marked stage n , 1.Let Z 0 consist successors t0 labeled atoms contained 00 . Z 0 1-covert0 . Since UZn,1 = ;, follows induction hypothesis (Vt [ X ) > D. Again,since Vt Vt [ C , (3) follows orderliness Lemma A.3, desired (2) followsLemma A.2.suppose k > 1. Let Y; D1 ; : : : ; Dm ; Z1 ; : : : ; Zm ; t1 ; : : : ; tm sets nodesguaranteed exist Lemma A.4. Since Zi ki -cover ti ki < k,induction hypothesis, (UZn [ Vt [ X ) > Di . Since UZn UZn Vt Vt [ C ,orderliness, (UZn [ Vt [ X [ C ) > Di . Since > qualitative,(UZn [ Vt [ X [ C ) > ([i Di ). Since [iDi = > C , (3) follows, (2)follows Lemma A.2.Finally, suppose, way contradiction, root r full tree marked, saystage n marking process. Lemma A.2 assures us \ X = ;, since (A; X )minimal pair s, condition (1) marking process apply. Since rancestors, condition (2) apply either. Thus, must minimalpair (A; ) > nodes set Z consisting successors rfull tree labeled atoms contained marked stage n , 1. Thus,UZn,1 = ;. Since Vr = ; Z 1-cover r, Lemma A.5, follows X > A,contradicting original assumption.000completeness theorems (Theorems 3.1 3.2) convenient start proving Theorem 3.2, since simpler, contains key ideas proof Theorem 3.1.Theorem 3.2: AXM sound complete axiomatization language Lrespect totally preordered preferential structures.19fiHalpernProof: Soundness proved main text, consider completeness here.Suppose ' consistent AXM . want show ' satisfiabletotally preordered preferential structure. Let '1 ; : : : ; 'm basic likelihood formulassubformulas '. definition, ' Boolean combination formulas.Define atom ' conjunction form 1 ^ : : : ^ , either 'i:'i. Using straightforward propositional reasoning (L1 MP), straightforwardshow ' provably equivalent disjunction consistent atoms '. Thus,since ' consistent, atom ', say , consistent. construct totallyordered preferential structure satisfying . Clearly structure satisfy ' well.Let p1 ; : : : ; pn primitive propositions appear '. Let consistN = 2n truth assignments primitive propositions. take W =let F consist subsets . define total preorder > F follows. Noticeset V F , corresponds propositional formula 'V made trueprecisely truth assignments subset V 0 corresponds V .precise, given truth assignment ff, let 'ff consist conjunction q1 ^ : : : ^ qn, qipi ff(pi ) = true, :pi otherwise. Let 'V disjunction formulas 'ffff 2 V 0 . (We take empty disjunction formula false.) Notice future reference'V [V provably equivalent 'V _ 'V . Conversely, every propositional formulamentions primitive propositions fp1 ; : : : ; pn g, correspondingsubset F consists truth assignments make true.define binary relation > F follows: V > V 0 iff AX ` ) ('V 'V ).claim > modular, qualitative, strict partial order F . fact >irre exive follows easily L2; fact orderly follows L4; factqualitative follows L3; transitivity follows fact > qualitativeorderly, Lemma 2.4; modularity follows L5. arguments straightforward. prove fact > qualitative here, leave remaining argumentsreader.Suppose V1 ; V2 ; V3 2 F , (V1 [ V2 ) > V3 , (V1 [ V3 ) > V2 . assumptionsdefinition F imply AX ` ) (('V _ 'V ) 'V ) AX ` )(('V _ 'V ) 'V ). L3 straightforward propositional reasoning, getAX ` ) ('V ('V _ 'V )), V1 > (V2 [ V3), desired.Lemma 2.6, total preorder >0 F > strict partial orderdetermined >0 . Theorem 2.10(a), total preorder W >0agree F . Since 0 strict partial order determined s, follows 0> agree. Since total preorder, Lemma 2.9, > agree. Let = (W; ; ).claim formula 'j one basic likelihood formulassubformula ', j= 'i iff 'j conjunct . suppose 'j form 0 .'j conjunct , clearly AX ` ) ( 0 ). Thus, > definition,construction. Since consist worlds W0 , respectively, true, follows (M; w) j= 0 . hand, :'jconjunct , AX ` ) :( 0 ). must (M; w) j= :( 0 ),(M; w) j= 0 , arguments would imply > ,AX ` ) 0 , contradicting consistency .Thus, satisfies , hence '.12120113232122000020fiRelative Likelihood Partially-Ordered Preferential StructuresTheorem 3.1: AX sound complete axiomatization language L respectpreferential structures.Proof: Again, soundness proved main text, consider completeness.ideas much spirit proof Theorem 3.2. take consistN = 2n truth assignments primitive propositions. However, since planapply part (b) Theorem 2.10, longer take W = . Rather, take W consist2n copies truth assignments . precisely, let W consist N 2nworlds form wffi , = 1; : : : ; 2n ff 2 . Let F consist subsetsW correspond subsets ; is, V 2 F iff exists V 0V = fwffi : = 1; : : : ; 2n ; ff 2 V 0 g. Clearly, F finite algebra N elements,nonempty set F least 2log(jFj)elements.define strict partial order > F proof Theorem 3.1: V > V 0 iffAX ` ) 'V 'V . before, > orderly qualitative strict partial order F .necessarily modular, since longer L5.Theorem 2.10(b), partial preorder W > agreeF . Let = (W; ; ), (wffi ) = ff. proof Theorem 3.2,show j= . .nnnnlog(jF j)0noted earlier, Daniel Lehmann found another proof Theorem 3.1, usingresults (Kraus et al., 1990). show formula L consistent AXsatisfiable, first translates formula conditional logic (using Proposition 4.3).follows representation theorem (Kraus et al., 1990) translatedformula satisfiable preferential structure. original formula satisfiablestructure. proof allows us avoid using Theorem 2.10 altogether. However,feel Theorem 2.10 gives insight connection partial orders worldspartial orders sets worlds, thus interest right.Proposition 3.4: formula satisfiable totally preordered preferential structure,satisfiable totally preordered preferential structure one world pertruth assignment.Proof: follows immediately completeness proof Theorem 3.2; structureconstructed proof one world per truth assignment.Lemma 4.1: W finite, best([[ ] ) [ '] iff u 2 [ :' ^ ] ,exists world v 2 [ ' ^ ] v u v dominates [ :' ^ ] .Proof: Suppose best([[ ] ) [ '] . u 2 [ :' ^ ] , cannot u 2best([[ ] ), since best([[ ] ) [ '] . Since W finite, exists world v 2 best([[ ] )v u. Since v 2 best([[ ] ), v dominates [ :' ^ ] . Conversely,suppose u 2 [ :' ^ ] , exists world v 2 [ ' ^ ] v uv dominates [ :' ^ ] . u 2 best([[ ] ), must u 2 [ '] , not,exists world v 2 [ ' ^ ] v u, contradicting assumptionu 2 best([['] ).21fiHalpernLemma 4.2: structures , j= ! ' iff j= !0 '.Proof: Suppose j= ! '. definition, means u 2 [ :' ^ ] ,exists world v 2 [ ' ^ ] v u v dominates [ :' ^ ] . immediatelyfollows (a) [ ' ^ ] = ; [ :' ^ ] = ; (b) [ ' ^ ] 6= ;,definition j= ' ^ :' ^ . follows (a) [ ' ^ ] = ;[ ] = ;, j= K : , (b) [ ' ^ ] 6= ; j= ' ^ :' ^ .Thus, j= K : _ (' ^ :' ^ ); i.e., j= !0 .converse follows equally easily. Suppose j= !0 '. Clearly j= K :trivially u 2 [ :' ^ ] , exists world v 2 [ ' ^ ]v u v dominates [ :' ^ ] . hand, j= ' ^ :' ^ ,follows definition u 2 [ :' ^ ] , exists world v 2 [ ' ^ ]v u v dominates [ :' ^ ] . Either way j= ! '.ReferencesBendova, K., & Hajek, P. (1993). Possibilistic logic tense logic. Carrete, N. P., &Singh, M. G. (Eds.), Qualitative Reasoning Decision Technologies, pp. 441{450.Boutilier, C. (1994). Conditional logics normality: modal approach. Artificial Intelligence, 68, 87{154.Brass, S. (1991). Deduction super-normal defaults. Proceedings 2nd InternationalWorkshop Nonmonotonic Inductive Logics, Lecture Notes AI, Vol. 659, pp.153{174 Berlin/New York. Springer-Verlag.Burgess, J. (1981). Quick completeness proofs logics conditionals. Notre DameJournal Formal Logic, 22, 76{84.Cayrol, C., Royer, R., & Saurel, C. (1992). Management preferences assumptionbased reasoning. IPMU '92 (4th International Conference Information Processing Management Uncertainty Knowledge-Based Systems), Lecture NotesComputer Science, Vol. 682, pp. 13{22 Berlin/New York. Springer-Verlag.Delgrande, J. P. (1994). preference-based approach default reasoning. Proceedings,Twelfth National Conference Artificial Intelligence (AAAI '94), pp. 902{908.Dershowitz, N., & Manna, Z. (1979). Proving termination multiset orderings. Communications ACM, 22 (8), 456{476.Doyle, J., Shoham, Y., & Wellman, M. P. (1991). logic relative desire. Proc. 6thInternational Symposium Methodologies Intelligent Systems, pp. 16{31.Dubois, D., & Prade, H. (1990). introduction possibilistic fuzzy logics.Shafer, G., & Pearl, J. (Eds.), Readings Uncertain Reasoning, pp. 742{761. MorganKaufmann, San Francisco, Calif.22fiRelative Likelihood Partially-Ordered Preferential StructuresDubois, D., & Prade, H. (1991). Possibilistic logic, preferential models, non-monotonicityrelated issues. Proc. Twelfth International Joint Conference Artificial Intelligence (IJCAI '91), pp. 419{424.Fari~nas del Cerro, L., & Herzig, A. (1991). modal analysis possibilistic logic.Symbolic Quantitative Approaches Uncertainty, Lecture Notes ComputerScience, Vol. 548, pp. 58{62. Springer-Verlag, Berlin/New York.Fine, T. L. (1973). Theories Probability. Academic Press, New York.Freund, M. (1993). Injective models disjunctive relations. Journal Logic Computation, 3 (3), 231{247.Friedman, N., & Halpern, J. Y. (1994). complexity conditional logics. PrinciplesKnowledge Representation Reasoning: Proc. Fourth International Conference(KR '94), pp. 202{213. Morgan Kaufmann, San Francisco, Calif.Friedman, N., & Halpern, J. Y. (1997). Plausibility measures default reasoning. JournalACM. Accepted publication. preliminary version work appearedProc. National Conference Artificial Intelligence (AAAI '96), 1996, pages 1297{1304.Gardenfors, P. (1975). Qualitative probability intensional logic. Journal Philosophical Logic, 4, 171{185.Geffner, H. (1992). High probabilities, model preference default arguments. MindMachines, 2, 51{70.Goldszmidt, M., & Pearl, J. (1992). Rank-based systems: simple approach beliefrevision, belief update reasoning evidence actions. PrinciplesKnowledge Representation Reasoning: Proc. Third International Conference (KR'92), pp. 661{672. Morgan Kaufmann, San Francisco, Calif.Halpern, J. Y., & Rabin, M. O. (1987). logic reason likelihood. ArtificialIntelligence, 32 (3), 379{405.Hughes, G. E., & Cresswell, M. J. (1968). Introduction Modal Logic. Methuen,London.Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferentialmodels cumulative logics. Artificial Intelligence, 44, 167{207.Lewis, D. K. (1973). Counterfactuals. Harvard University Press, Cambridge, Mass.Przymusinski, T. (1987). declarative semantics stratified deductive databseslogic programs. Minker, J. (Ed.), Foundations Deductive Databases LogicProgramming, pp. 193{216. Morgan Kaufmann, San Francisco, Calif.Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, N.J.23fiHalpernSpohn, W. (1988). Ordinal conditional functions: dynamic theory epistemic states.Harper, W., & Skyrms, B. (Eds.), Causation Decision, Belief Change,Statistics, Vol. 2, pp. 105{134. Reidel, Dordrecht, Netherlands.24fiJournal Artificial Intelligence Research 7 (1997) 231-248Submitted 7/97; published 11/97Dynamic Non-Bayesian Decision MakingDov MondererMoshe Tennenholtzdov@ie.technion.ac.ilmoshet@ie.technion.ac.ilIndustrial Engineering ManagementTechnion { Israel Institute TechnologyHaifa 32000, IsraelAbstractmodel non-Bayesian agent faces repeated game incomplete information Nature appropriate tool modeling general agent-environmentinteractions. model environment state (controlled Nature) may change arbitrarily, feedback/reward function initially unknown. agent Bayesian,form prior probability neither state selection strategy Nature,reward function. policy agent function assigns actionevery history observations actions. Two basic feedback structures considered.one { perfect monitoring case { agent able observe previousenvironment state part feedback, { imperfect monitoringcase { available agent reward obtained. settingsrefer partially observable processes, current environment state unknown.main result refers competitive ratio criterion perfect monitoring case.prove existence ecient stochastic policy ensures competitiveratio obtained almost stages arbitrarily high probability, eciencymeasured terms rate convergence. shown optimalpolicy exist imperfect monitoring case. Moreover, provedperfect monitoring case exist deterministic policy satisfies longrun optimality criterion. addition, discuss maxmin criterion provedeterministic ecient optimal strategy exist imperfect monitoring casecriterion. Finally show approach long-run optimality viewedqualitative, distinguishes previous work area.1. IntroductionDecision making central task artificial agents (Russell & Norvig, 1995; Wellman,1985; Wellman & Doyle, 1992). point time, agent needs select amongseveral actions. may simple decision, takes place once,complicated decision series simple decisions made. question\what right actions be" basic issue discussed settings,fundamental importance design artificial agents.static decision-making context (problem) artificial agent consists set actions agent may perform, set possible environment states, utility/rewardfunction determines feedback agent performs particular actionparticular state. problem best represented matrix columns indexedstates, rows indexed actions rewards entries. rewardfunction known agent say agent payoff uncertaintyc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMonderer Tennenholtzrefer problem problem incomplete information(Fudenberg & Tirole, 1991).modeling problem incomplete information one must also describe underlying assumptions knowledge agent reward function. example,agent may know bounds rewards, may know (or partially know) underlyingprobabilistic structure1 . dynamic (multistage) decision-making setup agent facesstatic decision problems stages. stage agent selects action performed environment selects state. history actions states determinesimmediate reward well next one-shot decision problem. history actionsstates also determines next selected state. Work reinforcement learning artificial intelligence (Kaelbling, Littman, & Moore, 1996) adopted view agentoperating probabilistic Bayesian setting, agent's last action last statedetermine next environment state based given probability distribution. Naturally,learner may a-priori familiar probability distribution, existenceunderlying probabilistic model key issue system's modeling. However,assumption ultimate one. particular, much work areas AIeconomics dealt non-probabilistic settings environment changesunpredictable manner2 . agent know uence choicesselection next state (i.e., certain environment strategy),say agent strategic uncertainty.paper use general model representation agent-environment interactions agent payoff strategic uncertainty. dealnon-Bayesian agent faces repeated game incomplete information Nature.repeated game Nature agent faces static decision problemstage environment state taken action chosen opponents.decision problem called game stress fact agent's actionstate independently chosen. fact game repeated refers factset actions, set possible states, one shot utility functionvary time3 . said, consider agent payoff uncertaintystrategic uncertainty. is, a-priori ignorant utility function (i.e.,game incomplete information) well state selection strategy Nature.agent non-Bayesian sense assume probabilistic modelconcerning nature's strategy sense assume probabilisticmodel concerning reward function, though may assume lower upper bounds4 .consider two examples illustrate above-mentioned notions model. Consider1. example, agent may know probability distribution set reward functions, may assumeprobability exists without assumption structure, may partial informationdistribution ignorant parameters (e.g., may believe rewardfunction drawn according normal distribution unknown covariance matrix).2. many intermediate cases assumed changes probabilistic nonMarkovian structure.3. general setup, sets may vary time. useful analysis done modelchanges completely arbitrary.4. Repeated games complete information, generally, multistage games stochastic gamesextensively studied game theory economics. partial list includes: (Shapley,1953; Blackwell, 1956; Luce & Raiffa, 1957), recently (Fudenberg & Tirole, 1991; Mertens,Sorin, & Zamir, 1995), evolving literature learning (e.g., Fudenberg & Levine 1997).incomplete information setup player ignorant game played inspired232fiDynamic Non-Bayesian Decision Makinginvestor, , investing daily certain index stock market. daily profitsdepends action (selling buying certain amount) environment state{ percentage change price index. investor complete informationreward function knows reward realized particularinvestment particular change, strategic uncertainty changesindex price. So, playing repeated game complete informationNature strategic uncertainty.Consider another investor, 1, invests particular mutual fund. fund investsstock market strategy known investor. Assumestate represents vector percentage changes stocks, investorknow reward function. example, cannot say advance would profitwould buy one unit fund stock prices increase 1 percent. Thus, 1plays repeated game incomplete information. addition 1 attemptconstruct probabilistic model concerning reward function market behavior,non-Bayesian analysis may apply him. another example, assume Bobdecide evening whether prepare tea coffee wife getshome. wife wishes drink either tea coffee wishes ready her.reaction Bob's wife tea coffee may depend state day,predicted based history actions states previous days. Bobgot married cannot tell reward get wife happy makescup tea. course may eventually know it, decisions learningperiod precisely subject paper.example generality above-mentioned setting, consider modelMarkov decision processes complete incomplete information. Markov decisionprocess agent's action given state determines (in probabilistic fashion) nextstate obtained. is, agent structural assumption state selectionstrategy. repeated game Nature without added assumptions captures facttransition state state may depend history arbitrary way.agent performs action state st , part feedback would u(at; st ),u reward function. distinguish two basic feedback structures.one { perfect monitoring case { agent able observe previousenvironment state part feedback, { imperfect monitoringcase { available agent reward obtained5 . Noticefeedback structures, current state observed agent calledselect action6 . investors 1 face repeated game perfect monitoringpercentage changes become public knowledge iteration.example, Bob make decision, situation imperfectmonitoring, Bob would able observe reward behavior (e.g., whether(Harsanyi, 1967). See Aumann Maschler (1995) comprehensive survey.literature deals (partially) Bayesian agents. rare exceptions cited Section 6.5. Notice former assumption popular related game theory literature (Aumann &Maschler, 1995). Many intermediate monitoring structures may interesting well.6. also case evolving literature problem controlling partially observable Markovdecision processes (Lovejoy, 1991; Cassandra, Kaelbling, & Littman, 1994; Monahan, 1982). contrast,Q-learning theory (Watkins, 1989; Watkins & Dayan, 1992; Sutton, 1992) assume knowledgecurrent state.233fiMonderer Tennenholtzsays \thanks", \that's terrible", \this exactly wanted", etc.). perfectmonitoring case, Bob able observe wife's state (e.g., whether came homehappy, sad, nervous, etc.) addition reward. cases Bob (like investors)able observe wife's state making decision particular day.Consider case one stage game Nature, utility functionknown, agent cannot observe current environment state selectingaction. agent choose action? Work decision making uncertaintysuggested several approaches (Savage, 1972; Milnor, 1954; Luce & Raiffa, 1957; Kreps,1988). One approaches maxmin (safety-level) approach. Accordingapproach agent would choose action maximizes worst case payoff. Anotherapproach competitive ratio approach (or additive variant, termed minmaxregret decision criterion (Milnor, 1954). According approach agent would chooseaction minimizes worst case ratio payoff could obtainedknown environment state payoff would actually obtain.7 Returningback example, Bob would known actual state wife, could chooseaction maximizes payoff. Since hint state, go aheadchoose action minimizes competitive ratio. example, action leadscompetitive ratio two, Bob guarantee payoff would gethalf payoff could gotten known actual state wife.Given repeated game incomplete information Nature, agent wouldable choose one stage optimal action (with respect competitive ratiomaxmin value criteria) stage, since utility function initially unknown. So,Bob initially know reward would receive actions functionwife's state, able simply choose action guarantees bestcompetitive ratio. calls precise definition long-run optimality criterion.paper mainly concerned policies (strategies) guaranteeing optimalcompetitive ratio (or maxmin value) obtained stages. interestedparticular ecient policies, eciency measured terms rate convergence.Hence Bob's case, interested policy adopted Bob would guaranteealmost day, high probability, least payoff guaranteed actionleading competitive ratio. Moreover, Bob wait muchstart getting type satisfactory behavior.Section 2 define mentioned setting introduce preliminaries.Sections 3 4 discuss long-run competitive ratio criterion: Section 3 showeven perfect monitoring case, deterministic optimal policy exist.However, show exists ecient stochastic policy ensureslong-run competitive ratio criterion holds high probability. Section 4 showstochastic policies exist imperfect monitoring case. Section 5prove perfect imperfect monitoring cases exists deterministicecient optimal policy long-run maxmin criterion. Section 6 comparenotions long-run optimality criteria appearing related literature.particular, show approach long-run optimality interpreted7. competitive ratio decision criterion found useful settings on-linealgorithms (e.g., Papadimitriou & Yanakakis, 1989).234fiDynamic Non-Bayesian Decision Makingqualitative, distinguishes previous work area. also discussconnections work work reinforcement learning.2. Preliminaries(one-shot) decision problem (with payoff certainty strategic uncertainty) 3-tuple=< A; S; u >, finite sets u real-valued function definedu(a; s) > 0 every (a; s) 2 . Elements called actionscalled states. u called utility function. interpretation numericalvalues u(a; s) context-dependent8 . Let nA denote number actions A, let nSdenote number states let n = max(nA ; nS ).above-mentioned setting classical static setting decision making,uncertainty actual state nature (Luce & Raiffa, 1957). paperdeal dynamic setup, agent faces decision problem D, withoutknowing utility function u, infinite number stages, = 1; 2; : : :.explained introduction, setting enables us capture general dynamic nonBayesian decision-making contexts, environment may change behaviorarbitrary unpredictable fashion. mentioned introduction, best capturedmeans repeated game Nature. state environment pointplays role action taken Nature corresponding game. agent knowssets , know payoff function u.9 dynamic decision problem(with payoff uncertainty strategic uncertainty) therefore represented agentpair DD =< A; > finite sets10. stage t, Nature chooses state st 2 .agent, know chosen state, chooses 2 A, receives u(at; st).distinguish two informational structures. perfect monitoring case, statest revealed agent alongside payoff u(at; st). imperfect monitoring case,states revealed agent. generic history available agent stage +1denoted ht . perfect monitoring case, ht 2 Htp = (A R+ )t , R+ denotesset positive real numbers. imperfect monitoring case, ht 2 Htimp = (A R+ )t.particular case = 0 assume H0p = H0imp = feg singleton containingpimp = [1 H imp . symbol Hempty history e. Let H p = [1t=0 Ht let Ht=0used H p H imp . strategy11 agent dynamic decision problemfunction F : H ! (A) , (A) denotesP set probability measures A.is, every ht 2 H , F (ht ) : ! [0; 1] a2A F (ht )(a) = 1. words,agent observes history ht chooses at+1 randomizing amongst actions,probability F (ht )(a) assigned action a. strategy F called pure F (ht )probability measure concentrated singleton every 0.Sections 2{4 strategy recommended agent chosen according \longrun" decision criterion induced competitive ratio one-stage decision criterion.8. See discussion Section 6.9. results paper remain unchanged agent initially know set , ratherupper bound nS .10. Notice need include explicit transition function representation. duefact non-Bayesian setup every transition possible.11. Strategy decision theoretic concept. coincides term policy used control theoryliterature, term protocol used distributed systems literature.235fiMonderer Tennenholtzcompetitive ratio decision criterion, described below, may used agentfaces decision problem once, knows payoff function u wellsets . \reasonable" decision criteria could used instead.One maxmin decision criterion discussed Section 5, anotherminmax regret decision criterion (Luce & Raiffa, 1957; Milnor, 1954). lattersimple variant competitive ratio (and treated similarly), thereforetreated explicitly paper.every 2 let (s) maximal payoff agent get state s.(s) = maxu(a; s):a2Aevery 2 2 definec(a; s) = uM(a;(ss)) :Denote c(a) = maxs2S c(a; s), letCR = minc(a) = minmax c(a; s) :a2Aa2A s2SCR called competitive ratio =< A; S; u >. action CR = c(a)called competitive ratio action, short CR action. agent chooses1 fraction could gotten,CR action guarantees receiving least CR1known state s. is, u(a; s) CR (s) every 2 . agent cannot guaranteebigger fraction.long-run decision problem, non-Bayesian agent form prior probabilityway Nature choosing states. Nature may choose fixed sequence states or,generally, use probabilistic strategy G, G : Q ! (S ), Q = [1t=0 Qt =t. Nature viewed second player knows reward function.[1()t=0strategy may course refer whole history actions states given pointmay depend payoff function.payoff function u pair probabilistic strategies F; G, G depend u,generate probability measure = F;G;u set infinite histories Q1 = (A )1endowed natural measurable structure. event B Q1 denoteprobability B according (B ) Prob (B ). precisely, probabilitymeasure uniquely defined values finite cylinder sets: Let : Q1 !St : Q1 ! coordinate random variables contain values actionsstates selected agent environment stage (respectively). is,At(h) = St(h) = st every h = ((a1; s1); (a2; s2); : : :) Q1 . every 1every ((a1; s1); : : :; (aT ; sT )) 2 QT ,Prob ((At; St) = (at; st) 1 ) =0t=1F ('t,1)(at )G( t,1)(st );'0 empty histories, 2t,1 = ((a1; s1 ); : : :; (at,1; st,1)) ;236fiDynamic Non-Bayesian Decision Makingdefinition 't,1 depends monitoring structure. perfect monitoringcase,'t,1 = ((a1 ; s1; u(a1; s1)); : : :; (at,1; st,1; u(at,1; st,1))) ;imperfect monitoring case't,1 = ((a1; u(a1; s1)); : : :; (at,1; u(at,1; st,1))) :define auxiliary additional random variables Q1 . PLet Xt = 1 c(At ; St) CR Xt = 0 otherwise, let NT = Tt=1 Xt .12 Let > 0.strategy F -optimal exists integer K every payoff function uevery Nature's strategy GProb (NT (1 , )T every K ) 1 ,(1)= F;G;u . strategy F optimal -optimal > 0.Roughly speaking, NT measures number stages competitive ratio (orbetter value) obtained first iterations. -optimal strategyexists number K , system runs K iterations get highprobability NT close 1 (i.e., almost iterations good ones). optimalstrategy guarantee get close wish situation iterationsgood ones, probability high wish. Notice requireabove-mentioned useful property hold every payoff function every strategyNature. strong requirement consequence non-Bayesian setup; sinceclue reward function strategy selected Nature (andstrategy may yield arbitrary sequences states reached), best policy wouldinsist good behavior behavior adopted Nature. Notice howevertwo relaxations introduced here; require successful behavior stages,whole process would successful (very high) probability.major objective find policy enable (1) hold every dynamicdecision problem every Nature strategy. Moreover, wish (1) hold small enoughK . K small agent benefit obtaining desired behavior alreadyearly stage. 13 subject following section. complete sectionuseful technical observation. show strategy F -optimal satisfiesoptimality criterion (1) every reward function every stationary strategynature, stationary strategy defined sequence states z = (st )1t=1 .strategy Nature chooses st stage t, independent history. Indeed, assume Fstrategy (1) holds every reward function every stationary strategyNature, show F -optimal.Given payoff function u strategy G, -optimality respect stationarystrategies implies = F;G;u ,Prob (NT (1 , )T every K )jS1; S2; : : :) 1 , ;12. Note function c(a; s) depends payoff function u therefore random variablesXt Nt .13. interested reader may wish think long-run optimality criteria view original workPAC learning (Valiant, 1984). setting, PAC learning, wish obtain desired behavior,situations, high probability, relatively fast.237fiMonderer Tennenholtzprobability one. ThereforeProb(NT (1 , )T every K ) 1 , :Roughly speaking, captures fact non-Bayesian settingneed present strategy good sequence states chosen Nature,regardless way chosen.3. Perfect Monitoringsection present main result. result refers case perfect monitoring, shows existence -optimal strategy case. also guaranteesdesired behavior obtained polynomially many stages. result constructive. first present rough idea strategy employed proof. utilityfunction known agent could use competitive ratio action. Sinceutility function initially unknown agent use greedy strategy,selects action optimal far competitive ratio concerned, accordingagent's knowledge given point. However, agent try time timesample random action.14 strategy chooses right tradeoff explorationexploitation phases order yield desired result. careful analysis neededorder prove optimality related strategy, fact yields desiredresult polynomially many stages.introduce main theorem.Theorem 3.1: Let DD =< A; > dynamic decision problem perfect monitoring.every > 0 exists -optimal strategy. Moreover, -optimal strategychosen ecient sense K (in (1)) taken polynomialmax(n; 1 ).Proof: Recall nA nS denote number actions states respectively,n = max(nA ; nS ). proof assume simplicity n = nA = nS .slight modifications required removing assumption. Without loss generality,< 1. define strategy F follows: Let = 8 . is,1= 8:stage 1 construct matrices UTF ; CTF subset actions WTfollowing way: Define U1F (a; s) = a; s. stage > 1, ,1performed stage , 1, sT ,1 observed, update U replacing(aT ,1; sT ,1) entry u(aT ,1; sT ,1). stage 1, UTF (a; s) = , defineF b;s)CTF (a; s) = 1. UTF (a; s) =6 , CTF (a; s) = maxfb:UTF (b;s)6=g UUTTF ((a;s) . Finally WT set2 minb2A maxs2S CTF (b; s) obtained. refer elements WTtemporarily good actions stage . Let (Zt)t1 sequence i.i.d. f0; 1g random14. use uniform probability distribution select among actions exploration phase. resultobtained different exploration techniques well.238fiDynamic Non-Bayesian Decision Makingvariables Prob(Zt = 1) = 1 , M1 . sequence generated part strategy,independent observed history. stage, choosing action,agent ips coin, independently past observations. stage agent observesZt. Zt = 1, agent chooses action Wt randomizing equal probabilities.Zt = 0 agent randomizes equal probabilities amongst actions A.complete description strategy F . Let u given payoff function, let (st)1t=1given sequence states. proceed show (1) holds K upperinteger value ff = max(ff1 + 2; ff2 + 2),256ff1 = 1282 ln 3n2 (n 8 + 1) lnff2 =3422n + 1:PRecall Xt = 1 c(At; st ) CR Xt = 0 otherwise, NT = Tt=1 Xt .slight change notation, denote P = Prob probability measure inducedF , u sequence states (A f0; 1g)1 (where f0; 1g corresponds Ztvalues).Let " = 8 . DefineBK =(TXt=1)1Zt 1 , , " K :Roughly speaking, BK captures cases temporarily good actions selectedstages.(Chernoff, 1952) (see also (Alon, Spencer, & Erdos, 1992)), every ,PXt=1!2Zt < (1 , 1 , ")T e, " 2T :Recall given set , denotes complement .Hence,!112XXX1Zt < (1 , , ")Te, " 2T :P (BK ) PThereforeSince K > ff1 ,Define:=kP (BK )t=1Z1k ,1e, " 2T dT = "22 e,2P (BK ) < 2=K"2 (K ,1)2:(2)LK = fNT (1 , )T every K g:Roughly speaking, LK captures cases competitive ratio actions (or betteractions regard) selected stages.order prove F -optimal (i.e., (1) satisfied), proveP (LK ) <239(3)fiMonderer Tennenholtz(2) suces prove(4)P (LK jBK ) 2define every 1, 2 2 six auxiliary random variables, Yt ; Rt; Yts ; Rst; Yts;a ; Rs;a.Let Yt = 1 whenever Zt = 1 Xt = 0, Yt = 0 otherwise. LetRT =Xt=1Yt :every 2 let Yts = 1 whenever Yt = 1 st = s, Yts = 0 otherwise. LetXYts :t=1Yts;a = 1RsT =every 2 every 2 A, letwhenever Yts = 1 = a,s;aYt = 0 otherwise. LetXRs;a=Yts;a :t=1Let g integer value 34 K . showP (LK jBK ) P(9T K ; RT gjBK )(5)order prove (5) showLK \ BK f9T K ; RT g g \ BK :Indeed, w path BK every K RT < g , then, w, everyK,XXNTXt VT , Yt;1tT;Zt=1t=1VT denotes number stages 1 Zt = 1. Since w 2 BK ,N (1 , 1 , ")T , R > (1 , 1 , ")T , gevery K . Since M1 = " = 8 g 34 K , NT (1 , )T every K . Hence,w 2 LK .(5) implies suces proveP(9T K ; RT gjBK ) 2Therefore suces prove every 2 ,P 9T K; RsT ng jBK 2n :Hence suces prove every 2 every 2 A,240(6)fiDynamic Non-Bayesian Decision Making= P 9T K;gRs;an2 jBK2n 2(7)gorder prove (7) , note inequality Rs;an2 satisfied gw,c(a; s) > CR nevertheless considered good action least n2 stagesb;s) > CR. b1 (w.l.o.g. assume ng2 integer). Let b 2 satisfy uu((a;s)ever played stage st = s, 62 Wt t. ThereforeP 9T K; b played first ng2 stages st = sjBK :Hence(1 , x1 )x+1 e,x x 1,ut1, 1nMg2n:ge, n2 (nM +1) < 2n 2 :Theorem 3.1 shows ecient dynamic non-Bayesian decisions may obtainedappropriate stochastic policy. Moreover, shows -optimality obtainedtime (low degree) polynomial max(n; 1 ). interesting question whethersimilar results obtained pure/deterministic strategy. following exampleshows, deterministic strategies suce job.give example agent optimal pure strategy.Example 1: Let = fa1; a2g = fs1; s2g. Assume negation agentoptimal pure strategy f .Consider following two decision problems whose rows indexed actionswhose columns indexed states:D1 =1 1030 2D2 =1 3010 2corresponding ratio matrices:C1 =30 11 5C2 =10 11 15241!!!!fiMonderer TennenholtzAssume addition cases Nature uses strategy g , defined follows:g (ht) = si f (ht) = ai , = 1; 2. is, every t, (at; zt ) = (a1; s1) (at; zt) = (a2; s2),zt denote action state selected stage t, respectively. Let < 0:25.Let NTi denote NT decision problem i. Since f -optimal, exists Kevery K , NT1 (1 , )T NT2 (1 , )T . Note also sequence((at; zt))t1 generated cases. NK1 (1 , )K implies (a2 ; s2) usedhalf stages 1; 2; : : :; K . hand, NK2 (1 , )K implies (a1; s1)used half stages 1; 2; : : :; K . contradiction.utanalytical completeness, end section proving existence optimalstrategy (and merely -optimal strategy). optimal strategy obtainedutilizing -optimal strategies (whose existence proved Theorem 3.1) intervalsstages sizes converge infinity, ! 0.Corollary 3.2: every dynamic decision problem perfect monitoring existsoptimal strategy.Proof: 1, let Fmsequence limm!1 = 0. Letevery 1-optimal strategy, (m )1 decreasingm=12(Km )1increasingsequenceintegersm=1Prob NT (1 , 2 )T every Km 1 , 2m ;PmKKm+1 2 j=1 j :Let F strategy 1 utilizes Fm stages K0 + : : : + Km,1 + 1K0 + : : : + Km,1 + Km, K0 = 0. easily verified F optimal.ut4. Imperfect Monitoringproceed give example imperfect monitoring case, sucientlysmall > 0, agent -optimal strategy.Example 2 (Non-existence -optimal strategies imperfect monitoring case)Let = fa1; a2g, = fs1 ; s2; s3g. Let < 0 , 0 defined endproof. Assume negation exists -optimal strategy F . Considerfollowing two decision problems whose rows indexed actions whose columnsindexed states:!22b2cD1 = b c242fiDynamic Non-Bayesian Decision Making!2a 2b 2cD2 =b ca; b c positive numbers satisfying: > 4b > 16c. = 1; 2, letCi = (ci (a; s))a2A;s2S ratio matrices. is:C1 =1 1 12 2 2!1 1 2ac2a 2b 1b cC2 =!Note a1 unique CR action D1 a2 unique CR action D2.Assume Nature uses strategy G randomizes stage equal probabilities(of 13 ) amongst 3 states. Given strategy Nature, agent cannot distinguishtwo decision problems, even knows Nature's strategy toldone chosen. implies 1 2 probability measures inducedF G (A )1 decision problems D1 D2 respectively, every2 f1; 2g, distribution stochastic process (NTi )1=1 respect j , j 2 f1; 2g,depend j . is, every 1Prob1 Nti 2 Mt = Prob2 Nti 2 Mt ; 2 f1; 2g (8)every sequence (Mt )Tt=1 Mt f0; 1; : : :; tg 1 .give complete proof (8), rather illustrate proving representingcase. reader easily derive complete proof. showProb1 (N21 = 0) = Prob2 (N21 = 0)(9)Indeed, j = 1; 2,Probj (N21 = 0) = 313Xk=1F (e)(a2)F (a2 ; uj (a2 ; sk ))(a2)(10)Let : f1; 2; 3g ! f1; 2; 3g defined (1) = 3, (2) = 1, (3) = 2.u1(a2 ; sk ) = u2 (a2; s(k) )every 1 k 3. Therefore (10) implies (9).F -optimal, exists integer K probability least1 , respect 1 , hence respect 2 , NT1 (1 , )T every K .implies probability least 1 , , a1 played least 1 ,stages time , K , particular = K . choose integer Ksuciently large according Law Large Numbers, Nature chooses243fiMonderer Tennenholtzs3 least 31 , stages stage K probability least 1 , . Let CR2c2t denote CR ct decision problem 2, respectively.> CR = max( 2a ; 2b ):22cb cTherefore, = a1, C2(At ; St) CR2 St =6 s3. Hence,2probability least 1 , 2 , + (1 , )( 3 + ) stages c2t CR2.Therefore F cannot -optimal, choose 0 20 < 1 , 0ut0 + (1 , 0)( 23 + 0 ) < 1 , 0 :5. Safety Levelsake comparison discuss section safety level (known also maxmin)criterion. Let =< A; S; u > decision problem. Denotev = maxminu(a; s)v called safety level agent (or maxmin value). Every actionu(a; s) v every called safety level action. consider imperfectmonitoring model dynamic decision problem < A; >. Every sequence statesz = (st)1t=1 st 2 every 1 every pure strategy f agent inducez;f 1sequence actions (at)1t=1 corresponding sequence payoffs (ut )t=1 ,z;fuz;f= u(at ; st) every 1. Let NT denote number stages stageagent's payoff exceeds safety level v . is,NTz;f = #f1 : uz;fvg(11)say f safety level optimal every decision problem every sequencestates,lim 1 N z;f = 1;!1convergence holds uniformly w.r.t. payoff functions u sequences states. is, every > 0 exists K = K ( ) NTz;f (1 , )T everyK every decision problem < A; S; u > every sequence states z .Proposition 5.1: Every dynamic decision problem possesses safety level optimal strategyimperfect monitoring case, consequently perfect monitoring case. Moreover,optimal strategy chosen strongly ecient sense everysequence states exists nA , 1 stages agent receives payoffsmaller safety level, nA denotes number actions.Proof: Let n = nA . Define strategy f follows: Play actionsfirst n stages. every n + 1, every history h = hT ,1 =244fiDynamic Non-Bayesian Decision Making((a1; u1); (a2; u2; : : :; (aT ,1; uT ,1)) define f (h) 2 follows: 2 A, let vTh (a) =min ut , min ranges stages , 1 = a. Define f (h) = ,maximizes vTh (a) 2 A. obvious every sequence states1z = (st )1t=1 n , 1 stages u(at ; st) < v , (at )t=1z;fsequence actions generated f sequence states. Hence NT , n,NTz;f defined (11). Thus K () = n , T1 NTz;f 1 , every K ( ).ut6. DiscussionNote notations established Section 5, Proposition 5.1 well, remainunchanged assume utility function u takes values totally pre-orderedset without group structure. is, approach decision making qualitative(or ordinal). distinguishes work previous work non-Bayesian repeatedgames, used probabilistic safety level criterion basic solution conceptone shot game15. works, including (Blackwell, 1956; Hannan, 1957; Banos, 1968;Megiddo, 1980), recently (Auer, Cesa-Bianchi, Freund, & Schapire, 1995; Hart& Mas-Colell, 1997), used several versions long-run solution concepts, basedoptimization average utility values time. is, Ppapersgoal find strategies guarantee high probability T1 Tt=1 u(At; St)close vp .work is, best knowledge, first introduce ecient dynamicoptimal policy basic competitive ratio context. study results sections 2-4easily adapted case qualitative competitive ratio well. approach,utility function takes values totally pre-ordered set G addition assumeregret function, maps G G pre-ordered set H . g1 ; g2 2 G, (g1; g2)level regret agent receives utility level g1 rather g2. Givenaction state s, regret function determine maximal regret, c(a; s) 2 Hagent action performed state s. is,c(a; s) = max (u(a; s); u(b; s));b ranges actions.qualitative regret action maximal regret action states.optimal qualitative competitive ratio obtained using actionqualitative regret minimal. Notice arithmetic calculations needed (or makesense) qualitative version. results adapted case qualitativecompetitive ratio. ease exposition, however, used quantitative versionmodel, numerical utility function represents regret function.15. probabilistic safety value, vp , agent decision problem =< A; S; u > maxminvalue max ranges mixed actions.vp = maxq2(A) mins2SXa2Au(a; s)q(a);(A) set probability distributions q A.245fiMonderer Tennenholtzwork relevant research reinforcement learning AI. Work area,however, dealt mostly Bayesian models. makes work complementarywork. wish brie discuss connections differenceswork existing work reinforcement learning.usual underlying structure reinforcement learning literature environment changes result agent's action based particular probabilisticfunction. agent's reward may probabilistic well.16 notation, Markovdecision process (MDP) repeated game Nature complete informationstrategic certainty, Nature's strategy depends probabilistically last actionstate chosen17 . Standard partially observable MDP (POMDP) described similarly introducing level monitoring perfect imperfect monitoring.addition, bandit problems basically modeled repeated games Natureprobabilistic structural assumption Nature's strategy , strategic uncertainty values transition probabilities. example, Nature's actionplay role state slot machine basic bandit problem. main difference classical problem problem discussed settingstate slot machine may change setting totally unpredictable manner (e.g.,seed machine manually changed iteration). saysolving learning problem solved problem reinforcement learningMDP, POMDP, bandit problems. later settings, optimal strategy behavepoorly relative strategies obtained theory reinforcement learning, takeparticular structure account.non-Bayesian qualitative setup call optimality criteria differones used current work reinforcement learning. Work reinforcement learningdiscusses learning mechanisms optimize expected payoff long run.qualitative setting (as described above) long-run expected payoffs may make muchsense. optimality criteria expresses need obtain desired behaviorstages. One easily construct examples one approaches favoriteone. emphasis obtaining desired behavior relatively short run.Though, analytical results reinforcement learning concernedeventual convergence desired behavior, policies shown quiteecient practice.addition previously mentioned differences work work reinforcement learning, wish emphasize much work POMDP uses informationstructures different discussed paper. Work POMDP usuallyassumes observations current state may available (following presentation Smallwood & Sondik, 1973), although observations previous statediscussed well (Boutilier & Poole, 1996). Recall case perfect monitoringprevious environment state revealed, immediate reward revealedprefect imperfect monitoring. may useful consider also situations16. results presented paper extended case randomnessreward obtained agents well.17. Likewise, stochastic games (Shapley, 1953) considered repeated games Naturepartial information Nature's strategy. matter one redefine concept stategames. state pair (s; a), state system action opponent.246fiDynamic Non-Bayesian Decision Making(partial) observations previous state current state revealed timetime. may used setting completely clear, may servesubject future research.ReferencesAlon, N., Spencer, J., & Erdos, P. (1992). Probabilistic Method. Wiley-Interscience.Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. (1995). Gambling riggedcasino: adversial multi-armed bandit problem. Proceedings 36th AnnualSymposium Foundations Computer Science, pp. 322{331.Aumann, R., & Maschler, M. (1995). Repeated Games Incomplete Information.MIT Press.Banos, A. (1968). pseudo games. Annals Mathematical Statistics, 39, 1932{1945.Blackwell, D. (1956). analog minimax theorem vector payoffs. Pacific JournalMathematic, 6, 1{8.Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observabledecision processes using compact representations. Proceedings 13th NationalConference Artificial Intelligence, pp. 1168{1175.Cassandra, A., Kaelbling, L., & Littman, M. (1994). Acting optimally partially observable stochastic domain. Proceedings 12th National Conference ArtificialIntelligence, pp. 1023{1028.Chernoff, H. (1952). measure asymptotic eciency tests hypothesis basedsum observations. Annals Mathematical Statistics, 23, 493{509.Fudenberg, D., & Levine, D. (1997). Theory learning games. miemo.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.Hannan, J. (1957). Approximation bayes risk repeated play. Dresher, M., Tucker,A., & Wolfe, P. (Eds.), Contributions Theory Games, vol. III (AnnalsMathematics Studies 39), pp. 97{139. Princeton University Press.Harsanyi, J. (1967). Games incomplete information played bayesian players, partsi, ii, iii. Management Science, 14, 159{182.Hart, S., & Mas-Colell, A. (1997). simple adaptive procedure leading correlatedequilibrium. Discussion paper 126, Center Rationality Interactive DecisionTheory, Hebrew University.Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. JournalArtificial Intelligence Research, 4, 237{258.Kreps, D. (1988). Notes Theory Choice. Westview press.247fiMonderer TennenholtzLovejoy, W. (1991). survey algorithmic methods partially observed markov decisionprocesses. Annals Operations Research, 28 (1{4), 47{66.Luce, R. D., & Raiffa, H. (1957). Games Decisions- Introduction Critical Survey.John Wiley Sons.Megiddo, N. (1980). repeated games incomplete information played nonbayesian players. International Journal Game Theory, 9, 157{167.Mertens, J.-F., Sorin, S., & Zamir, S. (1995). Repeated games, part a. CORE, DP-9420.Milnor, J. (1954). Games Nature. Thrall, R. M., Coombs, C., & Davis, R.(Eds.), Decision Processes. John Wiley & Sons.Monahan, G. (1982). survey partially observable markov decision processes: Theory,models algorithms. Management Science, 28, 1{16.Papadimitriou, C., & Yannakakis, M. (1989). Shortest Paths Without Map. Automata,Languages Programming. 16th International Colloquium Proceedings, pp. 610{620.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall.Savage, L. (1972). Foundations Statistics. Dover Publications, New York.Shapley, L. (1953). Stochastic games. Proceeding National Academic Sciences(USA), 39, 1095{1100.Smallwood, R., & Sondik, E. (1973). optimal control partially observable markovprocesses finite horizon. Operations Research, 21, 1071{1088.Sutton, R. (1992). Special issue reinforcement learning. Machine Learning, 8 (3{4).Valiant, L. G. (1984). theory learnable. Comm. ACM, 27 (11), 1134{1142.Watkins, C., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning, 8 (3{4),279{292.Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, Cambridge University.Wellman, M., & Doyle, J. (1992). Modular utility representation decision-theoreticplanning. Proceedings first international conference AI planning systems.Morgan Kaufmann.Wellman, M. (1985). Reasoning preference models. Tech. rep. MIT/LCS/TR-340,Laboratory Computer Science, MIT.248fiJournal Artificial Intelligence Research 7 (1997) 47-66Submitted 10/96; published 9/97New Look Easy-Hard-Easy PatternCombinatorial Search DicultyDorothy L. Mammenmammen@cs.umass.eduTad Hogghogg@parc.xerox.comDepartment Computer ScienceUniversity MassachusettsAmherst, 01003, U.S.A.Xerox Palo Alto Research Center3333 Coyote Hill RoadPalo Alto, CA 94304, U.S.A.Abstracteasy-hard-easy pattern diculty combinatorial search problems constraints added explained due competition decreasenumber solutions increased pruning. test generality explanationexamining one predictions: number solutions held fixed choiceproblems, increased pruning lead monotonic decrease search cost.Instead, find easy-hard-easy pattern median search cost even numbersolutions held constant, search methods. generalizes previous observationspattern shows existing theory explain full rangepeak search cost. cases pattern appears due changes sizeminimal unsolvable subproblems, rather changing numbers solutions.1. IntroductionRecently, many authors shown solution cost various kinds combinatorialsearch problems follows pattern easy-hard-easy function tightly constrainedproblems are. example, pattern appears graph coloring functionaverage graph connectivity (Cheeseman, Kanefsky, & Taylor, 1991; Hogg & Williams,1994), propositional satisfiability (SAT) function ratio number clausesnumber variables (Cheeseman et al., 1991; Mitchell, Selman, & Levesque, 1992; Crawford& Auton, 1993; Gent & Walsh, 1994b), constraint satisfaction problems (CSPs)function number nogoods (Williams & Hogg, 1994) constraint tightness (Smith,1994; Prosser, 1996).regularity raises possibility determining, prior search, likely dicultyproblems. Unfortunately, yet possible high variance associated observations. compounded fact single problemviewed belonging variety problem classes, somewhat different transition points. Thus one important direction improvement investigate whethersimple additional parameters reduce variance allow predictionshigher confidence.One approach question based explanation easy-hard-easy patterncompetition changes number solutions pruning unproductivec 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMammen & Hoggsearch paths function measure degree problems constrained. particular predicts problems many solutions tend easier,average, fewer given number constraints. Thus, least oneaspect high variance search cost appears due variance numbersolutions problems fixed degree constraint. observation motivatedintroduction additional parameters describing problem structure basedprecise specification number solutions (Hogg, 1996).paper investigate generality explanation examining problemsnumber solutions restricted, including cases number specifiedexactly either zero one. peak search cost fact arises generallycompetition changes number solutions pruning, cases fixednumber solutions show peak. However, find peak continuesappear cases sophisticated search algorithms, fails appearcases. calls question generality explanation based numbersolutions, also suggests search additional problem structure parameters basedsolely reducing variance number solutions likely sucientaccurately predict search cost. However, structural aspect problems likelyinvolved. Specifically, present data showing smallest problem's minimalunsolvable subproblems correlates well search cost.next section describe classes search problems. reviewpattern search behavior current theoretical explanation it. followingsection uncover limitations explanation examining problemsspecification number solutions. shows easy-hard-easy patterngeneral phenomenon suggested current explanations. suggest alternative explanation related problem structure, present data unsolvable problemsshowing positive relationship problem structure parameter, minimumsize minimal unsolvable subproblem, search cost. problem structure parameter may explain differences search cost among solvable problems equal numberssolutions, well. Finally, discuss implications observationsmake suggestions obtaining better understanding greater predictability hardsearch problems.2. Classes Search Problemscommon many previous studies transition phenomenon, use random binaryCSPs graph coloring example classes search problems. section describesproblems generated searched.2.1 Random CSPsconstraint satisfaction problems used experimental results consist 10variables three possible values one, cases, repeated experimentsproblems 20 variables. Problem constraints specified number binarynogoods, i.e., assignments pair variables considered inconsistent.search problem find consistent complete assignment, i.e., valuevariable include inconsistent pairs.48fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficultygenerated problems number ways fully sample range behaviors.first method (\generate-select") generate CSPs randomly selecting specifiednumber binary nogoods. produce classes problems restrictions numbersolutions, determine number solutions randomly generated problemsretain satisfying restrictions. example, produce classsolvable problems, solution included. Similarly, produce classproblems fixed number solutions, problems exactly specifiednumber solutions retained.random generation method gives simple, uniform selection various problem classes. However, also inecient generating problems. instance,nogoods, randomly generated problems solvable, hence requiring largenumber random trials obtain even unsolvable cases.address problem, also used ecient (\hill-climbing") methods. Specifically, generating solvable problems many nogoods, starting randomly generated unsolvable problem, removed constraints random problem becamesolvable, restored number constraints removed constraints chosen randomly,requirement problem become unsolvable again.generating unsolvable problems nogoods, hill-climbing method startedrandomly generated solvable problem, removed constraint constrainedproblem least (the one whose removal increased number solutions least),added randomly chosen constraint resulted problem fewer solutionsproblem constraint removal. If, removed one constraint,constraint could decrease number solutions, constraint increased numbersolutions least chosen { slightly backwards step. speed process up,checked one third possible constraints giving up, choosing oneincreased number solutions least, starting another iteration.methods generating problems specified requirements numbersolutions also studied. One popular method solvable problems randomlyselect assignment variables (a pre-specified solution) then,random selection nogoods, avoid inconsistent pre-specified solution.tends emphasize problems many solutions results instancessomewhat easier uniform random selection. Cha & Iwama (1995) also usedapproach generating problems specific attributes, SAT problems, using AIMgenerators (Asahiro, Iwama, & Miyano, 1993).solved problems using dynamic backtracking (Ginsberg, 1993) cases,using random variable value ordering. comparison, also searchessimple chronological backtrack instead. search cost measured number nodesexplored.2.2 Graph Coloringalso experimented 3-coloring problem. constraint satisfaction problemconsists graph requirement assign node one three colorspair nodes linked edge color. edge graph definesbinary nogoods problem, namely pairs assignments giving color49fiMammen & Hoggtwo nodes connected edge. Thus edge graph gives three binary nogoods.convenient measure number constraints , connectivity average degreenodes graph. equal twice number edges graph dividednumber nodes, edge incident two nodes. 100-nodegraphs studied, number binary nogoods given 150 .case, used simple chronological backtrack search combinationBrelaz heuristic variable value ordering (Johnson, Aragon, McGeoch, & Schevon,1991). heuristic assigns constrained nodes first (i.e.,distinctly colored neighbors), breaking ties choosing nodes uncoloredneighbors, remaining ties broken randomly. colors consideredfixed ordering nodes search. simple optimization, search neverchanges colors selected first two nodes. changes would amountunnecessarily repeating search permutation colors unsolvable cases.Search cost measured number nodes explored.3. Easy-Hard-Easy Patternsection, present example search cost varies tightnessconstraints class problems, describe behavior understoodterms changes structure problems, independent particular searchalgorithms. review summary previous studies transition formsbasis comparison new results presented subsequent sections.3.1 ExampleFigure 1 shows typical example easy-hard-easy pattern function constrainedness problem. Problems many constraints tend easysolve intermediate number dicult. fraction solvableproblems also shown Figure 1, scaled 1.0 left 0.0 right.illustrates hard problems concentrated so-called \mushy region" (Smith& Dyer, 1996) probability solution changing 1.0 0.0. particular,peak search cost near \crossover point," point half problemssolvable half unsolvable. problem class, crossover point occurs75 binary nogoods, peak dynamic backtracking solution cost occurs85 binary nogoods.results paper, include 95% confidence intervals (Snedecor &Cochran, 1967). intervals estimate pmedian obtained samplesgiven approximately percentiles 50 100= N data, Nnumbersamples. estimate fractions intervals given approximatelypfraction. Finally, estimatef 2 f (1 , f )=N , f estimated value pmeans intervals approximately x 1:96= N x estimate meanstandard deviation sample. many cases paper, sucientsamples make intervals smaller size plotted points.key point examples dicult instances within classsearch problems tend concentrated near particular value constraint tightness(here measured number binary nogoods). behavior seen50fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultyCost2001501005020406080100120140NogoodsFigure 1: Typical transition pattern. Median solution cost dynamic backtracking (solid line)probability solution (dashed line) function number nogoods.point represents 1000 problems 10 variables domain size 3, solved 100 times.Error bars showing 95% confidence intervals included, cases smallersize plotted points.variety search methods, indicates concentration depend muchdetails search algorithm. Instead, appears associated changeproperties problems themselves, namely solvability.3.2 Explanationobservations raise number questions, peak search cost exists,peak occurs near transition mostly solvable mostly unsolvable problemsthus independent particular search algorithm, behavior seenlarge variety constraint satisfaction problems.existing explanation concentration hard problems relies competitionchanges number solutions amount pruning providedproblem constraints (Williams & Hogg, 1994). constraints, many solutions search usually easy. constraints added number solutions dropsrapidly, making problems harder. new constraints also increase pruning unproductive search choices, tending make search easier. constraints,decrease number solutions overwhelms increase pruning, giving harderproblems average. Eventually last solution eliminated remainsincreased pruning additional constraints, leading easier problems. Thus phasetransition, point precipitous change solvability unsolvability, less coincides peak solution cost. effects becomepronounced larger problems considered, leading sharper peaks abrupt51fiMammen & Hoggtransitions. qualitative description explains many features observed behavior.pruning explanation also offered Cheeseman et al. (1991) respectfinding Hamiltonian circuits highly constrained problems.explanation also used obtain quantitative understanding behavior.instance, location transition region understood approximatetheory predicting cost peak occurs expected number solutions equalsone (Smith & Dyer, 1996; Williams & Hogg, 1994). example310 possible,10 2assignments 10 variables problem. 2 3 = 405 possible binarynogoods problem, counts number ways select pair variablesdifferent assignments pair. given complete assignment 10 variablessolution provided selected binary nogoods use the,assignmentpair variables given complete assignment. leaves 102 (32 , 1) = 360possible choices binary nogoods. Thus expected number solutions given,360103 ,405problems randomly selected binary nogoods. expression equals one= 82:9, location observed cost peak. Furthermore, expectednumber solutions grows exponentially number variables smallerthreshold value decreases exponentially zero larger, rangevalues expected number solutions near one rapidly decreasesvariables added. accounts observed sharpening transition largerproblems.quantitative success relating search cost peak transition phenomenaevaluation scaling behavior transition search cost peak (Kirkpatrick &Selman, 1994; Gent, MacIntyer, Prosser, & Walsh, 1995).4. Search Diculty Solvabilitysection take closer look behavior search cost, specifically,examining behavior depends whether problem solution and, so,number solutions.4.1 Search BehaviorFigure 2 shows median dynamic backtracking solution cost solvable unsolvablerandom CSPs generated described above, problems number variables n = 10n = 20, domain size three. Except specified otherwise figure caption,problems 10 variables generated 1000 solvable 1000 unsolvable problemspoint, problems 20 variables generated 500 solvable 500 unsolvableproblems point, using \generate-select" method. also generated unsolvableproblems 10 variables 10 70 nogoods using \hill-climbing" method.overlap range problems generated two methods show differentgeneration methods affect search cost.figure clearly shows easy-hard-easy pattern solution cost solvableunsolvable problems, problem sizes. two methods generating unsolvable52fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultyCost3102102468101214m/nFigure 2: Median solution cost using dynamic backtracking solvable (solid lines) unsolvable(dashed dotted lines) problems number variables n = 10 (black lines)n = 20 (gray lines) function number nogoods divided problem size, m=n.problems generated using \generate-select" method except unsolvable problems shown dotted line, generated using \hill-climbing"method. problems size 10, point median 1000 problems solved 100times, except unsolvable problems generated \generate-select" m=n = 3 (30nogoods) solvable problems m=n = 14 (140 nogoods), based 100problems. problems size 20, point median 500 problems solved 100times, except unsolvable problems m=n = 5 (100 nogoods) solvable problemsm=n = 12 (240 nogoods), based 15 35 problems, respectively. Errorbars showing 95% confidence intervals included, cases smallersize plotted points.problems give distinct curves: unsolvable problems generated \hill-climbing"method harder generated \generate-select" method. Nonetheless,sets problems show easy-hard-easy pattern.Another example behavior shown Figure 3 median searchcost instances 3-coloring random graphs. contrast Figure 2, solvableunsolvable cases similar median search costs near peaks. because,described above, graph coloring searches unsolvable cases used symmetryrespect permutations colors avoid unnecessary search. Without optimization, costs unsolvable cases would six times greater values shownfigure. Similar peaks seen classes graphs, connected ones, althoughsomewhat different values .data show random CSPs graph coloring problems exhibit easyhard-easy pattern solvable unsolvable problems considered separately.53fiMammen & HoggCost2502001501005001234567Figure 3: Median solution cost 3-coloring random graphs 100 nodes function connectivity using backtrack search Brelaz heuristic. solid dashed curvescorrespond solvable unsolvable cases respectively. results started100,000 random graphs value , additional samples generatedextremes produce least 100 samples point. random graphs,crossover mostly solvable mostly unsolvable occurs around connectivity 4.5.Error bars showing 95% confidence intervals included.4.2 Solvable Problemspeak search cost solvable problems observed also seen extensively studies local-repair search methods problems generated prespecified solution (Yugami, Ohta, & Hara, 1994; Kask & Dechter, 1995; Williams & Hogg,1994). search methods start assignment variablesproblem attempt adjust solution found. Generally, methods systematic searches: never determine problem solution.Thus empirical studies methods restricted consider solvable problemsincidentally provide useful examination properties solvable problems.Furthermore, study satisfiability problems backtracking search consistentpeak cost solvable problems (Mitchell et al., 1992), insucienthighly constrained solvable problems make definite conclusion behaviormany constraints.existence peak solvable problems fit explanation givenabove? Certainly explanation based transition solvable unsolvable problemscannot apply directly class solvable problems. However, competitionincreased pruning decreased number solutions still applies. shown Figure 4,number solutions solvable random CSPs size 10 first decreases rapidlyconstraints added nears minimum value one, giving slower decrease.54fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultySolutions410110020406080100120140NogoodsFigure 4: Mean (solid) median (dashed) number solutions log scale functionnumber binary nogoods, solvable problems 10 variables, 3 values each, based1000 problems generated \generate-select" method multiple 10 binarynogoods, except 140 nogoods, based 100 problems. 0 nogoods310 = 59049 solutions. Error bars showing 95% confidence intervals included.Except change minimum value 0 1 solution, behavior numbersolutions qualitatively similar general case including solvableunsolvable problems. additional constraints continue increase pruningunproductive search paths. Thus explanation given might continue applypredicts peak point solutions drop (i.e., onesolution) rather becoming unsolvable (i.e., zero solutions).Figure 5 evaluates idea. figure shows fraction problemsleast two solutions changes function number nogoods divided problemsize random CSPs 10 20 variables. problems size 10, secondlast solution disappears, average, 90 100 nogoods: median numbersolutions dropped 2 90 nogoods, 1 100 nogoods (Figure 4).peak solution cost solvable problems slightly lower this, 8090 nogoods, close crossover point Figure 5 half solvable problemsone solution. perhaps close enough consistent explanation givenabove. However, relationship hold problems size 20. classproblems, cost peak solvable problems around 180 nogoods (m=n = 9), whereaspoint half problems one solution still reached240 nogoods (m=n = 12). 180 nogoods, median number solutions 4 (mean10.0), 240 nogoods, median still 2 (mean 1.83). inconsistentexplanation cost peak solvable problems due increasing effectpruning given possible decrease number solutions.55fiMammen & HoggFraction10.80.60.40.22468101214m/nFigure 5: Fraction problems least two solutions function number nogoods di-vided problem size, problems size 10 (black line) size 20 (gray line). Dataproblems size 10 based 1000 solvable problems created \generate-select"method point, except 100 solvable problems m=n = 14 (140 nogoods).Data problems size 20 based 500 solvable problems point, except20 solvable problems m=n = 12 (240 nogoods), also created \generate-select"method. Error bars showing 95% confidence intervals included.Since explanation depending change insolubility apply,pruning versus number solutions explanation fit data, factorsmust work produce easy-hard-easy pattern solvable problems. suspect explanation related idea minimal unsolvable subproblems. minimalunsolvable subproblem subproblem unsolvable, subset variables associated constraints solvable; Gent & Walsh (1996) referredaspect SAT problems minimal unsatisfiable subset. ideabad choices made initially, remainder problem becomesunsolvable, unsolvability much harder determine problems others.particular, variables involved minimal unsolvable subproblem,harder determine subproblem unsolvable. make conjecturecost peak solvable problems tied average size minimal unsolvable subproblem choice made results remaining problemunsolvable.4.3 Problems Fixed Number Solutionsinteresting case behavior problems solutions shown Figures2 3. example, Figure 6 shows solution cost problems exactlyone solution. also shows peak. observations problems zero one56fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultyCost1601401201008060406080100120140NogoodsFigure 6: Median solution cost function number nogoods problems 10 variables,3 values each, exactly one solution, generated using \generate-select" method(solid line), hill-climbing one solution starting solvable problemsmany solutions produced using \generate-select" (dotted line), solved using dynamicbacktracking. point median 1000 problems solved 100 times, excepthill-climbing generated problems 25, 30 35 nogoods \generate-select"generated problems 140 nogoods, 100. Error bars showing 95%confidence intervals included.solution show even number solutions held constant, problems exhibiteasy-hard-easy pattern solution cost.According explanation transition, number solutions held constantincrease pruning factor, giving rise monotonic decreasesearch cost constraints added. Instead, see Figures 2, 3 6 evennumber solutions held fixed zero one, still peak solutioncost, smaller number nogoods. Thus existing explanation capturefull range behaviors. Instead, appears factors workproducing hard problems. focusing closely factors hope gainbetter understanding structure hard problems, may lead precisepredictions search cost.also investigated effect algorithm pattern solution cost unsolvableproblems repeating search random CSPs using chronological backtrack. comparison chronological backtracking search previous dynamic backtrack searchresults unsolvable problems shown Figure 7. figure, curves dynamic backtracking unsolvable problems shown Figure 2,except cost curves shown logarithmic scale. Interestingly,see peak search cost unsolvable problems using less sophisticated methodchronological backtrack.57fiMammen & HoggCost41031021020406080100120140NogoodsFigure 7: Comparison median solution cost log scale using sets unsolvableproblems chronological backtracking (black) dynamic backtracking (gray). Dottedlines problems generated using \hill-climbing" method, solid lines\generate-select" method. point median 1000 problems solved 100times, except \generate-select" method 30 nogoods, based 100problems. Error bars showing 95% confidence intervals included, smallersize plotted points.observation raises important point: easy-hard-easy pattern universalfeature search algorithms problems restricted fixed number solutions.suggests competition number solutions pruning, occurs,suciently powerful affect search algorithms (very simple methods,generate-and-test, make use pruning show monotonic increase searchcost number solutions decreases), algorithms ableexploit features weakly constrained problems fixed number solutionsmake easy.contrast observations, monotonic decrease cost reportedunsolvable binary random constraint problems (Smith & Dyer, 1996) unsolvable3SAT problems (Mitchell et al., 1992). case 3SAT, explanation may wellchoice algorithm. Indeed, Bayardo & Schrag (1996) recently found incorporatingcon ict-directed backjumping learning Tableau algorithm made differencemany orders magnitude problem diculty specifically rare, \exceptionally hard,"unsatisfiable problems underconstrained region. would interesting see whethereasy-hard-easy pattern unsolvable problems would appear using algorithm.respect Smith & Dyer's (1996) observations, difference may duerange problems generated, resulting different problem generation methods. SmithDyer used method akin \random" generation method, is, generating58fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficultyproblems without regard solvability, separating unsolvable ones.method, \hit rate" unsolvable problems underconstrained region low.possible Smith Dyer's data extend point costunsolvable problems begins decrease simply stopped finding unsolvableproblems point.two possible reasons might found unsolvable problems usingrandom generation underconstrained region, Smith Dyernot. One possibility since specifically interested unsolvable problemsfar underconstrained region possible, may spent computationaleffort generating region. Indeed, 40 nogoods, unsolvable problems occurredfrequency 4:5 10,5 , 30 nogoods, frequency 7:75 10,7 . rate, problems30 nogoods took six hours apiece generate.second possibility relates details generation methods. SmithDyer's random generation method, every pair variables exactly numberinconsistent value pairs them. implies degree homogeneitydistribution nogoods. hand, random generation method,variable-value pair equal probability selected nogood, independentone another. Thus least possible generation method, though still lowlikelihood, nogoods occasionally clump, produce unsolvable problem.idea discussed Section 5.difference observation Smith & Dyer's (1996) reinforces importantpoint: relatively subtle difference generation methods affect classproblems generated. nogoods less evenly distributed averageusing generation method, also clumped probability, whereasSmith Dyer's generation method, homogeneous distribution variable pairsguaranteed. types problems could different enough sometimes producedifferent behavior.5. Minimal Unsolvable Subproblemsobservations classes problems restrictions number solutionsmay shows common identification peak solution costalgorithm-independent transition solvability seen general problem classescapture full generality easy-hard-easy pattern.solvable problems, explanation could readily modified use transitionexistence solutions beyond specified construction classproblems symmetries problems might constrain allowable rangesolutions. modification simple generalization existing explanation basedcompetition number solutions pruning. However, datasolvable problems support explanation, search cost peakdisappearance second last solution coincide roughly n = 10,n = 20.Furthermore, number solutions held constant, competition increased pruning decreasing number solutions cannot possibly responsiblepeak solution cost. decrease search cost highly constrained problems (to59fiMammen & Hoggright peak) adequately explained prevailing explanation, basedincrease pruning additional constraints. explain weakly constrained problems also found easy, least search methods. low costunsolvable problems underconstrained region new unexpected observationlight previous studies easy-hard-easy pattern explanation. raisesquestion whether different aspect problem structure accountpeak search cost problems fixed number solutions.One possibility often mentioned context notion critically constrained problems. problems boundary solvable unsolvable problems, i.e., neither underconstrained (with many solutions) overconstrained(with none). notion forms basis another common interpretation costpeak. is, critically constrained problems typically hard search (because constraints must instantiated unproductive search pathsidentified) and, since concentrated transition (Smith & Dyer, 1996),give rise search peak. explanation include discussion changespruning capability constraints added. Taken face value, explanation wouldpredict peak solvable problems number solutions held constant,classes transition solvable unsolvable problems. Moreover,description critically constrained problems simply characteristic individual problem rather partly dependent class problems considerationexact location transition depends method problemsgenerated. observation makes dicult characterize degreeindividual problem critically constrained purely terms structural characteristicsproblem. contrast, measure number solutions well definedindividual problem instances, facilitates using average behavior various classesproblems approximately locate transition region. Thus, currently described,notion critically constrained problems explain observationsgive explicit way characterize individual problems.precisely defined alternative characteristic size minimal unsolvable subproblems. mentioned Section 4.2, minimal unsolvable subproblem subproblemunsolvable, subset variables associated constraintssolvable.problems one minimal unsolvable subproblem. example,problem might one minimal unsolvable subproblem five variables, another, different one, say, six. computed minimal unsatisfiable subproblems10-variable unsolvable problems generated. found monotonic positive relationship mean number minimal unsolvable subproblems number nogoods.example, problems 140 nogoods average 35 minimal unsolvable subproblems(range 4 64, standard deviation 8.7); 90 nogoods six (range 123, standard deviation 3.6); problems 50 fewer nogoods rarelyone minimal unsolvable subproblem. Similarly, Gent & Walsh (1996) observed unsatisfiable problems underconstrained region tend small unique minimalunsatisfiable subsets.behavior size smallest minimal unsolvable subproblem functionnumber nogoods shown Figure 8. Comparing Figure 2, see peak60fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultySize10987654320406080100120Nogoods140Figure 8: Mean size smallest minimal unsolvable subproblem function number nogoods, unsolvable problems generated using \hill-climbing" (dotted line)\generate-select" (solid line) methods. point based 1000 problems, except\generate-select" method 30 nogoods, based 100 problems. Error barsshowing 95% confidence intervals included.minimum size minimal unsolvable subproblems matches location searchcost peak unsolvable problems. result independent whether plot smallestminimal unsolvable subproblem size, shown Figure 8, medians means,shown here. Moreover, location peaks minimal unsolvable subproblemsize different generation methods correspond location respectivesearch cost peaks. peak search cost minimal unsolvable subproblem sizeoccurs around 40 nogoods problems generated using \hill-climbing" method,significantly higher, around 60 nogoods, problems generated using \generateselect" method. strong correspondence minimal unsolvable subproblem sizesearch cost suggestive minimal unsolvable subproblem size structuralcharacteristic problems plays important role search cost. contrast, numberminimal unsolvable subproblems match pattern search cost. mentionedabove, increases monotonically number nogoods, suggesting playprimary role explaining search cost unsolvable problems.behavior minimal unsolvable subproblem size function numberconstraints simple explanation. Unsolvable weakly constrained problems generally need concentrate available constraints variables ordermake assignments inconsistent. tend give one small minimal unsolvablesubproblem. constraints added, concentration longer required and,since problems randomly selected constraints happen concentratedvariables rare, expect larger minimal unsolvable subproblems.61fiMammen & HoggCost35030025020015046810SizeFigure 9: Mean solution cost function size smallest minimal unsolvable subproblem,unsolvable problems 60 nogoods generated using \generate-select" method.point mean median solution costs, based solving problem 100 times,set problems corresponding smallest minimal unsolvable subproblemsize. points based following numbers problems smallest minimalunsolvable subproblem size, totaling 1000 problems: 3 { 1; 4 { 17; 5 { 71; 6 { 156; 7 {253; 8 { 283; 9 { 165; 10 { 54. Error bars showing 95% confidence intervals included,except single problem size 3 confidence intervals cannot calculated.Finally, constraints added, increased pruning equivalentnotion instantiating variables required find inconsistency.means expect large number small unsolvable subproblems. qualitativedescription corresponds observe Figure 8.observations weakly constrained problems suggest search algorithms,dynamic backtracking, able rapidly focus one unsolvable subproblems hence avoid extensive thrashing, high search cost, seen methods.cases, one would expect smaller unsolvable subproblem, easiersearch determine solutions.order examine role minimal unsolvable subproblem search costclosely, plotted mean search cost versus size smallest minimal unsolvable subproblemunsolvable problems 10 variables multiple 10 nogoods 30 140nogoods. every case, mean search cost increased function size smallest minimalunsolvable subproblem. Figure 9 shows example one plots, peaksolution cost class problems, 60 nogoods. makes sense smallestminimal unsolvable subproblem, easiest detect, would play significant rolesearch cost. However, situation surely complicated this, suggestedfact still variation among problems size smallest minimal62fiThe Easy-Hard-Easy Pattern Combinatorial Search Difficultyunsolvable subproblem. could due, example, one problem severalsmall minimal unsolvable subproblems, another might one minimal unsolvablesubproblem, even smaller. Number size minimal unsolvable subproblemslikely play role search cost.Number minimal unsolvable subproblems seem play significant rolesize smallest minimal unsolvable subproblem, effect also demonstrated.sets unsolvable problems above, multiple 10 nogoods80 140 nogoods, search cost correlates negatively number minimal unsolvablesubproblems. However, unsolvable problems 30 70 nogoods, variancenumber minimal unsolvable subproblems lower (but variance search cost higher),relationship search cost number minimal unsolvable subproblems. Additional clarification role search cost size number minimalunsolvable subproblems left investigation. size smallest minimal unsolvable subproblem, correlates strongly search cost (1) unsolvable problemstaken whole (see Figures 2 8) (2) unsolvable problems fixed numbernogoods full range number nogoods, appears primary effect.discussion minimal unsolvable subproblems also relevant solvable problems:series choices precludes solution made search, remaining subproblem unsolvable one. example, 10-variable CSP, suppose valuesgiven first two variables incompatible solutions problem.means context two assignments, remaining eight variables constitute unsolvable subproblem. number search steps required determinesubproblem fact unsolvable cost added search backtrackingoriginal two variables trying new assignment one them. Thus, costidentifying unproductive search choices solvable problems determined rapidlyassociated unsolvable subproblem searched. described above,constraints expect unsolvable subproblems smallminimal unsolvable subproblems hence easy search methods ablefocus subproblems. unsolvable subproblems associated incorrectvariable choices solvable problems may different structure, argument suggests changes minimal unsolvable subproblems may explain behavior solvableproblems fixed number solutions well. could also explain observationsthrashing behavior rare exceptionally hard solvable problems underconstrainedregion (Gent & Walsh, 1994a; Hogg & Williams, 1994); would expect problemsrelatively large unsolvable subproblem detect given initial variable assignments. Finally, would interesting study behavior local repair search methodsproblems single solution see also affected change minimalsubproblem size.6. Conclusionspresented evidence explanation easy-hard-easy pattern solutioncost based competition changes number solutions pruninginsucient explain phenomenon completely sophisticated search methods.explain overall pattern problems restricted solvability number63fiMammen & Hoggsolutions. However, explanation fails number solutions held constantsophisticated search methods used. cases solution cost peakdisappear would predicted. Alternatively, view explanation adequateless sophisticated methods able readily focus unsolvable subproblemsencountered search.considering relatively small search problems, able exhaustively examineproperties search space. allowed us definitively demonstrate importance search behavior aspect problem structure: size minimal unsolvablesubproblems. approach contrasts much work area involves solvingproblems large feasible within reasonable time bounds. latter approachgives better indication asymptotic behavior transition, suitableexhaustive evaluation nature search spaces encountered, detailedanalysis aspects individual problem structure.believe detailed examination structure combinatorial problemsyield information certain types problems dicult easy. class, graphcoloring random CSPs NP-complete, yet practice many problems actuallyeasy. addition, theoretical work area produced predictionsasymptotically correct average, variance among individual problems predictedclass enormous. Increased understanding relationships problem structure,problem solving algorithm, solution cost important determining whether, so,how, determine prior problem solving problems easy versus infeasiblyhard. contrast previous theoretical studies focus number solutions,work suggests size minimal unsolvable subproblems alternate characteristicstudy potential producing precise characterization transitionbehavior nature hard search problems.AcknowledgementsMuch research carried first author summer intern XeroxPalo Alto Research Center. research also partially supported NationalScience Foundation Grant No. IRI-9321324 Victor R. Lesser. opinions,findings, conclusions recommendations expressed materialauthors necessarily ect views National Science Foundation.ReferencesAsahiro, Y., Iwama, K., & Miyano, E. (1993). Random generation test instancescontrolled attributes. Second DIMACS Challenge Workshop.Bayardo, Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques solve exceptionally hard SAT instances. Freuder, E. C. (Ed.), Principles PracticeConstraint Programming { CP96, pp. 46{60 Cambridge, MA. Springer.Cha, B., & Iwama, K. (1995). Performance test local search algorithms using newtypes random CNF formulas. Proceedings Fourteenth International Joint64fiThe Easy-Hard-Easy Pattern Combinatorial Search DifficultyConference Artificial Intelligence, pp. 304{310 Montreal, Quebec, Canada.Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.Proceedings Twelfth International Joint Conference Artificial Intelligence,pp. 331{337 Sydney, Australia.Crawford, J. M., & Auton, L. D. (1993). Experimental results cross-over pointsatisfiability problems. Proceedings Eleventh National ConferenceArtificial Intelligence, pp. 21{27 Washington, DC, USA.Gent, I. P., MacIntyre, E., Prosser, P., & Walsh, T. (1995). Scaling effects CSP phasetransition. Montanari, U., & Rossi, F. (Eds.), Proc. Principles PracticesConstraint Programming PPCP95, pp. 70{87. Springer-Verlag.Gent, I. P., & Walsh, T. (1994a). Easy problems sometimes hard. Artificial Intelligence,70, 335{345.Gent, I. P., & Walsh, T. (1994b). SAT phase transition. Cohn, A. (Ed.), ProceedingsECAI-94, pp. 105{109. John Wiley Sons.Gent, I. P., & Walsh, T. (1996). satisfiability constraint gap. Artificial Intelligence,81 (1-2), 59{80.Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,1, 25{46.Hogg, T. (1996). Refining phase transitions combinatorial search. Artificial Intelligence, 81, 127{154.Hogg, T., & Williams, C. P. (1994). hardest constraint problems: double phasetransition. Artificial Intelligence, 69, 359{377.Johnson, D. S., Aragon, C. R., McGeoch, L. A., & Schevon, C. (1991). Optimizationsimulated annealing: experimental evaluation; part II, Graph coloring numberpartitioning. Operations Research, 39 (3), 378{406.Kask, K., & Dechter, R. (1995). GSAT local consistency. Proceedings Fourteenth International Joint Conference Artificial Intelligence, pp. 616{622 Montreal,Quebec, Canada.Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability randomboolean expressions. Science, 264, 1297{1301.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SATproblems. Proceedings Tenth National Conference Artificial Intelligence,pp. 459{465 San Jose, CA, USA.Prosser, P. (1996). empirical study phase transitions binary constraint satisfactionproblems. Artificial Intelligence, 81, 81{109.65fiMammen & HoggSmith, B. M. (1994). Phase transition mushy region constraint satisfactionproblems. Cohn, A. (Ed.), Proceedings ECAI-94, pp. 100{104. John WileySons.Smith, B. M., & Dyer, M. E. (1996). Locating phase transition binary constraintsatisfaction problems. Artificial Intelligence, 81, 155{181.Snedecor, G. W., & Cochran, W. G. (1967). Statistical Methods (6th edition). Iowa StateUniv. Press, Ames, Iowa.Williams, C. P., & Hogg, T. (1994). Exploiting deep structure constraint problems.Artificial Intelligence, 70, 73{117.Yugami, N., Ohta, Y., & Hara, H. (1994). Improving repair-based constraint satisfactionmethods value propagation. Proceedings Twelfth National ConferenceArtificial Intelligence, pp. 344{349 Seattle, WA, USA.66fiJournal Artificial Intelligence Research 7 (1997) 125-159Submitted 5/97; published 10/97Analysis Three-Dimensional Protein ImagesLaurence LeherteLaboratoire de Physico-Chimie InformatiqueFacultes Universitaires Notre-Dame de la PaixNamur, BelgiumLaurence.Leherte@scf.fundp.ac.beJanice GlasgowKim Baxterjanice@qucis.queensu.cabaxter@qucis.queensu.caDepartment Computing Information ScienceQueen's University, Kingston, Ontario, Canada, K7L 3N6Evan Steegsteeg@qucis.queensu.caMolecular Mining Corp., PARTEQ InnovationsQueen's University , Kingston, Ontario, Canada, K7L 3N6Suzanne Fortierfortiers@qucdn.queensu.caDepartments Computing Information Science ChemistryQueen's University, Kingston, Ontario, Canada, K7L 3N6Abstractfundamental goal research molecular biology understand protein structure.Protein crystallography currently successful method determining threedimensional (3D) conformation protein, yet remains labor intensive reliesexpert's ability derive evaluate protein scene model. paper, problemprotein structure determination formulated exercise scene analysis. computational methodology presented 3D image protein segmentedgraph critical points. Bayesian certainty factor approaches described usedanalyze critical point graphs identify meaningful substructures, ff-helicesfi -sheets. Results applying methodologies protein images low mediumresolution reported. research related approaches representation, segmentation classification vision, well top-down approaches protein structureprediction.1. IntroductionCrystallography plays major role current efforts characterize understand molecular structures molecular recognition processes. information derived crystallographic studies provides precise detailed depiction molecular scene, essentialstarting point unraveling complex rules structural organization molecularinteractions biological systems. However, small fraction currently knownproteins fully characterized.determination molecular structures X-ray diffraction data belongsgeneral class image reconstruction exercises incomplete and/or noisy data. Researchartificial intelligence machine vision long concerned problems.Similar concept visual scene analysis, molecular scene analysis concernedprocesses reconstruction, classification understanding complex images.c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiLeherte, Glasgow, Baxter, Steeg, & Fortieranalyses rely ability segment representation molecule meaningfulparts, availability priori information, form rules structuraltemplates, interpreting partitioned image.crystal consists regular (periodic) 3D arrangement identical building blocks,termed unit cell. crystal structure defined disposition atoms moleculeswithin fundamental repeating unit. given structure solved interpretingelectron density image unit cell content, generated { using Fourier transform {amplitudes phases experimentally derived diffraction data. electron densitymap 3D array real values estimate electron density given locationsunit cell; information gives access structure protein1 . Unfortunately,diffraction amplitudes measured directly crystallographic experiment;necessary phase information constructing electron density image must obtainedmeans2 . classic phase problem crystallography.contrast small molecules (up 150 independent, non-hydrogen atoms),determination protein structures (which often contain excess 3000 atoms) remainscomplex task hindered phase problem. initial electron density images obtainedcrystallographic data macromolecules typically incomplete noisy.interpretation protein image generally involves mental pattern recognition proceduresimage segmented features, compared anticipatedstructural motifs. feature identified, partial structure informationused improve phase estimates resulting refined (and eventually higher-resolution)image molecule. Despite recent advances tools molecular graphics modeling,iterative approach image reconstruction still time consuming process requiringsubstantial expert intervention. particular, depends individual's recall existingstructural patterns ability recognize presence motifs noisycomplex 3D image representation.goal research described paper facilitate image reconstruction processes protein crystals. Towards goal, techniques artificial intelligence,machine vision crystallography integrated computational approach interpretation protein images. Crucial process ability locate identifymeaningful features protein structure multiple levels resolution. requiressimplified representation protein structure, one preserves relevant shape, connectivity distance information. proposed approach, molecular scenes represented3D annotated graphs, correspond trace main side chainsprotein structure. methodology applied ideal experimental electrondensity maps medium resolution. images, nodes graph correspondamino acid residues edges correspond bond interactions. Initial experimentsusing low-resolution electron density maps demonstrate image segmentedprotein solvent regions. medium resolution protein regionsegmented main side chains individual residues along main chain.1. Strictly speaking, diffraction experiment provides information ensemble averageunit cells.2. Current solutions phase problem macromolecules rely gathering extensive experimentaldata considerable input experts image interpretation process.126fiAnalysis Three-Dimensional Protein ImagesFurthermore, derived graph representation protein analyzed determinesecondary structure motifs within protein.paper presents brief overview protein structure problem analyzingmolecular scene. processes protein segmentation secondary structure identification described, along experimental results. Related ongoing research issuesalso presented.2. Protein Structurefundamental goal research molecular biology understand protein structurefunction. particular, structure information essential medicine drug design.section review concepts involved protein structure. conceptsused later describing computational approach protein structure determination.protein often characterized linear list amino acids called primary structure, sequence, protein. naturally occurring amino acids similarbackbone structure, consisting central carbon atom (Cff ), amino group (NH2 )carboxyl group (COOH ). distinguished one another varying sidechains connected Cff atom. Figure 1 illustrates alternative representationsamino acid alanine, Figure 1(c) displays side chain consisting carbonthree hydrogen atoms. Associated side chain amino acid propertieshydrophobicity (dislikes water), polarity, size charge.side chainHCCH 3N+C H37H3 N2CCOO-H(a) 1D chemical formula(b) 2D structural formula(c) Ball stick modelFigure 1: Representations amino acid alanine.Adjacent amino acids primary structure protein linked togetherpeptide bonds form polypeptide main chain, backbone, various sidechains project (see Figure 2). carboxyl group one amino acid joins aminogroup another eliminate water molecule (H2 O) form peptide bond.secondary structure protein refers local arrangement polypeptide subchaintakes regular 3D conformation. two commonly recurring classessecondary structure: ff-helix fi -sheet. ff-helix occurs corkscrew-shapedconformation, amino acids packed tightly together; fi -sheets consist linearstrands (termed fi -strands) amino acids running parallel antiparallel one another(see Figure 3). secondary structure motifs generally linked together less127fiLeherte, Glasgow, Baxter, Steeg, & Fortieramino acid nHHCNCRHCNNCHRHHCCRpeptide bondside chainFigure 2: Proteins built joining together amino acids using peptide bonds.regular structures, termed loops turns. discussed later paper,characterization subsequence amino acids ff-helix fi -sheet determinedgeometric analysis distance angle relations among local subsequencesamino acids.global conformation protein referred tertiary structure. wayproteins adopt particular folding pattern depends upon intramolecular interactions occur among various amino acid residues, well upon interactionmolecule solvent (water). Two types intramolecular interactions often referred order describe secondary tertiary structure protein. first typehydrogen bond, results sharing hydrogen atom residues.ff-helices fi -sheets described terms regular specific hydrogen bondnetworks. Figure 3 illustrates portion fi -sheet hydrogen bond interactionslink together parallel fi -strands. Additional stability 3D structure proteinprovided disulfide bridges. second type interaction result chemical bondoccurring two sulfur atoms carried cysteine amino acid residues. bondsenergetically stronger hydrogen bonds contribute stability extremeconditions (temperature, acidity, etc.).Molecular biology concerned understanding biological processes macromolecules terms chemical structure physical properties. Crucial achievinggoal ability determine protein folds 3D structure given knownsequence amino acids. Despite recent efforts predict 3D structure proteinsequence, folding problem remains fundamental challenge modern science. Since3D structure protein cannot yet predicted sequence information alone,experimental techniques X-ray crystallography nuclear magnetic resonance currently provide realistic routes structure determination. remainderpaper focus computational approach analysis protein images generatedcrystallographic data.128fiAnalysis Three-Dimensional Protein ImagesCCCNCHNCCHHHCNCNNCCNCNCHCCCCCHNCHNHFigure 3: Hydrogen bonds (dotted lines) link three individual fi -strands (linear sequencesamino acids main chain protein) form parallel fi -sheet.129fiLeherte, Glasgow, Baxter, Steeg, & Fortier3. Scene AnalysisResearch machine vision long concerned problems involved automatic image interpretation. Marr (1982) defines computational vision \the processdiscovering present world, is". Similar visual scene analysis, molecular scene analysis concerned processes reconstruction, classificationunderstanding complex images. section presents problem molecular sceneanalysis context related research machine vision medical imaging.Early vision systems generally include set processes determine physical properties 3D surfaces 2D arrays. input arrays contain pixel values denoteproperties light intensity. Considerable research carried extracting3D information one 2D images. review application stereo visionsets 2D images found (Faugeras, 1993). principles stereo visionalso applied moving images (Zhang & Faugeras, 1992). Range data providesexplicit depth information visible surfaces form 2D array (depth map).Depending application, surface or/and volume fitting techniques appliedimages. complete review vision techniques found elsewhere (e.g.,(Arman & Aggarwal, 1993; Besl & Jain, 1986; Jain & Flynn, 1993)).Similar crystallography problem, medical imaging techniques require genuine3D data: magnetic resonance imaging (MRI) provides detailed high-resolution informationtissue density; emission computed tomography (ECT), includes positron emission tomography (PET) single photon emission computed tomography (SPECT), givesnoisy, low-resolution information metabolic activity. X-ray computed tomography(CT) ultrasound also provide 3D density data. methods used obtainseries 2D images (slices) which, properly aligned, provide 3D grid.interslice spacing may much larger spacing grid points slice,alignment slices followed interpolation slices one area research.low-level segmentation medical images typically uses 3D extensions 2D techniques. Edge detection becomes surface detection, region growing defines volumes insteadareas. Many applications typically require detailed, high-level models. Surfaceinformation used construct models simulations, volumes surfaces providestructural measurements. Higher-level models used construction \templates"pattern matching. One interesting aspect medical imaging availability prioriknowledge, either database similar structures, images regiondifferent modalities (e.g. MRI images brain used guide segmentationlower-resolution PET image). One modality may also provide information clearanother modality. considerable research \registration" images { aligningoverlaying two 3D images combine information. Segmentation identificationmatching \landmarks" important image representations.Unlike input vision medical imaging problems, crystallographic experiment yields data define 3D function, allows construction 3D arrayvoxels arbitrary size3 . interpretation 3D atomic arrangement crystal structure readily available small molecules using data generated X-ray3. Comparatively, machine vision techniques generally provide 2D image representations range dataprovide surface information. Medical imaging techniques may result 3D grid, spacing130fiAnalysis Three-Dimensional Protein Imagesdiffraction techniques. Given magnitudes diffracted waves prior knowledgephysical behavior electron density distributions, probability theory applied retrieve phase information. magnitudes phases known, spatialarrangement atoms within crystal obtained Fourier transform. electron density function obtained, (x; y; z ), scalar field visualized 3D gridreal values called electron density map. High-density points image associatedatoms small molecule.construction interpretable 3D image protein structure diffractiondata significantly complex small molecules, primarily due naturephase problem. generally involves many iterations calculation, map interpretationmodel building. also relies extensively input expert crystallographer.previously proposed process could enhanced strategyintegrates research crystallography artificial intelligence rephrases problemhierarchical iterative scene analysis exercise (Fortier et al., 1993; Glasgow et al.,1993). goal exercise reconstruct interpret images proteinprogressively higher resolution. initial low-resolution map, proteinappears simple object outlined molecular envelope, goal locateidentify protein solvent regions. medium-resolution, goal involves locating aminoacid residues along main chain identifying secondary structure motifs. higherresolution, analysis would attend identification residues and, possibly,location individual atoms.primary step scene analysis (whether vision, medical crystallographic dataused) automatically partition image representation disjoint regions. Ideally,segmented region corresponds semantically meaningful component objectscene. parts used input high-level classification task. processessegmentation classification may interwoven; domain knowledge, formpartial interpretation, often useful assessing guiding segmentation.Several approaches image segmentation classification consideredvision literature. particular interest molecular domain approach describedBesl Jain (1986) , surface curvature sign Gaussian derivedpoint surface range image. Image segmentation achievedidentification primitive critical points (peaks, pits, ridges, etc.). Haralick et al. (1983)defined similar set topographic features use 2D image analysis, Wang Pavlidis(1993), later Lee Kim (1995), extended work extract features characterrecognition. Gauch Pizer (1993) also identify ridge valley bottoms 2D images,ridge defined point intensity falls sharply two directionsvalley bottom point intensity increases sharply two directions.examined behavior ridges valleys scale space; resultingresolution hierarchies could used guide segmentation. Maintz et al. (1996) GuziecAyache (1992) use 3D differential operators scale space define ridgestroughs. provide landmarks used register images. Leonardis, GuptaBajcsy (1993, 1995)) use approach surface fitting (using iterative regression)volume fitting (model recovery) initiated independently; local-to-global surfacealong third axis may large, and, case, necessary align interpolatemultiple 2D slices.131fiLeherte, Glasgow, Baxter, Steeg, & Fortierfitting used guide multiple global-to-local volume fittings, used evaluationpossible models.discussed next section, topological approach usedsegmentation classification molecular scenes. Similar method GauchPizer, critical points used delineate skeletal image protein segmentmeaningful parts. critical points considered analysis segmentedparts. approach also compared skeletonization method,described Hilditch (1969) applied protein crystallography Greer (1974) . UnlikeGreer's algorithm, \thins" electron density map form skeleton tracesmain secondary chains molecule, proposed representation preservesoriginal volumetric shape information retaining curvatures electron densitycritical points. Furthermore, rather thinning electron density form skeleton,approach reconstructs backbone protein connecting critical points 3Dgraph structure.Critical points image also considered medical domain. Higgins etal. (1996) analyze coronary angiograms CT data thresholding define \bright"regions correspond area around peak critical points. seed regionsgrown along ridges steep dropoff. Post-processing removes cavities spurs.resulting volume tree-like structure, skeletonized prunedprovide axes. axes converted sets line segments minimum length.similar BONES (Jones, Zou, Cowan, & Kjeldgaard, 1991), graphical methoddeveloped applied interpretation medium- high-resolutionprotein maps. method incorporates thinning algorithm postprocessing analysiselectron density maps. Also worth mentioning previously described methodologyoutlining envelope protein molecule crystallographic environment (Wang,1985).distinct advantage molecular scene analysis, many applications machinevision, regularity chemical structures availability previously determinedmolecules Protein Data Bank (PDB) (Bernstein, Koetzle, Williams, & Jr., 1977).database 3D structures forms basis comprehensive knowledge base templatebuilding pattern recognition molecular scene analysis (Conklin, Fortier, & Glasgow,1993b; Hunter & States, 1991; Unger, Harel, Wherland, & Sussman, 1989); althoughscenes wish analyze novel, substructures likely appeared previously determined structures. Another significant difference molecular visualscene analysis diffraction data resulting protein experiments yield 3D images,simplifying eliminating many problems faced low-level vision (e.g., occlusion,shading). complexity exist crystallographic domain relatesincompleteness data due phase problem.4. Segmentation Interpretation Protein Imagesuse artificial intelligence techniques assist crystal structure determination, particularly interpretation electron density maps, first envisioned Feigenbaum,Engelmore Johnson (1977) pursued Crysalis project (Terry, 1983). conjunction earlier project, topological approach representation analysis132fiAnalysis Three-Dimensional Protein ImagesFigure 4: Depictions electron density maps viewed (a) 1A, (b) 3A, (c) 5resolutionprotein electron density maps implemented program called ORCRIT (Johnson,1977). Recent studies suggest approach also applied segmentationmedium-resolution protein images (Leherte, Baxter, Glasgow, & Fortier, 1994a; Leherte,Fortier, Glasgow, & Allen, 1994b). section describe supportfeasibility topological approach analysis low medium-resolution electrondensity maps proteins.information stored electron density map protein may representedanalyzed various levels detail (see Figure 4)4 . high-resolution (Figure 4(a))individual atoms observable; medium-resolution (Figure 4(b)) atoms observable, possible differentiate backbone protein side chainssecondary structure motifs may discernerable. clear segmentation proteinmolecular envelope (region atoms protein reside) surroundingsolvent region still seen low-resolution (Figure 4(c)).4. Resolution electron density images proteins often measured terms angstrom (A) units,1A=10,10 meters.133fiLeherte, Glasgow, Baxter, Steeg, & FortierMethods machine vision crystallography considered development computational approach analysis protein structures. Amongstudied, topological analysis provided natural way catch uctuationsdensity function molecular image. section overview methodmapping 3D electron density map onto graph traces backbone protein structure. present results applying method segmentation lowmedium-resolution maps protein structures reconstructed using Protein DatabankBrookhaven. well, show critical point graphs constructed medium resolutionmaps analyzed order identify ff-helix fi -sheet substructures.4.1 Representation Protein StructureCrucial molecular scene analysis representation capture molecular shapestructure information varying levels resolution; important step molecularscene analysis parsing protein, protein fragments, shape primitivesallow rapid accurate identification. Shape information extractedseveral depictive representations { example, van der Waals surfaces, electrostaticpotentials electron density distributions. Since molecular scene analysis primarilyconcerned images reconstructed crystallographic experiments, electron densitymaps provide natural convenient choice input representation.mentioned earlier, electron density map depicted 3D array real, nonnegative values corresponding approximations electron density distributionpoints unit cell crystal. task segmenting map meaningfulparts, also consider array terms smooth continuous function , mapsinteger vector r = (x; y; z ) value corresponding electron density locationr electron density map. Similar related formalisms vision5, informationelectron density map uninterpreted detailed level allow rapidcomputational analysis. Thus, essential transform array representationsimpler form captures relevant shape information discards unnecessarydistracting details. desired representation satisfy three criteria put forwardMarr Nishihara concerning: 1) accessibility { representation derivableinitial electron density map reasonable computing costs; 2) scope uniqueness{ representation provide unique description possible molecular shapesvarying levels resolution; 3) stability sensitivity { representationcapture general (less variant) properties molecular shapes, along finerdistinctions.Several models representation segmentation protein structures considered. included generalized cylinder model (Binford, 1971), skeletonizationmethod (Greer, 1974; Hilditch, 1969). choose topological approach,previously applied chemistry machine vision. chemistry, approachproven useful characterizing shape properties electron density distributionlocation attributes critical points (points gradientelectron density equal zero) (Johnson, 1977).5. level representation electron density map comparable 3D version primal sketchMarr Nishihara's formalism (1978) .134fiAnalysis Three-Dimensional Protein Imagesfollowing section, describe representation protein structure termsset critical points obtained topological analysis.4.2 Deriving Critical Point Graphsproposed topological approach protein image interpretation, protein segmentedmeaningful parts location identification points electrondensity map gradients vanish (zero-crossings). points, local maximaminima defined computing second derivatives adopt negative positive valuesrespectively. first derivatives electron density function characterize zerocrossings, second derivatives provide information zero-crossings; particular,identify type critical points map. index value r = (x; y; z )electron density map, define function (r).Candidate grid points (those maximum minimum along three mutuallyorthogonal axes) chosen function (r) evaluated vicinity determining three polynomials (one along axes) using least square fitting. (r)tensor product three polynomials. location critical point derivedusing first derivative (r). second derivatives used determine naturecritical point. critical point, construct Hessian matrix:@ 2 =@x2 @ 2 =@x@y @ 2 =@x@zH(r) = @ 2 =@y@x @ 2 =@y2 @ 2=@y@z@ 2 =@z@x @ 2 =@z@y @ 2 =@z2matrix put diagonal form three principal second derivativescomputed index value r:H'(r) =@ 2 =@ (x0 )2000@ 2 =@ (y0 )2000@ 2 =@ (z0 )2three non-zero diagonal elements array H'(r) { eigenvalues { used determine type critical points electron density map. Four possible casesconsidered depending upon number negative eigenvalues, nE . nE = 3,critical point r corresponds local maximum peak; point nE = 2 saddlepoint pass. nE = 1 corresponds saddle point pale, nE =0 characterizes rpit. Figure 5 depicts 2D graphical projection potential critical points.High density peaks passes critical points currently consideredstudy. Low density critical points less significant since often indistinguishable noise experimental data.use critical point mapping method analyzing protein electron densitymaps first proposed Johnson (1997) analysis medium high-resolution protein electron density maps. Within framework molecular scene analysis project,use critical points extended analysis medium low-resolutionmaps proteins. topological approach segmentation proteins initiallyimplemented Johnson computer program ORCRIT (Johnson, 1977). first locating connecting critical points, program generates representation135fiLeherte, Glasgow, Baxter, Steeg, & FortierPeakPassPeakXFigure 5: Graphical illustration critical points 2D (X Y) plotted densityfunction .captures skeleton volumetric features protein image. occurrence probability connection two critical points j determined followingdensity gradient vector r(r). pair critical points, program calculatesweight wij , inversely proportional occurrence probability connection.collection critical points linkage represented set minimal spanningtrees (connected acyclic graphs minimal weight)6 .4.3 Results Segmentation Medium Low Resolutionsection presents experimental studies carried electron densitymaps 3resolution. Computations first performed calculated maps reconstructed available structural data order generate procedureanalysis experimental maps. Three protein structures: Phospholipase A2 (1BP2), Ribonuclease T1 complex (1RNT) Trypsin inhibitor (4PTI), retrieved PDB (Bernsteinet al., 1977), considered. structures composed 123, 104 53 amino acidresidues, respectively, chosen quality data sets. electrondensity images proteins constructed using XTAL program package (Hall &Stewart, 1990), analyzed using version ORCRIT extendedenhanced construct interpret critical point graphs low- medium-resolutionelectron density maps.Applying ORCRIT electron density maps generated medium resolution providesdetailed analysis protein structures (Leherte et al., 1994b). illustratedFigure 6, topological approach produces skeleton protein backbone sequence6. discussed Section 4, part program currently modified allow cyclesgraph.136fiAnalysis Three-Dimensional Protein Imagesalternating peaks (dark circles) passes (light circles). results obtainedanalysis calculated electron density maps 3resolution led followingobservations:peak linear sequence generally associated single residueprimary sequence protein.pass sequence generally corresponds bond chemical interactionlinks two amino acid residues (peaks).Thus, critical point graph decomposed linear sequences alternatingpeaks passes corresponding main chain backbone protein. largerresidues, side chains may also observed graph side branches consistingpeak/pass motif. observations featured Figure 7, illustrates criticalpoint graph electron density contour unit cell protein crystal.practice, found critical point graph included arcs originatingpresence connections critical points associated non-adjacent residues.illustrated Figure 6 bottom left corner Figure 7; main chaingraphs jump occurred result disulfide bridge nearbyresidues. bonds often identified, however, analysiscritical point graphs. example, disulfide bridges discerned representationhigher density values associated cysteine residues. overcomeproblem errors critical point graph due ambiguous data plan generatemultiple possible models protein, corresponding different hypothesized backbonesresulting critical point graph. Thus, several alternative hypotheses considered used refine image iterative approach scene analysis.Experiments also carried low (5A) resolution, followingobserved:Secondary structure motifs, ff-helices fi -strands, correspond linear(or quasi-linear) sequences critical points. case helices, sequencestrace central axis structure (see Figure 8), whereas tend catchbackbone fi -strands. average distance observed critical pointsmodel protein backbone 1:68 0:59A.non-linear sequences critical points sometimes found representativeirregular protein motifs loops.Highly connected, small graphs critical points appear regions maps:solvent region, disulfide bridges close protein segments.Although results segmenting protein images using topological approachproved promising, ongoing research carried improve enhanceORCRIT. particular, redeveloping code building graph critical points.new version code incorporate domain knowledge order findmultiple possible backbone traces. also incorporate spline (rather polynomial)fitting function interpolate critical points constructing function (r).137fiLeherte, Glasgow, Baxter, Steeg, & Fortierside chain(pass) (peak)disulphide bridgepeptide bondamino acidFigure 6: Planar representation critical point sequence obtained topologicalanalysis electron density map 3resolution.138fiAnalysis Three-Dimensional Protein ImagesFigure 7: 3D contour critical point graph unit cell protein 4PT1 (58 residues)constructed 3resolution. critical point graph figure generatedusing output ORCRIT program.139fiLeherte, Glasgow, Baxter, Steeg, & FortierFigure 8: Critical point graph Cff chain (black) helix motif 3(white) 5(gray) resolution.Currently, investigating relationships critical points varying resolutions. Figure 8 illustrates superimposition critical point representationshelix motif low medium resolution obtained using ORCRIT. figure shows,linear segment critical points derived 5resolution approximates detailedcritical point graph helix derived 3A. careful analysis suggestsexists hierarchy peaks passes 53A. relationshipcritical points medium low-resolution illustrated Figure 9, individual critical points 5resolution associated individual multiple pointsmedium-resolution.5. Methods Secondary Structure Identificationcritical point graph constructed, analyzed classify substructuresprotein. statistical analysis conformation critical point sequencesterms geometrical parameters motifs consisting four sequential peak critical points(pi ; pi+1 ; pi+2 ; pi+3 ) suggests useful parameters identification ffhelices fi -strands distance peaks pi pi+3 , individualplanar angles among critical points. describe criteria used formulaterules identification secondary structure motifs medium-resolution electrondensity map protein.previous paper (Leherte et al., 1994a), described approach secondarystructure identification geometrical constraints critical point subgraph140fiAnalysis Three-Dimensional Protein Imagesaminoacid 13234*147+244*106+191*122+309*74+172*38+224*76+282*77+227*132+212*52+113*4+33+24*23+71*37*34+36*38+2+48*5 Resolution109*98+349*316*83+259*123+283*49+216*137+210*125+235*23+167*43+278*aminoacid 293 ResolutionFigure 9: Relationship critical points 3 5resolution amino acids 1329 protein structure 1RNT. `+' `*' denote peaks passes mainchain. numeric values correspond critical points location orderedlist (based electron density) points. correspondence pointsdifferent levels hierarchy based interdistance (must less2A).141fiLeherte, Glasgow, Baxter, Steeg, & Fortiertreated boolean fashion, i.e., either satisfied depending uponwhether values fell within predetermined ranges. procedure describedcurrent paper relies probabilistic belief measures based statistics derivedPDB. Following, describe alternative approaches based comparison criticalpoint graphs idealized secondary structure motifs. templates used consistedlocal subsequences critical points, point denoting residue idealized modelprotein.5.1 Estimating Probabilities Combining Evidenceconstruct model templates, first performed statistical analysis 63 nonhomologous protein structures retrieved PDB. set occurrence probabilitydistributions f (ssmjg) estimated given secondary structure motifs (ssm) geometric constraints (g). derived values ff-helix, fi -sheet turn motifsgeometric constraints based torsion bond angles relative distanceresidues.building procedures structure recognition discrimination, two important issues must faced: first, one compute primitive marginal conditionalprobability estimates f (ssmjg); and, second, one combine information several different pieces geometric evidence class,f (ssmjg1 ; g2 )? many tradeoffs consider.single-attribute probability estimations, f (ssmjg), one use discrete categories estimate probabilities frequency counts. \bins" employedfor, e.g., ranges critical point inter-distance values, achieving sucient sample sizesbin counts presents little diculty. number bins grows \width"bin correspondingly shrinks, resulting histogram becomes better better approximator underlying continuous distribution, problems small countslead larger sampling error (variance). one chooses fit continuous distributionsdata, bias/variance dilemma manifests choice distribution typesnumber parameters parameterized models.combining individual terms representing secondary structure evidence, one mustaddress issue inter-attribute dependencies accuracy eciency tradeoffsposes. Put simply, compute f (ssmjg1; g2) f (ssmjg1) f (ssmjg2)?pure Bayesian approach without underlying independence assumptions requires exponentially many terms, therefore seek heuristic shortcuts.Two methods determining confidence values secondary structure assessmentstudied applied problem secondary structure identification: 1) Bayesian,Minimum Message Length (MML) approach, similar previously used proteinsubstructure classification (Dowe, Allison, Dix, Hunter, Wallace, & Edgoose, 1996),2) approach similar used expert systems MYCIN (Shortliffe, 1976).emphasize primary goal described research constructioneffective structure recognition systems, rather comparison alternative methodsmachine learning classification per se.142fiAnalysis Three-Dimensional Protein Images5.2 Bayesian/MML Approachadopting Bayesian latent class analysis approach problem, decided treatestimation combination issues together fitting mixtures continuous distributionsdata class, conditional independence assumption commonly usedmixture model approaches classification clustering (McLachlan & Basford, 1988).latent class analysis approach finding structure set datapoints, one beginsunderlying parameterized model. example, one might posit set pointsrepresented 2D scatterplot generated 2D Gaussian (normal) distribution,means 1 ; 2 covariance matrix V12 . data might better explainedmixture, weighted sum, several Gaussian distributions, 2D meanvector covariance matrix. approach, one tries find optimal set parametervalues representation datapoint x = (x1 ; x2 ). Optimality may definedterms maximum likelihood, Bayes optimality, or, case, minimum messagelength (MML)7 .case hand, 11 dimensions instead 2, dimensionsbest modeled simple Gaussians. generally accepted angular datamodeled one circular distributions von Mises distribution (Fisher,1993).Two independence assumptions, crucial computational eciency data eciency,underlie approach:1. Within given class, attributes characterizing segment mutually independent.2. separate datapoints, corresponding segment, mutually independent.Although neither assumptions strictly true application, assumptions commonly made circumstances, methods based workwell practice. dependence assumptions proves untenable, one employ elaborate models incorporate explicit dependencies, Bayes Netsgraphical models (Buntine, 1994).5.3 MYCIN-Like Approachdetermined method similar one used diagnosis system MYCIN (Rich& Knight, 1991) also effective application. Frequency distribution values providemeasures belief disbelief secondary structure assignments based individualgeometric constraints:MB (ssm; g) = f (ssm; g)MD(ssm; g) = f (not ssm; g)(1)(2)MB (ssm; g) measure belief hypothesis given peak associatedsecondary structure ssm given evidence g, whereas MD(ssm; g) measures7. However, use general term \Bayesian" informally Bayesian, Minimum Description LengthMML approaches distinguish jointly other, especially \frequentist" approaches.143fiLeherte, Glasgow, Baxter, Steeg, & Fortierextent evidence g supports negation hypothesis ssm peak. Figure10 illustrates computed probability distributions geometric constraint (bondangle, distance torsion angle) secondary structure motif (helix, strand).Like modified Bayesian mixture modeling approach described previous section,MYCIN methodology represents another heuristic approximation pure \naive" Bayesapproach. case, initial primitive probability terms simple frequency countsrules combining probabilities assume implicitly different evidence sourcesindependent. shown lead nonsensical classifications extreme cases,though practice approach often works quite well.two pieces evidence considered, confidence measures computed using following formulae:MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2)(1 , MB (ssm; g1 ))(3)MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))(4)Given measures, overall certainty factor, CF , determined peak pcritical point graph difference belief disbelief measures:CF (ssm; g) = MB (ssm; g) , MD(ssm; g)(5)g corresponds geometric constraints associated peak p.result application method interpretation ideal critical pointgraph illustrated Figure 11. graph shows broad bands positive CFindeed representative regular secondary structure motifs ff-helices fi -strands.practice, critical point, approach constructs CF value secondarystructure hypothesis. end procedure, hypothesis highest CFvalue selected. final results thus set sequences CF values characterizedsubsequences various lengths identical secondary structure selection.two pieces evidence considered, confidence measures computed using following formulae:MB (ssm; g1 ^ g2 ) = MB (ssm; g1 ) + MB (ssm; g2 )(1 , MB (ssm; g1 ))(6)MD(ssm; g1 ^ g2 ) = MD(ssm; g1 ) + MD(ssm; g2 )(1 , MD(ssm; g1 ))(7)Given measures, overall certainty factor, CF , determined peak pcritical point graph difference belief disbelief measures:CF (ssm; g) = MB (ssm; g) , MD(ssm; g)(8)g corresponds geometric constraints associated peak p. resultapplication method interpretation ideal critical point graph illustratedFigure 11. graph shows broad bands positive CF indeed representativeregular secondary structure motifs ff-helices fi -strands.5.4 ResultsFollowing demonstrate two methods analysis described previous sectionapplied identification secondary structure critical point graphs.consider graphs constructed ideal experimental electron density maps.144fiAnalysis Three-Dimensional Protein Images0.450.18MB(helix,torsion angle)MD(helix,torsion angle)0.350.30.250.20.150.10.050.10.080.060.04150-150 -100 -50050 100Torsion angle (degrees)0.81500.4MB(helix,distance 1-4)MD(helix,distance 1-4)MB(strand,distance 1-4)MD(strand,distance 1-4)0.35Probability Distributions0.7Probability Distributions0.120-150 -100 -50050 100Torsion angle (degrees)0.60.50.40.30.20.10.30.250.20.150.10.05000246810 12Distance 1-4 (Angstroms)1400.6246810 12Distance 1-4 (Angstroms)140.3MB(helix,angle)MD(helix,angle)Probability DistributionsProbability Distributions0.140.0200.5MB(strand,torsion angle)MD(strand,torsion angle)0.16Probability DistributionsProbability Distributions0.40.40.30.20.100.25MB(strand,angle)MD(strand,angle)0.20.150.10.050-150 -100 -50050Angle (degrees)100150-150 -100 -50050Angle (degrees)100Figure 10: Probability distributions computed measures belief (MB) disbelief(MD) given secondary structure motif geometric constraint.145150fiLeherte, Glasgow, Baxter, Steeg, & Fortier80helixstrandCertainty Factor60402003-10strandturnstranda-helix-20-40-60-80361623272835Residue #4756Figure 11: Certainty factors obtained ff-helix fi -strand hypotheses ideal critical point representation protein 4PTI (58 residues) medium-resolution.figure also denotes correct interpretation residues 16-23 (strand),23-27 (turn), 28-35 (strand) 47-56 (helix).5.5 Application Ideal DataTwo Bayesian/MML one MYCIN-based analyses applied secondary structureidentification ideal critical point trees. first Bayesian module (Bayes1 ) trainedusing 60 63 ideal protein structure representations previously usedgenerate occurrence frequency distribution functions torsion angles, distances planarangles (Figure 10). second Bayesian module (Bayes2 ) trained using 46 ideal criticalpoint trees 18 critical point representations obtained ORCRIT analysis 3resolution reconstructed electron density maps. Three ideal critical point representationskept testing: Cytochrome C2 (2C2C { 112 residues) characterized helicesturns only; Penicillopepsin (3APP { 323 residues) contains short helices (8 residuesless), turns, fi -strands 14 residues long; photosynthetic reaction centreRhodobacter Sphaeroides (4RCR { 266 residues) rich ff-helix structure regularsegments 24 residues.statistical Bayesian modules allow classification critical points 11geometrical attributes calculated: except first three last three pointscritical point sequence, points participate four torsion angles, four distances(pi pi+3 ), three planar angles. Bayesian module thus appliedsecondary structure recognition segments contain 7 peak critical points more,MYCIN-based module applicable 4-point (or longer) sequences. However,comparison purposes, points 11 geometrical attributes could calculatedconsidered recognition. Results presented Table 1. table reports146fiAnalysis Three-Dimensional Protein Imagesnumber segments8 correctly incorrectly identified eitherBayesian approaches MYCIN-based module. modules designed classifyrecognized secondary structure motifs among four different classes: `helix', `strand', `turn',`other'. Regarding class `helix', distinction ff-helices helices 310made posteriori help interpretation results.Two types percentage values given Table 1. first type, i.e., percentageactual secondary structure information identified, computed totalnumber actual secondary structure motifs present three test protein structures: 25ff-helices, 25 fi -strands, 10 310 helices, 42 turns. Higher percentage values observedMYCIN-based results versus Bayesian results come fact longer segmentsrecognized potential helices strands. better overlap actual secondarystructure motifs thus likely occur using MYCIN approach. illustratedfirst two examples described Figure 12. Selected secondary structure motifs proteins2C2C 3APP compared hypotheses generated MYCIN-based Bayesmodules. observed that, two cases, longer identifications provided usingMYCIN closer actual secondary structure amino acid sequences.percentage correctly identified points within ideal critical point segmentscomputed total number assigned critical point segments reported Table 1.Regarding class `helix', longer segments discovered MYCIN-based module,well larger number incorrectly recognized segments, lead lower percentage valuesparticular method. shown third example displayed Figure 12.MYCIN-based module associates long ff-helix particular amino acid sequenceprotein 4RCR deviates ideality five residues, Bayes modules providesreasonable solutions.worthwhile even segments correctly assigned,percentage correctly identified peaks 100%. due factrecognized segments (sequences peaks) shifted one residue respectdefinition given PDB file.results reported Table 1, clear first Bayesian module allowsfiner differentiation helices turns (turns four five residue long segmentswhose geometry may similar helix geometry) MYCIN-based approach.MYCIN-based approach tends assign label `helix' actual turns shown Example(4) Figure 12. hand, 310 helices correctly identified MYCINderived rules, less often discerned using first Bayesian approach (See Example (5)Figure 12). MYCIN-based module actually strong tendency exaggeratehelical character segment distorted respect ideal case. raisesidentification ambiguities 27 (51-24) short segments. wrong identification madeusing first Bayesian approach, except one fi -strand. segment also identifiedpossible strand using MYCIN-based module, hypothesis later rejectedpost-processing stage checks parallelism discovered fi -strands.8. table segment denotes sequence (length 2) adjacent peak critical points belongsecondary structure class (helix, fi -strand, turn). comparing results, notedPDB data set is, itself, strictly consistent since varying secondary structure definitionsassignment methods used assess structure proteins.147fiLeherte, Glasgow, Baxter, Steeg, & FortierMYCINBayes1 Bayes2ff-Helices (actual = 25)(correctly) assigned segments(24) 51 (24) 24 (21) 22% correctly recognized actual motifs988788% correctly identified peaks638382fi -Strands (actual = 25)(correctly) assigned segments(24) 24 (20) 21 (24) 30% correctly recognized actual motifs897184% correctly identified peaks828281(10) 10(7) 7(7) 7% correctly recognized actual motifs975647% correctly identified peaks707061310 Helices (actual = 10)(correctly) assigned segmentsTurns (actual = 42)(correctly) assigned segments(4) 4(12) 12 (21) 28% correctly recognized actual motifs73441% correctly identified peaks467759Table 1: Results application two Bayesian approaches MYCIN-basedmethod recognition secondary structure motifs ideal protein backbones constructed Cff CO centres mass. Note numbers bracketsdenote number correctly assigned, versus total number assigned, segments(sequences peaks).148fiAnalysis Three-Dimensional Protein Imagesapplication second Bayesian approach trained realistic criticalpoint representations generated larger number identified fi -strands turns.however went number incorrect identifications are, case fi -strands,associated short segments (2 3 points). case turns, percentagecorrectly identified critical points lower (59% respect 77%) due one particularmotif containing seven points.analysis ideal critical point trees allows conclude second Bayesianmodule accurate detecting fi -strand turn structures (there increasednumber recognized motifs); use noisy data training stage leadsless acute ability module distinguish short helix-like motifs (there increasednumber incorrectly identified motifs).5.6 Application Experimental Datapresented results obtained applying methods secondary structure identification critical point graphs constructed ideal electron density maps. Following,describe application methods recognition motifs critical pointrepresentation constructed applying ORCRIT electron density map generatedexperimental data. also show structure recognition approaches improvedpostprocessing analysis representation. experiment carriedusing 3resolution experimental map Penicillopepsin, protein composed 323amino acid residues (Hsu, Delbare, James, & Hofmann, 1977; James & Sielecki, 1983).Neglecting passes located peaks, geometrical parameters computedshort fragments composed seven adjacent peaks main branch graphprotein. achieving geometrical analysis, preprocessing work doneorder fit critical point graphs ideal model described above. Distancescomputed sets adjacent peaks, peaks separated distance smaller 1.95merged single point situated center mass. critical point linkagechecked: two adjacent peaks separated distance 5peaksassumed connected. Considering connected sequences three peaks time,distance first third peak smaller 4A, middle peakconsidered part backbone protein (i.e., middle peak probablydenotes side chain). Finally, resulting sequences peaks (which thus likelyrepresentative protein backbone) submitted three secondary structureanalysis methods.Initially poor results observed MYCIN-like method motivated developmentpost-processing procedure imposed eliminate helical segmentsnegative torsion angle values isolated fi -strand segments, i.e., extended segmentsparallel similar motifs. postprocessing step analyses globalproperties structure, measures belief/disbelief focus localgeometric properties motif. Postprocessing drastically reduces number incorrectlyrecognized motifs consequently increases quality recognition procedure (Rost,Casadia, & Farisellis, 1996).Table 2 presents comparison results applying three methods identifyingsecondary structure motifs experimental electron density map penicillopepsin.149fiLeherte, Glasgow, Baxter, Steeg, & Fortier(1) 2c2caa no.Actual ssMYCINBayes1Bayes24HHHH5HHH-6HHHH7HHHH8HHHH9HHH10HHH11310HHH12310HHH13310HHH14310HHH15HH16HH17H-417(2) 3appaa no.Actual ssMYCINBayes1Bayes2203204-205-206-207-208-209210211212(3) 4rcraa no.Actual ssMYCINBayes1Bayes2149H150H-151H-152HHH153H154HHHH155HHHH156HHHH157HHHH158HHHH203212159HHHH160HHHH31-(5) 3appaa no.Actual ssMYCINBayes1Bayes2126-127310HH-128310HH-(6) 3appcp no.aa no.Actual ssMYCINBayes1Bayes271139H-199140HHH1370141HHH32H33H34H35H129310H-506142HHHH36H37H130H-131-75143HH-38-162HHHH163HHH1631493931(4) 2c2caa no.Actual ssMYCINBayes1Bayes2161HHHH39131126388144HH144139129(7) 3appcp no.aa no.Actual ssMYCINBayes1Bayes2188129HH482H-205135HH235134H905133HHH320132H756131H-581132H122H-422HH-1431103H-42102HHH630HH90485H-82586HH1311351021038685Figure 12: Selected amino acid secondary structure motifs identifications (`cp',`aa', `ss' stand `critical point', `amino acid', `secondary structure',respectively. `H', `T', `S', `-' denote secondary structure classes: `helix',`turn', `sheet', `other'.)150fiAnalysis Three-Dimensional Protein ImagesMYCINBayes1 Bayes2ff-Helices (actual = 3)(correctly) assigned segments(3) 7(0) 0(2) 3% correctly recognized actual motifs91945% correctly identified peaks26-57fi -Strands (actual = 15)(correctly) assigned segments(12) 12 (12) 12(9) 9% correctly recognized actual motifs704130% correctly identified peaks739196(1) 1(0) 0(0)0% correctly recognized actual motifs50170% correctly identified peaks75--(0) 0(1) 3(1) 2% correctly recognized actual motifs03327% correctly identified peaks-10043310 Helices (actual = 2)(correctly) assigned segmentsTurns (actual = 1)(correctly) assigned segmentsTable 2: Results application two Bayesian approaches MYCIN-basedmethod recognition secondary structure motifs minimal spanning treesconstructed critical point analysis experimental electron density mappenicillopepsin 3resolution. Note numbers brackets denotenumber correctly assigned, versus totally assigned, segments (sequencespeaks).151fiLeherte, Glasgow, Baxter, Steeg, & FortierAccording Table 2, MYCIN-based approach appears greater successrecognizing helical motifs experimental maps. Example (6) Figure 12 depicts onethree helix motifs correctly recognized using MYCIN-based approach.However, approach also misidentifies several motifs helices. Among four incorrectly identified helices, two four-point segments actual turns, one four-point segmentcharacterized negative torsion angles, 15-point sequence critical pointssuccession three jumps (a jump connection occurring non-adjacent aminoacid residues) (See Example (7) Figure 12). Bayes modules incorrectly identifyturn region electron density map. Jumps problematic mayseriously hinder recognition rate, especially experimental maps blurred noiseerrors.Table 2 illustrates consideration noisier data training set (moduleBayes2 ) leads improvement number identified ff-helices respectfirst Bayesian module (Example (6) Figure 12). However, also leads numberincorrectly identified segments. One segment length two wrongly identified helix.actually corresponds jump non-adjacent amino acid residues; jump alsogenerates interpretation error MYCIN-based algorithm. poor accuracyturn recognition (43 %) due wrongly identified segment.6. Related Researchinterpretation protein images greatly facilitated recent yearsadvent powerful graphics stations coupled implementation highly ecientcomputer programs, notably FRODO (Jones, 1992) (Jones et al., 1991). Althoughprograms designed specifically visual analysis electron density mapsproteins, still require significant amount expert intervention interpretationrequire considerable time investment. Unlike systems ORCRIT designedautomated approach protein model building interpretation.research presented paper component ongoing research projectarea molecular scene analysis (Fortier et al., 1993; Glasgow et al., 1993). primaryobjective research implementation application computational methodsclassification understanding complex molecular images. Towards goal,proposed knowledge representation framework integrating existing sourcesprotein knowledge (Glasgow, Fortier, Conklin, Allen, & Leherte, 1995). Representationsreasoning visual spatial characteristics molecular scene capturedframework using techniques computational imagery (Glasgow, 1993; Glasgow& Papadias, 1992). paper extends previous publications molecular scene analysisplacing research artificial intelligence framework relating workmachine vision. well, focuses use uncertain reasoning secondary structureinterpretation critical point representation provides experimental resultssupporting approaches protein image interpretation.Two kinds image improvement procedures considered conjunctioninformation stored critical point representation. first one consists improving phase information given resolution. necessary, dicult, stepprotein structure determination carried experimental data. Structural informa152fiAnalysis Three-Dimensional Protein Imagestion retrieved topological analysis might injected so-called direct methodsprocedure, previously successfully applied structure determinationsmall molecules high resolution (Hauptman & Karle, 1953), recently macromolecules well. However, methods presently applicable protein imageslow- medium-resolution data, time-consuming experimental methods generallyused phase recovery protein structure elucidation.second set procedures protein image enhancement involves constructioninterpretation increasingly higher-resolution maps. presently carriedvisually crystallographers access well-phased medium- high-resolutionmap. highest density regions fitted fragments retrieved databasechemical templates, eventually allowing determination protein's 3D structure(Jones et al., 1991). two protein image reconstruction procedures interrelated:improved phases lead reliable map motif identification takeplace. considerations, secondary structure motifs detected low-resolutionmap regions interest generate medium-resolution information, wouldgive access amino acid residue locations.procedures give rise iterative approach molecular scene analysis.iterative refinement process, portion image interpretedinformation applied (via inverse Fourier transform) adjust current phases.modified phases used generate new image. approach scene analysis thusproceeds initial coarse (low-resolution) image progressively detailed(higher-resolution) images substructures identifiable9.implies particular resolution, necessary analysisidentify substructures. recognition parts scene used improvephases, giving rise overall improvement image. new imageanalyzed leading additional interpretations. process iteratively applied(within heuristic search strategy) protein structure fully determined.critical point representation described paper one componentknowledge representation scheme computational imagery. second componentscheme involves spatial logic, used represent reasonconcepts qualitative spatial features associated protein molecule (Conklin et al.,1993b; Conklin, Fortier, Glasgow, & Allen, 1996). Associated spatial representationknowledge discovery technique, called IMEM (Conklin & Glasgow, 1992), basedtheory conceptual clustering. system used discover recurrent 3Dstructural motifs molecular databases (Conklin, Fortier, & Glasgow, 1993a; Conklinet al., 1996). anticipate machine learning/discovery techniques(e.g., (Hunter, 1992; Lapedes, Steeg, & Farber, 1995; Unger et al., 1989)) could appliedaid top-down analysis novel molecular scenes order anticipate classifystructural motifs. would complementary bottom-up scene analysis providedtopological approach described paper.Molecular scene analyses benefit research protein structure prediction. particular, currently investigating formulations derived inverse foldingproblem (Bowie, Luethy, & Eisenberg, 1991). Given amino acid sequence set9. resolution image depends number experimental ections available wellamount phase information.153fiLeherte, Glasgow, Baxter, Steeg, & Fortiercore segments (pieces secondary structure forming tightly packed internal proteincore), approach prediction evaluates possible alignment (threading) knownprimary sequence amino acids onto possible core templates. problem identifyingindividual residues critical point map medium high-resolution addressedsimilar manner, i.e., attempting thread sequence onto protein structure derivedtopological analysis. problem significantly simpler protein structureprediction since involves threading sequence onto experimentally determinedstructure, rather onto templates retrieved library possible models.threading approach proposed Lathrop Smith (1994), scoring function usedderive statistical preference residue given environment. Modificationscurrent scoring function, incorporate properties available electron density mapcritical point graph representations, implemented order customize approach information available topological analysis (Baxter, Steeg, Lathrop,Glasgow, & Fortier, 1996).7. Conclusionsreported paper topological approach effectively appliedsegmentation protein images meaningful parts low- medium-resolution.Furthermore, shown secondary structure motifs could identified mediumresolution images geometric analysis image representation; applicationgeometric rules probabilities yields measure confidence given peakcomponent known secondary structure motif.Three secondary structure identification modules applied interpretationideal experimental critical point graphs. Two probabilistic Bayesian approachesMYCIN-based method revealed geometric components torsion angles,distances planar angles useful differentiate helices, strands,turns.Bayesian MYCIN-derived approaches relatively successful assigningsecondary structure identifications sequences critical points geometrically wellresolved. case noisy experimental data, accuracy decreased. anticipateaccuracy could improved use larger training setstraining 3-10 helix subclasses. However, expect achieve fullsecondary structure recognition protein { rather expect interpret good (lessnoisy) portions electron density map use information iteratively improveimage order carry analyses.protein structures used compose training test sets contain backboneinformation only. structures free heteroatoms and/or small solvent molecules.prior knowledge chemical composition crystallographic cell would certainlyhelp anticipating problems connections non-adjacent residueshigh density peaks. Additional experimental data would permit us extend scopethree approaches described present paper.Modern crystallographic studies remain forefront current efforts characterize understand molecular recognition processes. long-term goal researchmolecular scene analysis assist studies computational methodology154fiAnalysis Three-Dimensional Protein Imagesaiding expert crystallographers complex imagery processes required fully interpret3D structure protein. topological approach presented importantcomponent methodology. research required, however, extendanalysis multi-resolution maps, incorporate domain knowledgeanalyses.Acknowledgementsauthors wish thank Carroll Johnson providing ORCRIT programongoing collaboration project, Marie Fraser providing accessexperimental electron density map penicillopepsin. Financial support researchprovided Natural Science Engineering Research Council (NSERC) CanadaBelgian National Council Scientific Research (FNRS). also thanks FNRS\Charge de Recherches" position.ReferencesArman, F., & Aggarwal, J. (1993). Model-based object recognition dense-range images- review. ACM Computing Survery, 25 (1), 5{43.Baxter, K., Steeg, E., Lathrop, R., Glasgow, J., & Fortier, S. (1996). electron densitysequence structure: Integrating protein image analysis threading structure determination. Proceedings 4th International Conference IntelligentSystems Molecular Biology, pp. 25{33. AAAI/MIT Press, Menlo Park, California.Bernstein, F., Koetzle, T., Williams, J., Meryer, E., Brice, M., Rodgers, J., Kennard, O.,Shimanouchi, T., & Tasumi, M. (1977). Protein Data Bank: computer{basedarchival file macromolecular structures. Journal Molecular Biology, 112, 535{542.Besl, P., & Jain, R. (1986). Invariant surface characteristics 3D object recognitionrange images. CVGIP, 33, 33{80.Binford, T. (1971). Visual perception computer. Proceedings IEEE ConferenceSystems Control Miami, Florida.Bowie, J., Luethy, R., & Eisenberg, D. (1991). method identify protein sequencesfold known three-dimensional structure. Science, 253, 164{170.Buntine, W. (1994). Operations learning graphical models. Journal ArtificialIntelligence Research, 2, 159{225.Conklin, D., Fortier, S., & Glasgow, J. (1993a). Knowledge discovery molecular databases.IEEE Transactions Knowledge Data Engineering, 985{987. Special IssueLearning Discovery Knowledge-Based Databases.155fiLeherte, Glasgow, Baxter, Steeg, & FortierConklin, D., Fortier, S., & Glasgow, J. (1993b). Representation discovery proteinmotifs. Hunter, L., Searls, D., & Shavlik, J. (Eds.), Proceedings First International Conference Intelligent Systems Molecular Biology. AAAI/MIT Press,Menlo Park, California.Conklin, D., Fortier, S., Glasgow, J., & Allen, F. (1996). Conformational analysiscrystallographic data using conceptual clustering. Acta Crystallographica, B52, 535{549.Conklin, D., & Glasgow, J. (1992). Spatial analogy subsumption. Sleeman, &Edwards (Eds.), Machine Learning: Proceedings Ninth International ConferenceML(92), pp. 111{116. Morgan Kaufmann.Dowe, D., Allison, L., Dix, T., Hunter, L., Wallace, C. S., & Edgoose, T. (1996). Circular clustering protein dihedral angles minimum message length. PacificSymposium Biocomputing '96, pp. 242{255.Faugeras, O. (1993). Three-dimensional computer vision: geometric viewpoint. MIT Press.Feigenbaum, E., Engelmore, R., & Johnson, C. (1977). correlation crystallographic computing artificial intelligence research. Acta Crystallographica, A33,13{18.Fisher, N. (1993). Statistical Analysis Circular Data. Cambridge University Press, Melbourne, Australia.Fortier, S., Castleden, I., Glasgow, J., Conklin, D., Walmsley, C., Leherte, L. & Allen, F.(1993). Molecular scene analysis: integration direct methods artificialintelligence strategies solving protein crystal structures. Acta Crystallographica,D49, 168{178.Gauch, J., & Pizer, S. (1993). Multiresolution analysis ridges valleys grey-scaleimages. IEEE Transactions Pattern Analysis Machine Intelligence, PAMI15 (6), 635{646.Glasgow, J., Fortier, S., Conklin, D., Allen, F., & Leherte, L. (1995). Knowledge representation tools molecular scene analysis. Proceedings Hawaii InternationalConference Systems Sciences, Biotechnology Computing Track.Glasgow, J. (1993). imagery debate revisited: computational perspective. Computational Intelligence, 9 (4), 309{333. Taking issue paper.Glasgow, J., Fortier, S., & Allen, F. (1993). Molecular scene analysis: crystal structure determination imagery. Hunter, L. (Ed.), Artificial Intelligence MolecularBiology, pp. 433{458. AAAI Press, Menlo Park, California.Glasgow, J., & Papadias, D. (1992). Computational imagery. Cognitive Science, 16 (3),355{394.156fiAnalysis Three-Dimensional Protein ImagesGreer, J. (1974). Three-dimensional pattern recognition: approach automated interpretation electron density maps proteins. Journal Molecular Biology, 82,279{301.Gupta, A., & Bajcsy, R. (1993). Volumetric segmentation range images 3d objectsusing superquadric models.. CVGIP: Image Understanding, 58 (3), 302{326.Guziec, A., & Ayache, N. (1992). Smoothing matching 3-d space curves. VisualizationBiomedical Computing, Proc. SPIE, 1808, 259{273.Hall, S., & Stewart, J. (Eds.). (1990). XTAL 3.0 User's Manual. Universities WesternAustralia Maryland.Haralick, R., Watson, L., & Laffey, T. (1983). topographic primal sketch. InternationalJournal Robotics Research, 2, 50{72.Hauptman, H., & Karle, J. (1953). Solution Phase Problem, 1. CentrosymmetricCrystal, ACA Monograph No. 3. Wilmington:Polycrystal Book Service.Higgins, W., Spyra, W., Karwoski, R., & Ritman, E. (1996). System analyzing highresolution three-dimensional coronary angiograms. IEEE Transactions MedicalImaging, 15 (3), 377{385.Hilditch, C. J. (1969). Linear skeletons square cupboards. Machine Intelligence, 4,403{420.Hsu, I.-N., Delbare, L., James, M., & Hofmann, T. (1977). Penicillopepsin penicilliumjanthinellum. crystal structure 2.8 sequence homology porcine pepsin.Nature, 266, 140{145.Hunter, L. (1992). Artificial intelligence molecular biology. ProceedingsTenth National Conference Artificial Intelligence, pp. 866{868. AAAI, Menlo Park,California.Hunter, L., & States, D. (1991). Applying Bayesian classification protein structure.Proceedings Seventh IEEE Conference Artificial Intelligence ApplicationsMiami, Florida.Jain, A., & Flynn, P. (Eds.). (1993). Advances Three Dimensional Object RecognitionSystems, volume 1. Elsevier.James, M., & Sielecki, A. (1983). Structure refinement penicillopepsin 1.8resolution. Journal Molecular Biology, 163, 299{361.Johnson, C. (1977). ORCRIT. Oak Ridge critical point network program. Tech. rep.,Chemistry Division, Oak Ridge National Laboratory, USA.Jones, T. (1992). FRODO. graphics fitting program macromolecules. Sayre, D.(Ed.), Crystallographic Computing. Clarendon Press, Oxford.157fiLeherte, Glasgow, Baxter, Steeg, & FortierJones, T., Zou, J., Cowan, S., & Kjeldgaard, M. (1991). Improved methods buildingprotein models electron-density maps location errors models.Acta Crystallographica, A47, 110{119.Lapedes, A., Steeg, E., & Farber, R. (1995). Use adaptive networks evolve highlypredictable protein secondary-structure classes. Machine Learning, 21, 103{124.Lathrop, R., & Smith, T. (1994). branch bound algorithm optimal protein threading pairwise (contact potential) interaction preferences. L., H., & B., S. (Eds.),Proc. 27th Hawaii Intl. Conf. System Sciences, pp. 365{374. IEEE Computer Society Press, Los Alamitos, California.Lee, S., & Kim, Y. (1995). Direct extraction topographic features gray scale characterrecognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-17 (7), 724{729.Leherte, L., Baxter, K., Glasgow, J., & Fortier, S. (1994a). computational approachtopological analysis protein structures. Altman, R., Brutlag, D., P.Karp, Lathrop, R., & Searls, D. (Eds.), Proceedings Second International ConferenceIntelligent Systems Molecular Biology. MIT/AAAI Press, Menlo Park, California.Leherte, L., Fortier, S., Glasgow, J., & Allen, F. (1994b). Molecular scene analysis:topological approach automated interpretation protein electron density maps.Acta Crystallographica D, D50, 155{166.Leonardis, A., Gupta, A., & Bajcsy, R. (1995). Segmentation range images searchgeometric parametric models. International Journal Computer Vision, 14, 253{277.Maintz, J., van den Elsen, P., & Viergever, M. (1996). Evaluation ridge seeking operatorsmultimodality medical image matching. IEEE Transactions Pattern AnalysisMachine Intelligence, 18 (4), 353{365.Marr, D. (1982). Vision. W.H. Freeman Company: San Francisco.Marr, D., & Nishihara, H. (1978). Representation recognition spatial organisationthree-dimensional shapes. Proceedings Royal Society London, B200, 269{294.McLachlan, G., & Basford, K. (1988). Mixture Models. Inference Applications Clustering. Marcel Dekker, Inc.Rich, E., & Knight, K. (1991). Artificial Intelligence. McGraw-Hill, Inc. Second Edition.Rost, B., Casadia, R., & Farisellis, P. (1996). Refining neural network predictions helicaltransmembrane proteins dynamic programing. Fourth International ConferenceIntelligent Systems Molecular Biology (ISMB '96), pp. 192{200. AAAI Press,Menlo Park, California.Shortliffe, E. (1976). Computer-Based Medical Consultations: MYCIN. Elsevier, New York.158fiAnalysis Three-Dimensional Protein ImagesTerry, A. (1983). Crysalis Project: Hierarchical Control Production Systems. Ph.D.thesis, Stanford Heuristic Programming Project, Stanford University, California, USA.Unger, R., Harel, D., Wherland, S., & Sussman, J. (1989). 3D building blocks approachanalyzing predicting structure proteins. Proteins, 5, 355{373.Wang, B. (1985). Resolution phase ambiguity macromolecular crystallography.Wyckoff, H., Hirs, C., & Timasheff, S. (Eds.), Diffraction Methods BiologicalMacromolecules. Academic Press, New York.Wang, L., & Pavlidis, T. (1993). Direct gray scale extraction features characterrecognition. IEEE Trans. Patt. Anal. Mach. Intell., PAMI-15 (10), 1053{1067.Zhang, Z., & Faugeras, O. (1992). 3D Dynamic Scene Analysis. Springer-Verlag.159fiJournal Artificial Intelligence Research 7 (1997) 199-230Submitted 5/97; published 11/97Model Approximation Scheme Planning PartiallyObservable Stochastic DomainsNevin L. ZhangWenju LiuDepartment Computer ScienceHong Kong University Science TechnologyHong Kong, Chinalzhang@cs.ust.hkwliu@cs.ust.hkAbstractPartially observable Markov decision processes (POMDPs) natural modelplanning problems effects actions nondeterministic state worldcompletely observable. dicult solve POMDPs exactly. paper proposes new approximation scheme. basic idea transform POMDP anotherone additional information provided oracle. oracle informs planning agent current state world certain region. transformedPOMDP consequently said region observable. easier solve original POMDP. propose solve transformed POMDP use optimal policyconstruct approximate policy original POMDP. controlling amount additional information oracle provides, possible find proper tradeoffcomputational time approximation quality. terms algorithmic contributions,study details exploit region observability solving transformed POMDP.facilitate study, also propose new exact algorithm general POMDPs.algorithm conceptually simple yet significantly ecient previousexact algorithms.1. Introductioncompletely observable deterministic world, plan find sequence actionslead agent achieve goal. real-world applications, world rarely completely observable effects actions almost always nondeterministic. reason,growing number researchers concern planning partially observablestochastic domains (e.g., Dean & Wellman, 1991; Cassandra et al., 1994; Parr & Russell,1995; Boutilier & Poole, 1996). Partially observable Markov decision processes (POMDPs)used model planning domains. model, nondeterminismeffects actions encoded transition probabilities, partial observability worldobservation probabilities, goals criteria good plans reward functions (seeSection 2 details).POMDPs classified finite horizon POMDPs infinite horizon POMDPs depending number time points considered. Infinite horizon POMDPs usuallyused planning one typically know beforehand number stepstakes achieve goal. paper concerned solve infinite horizonPOMDP.c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiZhang & Liu1.1 Diculties Solving POMDPsworld fully observable, POMDP reduces Markov decision process (MDP).MDPs studied extensively dynamic-programming literature (e.g., Puterman, 1990; Bertsekas, 1987, White, 1993). Recent works concentrated deallarge state spaces (Dean et al., 1993; Boutilier et al., 1995; Dean & Lin, 1995).concerned partially observable case. case considerablydicult fully observable case two related reasons. First, agent knowsexactly state world currently is, information past (past observationsactions) irrelevant current decision. Markov property.hand, agent fully observe state world, past informationbecomes relevant help agent better estimate current stateworld. problem number possible states past information increasesexponentially time.Second, MDPs effects action fully observed next time point.POMDPs, hand, effects action fully observed nexttime point. Hence one cannot clearly tell effects current actionagent's future behaviors. properly evaluate effects action, one needs lookfuture consider combination action agent's possiblebehaviors a, possibly large, number future steps. problem numberways agent behave exponential number future steps considered.1.2 Previous WorkPrevious methods solving POMDPs usually classified exact methods approximate methods (Lovejoy, 1991a). also classified accordingaforementioned two diculties directly address. previous methods addressdiculty exponential number future behaviors (Sondik, 1971; Sondik & Mendelssohn,1979; Monahan, 1982; Cheng, 1988; Lovejoy, 1991b; Cassandra et al., 1994).prune consideration behaviors never optimal matter information state (Section 4). methods deal problem exponential numberpast information states either aggregating (Platzman, 1977; White & Schere,1994) considering subset (Lovejoy, 1992; Brafman, 1997; Hauskrecht,1997). approximation methods nature.1.3 Model Approximationprevious approximation methods, approximation takes place process solvingPOMDP. advocate model approximation methods. method approximatesPOMDP another one easier solve uses solution latterconstruct approximate solution original POMDP.Model approximation form informative observation model,deterministic action model, simpler state space, combination twothree alternatives. Cassandra et al. (1996) proposed approximate POMDPsusing MDPs. example model approximation form informativeobservation model. also work reducing size state spaces MDPs200fiModel Approximation Planning Uncertaintyaggregation (e.g., Bertsekas & Castanon, 1989; Dean & Lin, 1995; Dean & Givan, 1997).work conceivably extended POMDPs, leading model approximationform simpler state space. aware model approximation schemesform deterministic action model.1.4 Proposalpaper proposes new model approximation scheme form informativeobservation model. generalization idea approximating POMDPs usingMDPs.transform POMDP assuming that, addition observations obtaineditself, agent also receives report oracle knows true state world.oracle report true state itself. Instead, selects, predeterminedlist candidate regions, region contains true state reports region.transformed POMDP said region observable agent knows suretrue state region reported oracle.candidate regions singletons, oracle actually reports true stateworld. region observable POMDP reduces MDP. MDPs much easiersolve POMDPs. One would expect region observable POMDP solvablecandidate regions small.terms approximation quality, larger candidate regions, less additionalinformation oracle provides hence accurate approximation.extreme case one candidate region consists possible statesworld, oracle provides additional information all. Consequently, regionobservable POMDP identical original POMDP.method determining approximation quality described later paper.allows one make tradeoff approximation quality computational timefollows: start small candidate regions increase sizes graduallyapproximation becomes accurate enough region observable POMDP becomes untractable.Due problem characteristics, accurate approximation usually achievedsmall candidate regions. many applications agent often good ideastate world (e.g., Simmons & Koenig, 1995). Take robot path planning example.Observing landmark, room number instance, would imply robotproximity landmark. Observing feature world, corridor T-junctioninstance, might imply robot one several regions. Taking history account,robot might able determine unique region current location. Also, actionusually moves state world \nearby" states. Thus robotgood idea current state world, continue good ideanext steps.agent good idea state world times, oracleprovide much additional information even small candidate regions henceapproximation accurate. Region observable POMDPs small candidate regionsmuch easier solve general POMDPs.201fiZhang & Liu1.5 Organizationfirst show POMDPs used model planning partially observablestochastic domains (Section 2) give concise review theory POMDPs (Sections3 4). propose new method dynamic-programming updates, keystep algorithms solve POMDPs via value iteration (Section 5). Thereafter,formally introduce concept region observable POMDPs (Section 6) developalgorithm solving region observable POMDPs (Sections 7, 8, 9). Section 10,discuss decision making original POMDPs based solutionsregion observable approximations, followed method determining approximationquality (Section 11) method make tradeoff approximation qualitycomputational time (Section 12). Finally, empirical results reported Section 13conclusions provided Section 14.2. Planning Stochastic Domains POMDPsspecify planning problem, one needs give set possible states world,set possible observations, set possible actions. setsalways assumed finite literature, state space continuouswell finite. paper, consider finite state space. One needs also giveobservation model describes relationship observations stateworld, action model describes effects actions.background example, consider path planning robot acts oceenvironment. set location-orientation pairs, set possiblesensor readings, consists actions move-forward, turn-left, turn-right,declare-goal.current observation depends current state world s. Due sensornoise, dependency uncertain nature. observation sometimes also dependsaction robot taken a- . minus sign subscript indicatesprevious time point. POMDP model, dependency upon a-numerically characterized conditional probability P (ojs; a- ), usually referredobservation probability. observation model.region observable POMDP, current observation also depends previous state world s- . observation probability case writtenP (ojs; a- ; s-).state s+ world next time point depends current actioncurrent state s. plus sign subscript indicates next time point.dependency uncertain nature due uncertainty actuator. POMDPmodel, dependency s+ upon numerically characterized conditionalprobability P (s+ js; a), usually referred transition probability.action model.many occasions, need consider joint conditional probability P (s+ ; o+ js; a)next state world next observation given current statecurrent action. givenP (s+; o+js; a) = P (s+ js; a)P (o+ js+; a; s):202fiModel Approximation Planning UncertaintyKnowledge initial state, available, represented probability distributionP0 . agent knows initial state certainty, P0 1 initial state0 everywhere else. planning goal encoded reward functionfollowing:(a=declare-goal s=goal,r(s; a) = 10 ifotherwise.preference short plans encoded discounting future rewards respectcurrent reward (see next section).summary, POMDP consists set possible states world, set possibleobservations, set possible actions, observation probability, transition probability,reward function. MDP ingredients POMDP exceptobservation probability. state world completely observedMDP.3. Basics POMDPssection reviews several concepts results related POMDPs.3.1 Belief StatesPOMDP, agent chooses executes action time point. choicemade based information past (past observations past actions)current observation. amount memory required store past observations actionsincreases linearly time. makes dicult maintain past informationlong period time.standard way overcome diculty maintain, instead past information,agent's belief state | probability distribution P (st jot ; at,1 ; ot,1 ; : : : ; a1 ; o1 ; P0 )current state st world given past information current observation. wellknown belief state sucient statistic sense capturesinformation contained past information current observation usefulaction selection. Hence agent base decision solely belief state.Compared maintaining past information, maintaining belief state desirablenumber possible states world finite. One needs maintainfixed finite number probability values1 .initial belief state P0 . One question agent update beliefstate time goes by. Following Littman (1994), use b denote belief state.state s, b(s) probability world state s. set possible beliefstates denoted B.Suppose b current belief state, current action. observation o+obtained next time point, agent update belief state bnew belief state b+ givenXb+ (s+) = k P (s+; o+ js; a)b(s);(1)1. Storing values exactly could require unbounded precision. Approximations implicitlymade due fact machine precision bounded.203fiZhang & Liuk=1=Ps;s+ P (s+ ; o+js; a)b(s) normalization constant (e.g., Littman, 1994).3.2 POMDPs MDPsbelief state b action a, definer(b; a) =Xb(s)r(s; a):(2)expected immediate reward taking action belief state b.belief state b, action a, observation o+ , defineP (o+ jb; a) =Xs;s+P (s+; o+ js; a)b(s):(3)probability observing o+ next time point given current belief stateb current action a. Let b+ belief state given equation (1). P (o+ jb; a)also understood probability next belief state b+ givencurrent action current belief state b.POMDP world state space viewed MDP belief statespace B. reward function transition probability MDP givenEquations (2) (3) respectively.3.3 Optimal Policiestime point, agent consults belief state chooses action. policyprescribes action possible belief state. Formally mapping B A.belief state b, (b) action prescribed b.Suppose b0 current belief state. agent follows policy , currentaction (b0 ) immediate reward r0 (b; (b0 )); probability P (o+ jb0 ; (b0 )),agent's next belief state b1 given Equation (1), next action(b1 ), next reward r1 (b1 ; (b1 )); forth. qualitypolicy measured expected discounted rewards garners. Formally valuefunction policy defined belief state b0 following expectation:1XV (b0 ) = Eb0 [i=0ri (bi ; (bi ))];(4)0 <1 discount factor.policy 1 dominates another policy 2 belief state b2BV 1 (b) V 2 (b):(5)Domination partial ordering among policies. well known exists policydominates policies (e.g., Puterman, 1990). policy called optimalpolicy. value function optimal policy called optimal value functiondenoted V .204fiModel Approximation Planning Uncertainty3.4 Value IterationValue iteration standard way solving infinite horizon MDPs (Bellman, 1957).begins arbitrary initial function V0 (b) improves iteratively usingfollowing equationVt(b) = maxa [r(b; a) +Xo+P (o+ jb; a)Vt,1 (b+ )];(6)b+ belief state given equation (1). V0 =0, Vt called t-stepoptimal value function. belief state b, Vt (b) optimal expected rewardagent get steps starting b.following theorem (Puterman, 1990, page 361) tells one terminate valueiteration construct \good enough" policy.Theorem 1 Let policy given(b) = arg maxa [r(b; a) +Xo+P (o+ jb; a)Vt (b+ )]:(7)maxb2B jVt (b) , Vt,1 (b)j ,maxb2B jV (b) , V (b)j 12, :2(8)quantity maxb2B jVt (b) , Vt,1 (b)j sometimes called Bellman residualpolicy called greedy policy based Vt .Algorithms POMDPs classified exact approximation algorithms dependingwhether compute t-step optimal value function Vt exactly (Lovejoy, 1991a).next two sections, discuss theoretical foundations exact algorithmsdevelop new exact algorithm. Thereafter, propose new approximation algorithm.4. Piecewise Linearity Implicit Value IterationSince belief space continuous, exact value iteration cannot carried explicitly.Fortunately, carried implicitly due piecewise linearity t-stepoptimal value functions. explain piecewise linearity, need concept policy trees.4.1 Policy Treest-step policy tree pt (Littman, 1994) prescribes action current time pointaction possible information scenario (o1 ; : : : ; oi ; a0 ; : : : ; ai,1 )next t,1 time points i. Figure 1 shows 3-step policy tree. tree reads follows.Move-forward current time point. next time point, o1 =0 observedturn-left. Thereafter o2 =0 observed turn-left again; else o2 =1 observeddeclare-goal; else o2 =2 observed move-forward. forth.relate back introduction, t-step policy tree prescribes way agent mightbehave current next t,1 time points.205fiZhang & Liuturn-left20turn-lefta1O21a2declare-goal2a20forwarddeclare-goala20forwarda0O11turn-right2a11turn-right22turn-left22declare-goala20a1forward21turn-lefta22declare-goal2Figure 1: 3-step policy tree.t>1, subtree rooted o1 node called o-rooted t,1-step policytree, denoted t,1 . mapping set possible observationsset possible t,1-step policy trees; prescribes t,1 step policy tree t,1 (o)possible observation o. example, 2 (o1 =0) 2-step policy tree rooteduppermost a1 node.t>1, t-step policy tree pt two components: action current timepoint o-rooted t,1-step policy tree t,1 next t,1 time points.reason, shall sometimes write pt pair (a; t,1 ) call first action pt .altering actions edges a-nodes, one obtains different t-steppolicy trees. set possible t-step policy trees denoted Pt . 1-steppolicy tree simply action, hence P1 set possible actions A.4.2 State Value Functions Policy Treesstate t-step policy tree pt =(a; t,1 ), recursively defineVp (s) = r(s; a) +XXo+ s+V ,1 (o+) (s+ )P (s+ ; o+ js; a);(9)second term understood 0 t=1. expected discountedtotal reward agent receives current time next t,1 time pointsworld currently state agent behaves according policy tree pt .call Vp state value function t-step policy tree pt .Without mentioning policy tree, shall sometimes call Vp t-step state valuefunction. collection t-step state value functions denoted Vt , i.e.Vt = fVp jpt 2Pt g:convenience, let V0 consist one single function zero s.206fiModel Approximation Planning Uncertainty4.3 State Space Functions Belief Space Functionsworthwhile point t-step state value function state space function, i.e.function state space , t-step optimal value function belief spacefunction, i.e. function belief space B. often use notations ff firefer state space functions. state space function ff(s) induces belief space functionXff(b) = ff(s)b(s):Regarding b vector one component b(s) s, induced belief space functionlinear combination components b. convenience, simply say ff(b)linear b.collection V state space functions induces belief space functionV (b) = maxff2V ff(b):(10)Note using V denote set state space functions belief spacefunction induces. V empty, V (b) 0 definition.induced belief space function V (b) piecewise linear b sense that,ff2V , equals ff(b) region fbjff(b)fi (b) fi 2Vg belief space Bhence linear b region.4.4 Piecewise Linearity Optimal Value Functionsfollowing theorem first proved Sondik (1971). first appeared presentform Littman (1994).Theorem 2 (Piecewise Linearity) t-step optimal value function Vtbelief space function induced collection t-step state value functions Vt , i.e.belief state bVt (b) = Vt (b):2theorem true following reasons. Vt (b) reward agent receives behaves optimally policy tree pt , Vp (b) reward agent gets behaves according pt . one policy trees must optimal, Vt (b) = maxp Vp (b)=Vt (b).Due theorem, say collection Vt state value functions representationVt .4.5 Parsimonious Representationssize Vt increases exponentially t. matter fact, total number t-steppolicy trees (Cassandra, 1994) is:jOj ,1jPt j = jAj jOj,1 :potentially number t-step state value functions. Fortunately, manystate value functions pruned without affecting induced belief space function.Let us make property explicit.207fiZhang & LiuLet W X two sets state space functions. say W covers X inducesbelief space function X does, i.e.W (b) = X (b)belief state b. say W parsimoniously covers X W covers X noneproper subsets do. W covers parsimoniously covers X , refer Wcovering parsimonious covering X .Theorem 3 parsimonious coverings set state space functions consistnumber state space functions. 2theorem known sometime (e.g., Littman, 1994). Due theorem, onealso define parsimonious covering covering contains minimum numberstate space functions.parsimonious covering V^t Vt also representation Vt sense V^t (b) =Vt (b) belief state b. representation parsimonious consistsfewest number state space functions among representations Vt .4.6 Dynamic-Programming Updatesquestion obtain parsimonious covering Vt . shownnext section, possible obtain parsimonious covering Vt startingparsimonious covering Vt,1 . process computing parsimonious covering Vtparsimonious covering Vt,1 called dynamic-programming updates (Littman etal., 1995). key step algorithms solve POMDPs via value iteration.Previous algorithms dynamic-programming updates include enumerationpruning algorithms Monahan (1992), Eagle (1984), Lark (White, 1991), onepass algorithm Sondik (1971), linear support relaxed region algorithms Cheng(1988), witness algorithm Cassandra et al. (1994) Littman (1994).witness algorithm empirically proved ecient amongalgorithms (Littman et al., 1995).4.7 Implicit Value Iterationprocedure solvePOMDP shown Figure 2 carries value iteration implicitly: insteadinductively computing t-step optimal value function Vt itself, computes parsimonious covering Vt | set state space functions represents Vt . procedure,subroutine update(V^t,1) takes parsimonious covering V^t,1 Vt,1 returns parsimonious covering V^t Vt . implemented using algorithms mentionedprevious subsection. subroutine stop(V^t; V^t,1 ; ) determines whether Bellmanresidual fallen threshold parsimonious coverings V^t,1 V^tVt,1 Vt. See Littman (1994) implementation subroutine.Procedure solvePOMDP terminates Bellam residual falls thresholdreturn set state space functions. set V^t state space functions returnedrepresents t-step optimal value function Vt . solution input POMDP.planning agent keeps V^t memory. needs make decision, agentconsults belief state b chooses action using (7) Vt (b+ ) replaced V^t (b+ ).208fiModel Approximation Planning Uncertainty||||||||||||||||||||||Procedure solvePOMDP(M; ):Input: | POMDP,| positive number.Output: set state space functions.1. 0, V^0 f0g.2.t=t+1.V^t update(V^t,1 ):stop(V^t; V^t,1 ; ) = no.3. Return V^t .||||||||||||||||||||||Figure 2: Implicit value iteration.5. New Algorithm Dynamic-Programming Updatessection proposes new algorithm dynamic-programming updates. foursubsections. first three subsections, show parsimonious covering Vtobtained starting parsimonious covering Vt,1 and, so, introduceconcepts results necessary development new algorithm.5.1 Relationship Vt,1 VtLSuppose W X two sets state space functions. cross sum W X WX following set state space functions:W X = fff+fi jff2W ; fi 2Xg:evident cross sumLoperation commutative associative. Consequently,talk cross sum Ni=0 Wi list sets W0 , . . . , WN state space functions.action observation o+, defineQa;o+ = fXs+ff(s+)P (s+ ; o+ js; a)jff2Vt,1 g:P(11)Note since o+ given, member s+ ff(s+ )P (s+ ; o+ js; a)set function s, words, state space function. Hence Qa;o+ set statespace functions. Let 0, 1, . . . , N beL enumeration possible values o+. useLNo+ Qa;o+ denote cross sum i=0 Qa;i .Proposition 1 Vt = [a[fr(s; a)gL(Lo+ Qa;o+ )]:209fiZhang & LiuProof: definition set Vt Equation (9), state space function ff Vtexist action fio+ 2 Vt,1 o+ 2ff(s) = r(s; a) +X Xfio+ (s+)P (s+; o+ js; a):o+s+proposition follows. 25.2 Properties CoveringsLemma 1 Suppose W , X , three sets state space functions. W parsimoniously covers X X covers , W parsimoniously covers . 2Lemma 2 Let W , W 0 , X , X 0 four sets state space functions. W 0 covers WX 0 covers X ,LL1. W 0 X 0 covers W X .2. W 0 [X 0 covers W[X .25.3 Coverings Vt Parsimonious Coverings Vt,1Let V^t,1 parsimonious covering Vt,1 . action observation o+ ,defineQ0a;o+ = fXs+ff(s+)P (s+ ; o+ js; a)jff2V^t,1 g:Note definition Q0a;o+ Qa;o+ except Vt,1 replacedV^t,1 . Also defineMMVt0 = [a [fr(s; a)g ( o+ Q0a;o+ )]:Proposition 2 set Vt0 covers Vt.Formal proof proposition given Appendix A. Informally, fact V^t,1covers Vt,1 implies Q0a;o+ covers Qa;o+ , turn implies Vt0 covers Vt dueProposition 1 Lemma 2.According Proposition 2 Lemma 1, one obtain parsimonious coveringVt finding parsimonious covering Vt0 Vt0 defined terms parsimoniouscovering V^t,1 Vt,1 . said parsimonious covering Vtobtained starting parsimonious covering Vt,1 .Monahan's exhaustive method finds parsimonious covering Vt0 enumeratingstate space functions Vt0 one one detecting pruned solvinglinear programs. Lark's algorithm works similar fashion except linear programsfewer constraints. Since Vt0 consists jAjjV^t,1 jjOj state space functions, enumeratingone one expensive. algorithms (Sondik, 1971; Cheng, 1988; Littman,1994) avoid diculty exploiting structures Vt0 .210fiModel Approximation Planning Uncertainty|||||||||||||||||||||||Procedure incrPruning(fW0; W1 ; : : : ; WN g):1. W W0 .2. = 1 N ,WW Wi):purge(3. Return W .Procedure update(V^t,1):Input: V^t,1 | parsimonious covering Vt,1.Input: parsimonious covering Vt.1. a2A,(a) Compute sets Q0a;0 , Q0a;1 , . . . , Q0a;N .(b) Wa incrPruning(fQ0a;0 ; Q0a;1 ; : : : ; Q0a;N g).L2. Return purge([a [fr(s; a)g Wa ]).|||||||||||||||||||||||Figure 3: Incremental pruning dynamic-programming updates.5.4 New Algorithm Dynamic-Programming UpdatesLet purge(W ) subroutine takes set W state space functions returnsparsimonious covering W . implementation purge found appendix.Let W0 , . . . , WN sets state space functions. Consider procedure incrPruningshown Figure 3. Let n number 0 N . Using Lemmas 1 2, oneeasily show induction that,end nth pass for-loop, set WLnparsimoniousL covering i=0 Wi. Consequently, procedures returns parsimoniouscovering Ni=0 Wi . procedure named incremental pruning pruning takesplace cross sum.Let 0, 1, . . . , N enumeration possible observations, i.e. possible instantiations o+ . action a, suppose sets Q0a;0 , Q0a;1 , . . . , Q0a;Ncomputed. Applying incrPruning sets, get parsimoniouscoveringLN Q0 . Denote W . According Lemma 2, [ [fr (s; a)gLW ] covers V 0 . DueLi=0 a;iLemma 1, fact implies parsimonious covering [a [fr(s; a)g Wa ] alsoparsimonious covering Vt0 hence Vt . Thus, parsimonious covering Vtfound parsimonious covering Vt,1 using procedure update shown Figure 3.also use term incremental pruning refer algorithm dynamicprogramming updates. shown elsewhere (Cassandra et al., 1977) incremental pruning asymptotic complexity witness algorithm empiricallysignificantly outperforms latter.211fiZhang & Liu6. Region-Based Model Approximationfar concerned exact algorithms. Experiments incremental pruning, presently ecient exact algorithm, revealed solve smallPOMDPs (Cassandra et al., 1997). One needs resort approximation order solvelarge real-world problems.previous approximation methods solve POMDP directly; approximatet-step optimal value function POMDP. rest paper, develop newmethod approximates POMDP another informative observation model hence easier solve. latter POMDP solved solutionused construct solution original POMDP.6.1 Basic Ideamake following assumption problem characteristics. POMDP M, eventhough agent know true state world, often good ideastate. Justifications assumption given introduction empiricalevidence presented Simmons & Koenig (1995).Consider another POMDP M0 except additionobservation made itself, agent also receives report oracle knowstrue state world. oracle report true state itself. Instead selects,predetermined list candidate regions, region contains true statereports region.information available agent M0 M; additional informationprovided oracle. Since agent already good idea truestate world, oracle might provide much additional information evencandidate regions small. Consequently, M0 could good approximation M.M0 , agent knows sure true state world region reportedoracle. reason, say region observable. region observablePOMDP M0 much easier solve candidate regions small.example, oracle allowed report singleton regions, actually reportstrue state world hence M0 MDP. MDPs much easier solvePOMDPs. One would expect region observable POMDP M0 solvablecandidate regions small.6.2 Spectrum Approximationsregion reported oracle always set possible states, additionalinformation provided, report true state world onepossible states information content. case, M0 solutionsolving M0 equivalent solving directly. one extreme spectrum.extreme, candidate regions singletons, oracle reportstrue state world. Maximum amount additional information provided M0actually MDP. MDP might good approximation mucheasier solve M.212fiModel Approximation Planning UncertaintyPrevious methods solving POMDP either solve directly approximateusing MDP. allowing oracle report regions neither singletonsset possible states, paper opens possibility exploring spectrumtwo extremes. One way explore spectrum start singletoncandidate regions increase sizes gradually. Approximation quality computational time increase one goes along. One stops approximation accurateenough region observable POMDP becomes intractable. method determiningapproximation quality described later.set make ideas concrete starting concept regionsystems.6.3 Region Systemsregion simply subset states world. region system collection regionsregion subset another region collection union regionsequals set possible states world. use R denote region Rdenote region system.Region systems used restrict regions oracle choose report.choice region system determines computational complexity region observablePOMDP M0 approximation quality. choose regions make propertradeoff computational time approximation quality open research issue.preliminary approach. idea create region state including\nearby" states. say state s0 ideally reachable one step another stateexecuting certain action state s, probability world ending states0 highest. state sk ideally reachable k steps another state s0state s1 , . . . , sk,1 si+1 ideally reachable si one step 0ik,1.state ideally reachable 0 step.non-negative integer k, radius-k region centered state setstates ideally reachable k less steps. radius-k region system oneobtained creating radius-k region state removing, one another,regions subsets others.k 0, radius-k region system consists singleton regions.hand, state reachable state k less steps, oneregion radius-k region system | set possible states.6.4 Region Observable POMDPsGiven region system R POMDP M, construct region observable POMDP M0assuming time point agent obtains observationalso receives report oracle knows true state world. oraclereport true state itself. Instead chooses R one region contains truestate reports region.amount additional information provided oracle dependsregion system used also way oracle chooses regions. example,213fiZhang & Liuoracle always reports region centered true state, implicitly reportstrue state itself.order provide little additional information possible, oracle consideragent already knows. However, cannot take entire history past actionsobservations account did, M0 would POMDP. currentobservation would depend entire history.non-negative state space function f (s) region R, call quantitysupp(f; R)= Ps2R f (s)= Ps2S f (s) degree support f R. Note fprobability distribution, denominator 1. R supports f degree 1, say Rfully supports f .suggest following region-selection rule oracle. Let s- previous truestate world, a- previous action, current observation. oraclechoose, among regions R contain true state world, onesupports function P (s; ojs- ; a- ) maximum degree.one regions, choose one comes first predetermined ordering amongregions.arguments support rule. previous world state s-known agent, current belief state b(s), function s, would proportionalP (s; ojs- ; a- ). case, rule minimizes additional information senseregion reported supports current belief state maximum degree. previous world state known around s- , roughly true. Also currentobservation informative enough, landmark instance, ensure worldstate certain region, region chosen using rule fully supports currentbelief state. case, additional information provided. Despite arguments,claim rule described optimal. Finding rule minimizesadditional information still open problem.probability P (Rjs; o; s- ; a- ) region R chosen schemegiven8>< 1 Pif R the0 first regionPs.t. s2R 0and region R0P (Rjs; o; s-; a-) = >s0 2R P (s ; ojs- ; a- ) s0 2R0 P (s ; ojs- ; a- ): 0 otherwise.region observable POMDP M0 differs original POMDP termsobservation; addition observation made itself, agent also receivesreport R oracle. shall denote observation M0 z write z =(o; R).observation model M0 givenP (zjs; a- ; s-) = P (o; Rjs; a- ; s- ) = P (ojs; a- )P (Rjs; o; s- ; a- ):joint conditional probability P (s+ ; z+ js; a) next state s+ worldnext observation z+ given current state current actionP (s+; z+js; a) = P (s+ js; a)P (z+ js+ ; a; s):214fiModel Approximation Planning Uncertainty7. Solving Region Observable POMDPsprinciple, region observable POMDP M0 solved way generalPOMDPs using procedure solvePOMDP. advisable so, however, sincesolvePOMDP automatically exploit region observability. section nexttwo sections develop algorithm solving M0 takes advantage region observability.7.1 Restricted Value Iterationregion R, let BR set belief states fully supported R. Let Rregion system underlying region observable POMDP M0 . Define BR = [R2R BR .easy see that, M0 , matter current belief state b is, next beliefstate b+ must BR . assume initial belief state BR . possiblebelief states agent might encounter BR . implies policies M0 needdefined BR value iteration M0 restricted subset BR B.restrict value iteration M0 BR sake eciency. impliest-step optimal value function M0 , denoted Ut , defined BRBellman residual maxb2BR jUt (b) , Ut,1 (b)j. avoid confusion, callrestricted Bellman residual call Ut restricted t-step optimal value function.Since BR continuous, restricted value iteration cannot carried implicitly.next subsection shows carried implicitly.7.2 Implicit Restricted Value IterationLet W X two sets state space functions let R region. say Wcovers X region R if, b2BR ,W (b) = X (b):say W parsimoniously covers X region R W covers X region R noneproper subsets do. W covers parsimoniously covers X region, referW regional covering parsimonious regional covering X .Let Ut set t-step state value functions M0 . According Theorem 2,Ut (b) = Ut (b)belief state b2BR .region R, suppose U^t;R set state space functions parsimoniouslycovers Ut region R. collection fU^t;R jR2Rg representation Ut senseb2BR ,Ut (b) = U^t;R (b);(12)Rb b2BR , i.e. Rb fully supports b.shown next section, parsimonious regional coverings Ut obtained parsimonious regional coverings Ut,1 . Let ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg)procedure takes region R parsimonious regional covering fU^t,1;R+ jR+ 2Rgb215fiZhang & Liu|||||||||||||||||||||||||||Procedure solveROPOMDP(M0; )Input: M0 | region observable POMDP,| positive number.Output: list sets state space functions.1. 0.2. R2R, U^0;R f0g.3.t+1.R2R,U^t;R ROPOMDPupdate(R; fU^t,1;R+ jR+2Rg):ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R+ jR+2Rg; ) = no.4. Return fU^t;R jR2Rg.|||||||||||||||||||||||||||Figure 4: Implicit restricted value iteration region-observable POMDPs.Ut,1 returns set state space functions parsimoniously covers Ut region RLet ROPOMDPstop procedure determines, parsimonious regional coveringsUt,1 Ut , whether restricted Bellman residual fallen predeterminedthreshold.procedure solveROPOMDP shown Figure 4 carries restricted value iterationimplicitly: instead inductively computing restricted t-step optimal value function Utitself, computes parsimonious regional coverings Ut . words, computes setsstate space functions represent Ut sense (12).Let 0 greedy policy M0 based Ut . b2BR , 0 (b) definedEquation (7) o+ replaced z+ =(o+ ; R+ ) Vt replaced Ut . Since listfU^t;R jR2Rg sets state space functions returned solveROPOMDP represents Utsense (12), b2BR2.0 (b) = arg maxa[r(b; a) +Xo+ ;R+P ((o+ ; R+ )jb; a)U^t;R+ (b+ )]:next two sections show implement proceduresROPOMDPstop.ROPOMDPupdate2. string \ROPOMDP" ROPOMDPupdate stands region-observable POMDP.216(13)fiModel Approximation Planning Uncertainty8. Dynamic-Programming Updates Region Observable POMDPssection shows incremental pruning algorithm developed Section 5adapted compute parsimonious regional coverings Ut parsimonious regionalcoverings Ut,1 .8.1 Properties Regional CoveringsLemma 3 Let R region let W , X , three sets state space functions.W parsimoniously covers X region R X covers region R, W parsimoniouslycovers region R. 2Lemma 4 Let R region let W , W 0 , X , X 0 four sets state space functions.W 0 X 0 respectively cover W X region R,LL1. W 0 X 0 covers W X region R.2. W 0 [X 0 covers W[X region R. 28.2 Regional Coverings Ut Parsimonious Regional Coverings Ut,1parsimonious regional coverings U^t,1;R+ (R+ 2R) Ut,1 , subsection constructs,region R2R, set Ut;R state space functions shows covers Ut regionR.action observation z+ =(o+ ; R+ ) M0 , let Qa;z+ ;R setstate space functions fi following form:( Pfi (s) = s+ ff(s+ )P (s+ ; z+ js; a) s2R0otherwise.ff 2 U^t,1;R+ . DefineMMUt;R = [a [fr(s; a)g ((14)Q)]:z+ a;z+ ;RProposition 3 set Ut;R covers Ut region R.Formal proof proposition found Appendix A. Informally, factU^t,1;R+ covers Ut,1 region R+ implies Qa;z+;R covers Qa;z+ region R, Qa;z+given (11) o+ Vt,1 replaced z+ Ut,1 . fact turn impliesUt;R covers Ut region R Proposition 1 Lemma 4.8.3 Possible Observations Next Time Pointdefinition Ut;R , cross sum taken possible observations. subsectionshows possible observations skipped.action region R, defineZa;R = fz+ jXs+P (s+; z+ js; a) > 0 s2R g:217fiZhang & Liu||||||||||||||||||||||||||||||||||Procedure ROPOMDPupdate(R; U^t,1;R+ jR+ 2Rg):Inputs: R | region, region R+,U^t,1;R+ parsimoniously covers Ut,1 region R+.Output: set state space functions parsimoniously covers Utregion R.1. action a,(a) Compute set Za;R enumerate members 0; 1; : : : ; .(b) i=0 , compute set Qa;i;R .(c) Wa restrictedIncrPruning(fQa;0;R ; Qa;1;R ; : : : ; Qa;M;R g; R):L2. Return purge([a [fr(s; a)g Wa ]; R).Subroutine restrictedIncrPruning(fW0; W1 ; : : : ; WM g; R):1. Let W W0 .2. i=1 ,W purge(W Wi; R):3. Return W .||||||||||||||||||||||||||||||||||Figure 5: Dynamic-programming updates region observable POMDPs.set observations agent possibly receive next time point givencurrent state world lies region R current action a.many observations outside set. matter fact, observation z+ =(o+ ; R+ )set possible reach regionPR+ region R one step.z+ =(o+ ; R+ ), z+ 2= Za;R , s+ P (Ls+; z+ js; a) = 0 s2R.case, Qa;z+;R = f0g according (14). Since, f0g W =W set W state spacefunctions,MMUt;R = [a[fr(s; a)g (8.4 Parsimonious Regional Covering UtQ)]:z+ 2Za;R a;z+ ;RProposition 3 Lemma 3 imply that, region R, set state space functionsparsimoniously covers Ut region R parsimoniously covering Ut;R regionR. According Lemmas 3 4, set state space functions parsimoniously coversUt;R region R found using procedure ROPOMDPupdate shown Figure 5 (c.f.Section 5.4). procedure, subroutine purge(W ; R) takes set W state space218fiModel Approximation Planning Uncertainty|||||||||||||||||||||||||||Procedure ROPOMDPstop(fU^t;RjR2Rg; fU^t,1;R jR2Rg; )Inputs: | positive number, region RU^t;R covers Ut region R,U^t,1;R covers Ut,1 region R.Outputs: yes | restricted Bellman residual ,| Otherwise.1. region R,(a) ag yes.(b) ff2U^t,1;R ,ag dominate(ff; U^t;R ; R; ) 6= nil:(c) ff2U^t;R ,agdominate(ff; U^t,1;R ; R; ) 6= nil:(d) Return ag = no.2. Return yes.|||||||||||||||||||||||||||Figure 6: Procedure determining whether restricted Bellman residual fallenthreshold.functions region R, returns set state space functions parsimoniously coversW region R. implementation subroutine found Appendix B.9. Stopping Conditionsection shows determine whether restricted Bellman residual fallenpredetermined threshold regional coverings Ut Ut,1 . regionR, let U^t;R U^t,1;R two sets state space functions respectively cover UtUt,1 region R. definition regional coverings,Lemma 5 restricted Bellman residual larger regionR belief state b2BR ,1. ff2U^t;R ,ff(b) U^t,1;R (b)+;2. ff2U^t,1;R ,ff(b) U^t;R (b)+:2219fiZhang & LiuLet dominate(ff; W ; R; ) procedure returns belief state b BRff(b) > W (b)+. belief state exist, returns nil. implementationprocedure found Appendix B. procedure ROPOMDPupdate shownFigure 6 returns yes restricted Bellman residual fallen otherwise.couple notes order. First, reward function r(s; a) non-negative, Utincreases t. case, restricted Bellman residual becomes maxb2BR (Ut (b),Ut,1 (b)).Consequently, step (c) skipped. Second, r(s; a) takes negative valuesa, constant added becomes non-negative. Adding constant r(s; a) affect optimal policy. However, makes easier determinewhether restricted Bellman residual fallen threshold.10. Decision Making Original POMDPSuppose solved region observable POMDP M0 . next step constructpolicy original POMDP based solution M0 .Even though assumption original POMDP agent goodidea state world times, guarantee belief statealways BR . oracle M. policy prescribe actions belief statesBR well belief states outside BR . One issue policy 0 M0defined belief states BR . Fortunately, 0 naturally extended entirebelief space ignoring constraint b2BR Equation (13). hence define policyfollows: b2B,X(b) = arg maxa [r(b; a) +P ((o+ ; R+)jb; a)U^t;R+ (b+ )]:(15)o+ ;R+Let k radius region system underlying M0 . policy givenreferred radius-k approximate policy M. entire process obtainingpolicy, including construction solving region observable POMDP M0 ,referred region-based approximation.worthwhile compare equation Equation (7). Equation (7),two terms right hand side. first term immediate reward taking actionsecond term discounted future reward agent expect receivebehaves optimally. sum total expected reward taking action a. actionhighest total reward chosen.second term dicult obtain. essence, Equation (15) approximatessecond term using optimal expected future reward agent receive helporacle, easier compute.emphasized presence oracle assumed processcomputing radius-k approximate policy. oracle present executingpolicy.11. Quality Approximation Simulationgeneral, quality approximate policy measured distancevalue function V (b) optimal value function V (b). measurement220fiModel Approximation Planning Uncertaintyconsider agent might know initial state world. such,appropriate policy obtained region-based approximation. One cannot expectpolicy good quality agent uncertain initial stateworld obtained assumption agent good ideastate world times.section describes scheme determining quality approximate policycases agent knows initial state world certainty. schemegeneralized cases small amount uncertainty initial state;example, cases initial state known small region.agent might need reach goal different initial states different times. LetP (s) frequencyPit start state s3 . quality approximate policymeasured jV (s) , V (s)jP (s), V (s) V (s) denote rewardsagent expect receive starting state behaves optimally accordingrespectively.definition V (s)V (s) s. Let U optimal value functionregion observable POMDP M0 . Sinceinformation available agentM0 ,PPU (s)V (s) s. Therefore, [U (s) , V (s)]P (s) upper bound [V (s) ,V (s)]P (s).Let 0 policy M0 given (13). 0restricted Bellman residual small,P0 closeoptimal M0 value functionV 0 close U . Consequently,P0[V (s) , V (s)]P (s) upper bound [V (s) , V (s)]P (s) restrictedBellman residual small enough. P 0One way estimate quantity [V (s) , V (s)]P (s) conduct large numbersimulation trials. trial, initial state randomly generated according P (s).agent informed initial state. Simulation takes place M0 .M, agent chooses, step, action using based current belief state.action passed simulator randomly generates next state worldnext observation according transition observation probabilities. observation(but state) passed agent, updates belief state chooses nextaction. forth. trial terminates agent chooses actiondeclare-goal maximum number steps reached. Simulation M0 takes placesimilar manner except observations observation probabilities differentactions chosen using 0 .goal correctly declared end trial, agent receives rewardamount Pn ,n number steps. Otherwise, agent receive reward.0quantity [V (s) , V (s)]P (s) estimated using difference averagereward received trials M0 average reward received trials M.12. Tradeoff Quality ComplexityIntuitively, larger radius region system, less amount additionalinformationthe0 oracle provides.Hence closer M0 narrower gapPPV (s)P (s) V (s)P (s). Although theoretically proved this,3. confused initial belief state P0 , represents agent's knowledgeninitial state particular trial.221fiZhang & LiuPempirical results (see next section)do0 suggest V (s)P (s) increasesPradius region system V (s)P (s) decreases it. extreme caseone region region systempossible statesP contains Pworld, M0 identical hence V 0 (s)P (s) V (s)P (s).discussions lead following scheme making tradeoff complexity quality:P Start0 radius-0 region system increase radius graduallyquantity [V (s) , V (s)]P (s) becomes suciently small region observablePOMDP M0 becomes untractable.13. Simulation ExperimentsSimulation experiments carried show (1) approximation quality increases radius region system (2) much uncertainty, POMDPaccurately approximated region-observable POMDP solved exactly.section reports experiments.13.1 Synthetic Oce Environmentsexperiments conducted using two synthetic oce environments borrowedCassandra et al. (1996) minor modifications. Layouts environmentsshown Figure 7, squares represent locations. location representedfour states POMDP model, one orientation. dark locations roomsconnected corridors doorways.environment, robot needs reach goal location correct orientation. step, robot execute one following actions: move-forward,turn-left, turn-right, declare-goal. two sets action models given Figure7 used experiments. action move-forward, term F-F (0.01) meansprobability 0.01 robot actually moves two steps forward. termsinterpreted similarly. outcome cannot occur certain state world,robot left last state impossible outcome.state, robot able perceive three nominal directions (front,left, right) whether doorway, wall, open, undetermined. twosets observation models shown Figure 7 used experiments.13.2 Complexity Solving POMDPsOne POMDPs 280 possible states 200. 64possible observations 4 possible actions. Since largest POMDPs researchersable solve exactly far less 20 states 15 observations, safesay existing exact algorithms solve two POMDPs.able solve radius-0 radius-1 approximations (region observablePOMDPs) two POMDPs SUN SPARC20 computer. thresholdBellman residual set 0.001 discount factor 0.99. amounts timetook CPU seconds collected following table.222fiModel Approximation Planning UncertaintyNNGoal(south)Enviroment BGoal(east)EnvironmentTransition ProbabilitiesActionmove-forwardturn-leftturn-rightdeclare-goalStandard outcomesN (0.11), F (0.88), F-F (0.01)N (0.05), L (0.9), L-L (0.05)N (0.05), R (0.9), R-R (0.05)N (1.0)Noisy outcomesN (0.2), F (0.7), F-F (0.1)N (0.15), L (0.7), L-L (0.15)N (0.15), R (0.7), R-R (0.15)N (1.0)Observation ProbabilitiesActual case Standard observationswallwall (0.90), open (0.04), doorway(0.04), undetermined (0.02)openwall (0.02), open (0.90), doorway(0.06), undetermined (0.02)doorwaywall (0.15), open (0.15), doorway(0.69), undetermined (0.01)Noisy observationswall (0.70), open (0.19), doorway(0.09), undetermined (0.02)wall (0.19), open (0.70), doorway(0.09), undetermined (0.02)wall (0.15), open (0.15), doorway(0.69), undetermined (0.01)Figure 7: Synthetic Oce Environments.EnvironmentBStandard modelsNoisy modelsRadius-0 Radius-1 Radius-0 Radius-11.2633731.3559840.6124370.723952see radius-1 approximations took much longer time solve radius-0approximations. Also notice region observable POMDPs noisy actionobservation models took time solve standard models. suggests nondeterministic actions less informative observations,dicult solve POMDP.223fiZhang & Liuunable solve radius-2 approximations. approximation techniquesneed incorporated order solve approximations based region systemsradius larger equal 2.13.3 Approximation Quality Standard Modelsdetermine quality radius-0 radius-1 approximate policies POMDPsstandard action observation models, 1000 simulation trials conducted usingscheme described Section 11. assumed agent equally likely startstate. Average rewards obtained original POMDPs (i.e. withouthelp oracle) corresponding region-observable POMDPs M0 (i.e.help oracle) shown following table.Environmentradius-0 radius-1Average reward 0.806535 0.815695Average reward M0 0.827788 0.818534Difference0.021253 0.002839Environment Bradius-0 radius-10.866118 0.8685330.883271 0.8763560.017153 0.007823see that, radius-0 policies used, differences rewardsobtained obtained M0 small environments. indicatesradius-0 region observable POMDPs (i.e. MDPs) accurate approximationsoriginal POMDPs. radius-0 approximate policies close optimaloriginal POMDPs. radius-1 policies used, differences even smaller;rewards obtained obtained M0 essentially same.Consider rewards obtained original POMDPs. see largerradius-1 policies used radius-0 policies used. supportsclaim approximation quality increases radius region system.another fact worth mentioning. differences rewards obtainedobtained M0 larger Environment B Environment A.Environment B symmetric consequently observations less effectivedisambiguating uncertainty agent's belief state world.13.4 Approximation Quality Noisy ModelsOne thousand trials also conducted POMDPs noisy action observation models. Results shown following table.Environmentradius-0 radius-1Average reward 0.596670 0.634934Average reward M0 0.812898 0.722441Difference0.214228 0.087507224Environment Bradius-0 radius-10.445653 0.5650990.871903 0.8183650.426250 0.253266fiModel Approximation Planning Uncertaintysee differences rewards obtained rewards obtainedM0 significantly smaller radius-1 policies used radius-0policies used. case especially Environment A. Also rewards obtainedlarger radius-1 policies used radius-0 policiesused. support claim approximation quality increases radiusregion system.far absolute approximation quality concerned, radius-0 POMDPs (i.e.MDPs) obviously poor approximations original POMDPs; radius-0policies used, rewards obtained significantly smaller rewards obtained M0 . Environment A, radius-1 approximation fairly accurate. However,radius-1 approximation remains poor Environment B. radius region systemneeds increased.Tracing trials step step, observed interesting facts. Environment B, agent, guidance radius-1 approximate policy, ablequickly get neighborhood goal even starting far way. factEnvironment around goal highly symmetric cause poor performance. Often agent able determine whether goal location(room), opposite room, left room, room rightgoal location. performance would close optimal goal locationdistinct features.Environment A, agent, guidance radius-1 approximatepolicy, able reach declare goal successfully got neighborhood.However, often took many unnecessarily steps reaching neighborhood dueuncertainty effects turning actions. example, agent reachedlower left corner above, facing downward. agent executed actionturn_left. Fifteen percent time, ended facing upward instead right.agent decided move-forward, thinking approaching goal.actually moving upward realize steps later. agentwould perform much better informative landmarks around corners.14. Conclusionspropose approximate POMDP using region observable POMDP. regionobservable POMDP informative observations hence easier solve.method determining approximation quality described, allows one maketradeoff approximation quality computational time starting coarseapproximation refining gradually. Simulation experiments shownmuch uncertainty effects actions observations informative,POMDP accurately approximated region observable POMDPsolved exactly. However, becomes infeasible degree uncertainty increases.approximate methods need incorporated order solve region observablePOMDPs whose radiuses small.225fiZhang & LiuAcknowledgementspaper benefited discussions Anthony R. Cassandra Michael Littman.also thank associate editor Thomas L. Dean three anonymous reviewersinsightful comments suggestions pointers references. Researchsupported Hong Kong Research Council grants HKUST 658/95E Hong KongUniversity Science Technology grant DAG96/97.EG01(RI).Appendix A: Proofs Propositions 2 3Lemma 6 Suppose W X two sets state space functions. W covers X ,non-negative function f (s),maxff2WXff(s)f (s) = maxfi2XXfi (s)f (s):2Proof Proposition 2: Proposition 1 Lemma 2, suces showQ0a;o+ covers Qa;o+ . definition Qa;o+ Equation (10), have, beliefstate b,X XQa;o+ (b) = maxff2V ,1 [ff(s+ )P (s+; o+ js; a)]b(s)XX= maxff2V ,1 ff(s+ )[ b(s)P (s+ ; o+ js; a)]s+s+Since V^t,1 covers Vt,1 term within square brackets non-negative functions+, Lemma 6Xff(s+ )[ b(s)P (s+; o+ js; a)]Xs+ X= maxff2V^ ,1 [ ff(s+ )P (s+ ; o+ js; a)]b(s)Qa;o+ (b) = maxff2V^ ,1X= Q0a;o+ (b);s+last equation due definition Q0a;o+ Equation (10). So, Q0a;o+cover Qa;o+ . proposition proved. 2Lemma 7 observation z+=(o+; R+) region observable POMDP M0,P (s+; z+ js; a) = 0;s+ 2= R+ . 2Informally, lemma says true state world must region reportedoracle.Lemma 8 Let W X two sets state space functions R region. W coversX region R, non-negative function f (s) 0 s=2R,XXmaxff2W ff(s)f (s) = maxfi2X fi (s)f (s):2226fiModel Approximation Planning UncertaintyProof Proposition 3: Proposition 1 Lemma 4, suces showQa;z+;R covers Qa;z+ region R, Qa;z+ given (11) o+ Vt,1 replacedz+ Ut,1 .Let b belief state BR . Similar proof Theorem 2,XXQa;z+ (b) = maxff2U ,1 ff(s+)[ b(s)P (s+; z+js; a)]s+Xff()[b(s)P (s+ ; z+ js; a)]++ s+X X= maxff2U^ ,1 + [ ff(s+ )P (s+ ; z+ js; a)]b(s)s2R s+X= maxfi2Q +fi (s)b(s)= maxff2U^ ,1a;zX;R;R;R= Qa;z+ ;R (b);second equation true fact U^t,1;R+ covers Ut,1 region R+Lemma 8. term within square brackets non-negative function s+0 s+2= R+ Lemma 7. fourth equation true b(s)=0s=2R. proposition proved. 2Appendix B: Domination Pruningappendix describes implementation procedures dominate(ff; W ; R; ), purge(W ; R),purge(W ). given main text minor adaptationsexisting algorithms.procedure dominate(ff; W ; R; ) takes, inputs, state space function ff, setstate space functions W , region R, nonnegative number . returns belief stateb BR ff(b)>W (b)+. belief state exist, returns nil.implemented follows.Procedure dominate(ff; W ; R; )Inputs: ff | state space function,W | set state space functions,R | region, | nonnegative number.Output: belief state BR nil.1. W =;, return arbitrary belief state BR .2. Solve following linear program:Variables: x, b(s) s2R.Maximize: xConstraints:XXff(s)b(s) x + fi (s)b(s) fi 2W ;s2 RXs2Rb(s) = 1s2 Rb(s) 0 s2R:227fiZhang & Liu3. x, return nil, else return b.procedure purge(W ; R) takes set state space functions W region Rreturns set state space functions parsimoniously covers W region R.implement it, need two subroutines.state space function ff pointwise dominates another state space function fi regionR ff(s)fi (s) s2R. subroutine pointwisePurge(W ; R) returns minimalsubset W 0 W state space function W pointwise dominatedregion R least one state space function W 0 . Implementation subroutinestraightforward.Psubroutinebest(b; W ; R) returns state space function ff W s2R b(s)ff(s)P b(s)fi (s) state space function fi W . Implementation subroutines2Rstraightforward except issue tie breaking. ties broken properly,purge(W ; R) might return regional covering W parsimonious. correct waybreak ties follows: Fix ordering among states R. induces lexicographicordering among state space functions. Among tied state space functions, choseone largest lexicographic ordering (Littman, 1994).following implementation purge based Lark's algorithm (White, 1991).Procedure purge(W ; R)Inputs: W | set state space functions,R | region.Output: set state space functions parsimoniously covers Wregion R.1. W pointwisePurge(W ; R).2. X ;.3. W6=;,(a) Pick state space function ff W .(b) b dominate(ff; X ; R; 0).(c) b =nil, remove ff W .(d) Else remove best(b; W ; R) W add X .4. Return X .Finally, procedure purge(W ) takes set state space functions W returnsparsimonious covering W . implemented simply follows.Procedure purge(W ):W ; ).purge(Here, set possible states world.228fiModel Approximation Planning UncertaintyReferencesBellman, R. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D. P. (1987). Dynamic Programming: Deterministic Stochastic Models.Prentice-Hall.Bertsekas, D. P., & Castanon, D. C. (1989). Adaptive Aggregation Infinite HorizonDynamic Programming. IEEE trans. auto. control, vol 34, 6.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structures policyconstruction. Proceedings IJCAI-95, 1104-1111.Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observabledecision processes using compact representations. Proceedings AAAI-96, 11681175.Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Proceedings AAAI-97, 727-733.Cassandra, A. R. (1994). Optimal polices partially observable Markov decision processes. TR CS-94-14, Department Computer Science, Brown University, Providence, Rhode Island 02912, USA.Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partiallyobservable stochastic domains. Proceedings AAAI-94, 1023-1028.Cassandra, A. R., Kaelbling, L. P., & Kurien, J. (1996). Acting uncertainty: Discrete Bayesian models mobile-robot navigation. Proceedings IEEE/RoboticsSociety Japan Conference Intelligent Robotics Systems (IROS-96).Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple,fast, exact method partially observable Markov decision processes. ProceedingsThirteenth Conference Uncertainty Artificial Intelligence, 54-61.Cheng, H. T. (1988). Algorithms partially observable Markov decision processes. PhDthesis, University British Columbia, Vancouver, BC, Canada.Dean, T. L., Givan, R., & Leach, S. (1997). Model reduction techniques computingapproximately optimal solution Markov decision processes. ProceedingsThirteenth Conference Uncertainty Artificial Intelligence, 124-131.Dean, T. L., Kaelbling, L. P., Kirman, J., & Nicholson A. (1993). Planning deadlinesstochastic domains. Proceedings AAAI-93, 574-579.Dean T. L., & Lin, S. H. (1995). Decomposition techniques planning stochasticdomains. TR CS-95-10, Department Computer Science, Brown University, Providence, Rhode Island 02912, USA.Dean, T. L., & Wellman, M. P. (1991). Planning Control. Morgan Kaufmann.229fiZhang & LiuEagle, J. N. (1984). optimal search moving target search pathconstrained. Operations Research, 32(5), 1107-1115.Hauskrecht, M. (1997). Incremental methods computing bounds partially observableMarkov decision processes. Proceedings AAAI-97, 734-739.Littman, M. L. (1994). witness algorithm: Solving partially observable Markov decision processes. TR CS-94-40, Department Computer Science, Brown University,Providence, Rhode Island 02912, USA.Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Ecient dynamic-programmingupdates partially observable Markov decision processes. TR CS-95-19, DepartmentComputer Science, Brown University, Providence, Rhode Island 02912, USA.Lovejoy, W. S. (1991a). survey algorithmic methods solving partially observableMarkov decision processes. Annals Operations Research, 28 (1), 47-65.Lovejoy, W. S. (1991b). Computationally feasible bounds partially observed Markovdecision processes. Operations Research, 39 (1), 162-175.Monahan, G. E. (1982). survey partially observable Markov decision processes: theory, models, algorithms. Management Science, 28 (1), 1-16.Parr, R., & Russell, S. (1995). Approximating optimal polices partially observablestochastic domains. Proceedings IJCAI-95, 1088-1094.Platzman, L. K. (1977). Finite-memory estimation control finite probabilistic systems. Ph.D. Thesis, Department Electrical Engineering Computer Science,Massachusetts Institute Technology.Puterman, M. L. (1990). Markov decision processes. D. P. Heyman M. J. Sobel(eds.), Handbooks & MS., Elsevier Science Publishers, Vol. 2, 331-434.Sondik, E. J. (1971). optimal control partially observable Markov processes. PhDthesis, Stanford University, Stanford, California, USA.Sondik, E. J., & Mendelssohn, R. (1979). Information seeking Markov decision processes,Southwest Fisheries Center Administrative Report H-79-13, National Marine FisheriesService, Honolulu, Hawaii.White III, C. C. (1991). Partially observed Markov decision processes: survey. AnnalsOperations Research, 32.White, D. J. (1993). Markov Decision Processes. John Wiley & Sons.White III, C. C., & Scherer, W. T., (1994). Finite-memory suboptimal design partiallyobserved Markov decision processes. Operations Research, 42(3), 440-455.230fiJournal Artificial Intelligence Research 7 (1997) 6782Submitted 5/97, published 9/97Identifying Hierarchical Structure Sequences:linear-time algorithmCraig G. Nevill-ManningIan H. WittenDepartment Computer ScienceUniversity Waikato, Hamilton, New Zealand.CGN@CS.WAIKATO.AC .NZIHW@CS.WAIKATO.AC .NZAbstractEQUITUR algorithm infers hierarchical structure sequence discrete symbolsreplacing repeated phrases grammatical rule generates phrase, continuingprocess recursively. result hierarchical representation original sequence,offers insights lexical structure. algorithm driven two constraints reducesize grammar, produce structure by-product. EQUITUR breaks new groundoperating incrementally. Moreover, methods simple structure permits proof operatesspace time linear size input. implementation process 50,000symbols per second applied extensive range real world sequences.1. IntroductionMany sequences discrete symbols exhibit natural hierarchical structure. Text madeparagraphs, sentences, phrases, words. Music composed major sections, motifs, bars,notes. Records user interface behavior encode hierarchical structure tasks usersperform. Computer programs constitute modules, procedures, statements. Discoveringnatural structure underlies sequences challenging interesting problem widerange applications, phrase discovery music analysis, programmingdemonstration code optimization.search structure sequences occurs many different fields. Adaptive textcompression seeks models sequences used predict upcoming symbolsencoded efficiently (Bell et al., 1990). However, text compression modelsextremely opaque, illuminate hierarchical structure sequence. Grammaticalinference techniques induce grammars set example sentences, possibly along setnegative examples (Gold, 1967; Angluin, 1982; Berwick Pilato, 1987). However,crucial operation input continuous stream segmented sentences,are, effect, independent examples structure sought. brief reviewpertinent systems appears Section 8. Techniques Markov modeling hidden Markovmodeling make attempt abstract information hierarchical form (Rabiner Juang, 1986,Laird Saul, 1994). Sequence learning also occurs areas automaton modeling(Gaines, 1976), adaptive systems (Andreae, 1977), programming demonstration (Cypher,1993), human performance studies (Cohen et al., 1990), generally plays peripheralrole.paper describe SEQUITUR, algorithm infers hierarchical structuresequence discrete symbols. basic insight phrases appearreplaced grammatical rule generates phrase, processcontinued recursively, producing hierarchical representation original sequence. result1997 AI Access Foundation Morgan Kaufmann Publishers. rights reservedfiNEVILL-MANNING & WITTENstrictly grammar, rules generalized generate one string. (Itprovide good basis inferring grammar, beyond scope paper.)scheme resembles one developed arose work language acquisition (Wolff,1975, 1977, 1980, 1982), operated time quadratic respect lengthinput sequence, whereas algorithm describe takes linear time. let us investigatesequences containing several million tokensin previous work examples much smaller,largest mentioned thousand tokens. Another difference, crucialimportance practical applications, new algorithm works incrementally.return Wolffs scheme, compare SEQUITUR, Section 8.ability deal easily long sequences greatly extended range SEQUITURsapplication. applied artificially-generated fractal-like sequences produced Lsystems, and, along unification-based rule generalizer, used recover original Lsystem. method inferred relatively compact deterministic, context-free grammarsmillion-symbol sequences representing biological objects obtained stochastic, contextsensitive, L-systems, turn greatly speeded graphical rendering objects.applied SEQUITUR 40 Mbyte segments digital library generate hierarchicalphrase indexes text, provides novel method browsing (Nevill-Manning et al.,1997). algorithm compresses multi-megabyte DNA sequences effectivelygeneral-purpose compression algorithms. Finally, post-processing, elicitedstructure two million word extract genealogical database, successfully identifyingstructure database compressing much efficiently best knownalgorithms. touch applications Section 3 below; Nevill-Manning (1996)describes all.paper describes SEQUITUR algorithm evaluates behavior. next sectiongives concise description algorithm terms constraints form outputgrammar. Section 3 gives taste kind hierarchies SEQUITUR capable inferringrealistic sequences. Section 4 describes implementation detail, particularemphasis achieves efficiency. Section 5 shows run time storagerequirements linear number input symbols, Section 6 discusses algorithmsbehavior extreme input strings. end quantitative analysis SEQUITURsperformance several example sequences, review related research.2. SEQUITUR AlgorithmSEQUITUR forms grammar sequence based repeated phrases sequence.repetition gives rise rule grammar, repeated subsequence replaced nonterminal symbol, producing concise representation overall sequence.pursuit brevity drives algorithm form maintain grammar, and, byproduct, provide hierarchical structure sequence.left Figure 1a sequence contains repeating string bc. Notesequence already grammara trivial one single rule. compress it, SEQUITUR formsnew rule bc, replaces occurrences bc. new grammar appears rightFigure 1a.sequence Figure 1b shows rules reused longer rules. longersequence consists two copies sequence Figure 1a. Since represents exact68fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCESrepetition, compression achieved forming rule abcdbc replace halvessequence. gains made forming rule B bc compress rule A.demonstrates advantage treating sequence, rule S, part grammarrules mayformed rule analogous way rules formed rule S. rules within rulesconstitute grammars hierarchical structure.grammars Figures 1a 1b share two properties:p 1 : pair adjacent symbols appears grammar;p 2 : every rule used once.Property p 1 requires every digram grammar unique, referreddigram uniqueness. Property p2 ensures rule useful, called rule utility.two constraints exactly characterize grammars SEQUITUR generates.Figure 1c shows happens properties violated. first grammar containstwo occurrences bc, p1 hold. introduces redundancy bc appears twice.second grammar, rule B used once, p 2 hold. removed,grammar would become concise. grammars Figures 1a 1b onesproperties hold sequence. However, always unique grammarproperties. example, sequence Figure 1d representedgrammars right, obey p 1 p2 . deem either grammar acceptable.Repetitions cannot overlap, string aaa give rise rule, despite containing twodigrams aa.SEQUITURs operation consists ensuring properties hold. describingalgorithm, properties act constraints. algorithm operates enforcing constraintsgrammar: digram uniqueness constraint violated, new rule formed,rule utility constraint violated, useless rule deleted. next two subsections describeoccurs.2.1 Digram UniquenessSEQUITUR observes new symbol, appends rule S. last two symbols rulenew symbol predecessorform new digram. digram occurs elsewheregrammar, first constraint violated. restore it, new rule formed digramright-hand side, headed new non-terminal symbol. two original digramsreplaced non-terminal symbol.SequenceGrammarabcdbcaAdAbccabcdbcabcdbcAAabcdbcSequenceGrammarbabcdbcabcdbcAAaBdBB bcaabaaabAaAaabCCbcB aAC BdAAbAabaaFigure 1 Example sequences grammars reproduce them: (a)sequence one repetition; (b) sequence nested repetition; (c)two grammars violate two constraints; (d) two different grammarssequence obey constraints.69fiNEVILL-MANNING & WITTENTable 1 shows grammars result successive symbols sequenceabcdbcabcd processed. second column shows sequence observed far, thirdcolumn gives grammar created sequence, fourth column notes constraintsviolated, actions taken resolve violations.SEQUITUR adds final c symbol 6, digram bc appears twice. SEQUITUR createsnew rule A, bc right-hand side, replaces two occurrences bc A.illustrates basic procedure dealing duplicate digrams.appearance duplicate digram always result new rule. new digramappears right-hand side existing rule, new rule need created: nonterminal symbol heads existing rule replaces digram. symbol 9 Table 1,third bc appears, existing non-terminal symbol replaces third occurrence bc.results new pair repeating digrams, aA, shown next line Table 1. SEQUITURaccordingly forms new rule B, replaces two occurrences aA. SEQUITUR createsmaintains hierarchy iterative process: substitution bc results newdigram aA, replaced B. larger sequences, changes ripplegrammar, forming matching longer rules higher hierarchy.symbolnumberstringfarresultinggrammarremarks1Sa2abab3abcabc4abcdabcd5abcdbabcdb6abcdbcabcdbcbc appears twiceaAdAbcenforce digram uniqueness7abcdbcaaAdAabc8abcdbcabaAdAabbc9abcdbcabcaAdAabcbcbc appears twiceaAdAaAbcenforce digram uniqueness.aA appears twiceBdABbcB aAenforce digram uniquenessBdABdbcB aABd appears twiceCACbcB aAC Bdenforce digram uniqueness.B usedCACbcC aAdenforce rule utility10abcdbcabcdTable 1 Operation two grammar constraints,digram uniqueness rule utility70fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCES2.2 Rule Utilitynow, right-hand sides rules grammar two symbols long. Longerrules formed effect rule utility constraint, ensures every rule usedonce. Table 1, symbol 10 demonstrates idea. appended rule S,new digram Bd causes new rule, C, formed. However, forming rule leaves oneappearance rule B, violating second constraint. reason, B removedgrammar, right-hand side substituted one place occurs. Removing Bmeans rule C contains three symbols. mechanism forming long rules:form short rule temporarily, subsequent symbols continue match, allow new rulesupersede shorter one delete latter. Although creation deletion rulesappears inefficient first glance, performed efficiently appropriate datastructures. importantly, keeps track long matches within grammar, obviatingneed external data structures. simplifies algorithm considerably, permitting conciseproof linear time complexity (see Section 5).3. Structures Inferred Realistic Sequencesdescribed mechanism SEQUITUR builds grammar, embarkingefficiency issues, instructive consider structures simple technique inferrealistic sequences. case applied SEQUITUR large sample excerptedpart structure illustrative purposes.Figures 2a, 2b 2c show parts three hierarchies inferred text BibleEnglish, French, German. hierarchies formed without knowledge preferredstructure words phrases, nevertheless capture many meaningful regularities.Figure 2a, word beginning split begin ninga root word suffix. Many wordsword groups appear distinct parts hierarchy (spaces made visiblereplacing bullets). algorithm produces French version Figure 2b,commencement split analogous way beginninginto root commencesuffix ment. Again, words Au, Dieu cieux distinct units hierarchy.German version Figure 2c correctly identifies words sentence, well phrasedie Himmel und die. fact, hierarchy heaven Figure 2a bearssimilarity German equivalent.London/Oslo-Bergen corpus (Johansson et al., 1978) contains 1.2 million words taggedword classes. example, sentence Labour sentiment would still favourabolition House Lords tagged classes determiner noun noun auxiliary adverbverb article noun preposition article noun preposition noun. hierarchy SEQUITUR infersword classes corresponds possible parse sentence corpus,tree expressed terms parts speech. Figure 2d shows part inferred hierarchy,tags replaced actual words text. SEQUITUR identifies middlepart sentence, sentiment would still favour abolition large block, part couldstand grammatical sentence. adjectival phrase House Lords alsoappears distinct unit, Labour, adjectival phrase precedes subject.Figure 2e shows two Bach chorales SEQUITUR detected internalrepetitionsthe light gray boxes show two halves first chorale almostidenticaland repetitions chorales, denoted gray box second half71fiNEVILL-MANNING & WITTENn h e b e g n n n g G c r e e h e h e v e n n h e e r hbu c e n c e e n , e u c r l e c e u x e l e r r ecxxn f n g c h u f G e H e l u n e E r eLabour sentiment would still favour abolition House LordseimperfectperfectFigure 2 Hierarchies various sequences: Genesis 1:1 (a) English, (b) French, (c) German;(d) grammatical parse inferred sequence word classes; (e) repetitions withintwo chorales harmonized J.S. Bach.second chorale. section white box occurs four halves. Also, detecting repeatedmotifs many chorales, SEQUITUR identifies imperfect perfect cadences endfirst second halves, respectively. general, SEQUITUR capable making plausibleinferences lexical structure sequences, hierarchies produces aid comprehensionsequence.4. Implementation IssuesSEQUITUR algorithm operates enforcing digram uniqueness rule utility constraints.essential violation constraints detected efficiently, sectiondescribe mechanisms fulfill requirement.choice appropriate data structure depends kind operations needperformed modify grammar. SEQUITUR are:appending symbol rule S;using existing rule;creating new rule;deleting rule.Appending symbol involves lengthening rule S. Using existing rule involves substitutingnon-terminal symbol two symbols, thereby shortening rules containing digrams.Creating new rule involves creating new non-terminal symbol left-hand side,72fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCESBcBbcddigramBcindexabFigure 3 Data structures rules digram indexinserting two new symbols right-hand side. creating rule, substitutions madeexisting rule replacing two digrams new non-terminal symbol. Deletingrule involves moving contents replace non-terminal symbol, lengthens rulecontaining non-terminal symbol; left-hand side rule must deleted.ensure rules lengthened shortened efficiently, SEQUITUR represents ruleusing doubly-linked list whose start end connected single guard node, showntwo rules B Figure 3. guard node also serves attachment point left-handside rule, remains constant even rule contents change. nonterminal symbol also points rule heads, shown Figure 3 pointer nonterminal symbol B rule head rule B. pointers, arrays necessaryaccessing rules symbols, operations affect adjacent symbols rules headednon-terminal.rule utility constraint demands rule deleted referred once.rule associated reference count, incremented non-terminal symbolreferences rule created, decremented non-terminal symbol deleted.reference count falls one, rule deleted.digram uniqueness constraint difficult enforce. new digram appears,SEQUITUR must search grammar occurrence it. One simple solution wouldscan entire grammar time looking match, inefficient leadsquadratic-time algorithm. better solution requires index efficient search.data structure storing digram index must permit fast access efficient additiondeletion entries. hash table provides constant-time access, adding deletingentries requires little extra work. digram appears once, table needcontain pointer first symbol single matching digram grammar data structure,shown Figure 3. hash table consists simple array pointers, collisionshandled open addressing avoid allocation memory chaining requires (Knuth,1968).Every time new digram appears grammar, SEQUITUR adds index. newdigram appears result two pointer assignments linking two symbols together doublylinked list (one forward pointer one back pointer). Thus updating indexincorporated low-level pointer assignments. digram also disappears grammarpointer assignment madethe pointer value overwritten assignmentrepresents digram longer exists.demonstrate mechanism updating hash table new rule created, Table2 shows example Figure 1a, addition contents digram index.second c appended rule S, digram table shows bc already exists grammar,rule bc created. Creating link b c right-hand side ruleupdates entry index bc point new locationthe hash table containspointer symbol b start rule A. Next, first bc removed. breaks linkb digram preceding symbol a, ab removed index. also73fiNEVILL-MANNING & WITTENActiongrammarobserve symbol cabcdbcchange digramsdigram indexmake new ruleabcdbcbcbc updated{ab, bc, cd, db}substitute bcaAdbcbcab, cd removed,aA, Ad added{bc, db, aA, Ad}substitute bcaAdAbcdb removed,dA added{bc, dA, aA, Ad}{ab, bc, cd, db}Table 2 Updating digram index links made brokenbreaks link c following d, cd removed index. Next, replacesbc, creating links A, well d, adding digrams index.process continues, resulting correct index digram pointers, costing oneindexing operation per two pointer operations.Next, SEQUITUR requires efficient strategy checking digram index. Recheckingentire grammar whenever symbol added infeasible, inefficient large portionsgrammar unchanged since last check. fact, parts need checkinglinks made broken. is, actions affectmaintenance digram table performed, newly created digrams checkedindex. course, every time link created, digram entered index,time check duplicate. entry found already present attemptingadd new digram index, duplicate digram detected appropriateactions performed. Therefore, one hash table lookup required accessingupdating digram index.5. Computational Complexitysection, show SEQUITUR algorithm linear space time. complexityproof amortized oneit put bound time required process one symbol,rather bounds time taken whole sequence. processing time one symbolfact large O( n ), n number input symbols far. However,pathological sequence produces worst case requires preceding O( n ) symbolsinvolve formation matching rules.basic idea proof two constraints effect reducingaction1new input symbol observed, append rule S.123456789time link made two symbolsnew digram repeated elsewhere repetitions overlap,occurrence complete rule,replace new digram non-terminal symbol heads rule,otherwise,form new rule replace digrams new non-terminal symbolotherwise,insert digram index2101112time digram replaced non-terminal symboleither symbol non-terminal symbol occurs elsewhere,remove rule, substituting contents place non-terminal symbolTable 3 SEQUITUR algorithm74345fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCESnumber symbols grammar, work done satisfying constraints boundedcompression achieved sequence. savings cannot exceed original size inputsequence, algorithm linear number input symbols.Table 3 gives pseudo-code SEQUITUR algorithm. Line 1 deals new observationssequence, lines 2 9 enforce digram utility constraint, lines 10 12enforce rule utility. on-line appendix contains implementation SEQUITUR Java,requires 400 lines algorithm.numbers right Table 3 identify main sections algorithm, proofdemonstrate bounds number times executes. Action 1 appendssymbols rules performed exactly n times, every symbol input. Linkcreation triggers action 2. Action 3 uses existing rule, action 4 forms new rule, action 5removes rule.Table 4 shows examples actions 3, 4, 5, associated savings grammar size.savings calculated counting number symbols grammaraction. non-terminal symbols head rules counted,recreated based order rules occur. Actions 3 5 actionsreduce number symbols. actions increase size grammar,difference size input size grammar must equal numbertimes actions taken.set stage, proceed proof. formally, letn size input string,size final grammar,r number rules final grammar,1 number times new symbol seen (action 1),2 number times new digram seen (action 2),3 number times existing rule used (action 3),4 number times new rule formed (action 4),5 number times rule removed (action 5).According reasoning above, reduction size grammar number timesactions 3 5 executed. is,(1)n = a3 + a5.Next, number times new rule created (action 4) must bounded. two actionsaffect number rules 4, creates rules, 5, deletes them. numberrules final grammar must difference frequencies actions:r = a4 a5.equation, r known a5 bounded equation (1), 4 unknown. Noting a1 ,number times new symbol seen, equal n, total workactionsavingMatching existing rule3...ab...ab...A...ab1Creating new rule4...ab...ab......A...A...ab0Deleting rule5...A...ab...ab...1Table 4 Reduction grammar size three grammar operations75fiNEVILL-MANNING & WITTEN1 + 2 + 3 + 4 + 5 = n + 2 + (n o) + (r + 5 ) .bound expression, note number rules must less number symbolsfinal grammar, rule contains least two symbols,r < o.Also, expression (1) above,a5 = n a3 < n.Consequently,1 + 2 + 3 + 4 + 5 = 2n + (r o) + a5 + 2 < 3n +a 2 .final operation bound action 2, checks duplicate digrams. Searchinggrammar done hash table lookup. Assuming occupancy less than, say, 80% givesaverage lookup time bounded constant (Knuth, 1967). occupancy assuredsize sequence known advance, enlarging table recreating entrieswhenever occupancy exceeds 80%. number entries table numberdigrams grammar, number symbols grammar minus numberrules grammar, symbols end rule form left hand sidedigram. Thus size hash table less size grammar, boundedsize input. means memory requirements algorithm linear.practice, linear growth memory poses problem. One strategy currentlyinvestigating break input small segments, form grammars them,merge resulting grammar.number times action 2 carried out, digram checked newlink created. Links created actions 1, 3, 4 5, already shownbounded 3n, time required action 2 also O(n).Thus shown algorithm linear space time. However, claim mustqualified: based register model computation rather bitwise one.assumed average lookup time hash table digrams bounded constant.However, length input increases, number rules increases without bound,unstructured (e.g., random) input, digram table grow without bound. Thus timerequired execute hash function perform addressing constant,increase logarithmically input size. proof ignores effect: assumes hashfunction operations register-based therefore constant time. practice, 32-bitarchitecture, linearity proof remains valid sequences around 109 symbols,64-bit architecture 1019 symbols.6. Exploring Extremesdescribed SEQUITUR algorithmically, characterize behavior varietydomains. section explores large small grammar given sequence length,well determining minimum maximum amount work algorithm carryamount work required process one symbol. Figure 4 summarizes extremecases, giving part example sequence grammar results. Bounds giventerms n, number symbols input.deepest hierarchy formed depth O( n ), example sequencecreates hierarchy shown Figure 4a. order hierarchy deepen everyrule, rule must contain non-terminal symbol. Furthermore, rule need longer two76fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCESsymbols. Therefore, produce deep hierarchy short string, rule oneterminal symbol longer one builds. order create rules, stringrepresented must appear two different contexts; otherwise rule incorporatedlonger rule. One context deepest hierarchy, must participate. contexthierarchy, reduce size input string, appear rule S.Note every rule Figure 4a appears hierarchy rule S. repetitionsequence, one terminal symbol appended, producing new level hierarchy.point including repetition length one, mth repetition length + 1.repetition gives rise mth rule (counting rule S). total length sequencehierarchy depth thereforen = 2 + 3 + 4 + ... + (m + 1) = O(m2)deepest hierarchy depth = O( n ).end spectrum, grammar shallowest hierarchy, shownFigure 4b, rules apart rule S. grammar also largest possible onesequence given length, precisely rules formed it. sequencegives rise one digram ever recurs. course, sequence alphabetsize ||, O(||2) different digrams, bounds length sequence.kind sequence produces worst case compression: repetitions,therefore SEQUITUR detects structure.boundexample sequenceexample grammardeepest hierarchyO(n)ababcabcdabcdeabcdefABCDDfabB AcC BdCeblargest grammar;shallowest hierarchynaabacadae...bbcbdbe...aabacadae...csmallest grammarO(log n)aaaaaaaaaaaaaa...DDaaB AAC BBCClargest number rulesn/4aaaaababacacadad...AABBCCDDaaB abC academaximum processingone symbolO(n)yzxyzwxyzvwxyABwBvwxyyzB xAfgreatest number rulecreations deletionsn new rulesn deleted rulesabcdeabcdeabcde...AAA...abcdeFigure 4 extreme cases algorithm77fiNEVILL-MANNING & WITTENTurning largest grammar smallest, Figure 4c depicts grammar formedordered sequence possibleone consisting entirely symbol. fourcontiguous symbols appear, aaaa, rule B aa formed. another four appear,rule contains BBBB, forming new rule C BB. Every time number symbols doubles,new rule created. hierarchy thus O(log n) deep, grammar O(log n) size.represents greatest data compression possible, although necessary sequenceone symbol achieve logarithmic lower boundany recursive structure do.produce grammar greatest number rules, rule includeterminal symbols, building hierarchy reduce number rules required coversequence given size. Furthermore, rule longer two symbols occurtwice. Therefore rule requires four symbols creation, maximumnumber rules sequence length n n/4, shown Figure 4d.discussed size grammars, consider effort involvedmaintaining them. shown upper bound processing sequence linearlength sequence. However, still useful characterize amount processinginvolved new symbol. Figure 4e shows sequence repetition built yz,xyz, wxyz, forth. second occurrence wxyz appears, matchespossible w, x, y. z appears, yz matches rule A, xA matches rule B.Finally, SEQUITUR forms new rule wB. cascading effect arbitrarily largerepetitions continue build right-to-left fashion. amount processing requireddeal last z proportional depth deepest hierarchy, matching cascadeshierarchy. maximum time process one symbol therefore O( n ). fact w,x, fail match means require little time process, preserving overall lineartime bound.Although bound linear, sequences certainly differ proportion work sequencelength. sequence Figure 4b, repetitions exist grammar formed,minimizes ratio. sequence Figure 4f, consists multiple repetitions multisymbol sequence, maximizes it. time repetition appears several rule deletionscreations match lengthens. fact, every symbol except incurs rule creationsubsequent deletion, O(n) creations deletions. length repetition,proportion symbols incur work 1/m, tends toward zerorepetition length approaches infinity.7. Behavior Practicegive idea SEQUITUR behaves realistic sequences, turn artificial casessequence English text. Figure 5a plots number rules grammar numberinput symbols 760,000 character English novel, shows increaseapproximately linear. Figure 5b shows approximately linear growth total numbersymbols grammar. growth number unique words text, shownFigure 5c, high start drops toward end. Zobel, et al. (1995) observedmuch larger samples English text thatsurprisinglynew words continue appear fairlyconstant rate, corresponding neologisms names, acronyms, typographicalerrors. example, number rules grows linearly because, wordsrecognized, multi-word phrases constructed, number phrases unbounded.78fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCESnearly linear growth number symbols grammar seems disappointing,fact inevitable consequence information content English. Since symbols endtext convey similar amount information symbols beginning, lowerbound achievable compression rate. English text, corresponds entropyEnglish.EQUITUR operates quicklyas shown Figure 5d, 760,000 character novelprocessed 16 seconds: rate 50,000 symbols per second, 3 Mb per minute. figurealso illustrates SEQUITURs linear-time behavior practice. sequence Figure 4b,repetitions exist rules formed, fast process, indeed processedrate 150,000 symbols per secondthree times faster novel. sequence Figure 4f,consists multiple repetitions multi-symbol sequence, slows performance 14,000symbols per seconda ten-fold decrease fastest sequence. sequence Figure 4c,consists many repetitions single character forms concise grammar, comes50,000 symbols per second; novel. measurements performedSilicon Graphics Indigo 2.EQUITUR effective data compression scheme outperforms schemesachieve compression factoring repetition, approaches performance schemesb200000symbols grammarrules grammar30000200001000015000010000050000000c200000400000 600000input symbols800000100005000200000400000 600000input symbols8000000200000400000 600000input symbols80000015time (seconds)vocabulary size150000105000200000400000 600000input symbols800000Figure 5 Growth rates English text: (a) rules grammar; (b) symbolsgrammar; (c) vocabulary size input; (d) time79fiNEVILL-MANNING & WITTENcompress based probabilistic predictions. SEQUITURs implementation evaluationcompression scheme described Nevill-Manning Witten (1997).8. Related Workmentioned introduction, research resembles work Wolff (1975).described SEQUITUR, possible contrast Wolffs system, MK10, processessequence left right, forms chunk (equivalent SEQUITUR rule) wheneverdigram seen 10 times. happens, occurrences digram replacednon-terminal symbol, system either carries sequence, restartsbeginning. either case, digram frequencies discarded process starts over. worstcase algorithm corresponds sequence Figure 4f, long exactrepetitions. symbol repeated segment gives rise chunk, process startsover. Figure 4f, length repetition linear length sequence,number restarts length repetition, algorithm quadratic lengthsequence. makes processing million-symbol sequences impractical.number systems, Langley (1994), Stolcke Omohundro (1994), Cook et al.(1976), form new grammar rules repeated sequences, also merge rules generalizegrammars. However, operate different domainas input, expect set sentencesdrawn language, rather single long sequence. allows make inferencesbased directly comparing corresponding parts different sequences. Furthermore, smallsize training data means efficiency lesser concern. performancealgorithms measured ability accept test sentences language, rejectnew sentences target languages. SEQUITURs case, onesequence available, metric apply.VanLehn Ball (1987) also infer grammars sets sentences. algorithmenforces three constraints grammars purpose making version space finite.are: (1) rule empty right side, (2) rule one symbol right side,symbol terminal, (3) every non-terminal appears derivation string.constraints reminiscent SEQUITURsfor example, third constraint weaker formSEQUITURs rule utilitybut serve different purpose. SEQUITUR, operational;drive formation grammar. VanLehn Balls work, make version spacetractable providing sensible restrictions form grammar, algorithmsearch space.9. Conclusionpaper presented EQUITUR , algorithm identifying hierarchical structuresequences. Based idea abstracting subsequences occur rulescontinuing operation recursively, algorithm works maintaining two constraints:every digram grammar must unique, every rule must used once.EQUITUR operates incrementally and, subject caveat register modelcomputation used, linear space time. efficiency permitted application longsequencesup 40 Mbytein many different domains.evaluated prediction accuracy EQUITUR paper. Evaluatingprediction accuracy fairly complex business. adequate simply give count80fiI NFERRING SEQUENTIAL STRUCTURE SEQUENCEScorrect versus incorrect predictions, begs question likelihooddifferent ones occurring. Prediction schemes assign probabilities predictionsmight offer, judged discrepancy probabilistic predictionstrue upcoming symbols. whole question accurate probabilistic prediction sequencestantamount compression sequences, substantial field right (Bell et al.,1990). fact evaluated SEQUITURs performance compression found viesbest compression algorithms, particularly large amount text available(Nevill-Manning Witten, 1997). point present paper different one:SEQUITUR re-represents sequence way exposes underlying structure. fair saycompression algorithm produces representation way perspicuous.Perhaps greatest drawback SEQUITUR algorithm memory usage,linear size grammar. Linear memory complexity ordinarily considered intractable,although practice EQUITUR works well sequences rather impressive size.clearly room approximate versions algorithm partition input re-mergegrammars formed them, could perhaps applied recursively create algorithmlogarithmic memory requirements. conjecture, however, approximationsdoubt turn useful practice, inevitably sacrifice propertydigram uniqueness appealing feature original algorithm.Acknowledgmentsgrateful many detailed suggestions Pat Langley anonymous referees.ReferencesAndreae, J.H. (1977) Thinking teachable machine. London: Academic Press.Angluin, D. (1982) Inference reversible languages, Journal Association ComputingMachinery, 29, 741765.Bell, T.C., Cleary, J.G., Witten, I.H. (1990) Text compression. Englewood Cliffs, NJ:Prentice-Hall.Berwick, R.C., Pilato, S. (1987) Learning syntax automata induction, Machine Learning,2, 938.Cohen, A., Ivry, R.I., Keele, S.W. (1990) Attention structure sequence learning,Journal Experimental Psychology, 16(1), 1730.Cook, C.M., Rosenfeld, A., & Aronson, A. (1976). Grammatical inference hill climbing,Informational Sciences, 10, 59-80.Cypher, A., editor (1993) Watch do: programming demonstration, Cambridge,Massachusetts: MIT Press.Gaines, B.R. (1976) Behaviour/structure transformations uncertainty, International JournalMan-Machine Studies, 8, 337365.Gold, M. (1967) Language identification limit, Information Control, 10, 447474.Johansson, S., Leech, G., Goodluck, H. (1978) Manual Information AccompanyLancaster-Oslo/Bergen Corpus British English, Use Digital Computers,Oslo: Department English, University Oslo.81fiNEVILL-MANNING & WITTENKnuth, D.E. (1968) art computer programming 1: fundamental algorithms. AddisonWesley.Laird, P. & Saul, R. (1994) Discrete sequence prediction applications, Machine Learning15, 4368.Langley, P. (1994). Simplicity representation change grammar induction. Unpublishedmanuscript, Robotics Laboratory, Computer Science Department, Stanford University,Stanford, CA.Nevill-Manning, C.G. & Witten, I.H. Compression explanation using hierarchical grammars,Computer Journal, press.Nevill-Manning, C.G. (1996) Inferring sequential structure, Ph.D. thesis, DepartmentComputer Science, University Waikato, New Zealand.Nevill-Manning, C.G., Witten, I.H. & Paynter, G.W. (1997) Browsing digital libraries:phrase-based approach, Proc. Second ACM International Conference DigitalLibraries, 230236, Philadelphia, PA.Rabiner, L.R. Juang, B.H. (1986) introduction hidden Markov models, IEEE ASSPMagazine, 3(1), 416.Stolcke, A., & Omohundro, S. (1994). Inducing probabilistic grammars Bayesian modelmerging. Proc. Second International Conference Grammatical InferenceApplications, 106118, Alicante, Spain: Springer-Verlag.VanLehn, K., & Ball, W. (1987). version space approach learning context-free grammars.Machine Learning, 2, 3974.Wharton, R. M. (1977). Grammar enumeration inference. Information Control, 33, 253272.Wolff, J.G. (1975) algorithm segmentation artificial language analogue, BritishJournal Psychology, 66, 7990.Wolff, J.G. (1977) discovery segments natural language, British Journal Psychology,68, 97106.Wolff, J.G. (1980) Language acquisition discovery phrase structure, LanguageSpeech, 23(3), 255269.Wolff, J.G. (1982) Language acquisition, data compression generalization, LanguageCommunication, 2(1), 5789.82fiff fi!"$#%$&('*),+--.'/!01$2,3.1@BA.CEDGFIH456789:';<-=>?6#& 98';-.'JLKMANOJQPSRUTVJXW8FVJXYZP.[]\_^_Y`WLP.JXabab[LadcGefgPP.[Xh`iajfgP.CQ[LYkTVJmlnAFoDpH[qFVToA.WnRrANO[s_tbuVvUw"xzy`{ w"|~}~b{}""~bX,: :}!}{_buxxuVX,: :5:!5XQ5.%_5%!<Vb,V S" 5_ E,V !,V:U b!8 !!: b:L! $"$.$ o$.$_G$! $ !"$!X $ ,$8"q5" 5 !Q:$.$ X8$$5! "%_"(( $ G$ <$Gq5" (5`M $.L $ m$ z S$$.$ Z .8 X%($,L< $$X z$ V$$ _ L! k! .$ kQ%o $kL`q"8k8ok _ Q $ $.55%!oz$ 5 L$$ 5 $ X! $k !$$,8$V_ !ff ff "!#$ &%(')fi%ff*ff+ ,,*-. #/103245 &%67ff8%1%1ff ,28ff9 !!%152 /,: ,*fi;ff # #ff < =>/,24; ?!%5 A@ BC%1%7ff D=FEG<GEH$=, #$ I%>%5 , ffJ,*ff #$/$ K,*<7L@MN ,*;ff D=PEG<QQHR ,*F?%ff28%S K#>%T@VUff W ff #=PEG<XGYZ[K%7F52\ ,*M;, KF#=,EG<G]H$^`_>)fiff aff #=b,28ffcff aff d;ff\#ff/#/528ff*d!#4%ff eKfR#ff /<7F)fi;d!#ff(g<, &%1$ /affc/"ffCB>%1%ff Dhiff #a &%&%ff #$ j@ B>%1%ff D=EGQ<]HS`k\lm 28"!%ff ffC@ nCo%5 &Fff R &% ^=EGQ<GH$=8#ff/ff #82;c;, 3fp28,/ff*c<\S*ff /1fqT24%5 /ffrfR!#%ff sC)>;ff #ff\#ff F5fi#$ 288 %ffF@Vt\#$ 'ff <#ff - K,*su<,/D=DE&GGvYwZ[%F52,*?M;, F#=EGG]wYxc W> ,*FyD *'<D=,EG<GEYkCff ,ff8%D ,*FUcz #82'ff #4={E&GGXY&aI "Uff ff '| K,* ;ff D=EGG<}YaI ~Uff ff 'P=REG<QGYa Uff ff 'P=DEGG<H$^C/1%[#ff28ff /%T=> !!#{ 24;ffF;, &aff"//%TN,ff ff ff874;ff #s"ff 4#/52#sg<, &%1$ /aff=fi)r74; Jfqff )ff8,28ff !/,J@Vxc W: ,*9y *'D=6EGGEY~ff8#/ =6EGGEYrZ[ff #ff a<jff &% ^=cEGG<]H$^_>)fiff aff #=;ff!!# 2;Jfu,/< K,*~U\ z 24'/4#z @$E&GGvHfi@V &%5/*ff aff8%!ff*J,*ff !,ff ,*ff /%T+{T~x\<, #$ '<5 =EGG<vH>s , <ff\~1fqT &%"{/cff a<ff #T+ !!#{ 24;+4#$ 28$ %ff"#4ff /+ ,<("ff #S2/"ff=g<, &%178 /aff(7?ff| ,*d;ff{ff <#$ ff* !!#4{ 24;ff~ff\fq#$ "ff )fi#4'3=;, Cfc$ {q5$<[/ qw>@V_C#m tcyD>H$=~)>;524;~;ffc#4ff /d!#%ff 2 K,ff|%aff*?~!,K%7TF5 &%/"ff^M7,28ffJ$?ff8!#4ffbaff ff-7ff #s?f(g, I%o$ K/affJ7fq#d /,/"ffd;, ?f(;ff&s &%#$ 288 %ff +F>t\m _C# I%7<ff #$ @/k>ff ff8% ,*:Ucz #82'ff #4=RE&GGXH$=7(2 Kff"a<7ff )fiff*: \&s &%>#$ <28$ %ff~/, &%ff #$ f[BC%o%ff Dhi{4ff #aI &%c &%ff #$ =!#4Ia<5*ff*N)fi;N?ff #/52dff "!#$ &%fp<#s /D^#$=;5!, !,ff #>28/{ff;ff>)fi#'F0,,*<7Fs I{s &%P#$ 288 %ffr, &%ff #$ fDBC%o%ff Dhi&%ff #$ J/$ #4ff*J{T:k>ff ff8%C K,*+Ucz #$2'<ff #F@$EGG<XHr K,*+28/{ff*:T+t\#$ 'ff <#ff + ,*+u,4/@$EG<GvH$=TdS*ff /1fqTff8;["<#ffcs &s &%#$ 28$ K%7ff(324%5 /ff\KfB>%1%ff Dhic &%ff #$ w^>Mff28,*P=)fiff[28Fff>;5)fi;";ffC)<#'(fDu,s ,*"U\ z 24'/#z @8EGGvH8=TF!#a5*<F;ff>s &s &%8,DI4Pi/iPi`q 4V 4 i8&cfi8q/Rq 4/ ii$/& >qqi/i\V8 i`i/+--'Vfi~fi"$## 9: 9L5bff76#& # fi%&# #q9fi,,8$wR fib 1&F /5b[(5F 4q (4c & q (" b1(c1{/ {/ bcbV b1ff<offF(`,",,K7$,9wfifiP+9w,fi9P9w9,99,FF4 ,<b85/,,{ 85/,c4 &15"!p>&1#85/, $~74%,:&&'$<#(fi " )/fi4 ",8&*!p4s/?s +!p4 !-,>4. /10> *( />8'b32',32?> K>! 54607.98:,C:&&'$'7;<2' w (sI{s&13=>32\! /|&&'8/ 7? ?@2//!(s&s&13=N!|/":&&'$A.9$B< '& 9,DC,4/FEGIHHJ*K8bL8~ /4d7L42, (IM&<'$F' { (fi+N!j d&{sIj&&8'$ +8'6 d/+N!POQGRIS*QITLUWVYXZ[VYUW\] ^(fi {_I&5)`<P",@$ !q(8,"?'&-2[87<E)a{,(>&1 bIHHc'K8d( |87<,[4c^= &1=e2"?fG2'C/I?@2 L8 F2'B{(fi*&w /c\ 9gL$/>32L IM&<'$ C174$)2'c >c&5/'<S"(fi " )h\4 ",8&P7*!qd/1jik=d 9! @8 (] K-&5/l85(/$N/'&F,<'&:,$ *=,Cm. /n0> 1(fi $">8,/oE:(fi )/8/, !+82'8/K[!fi8'b C! 4607.98:,C:&&'$,K,d >!/I?@2 {SIo3=+ ))2L8)2'6! |,K,\5(+!q17([p5aI8/rqF)*2L8 sCo 1tij{_I&&&'8aI8/u\Gg,` 78L8 $` >&$Kv?@2,&1$/[K,(? )/k/'&,4&(fi >S^g31o3="&&/ JI,laI8/lc[' {$ fi(Ns&s&)$88&&'$<, (96'5\ /9(fi ? )/>4 ",8&*!p4s/1#wbxaI87<zyF,"aI8/>J(fi'6 c "&&7 8@)I8(,J \ "&&'$<cFs&s&:{;,&1=#aI87<}|,~aI8/"<5)G2,c,>8<L4M2,F c,K,I-5:ffLlnN1%6:nLj@sCo 1ti|7)&rIM&<'$E:s>1 D7IH@u*Kfi5 ,/: "</N!3Q$ZX@UWVT<O)Q$UW#QQ$T>'XV_O3VYTLUWQIGIX@ZO7s\J{_I& 5 '4/ {4<[?)2x 8,!j4& *2,$9(r7 ,/'&+ d7G!q",r/& F ,,$"N![ ?7)& j4/,I8/8=>,r48SK/,, 3(fipL1_*3WI3j3G:3WI%Wff)YGIbW-ffIW-ff$W>-ffI"-ffI~-ff$~>-ff_IWIjIIWff_W3IjWff_Y@)$ ))9WIb3IW3W-W)WY%jW3Web^3$1 W3I3$^3$fi-YL'''j'"j'f*'*I~'f*$L_d 'I$-]*'x h'''~kjd_)$k)7G5d3I5#@Y3'LG3Lkj)Y6YLW$$'3I[WY'I*h__v_'d3kzb*L_x@h ^'LG3L N)6_')I3*)I>9IY#Lff9)G3Lp''7Lff '@3>3L_>)LIW5ffL5*9)'@Y3'LG3D])'fiLff"M*))$ L 53))*LL$7)LN ! 535I)'6@Y3'LG3j"Lff)G3Lh73)_$#}L _'vl'&%9)G3 b73)_$'(:)* h#he6L3IWb)G3L)L3]*))$L*LNM*b*'3 +*$7"%f9)eh&, *.-xL/*G'L)N30, *.-'%)I3IG3G1%2ff5'5$1 3' h')@h*I+M_)'LN3LkvGL$I_54-WI_GIWY26l798'YWY]@5*))hp:''3L$[#'I~*1%>)'{G*e LN3xff'*[h_31%]+'{G*3 @LeM@x;@I7>*))$)G3<b) 7G*3< ''$'I=%5*)3 I_>Lff9)G3"M?<_*@*ffL)L NMNL?B M~)' L*LNM*9)G3L93'7b*$CD%)' :G7_L7)')) )*)_?Lff)G3L FEHGJILKNM"OE Ld)^P*)G3LL3 d)_$lD)'~ *[]$1 3'Q*'))'e{9d_)$]_GhN3L:%/R__3I #)' W*j$1 3') '$'Ifi=%xGLff*3 3Le7NR$6+'){_SETGVUWLX.Y WVZ\[\[ 3L_53 _)eI3]#)eIb)L#)7_d3I'L*k)'LN3Lb'd_3IG31*Gd@3L>GlLdff3)])h")^5`_p3ab )' ~)'))]3G$G5''G3L$#')*9)3'_)I") b [Mdc 9d_)$#$1e3'<)*#L#WfGL3I)'7')H*M -WhgfdY[ihj\k\lnmpo1 3#NLd_)$%ehq*MI)~)G3LLL3x_'x'@h *I_@ x7'_'6)'_]ff*he x)^P @'5d9#*))h5_'6)I''9Wj_'7*)) N3*IL3L__Lj$[1 )'9)G3LD^5_'7*))h)]_30,LIrQ*ff,L'])*9 N63stHuwvdx1y.x{zdv}|~i}3k\lnmpow\%Lxe]d_)$)G3L3 b L3GLG5k\lmogh GI @M_IG)I @'K0:*7')]_' 'f*Ik N)9d)_$-3*I9L> 9{eL36N^+^ bLG[II= ^0dff? 5INL)L~L>) )G)I:%>=b W'LG3^ q; 9d)_$'ehq*M)*))$f_')I3'eM@S&K) ? NL fh)$>){YLW$i8 3$WW@5b lMLeLG K0L7_$)L Whfvdp)')9ffd35*))')G3> 3L_)L @vI@)@dffd?:&r&&1''*@*)'9L*L*7)G3L+).*)I=%$p^3b*$vN)P_30,LI>=%)'{_ff1 '5*L>#' 6_$>)L>7.6$*Q )G ))'51jL3LG `>5NP'@R' L$9)' W[ )Ie*M""zrz.x{y.x{zdv|r~|k\lnmpo@R^#Le:G5*)"zrz2ff 7[$6.OMOn?r0iqr@$0QL,Le'3ff2%>)I*)*))')e@)DW)3NL)3xNL>C@ \;'3).@ ff.OO=ffstHuwvdx1y.x{zdvd~i}xvt=2>"tn{y.x1z)vs>x@vdy.x1rtxivrt:2>"t1y.x{zdv%K .."\ A= L3 j)IPeW$'I3*IbLr'I L1%*'$ffL1%=eG'$]*3 )'^ )DeM@L$PG*ffz_d5 b [@>^$[W@^_'3$-ff'')I)^M@x#)' W)"j7') .5KK". b 6hg3*LIWYI[YG]3I[WYfi&dFv h @Y3'LG3#'95)9['I]_GhN3L3 b 6_$)^P@ }5d37@' -@h ^'LG+7'@7-)' @)!K(.fiw2fffi !#" $&% fi(')*%$+,-&fi.fi(0/1%)324%$,6587:9;+=<fi(, %>fi?<A@CBEDCF:GIHKJMLON PRQ/TSUVfjfi 58VW 7: , 94XZ[Y4 ,kfi(/lfi($[$fi.fi($fi\fi]^fi?<6 [,k_n,6m[og X,k'Ifi(,p,;_q_`%&):fab<A$%h fi?fihKA ,#rhcds?tuf%ev$%fi?)+f/wC,^myg 'hx fi($=ig V6Vz4{:|C}~3I>IM^Z , fi?$\$fi %,:UQ I\ SpQ<>g , V afi-, fi?$8$fi %,:U,<Q I\ SpQ2;%$&,p<>g , V afi-, fi?$8$fi %,:m;x.fC~??:3 [fi($fi4h"% !, %'hf * 'Ifi#b-X>%$')*%$\@B+DF3GIH0J8L(N PQ/Sm.fC\ofi(fi.%,i%,k,<A\ V&W $?% '1Q f SE%$;\%g $ W Q ?> Sm0x,h" $ , V " fiUfiK)$'Ifi(Y[%$ W %)58739;'# W fi? Eg , , fi V fi?$&!8%M<>i-, X>gi#fi(Y[fi(fi(,hgf i-a>fi,<e'Ifi($i V -,)*%$'6 %,:mE;fi(a>fi($fi fi?(U>Y;fi(,h V %'Ifi?%4<fi(,^i)*!>-, Xh$ V fi;g V &fi?(Ufi<> , V %,i V %,^a>fi(,-fi(,?mfffiff24%$, 58739" " $% VIg ig 'Ifi?[f 'I%^0f" $fi(a> %g ! W , %Y;,I" " $%^ Vfi?%8$ V fi'Ifi($i V ,<>gf afifi('"%$b$fi?%>,-, XU[fimXm[Q4fi(fi.,<8g $ VW fi($&?U ? \%>g $ W (U? 5\fi^fi($Afi(pbmU ?= fi $U ? >[ fi($fi(a> ,Zfi(Afm U ? Sm66Y[%$'Ifi(,^i-%>,-, XefiIV'#b]^ '#f[$ V fi#f Xfi( $M)%>g ,<T!T5\$ W fi(, X$&fi(,,<T %>,%,Q ?> V , , %.fifi] " $fi?fi?<;24%$,p587:9;Om%g Xh"% !^, %'bUfi;f X%>$'" $fi?fi(,fi?<e ,#%>,%,I,<h\ &$?% 'nQ ? SE>g-&fifi] "fi(, afiAQ-\$fi fi?8%,h , fi?$*" $&%X$''h , Xpf X%$'AS;%6Y;fi(,Y[fi.V&Wfafi., %6, fi(fi?<%)="fi V)!> , Xp'Ifi(&$ V ,)*%$'# %,:UCfie)% %Y[ , XpY[fi W , %Y;,wg V %)0fiIfi(8%)=24%$,T587:94\Y[$fi?g 4 ,ke %Y[fi($ V %'I" fi]-!Af X%$'m6>=: ?::nhC~C*I| f|C[fis>Ivu(TQ;f ,:U f S8fiTg %)24%$,y587:94 %,i-, X%).fiTfi(A%)fi] " $fi? %, 8 U Y;fi($fi ,< $fi8ab$i-fi?OV U,< ;%, fi8%)jfi8$&V fi %,.8U U U U,< mx[fiTi !" $&% fi(')%$6Ag V >A<fi(, %fi?<E.L(N PQ/SU+)%$Awfi(/q%)M"% ,^f Xfi( $Z)%$&'Zgfim.fC~??:3yE.L(N PQ/S:\% ab fie ,A , fi?$\ 'Ifi8 ,p&fi. (fi.%)0/wm.fChofi(fi fi($fi(a ,[fi(MfmQ f S\Q*)*%$" $ V V f0" g $"%^fi?\fi#b-X>%$'d%)=5\fi X$,<fi#,<g " U ?> U V %g<fi." $&fi)fi($$&fi?<Sm;x4fi]?UY[fiI<fi, fiZ&fiZ" $&% fi('d%)E ,^fi($&fi?; ,T&\""fi($4q&fi. ,fi($af+& !" $%>-fi('Y['Ifi($ V fi('I"%$fC ,)*%$'#i-%>,:m?fiR 6 0 0 ? f&^e #4?fR.4b 8 # K 0fifffi!"$#&%'(*),+&-/.&0132546)798;:fi8=<>+7?8=@A)B?CDEF&"G#&%=798=HJIK7ML=8N:fi+)<>),+OB9C=PQ(RS<*B9T5),UV+WE)<>),+YX[Z]\M0Z_^a`,Zb.!cB9CdT[79Ue:7?4Nfg) <ihDZ ^ Uj),kEU) <>),8N+>:fi8Ela<>+A79U+>:fi8Elmk6B9:fi8]+<n798=HZ \ ),8=H:fi8Elk=B9:fi8N+<nB9Co:fi8N+),UT97pfG<qZ6r8:fi8=<>+798=@A)JB9Cd+WE)tkEUB4Nfg),uvB9CSwGx6y{z |A} ~5~5y{w$~]iwGw$y{dw$y$Fz y{|AwG3wGxi5|AF~5y{w$5xFC{B5Uq7m<e),+#B9CO:fi8]+),UjT[7pfoUj)Af7?+>:fiB58=<,h=HN),8EB5+j) H/EF&"G#&%h:<n7F+EkNffi)-/.&0A10I2{r8wGx6y{z |D|>z y{~5y{w$5x CBU:G<Q798:fi8N+),UkEU),+7?+>:fiB58CB5Um-.&0132r!9:g8=@A)&)F8EB[8E),) H+BU)AC{),U+BF<>+79U+e:g8Elm798=H3),8=H:fi8Elmk=B?:g8N+<&B?CD:fi8N+),UT97pfG<,hE&)q)AE+),8=H+WE);8EB5+7?+>:fiB58a<e=@W+W=79+&"Z ^ %B4E+7p:fi8=<+WE)t<>+A79U+>:fi8Elmk6B9:fi8]+;B9Co+WE):fi8]+),UjT[7pf"Z_%hE798=H<:fiuF:fG79U>ffiC{B5Uq"Z \ %Ar83:g8=<e+798=@A)t:G<&<7p:GHm+jB46)t,~5y{wG&~],zY:+WE),U);)AN:<e+<S7Qu3BHN)AfoB9C&-/.&0132D<>=@jW+W=79+M+WE)PQ(RS<:g8I79U)t<7?+>:G<L=) H*hN&:fi+WT[7pffiE) <CBU7[ffoZ ^ 7?8=HZ \ 4N"Z ^ %Y7?8=H"Z \ %h5U) <ek=) @A+>:fiT5)Affi5r9:fi8=@A)q),T),U ffg),83:fi8]+j),UT[7pf=Uj)Af7?+>:fiB58@,798m46)S)AEkEU) <<>) Hm7<d7QPQ(R"/4EE+8EB+o8E) @A) <<j79U>:ffi75<d7QnB5U8PQ(R;%Ah=&)m@AB5NfGH:g8=<e+) 75HW=7pT5)JCB5UjuNfG79+j) H+WE)JkEUB54Nffi),u75<;73kEEU)m<79+>:G<LD794N:f:fi+>kEUjB54Nffi),uB9C7<>),+MB9CoPQ(RS<,hN4EE+<:g8=@A);&)q79U):g8N+),U) <e+) HF:fi8+WE)Sk=79Uj+>:G@ANf7?U<e+U=@A+EU):gu3k=B]<>) HB8m+WE)SkEUB4Nfg),u4Nm:fi8N+),UT[7[foU)AfG79+>:fiB58=<;<>k=) @j:LD@,7pfffi&)QkEU)AC),Un+WN:G<&C{B5UuFNfG79+>:fiB58r5),T),U7pf@AB58=@A),kE+A<o79Uj)8E),) HN) H:fi8tB5UHN),UO+BSkEUj) <>),8]+O+WE)ny{~5|Ay{w$x]Q~5x6Qz x65wGxNY5w$x=y*~55z9,|>~9,h,C{B5USWN:G@jW&)t<>W=7pffdkEUB9T5:GHN)tk6B9ffi]8EBuF:G7pffi{+>:fium)m7pffil5B5U>:fi+WEu<ir&WE)@AEUe:gB=<SU) 7HN),USuF:fil5WN+S+),umk6B5U79U>:ffi>Eumk+B5) @A+e:gB8CBUq+WE)F)AEkNf:@j:fi+FkEU) <>),8N+79+e:gB8B?C+WE)m7pffil5),4EU7<SSWN:G@jW&:ff46)kEUjB[T) H+jB46)<>+7?U+>:fi8ElmB5U&),8=H:fi8Elk=B9:fi8N+<S7pffil5),4EUA75<,rWE)FCB?fffiB9&:fi8ElHN)AL=8N:fi+>:fiB58=<379U)m8E),) HN) H+B+U7?8=<C),U;:fi8NC{B5Uu7?+>:fiB58C{UB5uv:fi8]+j),UT[7pf&U)AfG79+>:fiB58=<J+Bk=B?:g8N+;U)AfG79+>:fiB58=<,rfiff$,/D|>zp{"%Mz>D|>z "%dD|>z \ "%zeD|>z ^ "%'O795)F+WE)FU)AfG79+>:fiB58bh6ffi),+F798=HZ46)F:fi8]+),UjT[7pfT979U>:G794Nffi) <,hd798=H@AB58=<:GHN),Ut+jWE)F:fi8=<>+798=@A)B9CEF&"X[c5%nWN:@jWU)AfG79+j) <Q7?8=HZ&:fi+W+WE)FU)AfG79+>:fiB58FB58Nffi5rFP;)AL=8E)F+WE)FU)AfG79+>:fiB58/*|zp{"%&B58U) 7pf*8]EuF46),U<M+Bt46)q+WE)Q<>NuF4=B9f6CB5UM+WE)&:fiumkNf:fi) HU)AfG79+e:gB846),+&),),8+WE)Q<>+79U+e:g8ElJk=B9:fi8N+<MB9Co798=HZ6rW=79+&:G<,hNC{B5US4=75<:@U)AfG79+>:fiB58=<;HN)AL=8E)D|>z {"jQ% pqD|>z {"A;% 9S/*|zp{"% 9SD|>z "/E% 9SD|>z $"% 9SD|>z "/A% pq/D|>zp{"{,% 9S/*|zp$"93% "D|>z "%% ^= 0798=HCB5UH:G<$>E8=@A+>:fiB58=<D|>z "%Q:G<+WE)U)AfG79+e:gB8<e]uF4=B?f@AB5UU) <ek=B58=H:fi8El+jBQ[V/*|zp{"p%ArEB5U)A=79umkNffi)5h*D|>z {"j";%%dNq _r5Numum),+jU>:G@,7pffg5h6&)tHN)AL=8E)zeD|>z {">5%d+BF46)Q+WE);:fiumkNf:g) HU)AfG79+e:gB84=),+>&),),8),8=H:fi8Elk=B9:fi8N+<;l9:fiT5),8Nr;SB5+j)t+W=79+/D|>zp{"%S798=HzeD|>z {">5%&W=7pT5)Q+B4=)F)A:fi+WE),UQB9CqQhOQhthQhQhYt hoB5UJQr_EU+WE),U h;&)HN)AL=8E)<>k=) @j:G7pf:G<79+e:gB8=<B9Cm+WE) <>)5h;4ND|>z \ "%D|>z {">S"j&j3%%798=Hz>*|zp ^ "%SKz>D|>zp{"n"n %%Ah6:r)5rfih*+WE)F:fiumkNf:fi) HUj)Af7?+>:fiB58=<QB58<>+A79U+>:fi8El"/),8=H:fi8ElE%Sk6B9:fi8]+<4]NhEl9:fiT5),8+W=7?+S+WE)Q),8=H:fi8El"><>+79U+e:g8El_%k6B9:fi8]+A<q79Uj)Q]8EB9S8+BF46)t) =7pf/rfiEE65=6E55E=A_fifffi$5,p {6O{fiOD=pE!"#%$'&)(+*-,/.10325476+498;:5< =;>=?@#7< =A7"B CEDGFIH9JLKNMffO$5P7* < =QRA7BS=?@#9TVUA7#W#VX">=?@# <Y=A7"Z,\[ff.0325476498 [ :]B C^DF3HVJLK_M5O$`P-acb?@"#9#d>e=f8 [ .g8ihjlkmon3pqsrutvOswxPsyzm|{0Ik4 w 47y:}~6c5X"=, [ >??9<l>Q|#9B;a"Bxa# <u>="QRCT9BS,/acb_ nSq7vcpLSvq@rtSvSnrVptu;"Q"=BS#9"%#VX>?, [ abr9pt Os,_P7b"#VT@>A<uebS*U?I>=f~rdpq@rt <Y=Q"=Qx>=fB >=c#7?]>=?@#9"<SQB C-nIpq@rt <Y=Q?@# < T9#d>e=f_B >=c# ?*, [ >??9<u>Q#9B_a"Bxa# <u>="Q+CT9BS,acb_ lvc+ruSvcpLSvvnr9ptvv*LQ"=Bx#9"Q;r9ptv]Os,_P3#`>?"<S?@b+#9B?d""%#9X< #5BS=bB >=#<lefx"aT <CBST9_U< "< T9"<SQQ"Q#9B8R< =?sC"T9Td>e=fN>e=CBST9+< #@>BS=CT9BS>=#9"T9l<lT9"7< #d>eBx=?ff#9B_B >=c#T9"7< #@>BS=?QBc"?=BS#EAVX< =fS"_?9< #9>?I< a>>#sbS*<x?5"7L"A7#9"Qp Ofig!"#E$&(< =Q,< =>e=?d# < =A7"B CffDGFIH9JLKNM5O$5P _5X"=,>??9< #@>?I< a"_>rVpt O@,_P>?E?9<Y#@>?I< a"%>gr9ptv]Os,_P>?E?V< #@>?I< a"Sp *7]b+#9X"C3<SA7#5#9X< #5#9X"<SQQ"Q?@#7< T9#@>=f< =Q+"=Qx>=fB >=c#T9"7< #@>BS=?ff< TV"<uT9"<xQbfSU<YT < =#9""Q+#9BXB Q+>=< =b+BLQ"7B C^,ff;"o@U<YX"<SQab_T9"?@"=#@>=fW<?9< #@>?I< a>>#@bZ<ufSBxT@>#9XO3fSBST@>#9X'LP< =QaT@>"7bQx>?9A7U?9?#9X">=c#9U>#@>BS=a"X>=Q>e#>=RBST Q"T_#9B+>=Qx>A< #9"ffX< #S>=QRB CE<ufS"aT7<S?\>e#5BST9?CBST5X>?5>XBS"7CUb~<YS">#ff"<S?I>"T#9B< T9"AV>< #V""7=>e#d>eBx=z>T ?d#<S?9?@U"#9X< #8BS=bgA7Bx=c# <l>e=?ffBSTV=g%!ff?*5ffX>A9XBS=bT9"7< #9"?d# < T9#@>=f;B >=c#7?B C>=c#V"T9l<u?!>="<YS"?5#9X"\>e=#9"T9 <uoT9"7< #@>BS=?"7L>AV>#W<S??@# < TV#@>=fB >=#ETV"7<Y#@>BS=?%< =Q+>="AVX"A9?%?9< #@>?I<Ya>>#@b~B C-#VX"WTV"?@U#@>=f~?@"#EBYC?@# < T9#d>e=f+BY>e=#%T9"7< #@>BS=?!>e="?\#VBS_A7B "A7#>=#VX"ET9"7< #d>eBx=?ffk .gy *?@UAVX+#9X< #]>=~< =cbBLQ"7#9X"?d"?@#7< T9#@>=f_B >=# ?]X<uS"E#VBa"%"xU<u3oI=<SQQx>#@>BS=*CBST A7"?%<u-?@# < TV#@>=fB >=# ?#9B+a"Qx>?@#@>=A7#*#9X< #%< T9"_=BS#CBST A7"Q#9B+a""xU<u3%I#>?AV"< To#9X< ##9X"5"xU<u>e#@b\CBSTVWU< "]>=QB%=BS#o<u"A7#?V< #@>?I< a>>#sbS]ffB 5"S"T*>#>?"?9?]AV"< To#9X< ##9X"Qx>?@"xU<u>#sb+CBST9_U< ">=~A< ==BS#5< x"%#9X"ff>=?@#7< =A7"W, [[ .0I254 6+498 [ hZ:oU=?9< #@>?I<Yae"S5X>?C3<SA7#>=Q""QCB B E?CT9BS<+T9BS"T9#@b~B CffffBxT9=;%!ff?*ffX>AVX>?%T9B S"Q>=5X"BSTV"ff#^>="z* "c=B #VX< #-#9X"TV"E< T9"ff=B#@B%BLQ"7?^CBxT, [[ *SffX"TV"ffCBST-?@BS"Ek47y}~2*Lk .gy>=Bx="ffBQ"7*< =Q+k m.g >=#9X"BS#9X"ToBLQ"7355X>?>?]#9X"5>=c#VU>e#d>eBx=a"X>=Q"7=>#@>BS=~SxBl*>="~+A9X"AV?5CBST%?9< #@>?I< a>>#@bBYC-#9X""=Qx>=f~B >=c#7?B C-#9XBc?@"\>=c#9"TVl<u?ffXBc?d"N?d# < T9#@>=fBY>e=# ?5X<uS"%#VBWa""xU<u>=<Y=cbBLQ"73]Co#9X"W<ufSBxT@>#9XT9"@@"A7# ?5< #5>="*#9X"=#9X">=?@# <Y=A7">?5BSaS>BSU?seb=BS#ff?9< #@>?I< a"S5ff#VX"T95>?@"%5"E=""Q<_A7BS=Qx>#@>BS=Bx=#9X"%<ufS"aT <$ff*A7BSTVT9"?@Bx=Qx>e=f#9B"7=>#@>BS=z*S>=BST Q"Tff#9B_fSU<YT < =#9""?9< #@>?I<Ya>>#@bS`X"CBSTV<u<SAVX>="T9b+CBYB E?fi* =o Ofi D=V 5&,!"#$&(* < =Q%,.0325476498:c< =>=?@#7< =A7"-B CDGFIH9JLKNMffO$5P `X"o>=?@# < =A7"5, [ .0325476498h8 [ :B C DF3H9JK_M5O$5P>?5?9<l>Q#9Ba"_nSq vcpSvSr5vr%oq 3,>#9X"T9""7c>?@# ?5<CU=A7#@>BS=~c6jS.4 .% \?dUA9X+#9X< #ff8 [ .jlk Os Psy {03k4 w 4 yz:}~6c;"%Q"=BS#9"%#9X>?5T9"7< #d>eBx=acb~xr Os,4 , [ P5X>?"< =?#9X< #`CBST"<SA9XT9"7< #d>eBx=*"7>#9X"T%#9X"_?@# < TV#@>=fB >=# ?B C-T9"7< #V"Q+>=c#V"T9l<u?%< TV"%CBST A7"Q#9Ba""xU<u>e=<uBLQ"7?*BST#9X"bZ<YT9"%CBST A7"Q+#9B+a"_Qx>?@#@>=A7#>=<uoBLQ"7?5CoCBxTE?@BS"_,G5"X<uS"Sr Os,47,%[P *z#9X"=~,%[>?E?V<u>Q#9B_a"nxq vc\pLx-Srvr>_>< T@bS*ab"7zAVX< =f >=f?@# <YT9#@>=f<Y=Q"=Qx>=fB >=c# ?*ff5"~fS"##9X< #, [ >?rxpSvSrvroq73,*Q"=BS#9"QSr Os,47, [ Pfi v+--L LuV ffufilS%S]-!#"%$&(')+*-,/.10325476987:1;=<?>A@CBEDFHGIDJLKMONQPER7STCS1UWVX~XX XXiX~X-XMZY[NQPER7SLTCSUY\V^]`_ba1cd/ef6gMh:jkD lGnmoqpsrutwv^xzyb{ |f6gU :^}[<}--}]jEsKIJ1+PEuSLSV?TjD lGZmoApsrutvxzy-{ |f6gU eN: }[<e ^e N e]}3-}] e Ne}<uj}[<?#jEsN e U] 7_csg_d e 6g:gsP/uSSL VuT ejkD lGnqnyb{ |f6 :q}[<}--}} >#[D K X~ lqlHG~ X J1 KJ3FG1 Kll7D sIF77KZFIAFHK-KC}<uu<u"%$ ('qu Q L }j/C- %<s'1}<u=<su;>f=<;sK-GM(NQP/R7STCSUV[KzIFGI1GHD lDGkKLDG1KDFGIDJLKl)O,E.10 2h4698:u%lFlK^8ff IDJLlDFG1JLGMZYsNQPER7SLTYSUWVFHJ1G1IGTY[N PE#SSLVT e N e U K ffJLlDF/9K-DlD1KL9IGlDFCJlJLKG1 KFHGI1GD +lDGFwG1lKKI lM9FF1I9G1lKdLdd% -d_- %%c3 FwF1IG9F/IK l KLkF1IG9F/%D 9FFI9+G1ldLdd% -M %%zc3h9IfKLJ1ID FGIGD IDK-DD [lDGFbM9FFI9G1lKdd9d % bd__[c 9[ 9FZF1IG9F/IKfIDIl KLF1IGHFgD 9FZF1I9G1ldLd9d % hMO_[cKZD lQKLD KG1 KIK- LIlJlG1~ X FHlKFF1IGHFgIG}<uu<u"%$O'-s =<s'1}<u=<su;>f=< } ;CQF IK- IZ8(FF1I9CG1lhKI %%zc3qd _bg%lIDhDFGIDJLKMONQPER7SLTCS1UVl)O,E.032h47698:G1 K%ll7D l9 F-f%lIDNQP/R7STCS1U V^FJ1GIGk_= e 6L_-a1csd e 6gMh:SZ:9Fl J-IF1IG9F/IKZ%lFGIGD lDGF- G K-D9FF1IG9F/IKK-G9J-IKLJ1ID K-DD [lDGLF^IDFHGI1GD lDGF-7Kl GIDID_[97cd_-7 KF1IG9F/IG 1lK-ffFl7G1 KFHKIK- IFI1KKLD KIF%llkFfiff fiffff ff!#"%$&(')+*,-/.103254768:9<;=>,?@.A0324B6<8C9<;3DEGF/HI9J FLKBMNHKPO3HNQ RSLTUVQ RWHXKZY SF/JOK[]\<^F`_bac(d#_:eaWf@dCghd:c(i<jlkNmWf@gonZprqbmks_/c(akc(dCtvuwj5md:t cIag unxf@kyaP_{zId:c:|pBn!c(kdC}d:t/q/mkpBac(d:mt~QCMsH3^FMNF/HUV]Q R MNHKVR F!MA<3IUVX,.10325476<8C9<;<X^F/O3FH3^FEwMUVXKVO3F`O3F!MNH3OQ#HF!Q RHN<UXK!M/ OMNH!GKZURvY URvHKZQ RwUO3REXMKVR MF!UR GKZRUHURvHKZQ RKVRvVKVONQCKVJvY F!MsWvX^F/O3F5Q[F[ QHsKZURvY O3FYCKVH3FLMNHKVO3HNQ RSTUVQ RWHMUVQ RWHF/O3xKZYCM/[vF/HONQC/KZYhYJvF^ KVRSVQ RSMNHKVOHNQ RS7KPR F/R QRST UPQRvHM/v<FSF/H<H3^FB_/ac(d#_Ce<aWf/d:ghdCc(iwjlkNmWfb.ghn!p%q/mk`n!t dCtvusj5mdCtc]agunVf/kNaV_zIdCc:|pBnZc(kd:}d:t/q/mkpBac(d:mt[IsGvlAA]GFRUVTO3F!MF/RWHXH^FLKZY SF/JOKMwX^vQC3^KVO3FLMNHKVO3HNQ RS8AF/R Q RS;<T UVQ RvH{KZY SF/JOKM/[!#"r)>&('*BGPI Z/]8yZ;<G8yZ;DF/H - 8v%/;KVR ?< 8B;[]XUH3FH^ KVHX - URvHKZQ R M<KZYhY>J KMyQ#sOFY#KPHNQ UR MXMN ^H3^ KPHXX^F/RF/F/Os5Z(UO<Q RWHF/O3xKZYIxKPONQCKVJvY F!Msl%^ KMH3U^UVYC~Q RKVRvU5vFY]KVRMNvF/H3OQ#/KxYoY G ? QCMwF!vQ VKZY F/RWHH3UB%^UPY#Q RSQ RKPRWUvFY[Q OMH!UOsW B 5vF RF]8yZ;IH3UBJFLH3^FLMNF/HwUVOFY#KPHNQ UR MvMN ^H3^ KPHFQ H3^F/OsUVIH3^F(UVYhYUV<Q RS^UVYCM/8N;8yZ;8N ;- 8< ;-3 83X ;8X3;\<^F/RvJvMN<Q H^vQ RSMNHKVOHNQ RSKVR F/R Q RST UVQ RvHM<UVGQ RvH3F/O3xKxY#M@vUOsW3 8NZ;GQ#MwvF RF!H3UJFH3^FMF/HXUV>O3FYCKVHQUR Mv MN ^H3^ KVHwFQH^F/OUVH3^F(UVYhY UxQRS^UVYCM/8N;8yZ;8N ;? 8< ;?3 83X ;83< ;!#"r)>&:*BGPI Z/`GB@DEGF/HL - KVR ? J FKMwQ RsF RvQHQUR [ GKVR vF RF H3UJFH3^FBMNF/HUV]O3FYCKVHNQ UR MvMN ^H3^ KVHFQ H3^F/OsUVH^FsUVYhY UV<Q RS^UPY#M@83< ;8(< ;8/;83;8(/;8( ;8;!- -- 83< ;- 83X3;! -83w ;fi>:fiff!#"$%'&()"$x* ,+-# .ff/012123547698.:5;<=<0>?635@<-;A:8CBDEGF0IH JK;BLfi47M3N86O8BP356Q93QNRN>?J7S\ 3]D354O47M3)Q_^F`:<.;Q7QGacbdfeHOH7TRUF0J7SVE$ETWR>X;BLYZ$F0,Y[5>g 8=<3Qh:NiB4;8B8BD47M3);<D35F6;QG;673]Q9^@@<=83Lj;QO;kBIiBlm<=8CB32;@@*35BLA8=no47ic47M8.QG;67498.:<3dp 4c8.Q23;AQ90q4iqQ9353I47M;4W47M3,;<D35F6;Q;673,;r<s<]:NiBQt8.L356;F<0u<.;6D356247M;B?>wvxi623Nn;12@<3>U47M3yhzO{Gl}|$i67B;<D35F6;> \ M8-:Mo:NiAB4;r8CBQ$~~ 3N<351235B4NQ5d)X`--? M3QK8snj;<D35F6;Q J9R;BL,aWJKR :NiB4;8Bc3N<351235B4QG3;:Mo;kBL b ;BLb :NiAB4;r8CBj 3N<351235B4NQO3;:M?d)XNU Q_476;8DM49vxi6 \ ;6L2:NiA1F8B;4i698.;<'3Nn356:8.Q93;A:5:Ni6LA8BD#4i4M3L3NB8498iBQ5dGe3 ;<.Q9iQ_353)47M;4G47M3W JKR ;BLaWJKR ;<D35F6;Q$3;:Mo:NiB4;8BfiP3)F;QK8-: 673N<.;4_8CiABQ5>`;kBLI47M;4 bc;BLacb:NiAB4;r8CB47M67353F;Qt8.:W673N<.;498iBQc3;A:7M?d Q9^FQ9^12@498iB673Q9^<4#;kBLj;BiBQ9^FQ9^12@4_8CiAB673Q9^<4$vik<s<i \)X`--?= M3O4 \ 3N<P3h;<D35F6;AQ@673Q935B473LcF02{G6;35BDA6735B2;BL2iBQQ9iBIJR> \ M8.:M\ 35673]Bi4h:<.;QQt8=3Lo;AQU1#;n81#;<?476;:N4N;F<3>;673]3;:M8B:<^L3L8B,iB3 iv4M3);<D35F6;QGJKR ;BLaWJKRd)XNO 0Qt812@<0,:M3:7A8BD8B:<C^QK8CiAB,vx67i147M3)L3NB8498iBQ5d]e)X`--?mp Bu;<=<ivU47M3I;<D35F6;Q JKR>XaWJKR> b ;kBLja b >47M35673;6732673N<.;4_8CiABQ \ M8.:M;673]BiA4O3Nn@63Q7Qt8F<3F0I|Oi6B,{]?zOQG;<iB3dGR>)XN]p 4G8.Q3;Qt8=<0oPA35698=3L47M;4]47M3c@*i8B4]673N<.;4_8CiABQG8BL^:N3LjF0,4M3 <=<35Bq673N<.;4_8CiABQ JJK2 R>XJ}c R>JE R;BLJHNR;k673]Bi4h|$i67B,{]?z$Q5dOep 4 \ ;Q iFQ93567PA3LuF0{G6;35BD635B;BLuiBQ7Q_iBJR]47M;4W47M3yhzO{Gl}|$i67B;<D35F6;j:5;kBBi43Nn@673Q7Q47M3UBi498iBciv?5Nxm=mxr>;BL 47M^QQt8B:N3U848.Q1#;n8C1;<46;:N4;F<3> \ 3:5;kBBi4 ;LL 47M3673N<.;498iBJfGR47i]84 \ 847Mi^4<iQt8BDc476;:N4N;F8=<s8490d |$i \ 35PA356> \ 3h:5;BiF4;r8CBI; \ 3;356 0A354 ^Q93Nvx^<673Q9^<4 F047M3cvxi<=<Ci \ 8BDiFQ93567P;498iB? 3cBi \ v67iA147M3c673Q9^<4Q]ikviBQQ9iBq;BL G; :Q_476 1JARO47M;4c47M33Nn@673Q7Qt8PA8C490iv|$i67Bu{]?zOQcQ9^FQ9^1W3Qc47M;4civO47M3yhzO{Gl}|$i67Bu;<D35F6;>F03Nn@673Q7Qt8BDj47M3yhzO{Gl}|$i67Bu673N<.;4_8CiABQ2;Q)LA8.Qm9^B:N498iBQWivh@*i8B4c673N<.;498iBQ8CBu4M3Q94N;67498BDj;BL35BLA8BD@*i8B4Qikv47M38B43567Pr;<.Q5d M^Q>hQt8B:N3j47M3jQ7;k498.Qt`;F8=<=8C490@6iF<351vi6IQ94;k67498BDq@*i8B4;<D35F6;AQJK;BL35BLA8BD@*i8B4,;r<CDA35F6;Q5> \ M8.:Mvik<s<i \ QF0Q901212354670R2;<=<i \ ;67F8476N;670|$i67B{]?zOQW673N<.;498BDqQ_4;67498BDj@*i8B4NQ5> \ 3:5;B:NiBP356742;B0qB354 \ i67j3Nn@673Q7Q_3L8B47M3yhz${Gl}|Oi6B;<D35F6;8B4iq;B3A^8Pr;<35B4I8BQ94;kB:N3,iv ZN}c J.R]viA6Q9iA123Iiv]47M3,476N;:N4;F<3oQ_^F`:<.;Q7Q93Q;F*irPA3> \ M35673#iAB<C0Q94;674_8CBD@i8B4Q ivU8B47356Pr;<.Q2;632673N<.;473LXd M3I;LLA8498iB;<O3Nn@63Q7Qt8P8490jiv47M3cQ94;674_8CBDW@i8B4;<D35F6N;QO:5;B47M35B,F*3)^Q93L47ic3Nn@673Q7Q$3d(DdQ93A^35B498.;<=8C490J}^Qt8BD#iAB3)iv47M3;<D35F6;AQG JGRi6Ga2JNGR7Ri6Oi47M356U673N<.;4_8CiABQOF*354 \ 3535Bfi8CB473567P;<.Q5d\ 848.Q498123$47i]P35698=vx04M;447M3O@673Q_35B473L;<D35F6;AQ;673U8BL353LQ94;674_8CBD);kBLc35BLA8BD@*i8B4;<D35F6;AQ5>673Q9@*3:N498P3N<0d vx3 \ ;^n8=<=8-;k670,L3NB8498iBQ];BLI63Q9^<4QO;673]B353L3LXdA?-?'5-?u7?'g iA6jU>*<C354c7JKR]]F3c47M35sA#ikv?>*47M;4$8-Q>*8svOjf>4M35Bq7JKXRO]A>8=vfi 47M35Bj7JKXR>*;BLW8=v,>4M35Bj7XJKRdfe*o'm X354Uf}UNa#NF3G;)Q94;k67498BD]@i8B4L3NB8473$8BQ94;B:N3Oikv Z5t7 JmUR> \ M8.:M8.QU<i:5;<=<0oQ7;4_8-QK`;F<3)vxi6hQ_4;67498BD2@*i8B4NQOF0,Q9i123]1WiL3N<>X;BL<354]XF3c;BI8B473567@67354N;498iBvxi6hQ_^:7MI47M;k4fi**ff fi !#"$%&ff fi'()*+,' -!+, ./10324'56879:5 ; #/1032 " ,'5687< " :56;=>@?:ACBD?9EFHGJIKML;?GJLN " EOGQPRI%SLNT3AVUWFYX[Z\X;SE] A^I_L;?%F`A^IaLDFYX;b%X;FYLGJL1AcS3IdSeZfK,LGJX;L1AcI%gRbhSJA^IaL KY=GJITZ\SX@FYIT3A^I%gRbSJA^I:LKY=4GJI:PB;?GJI%g3FNACKiGkjlj^SJ>FHT4=G3Kj^SI%gRGKL;?%F A^XNX;F jCGJL1Acm3FnSXT:FYXMZ\SX@X;F jCGJL,A^SIKM>@?:ACBD??GQmFNL;?%FnK;GeEF[A^IaL;FYXDb%X;FYLGJL,A^SIKoSJZ6K1LGJX;L,A^I%gbhSJA^IaL K-ACK@L;?%FnKDGJEFprq?%FYI_ " GQjCK,SsjcS%BYGQjVj^PdK;GeL,ACKutFHKv Z\SXiK1LGJX;L,A^I%g)bSeAcI:LKYpwnxQy4yz {N| bGJX;LMZ}X;S3E~BD?%FHB;3A^I%gRL;?%FN@KMA^I<=jcS%BYGQjfK;GeL,ACKutGJ:AVjVAcL,P*Z\SXK1LGJX;L,A^I%gbSJA^I:LKNBD?%FHB;%KSI:j^P9X;F jCGJL1AcS3IKn>M?%FYX;FOLD?%F)A^IaL;FYXDmkGQjCK)L;?%FYP_X;F jCGJLDFGJXDF)Z}S3XB FHT_L;S*?GHm3FL;?%FRK;GJEFOK1LGJX;L,A^I%g*bSJA^I:LHpA^IB FT:SaFHKMI%SL@XDF jGeL;FnFYIT3A^I%gRbSeAcI:LK[SJZ&A^IaLDFYX;mkGQjCKY=4LD?%FnSI:j^PRL;?:A^I%gL;?GJLNGQUFHB LK@K;GJL1AKtGJ:AVjlA^L,PSJZrL;?%FHK1FnX;F jCGJL,A^SIKMACK[L;?%F`X;F jCGJL,A^mF)SXT:FYX[SJZrFYIT3A^I%gbhSJA^IaL KY=geAcm3FYIGst%%FHTdK1LGJX;L,A^I%gbSJA^I:LHp A^IB FL;?:ACKMSXT:FYXACKL;?%F)K;GJEF=%GJITR GeITR " B SJA^IBDACT:F)SIK,LGJXDL,A^I%gbSJA^I:LKY=%LD?%FNX;FHK,:j^L@Z\SJjVj^SJ>iKYp@hd_8^ 4FYL v ( O(; %F[GNK,LGJX;L1AcI%gNbhSJA^IaLT:F tI:A^L;F@A^IK,L GJIB F@SJZ< u;s@C =J>@?%FYX;FZ\SXOI%Su'(J( %=@)DO;GJIT7;;<%p+q?%FYI v ACKRK;GJL1AKtFHTv:P9L;?%FRES%T:F ji AVU# jcS%BYGQjVj^PK;GJL,ACKutFHKZ}SXK,L GJX;L,A^I%g_bSJA^I:LKGJIT K;GJL,ACKutFHK( "=&Z\SX`"%au'(J( %]:M;f; :apwnxQy4yz {| K;K,%E)A^I%gLD?GJLi K;GeL,ACKutFHK v =L;?%F[jCGJL;L;FYX@B SIT3A^L,A^SIAK[G)T3A^X;FHB LB S3IK,FH%FYIB F`SJZ8L;?%FnT:F tI:A^L,A^SIKYp8-P)L;?%FX;FHK,L;X,ACB L,A^SISI v =aKDGJL,ACKutGJ:AVjVA^LP)SJZ4FYmFYX;P)X;F jCGJL,A^SIoACKrBD?%FHB;FHTsaP`L;?%F@L,>SB SIT3A^L,A^SIKL;Sg3FYL;?%FYXH=aGeITL;?%FKDGJL,ACKutGJ:AVjVA^LPRSeZ~ACK-A^IBDjcT:FHTA^IRL;?%FMj^SBYGQj8K;GeL,ACKutGJ:AVjVAcL,PB SIT3A^L,A^SIpq?:K vACKiKDGJL,ACKutGJ:j^Fp@hd_8^ 4FYL v ((; 8hFsGeIA^IK,L GJIB F)SJZf+u;s@C =GJITj^FYLN+( (; " fhFK,BD?L;?GeL3\ v (;N p rSIK1L;X;B L@@"h( `"l( "V-aPRK,FYL;L,A^I%g!!Sk> " ACK@K;GJL,ACKutGe:jcF[AVU_ACKYprq?%FNGJIGQj^SgS3KrXDFHK,:j^L@?%SJjCT%K-Z\SXFYIT3AcI%gbSeAcI:LKY=:>@?%FYIRXDF Z}FYX;FYIB FHKL;SOK1LGJX;L,A^I%g)bSeAcI:LK[GJX;FnBD?GJI%gFHTL;SFYIT3AcI%gbSeAcI:LKY=hGJIT_;f 6AKMB;?GJI%g3FHTRL;SRDMpwnxQy4yz { MA^X;FHB L1jcPZ\X;SEL;?%FnT:F tI:A^L,A^SIKpfq?%FNXDFHK,L;X,ACB L,A^SIK-A^EbhSaK,FHTSIRL;?%Fn3GQjVAcL GJL,A^mFNX;F jCGJL,A^SIKGJX;FGQj^X;FHGT:P9gGeXGJI:L;FYFHT_L;S*?%SJjCT_A^IGJIaP_ES%T:F j= :PdLD?%FOX;FHK1L;X,ACB L,A^SIK`SI< " p SL;FL;?GJLn " AK>F jVjcT:F tI%FHT*KuA^IB F3\G3T%T%KrLDSnF A^L;?%FYXFH3GQjVAcL,PS3X&AcI%FH3GQjVA^L,PZ\SXrGQjVjA^I:L;FYX;mJGQj8K,LGJX;L1AcI%gNbhSJA^IaL KYpqo?%FNb%X;SbFYXDLPSJZ FYIT3A^I%gObhSJA^IaLKoZ\SJjVjcSJ>iKoaPRK,P:EEFYL;X;Pp3f^Hy8\aR&Yy4Yd%4S3XiR=T:FYI%S3L;Fn:Pd: /J4-L;?%FnGJK,SJj^%L;F`mkGQj^%F`SJZ6=3ApFpJ/10324Wpn"a'(-*;;(a'(7;(q?%FNEOGkAcI*X;FHK,:j^LKoZ}Sejlj^SJ>np) :yxQ8\h q?%FGQj^gFY%X GK)-QoGeX;FK,LGJX;L1AcI%gRbhSJA^IaL)GQj^gFY%XGK=8GJIT_LD?%FsGkjcg3FY%XGKnQGJX;FFYIT3A^I%gObhSJA^IaLNGQj^gFY%XG3KYpwnxQy4yz { 4FYL v ( (;9&FGJIAcIK1LGJIB FSJZf u;sfDrQ; =GJITj^FYLN+u((;*"@>A^L;?YD v(DNp-P4FYEEOGhp%=>FdBYGJIGKDK,%EFLD?GJLZ\SXFYmFYX;P'(J( %OO=F A^L;?%FYX; );NSX`9; );%=rKAcIB F*AKK,LGeX;L,A^I%g_bSJA^I:LOT:F tI:A^L;Fpq?aK=rL;?%FSI:j^PX;F jCGJL,A^SIK[`>@?:ACB;?_GJX;F[j^F Z\LiGJX;FNL;?%S:K,FnK;GJL,ACKuZ\P3AcI%gfi8$%_%%r% :Jff fiffQfi fik% N%_fi%&-fi!" #fiff %$')(*(,+.-0/1/12435126+')(-7/1/12')(,+8-0/1/126+1/'69;:<: +-=>?@ffACBDD?AFE<G6HIJGLKNM&A4O?P,IOQORA6IJGCM&ATSE UWVX?YAFGIJY6GCMZ[\D#?JMZGA4]ffR^I*_^?UffE`Obadce>JMZP`EfKgHIhALE`iDffOjM&PMGACGIkY6GCMZ["D#?JMZGAl@ ImOjOnY6E`O&IJGFMo?hZAeVXY?_pOQMZE\q^IJY6E\A6IJGCM&ATSE U8MZ%adc4rOsAF?@ATMZP`E"a;M_^D?AFE A<ItP`E,Y6GIMZ?YUffE,Y?ZgACGIJY6GFMoZ[D?JMZffGA?JVuMZG6E,YvmIO&A,@LwuE^xffZ?JwdG6HIkG"wuMG6H?BGO?A6Ay?JV<[E,ZE,YIOQMGCR@LY6E`O&IJGCM?ZA1{|1 2?ZNOQMZEgz%P,IJZg]EY6E,DffO&IP`E Ug]ffRNE`MoGHE,Y18{}1 2+?hY1 2@uATMZP`EIkZU1 26+1M_^D?ffACE}UhM&A~C?JMZG?YUffE,YFMoZ[ffA\?ZAFGIJY6GCMZ[D?JMZffGA,cuHffBA,@nwuMG6H?hBG\O?A6A?JVu[E,ZE,YIOQMGCR@LwuEWG`IJxE^K?ZffOR}G?}P`?ZffGIMZY6E`O&IJGCM?ZAVXY?_OQMZE AtIJZUq@#MZffvE,Y6GCMZ[Y6E`O&IJGCM?ZA"P`?hZGImMoZffMZ[OjMZEY6E`O&IJGCM?ZAyw<HffMQOoEP6HIJZ[kMoZ[G6HE`MY<UhMY6E P`GCM?ZnceVwuE\P`?BffO&U^_^?UhMQVXRaMZG6?^IJZ.MZGE,Y6DY6E,GIJGFMo?hZ5aACBPHG6HIkGGHEfP`?ZUhMGCM?ZAu?JVE,_^_ItqcQ"IJY6E\A6IJGFMsA)SE U@IJZUG6HE\Y6E`O&IJGFMo?hZAu?JV4OjMZEt^IJZUG6HE`MYuMZffvE,YACE A<IkY6E"A6IJGCM&ATSE U@G6HE,Z]RE,_^_I"q#c@A)MoZP`E\GHE ACE\Y6E`O&IJGCM?ZAuUff?tZ?Gu?JvE,YCO&IJDwuMG6H'90:e: +- @awu?BffO&U.]E"I_^?UffE`On?JVnK"@IJZUG6HE\YE ACBffOG<wu?BffO&U.VX?JOQO?Jw"cLTZUffE,E U@wuE\ACHIOQOA6IJGFMsA)VXR.OQMoZEttY6E`O&IJGCM?ZAwuMG6HG6HE\]IATM&P*Y6E`O&IJGFMo?hZ(?ZE,vE,YR5IJY`PJc'rVXE,wIJBffiffMjOQM&IJY6R|UffE`SZffMGCM?ZA^IkY6EtZE,E UffE UV?Y\G6HE^P`?ZACGY6BP`GCM?Znc^*E`SZE%OE IACG*Z?Z,E,Y6?_^E,_t]E,Y*?JVLG6HEWACE,G ''C4-')UhM&ACGIJZP`E]E,GCwuE,E,Z}ACG`IJY6GCMZ[tD?JMZffGAMoZadc<MvE,Z%I^')^%-L'@ffOE,Gt'-G6?]#E^G6HE-6-\^. @ffMc!Ec@#G6HEyOoE IhACGfZ?hZ,E,Y6?-]#E"G6HEtACE,G-6ffMc!Ec@eG6HE}AFE,G^?JV<MZffG6E,Y6vmImOsAwH?ACE?YUffE,Y.?JVE,ZUhMZ[ND?JMZffGA.HIAtG6?|]#ESiE U@G?|_IMZffGIMZgO?P,IOA6IJGFMsA)SbIJ]ffMQOjMGCR@L]ffRJaV?YI[JMvE,Z"@hOE,G<#')ff-ff^wuMG6HffMZA`[hY6?BD - @JIJZU gt'Fh?G6E\G6HIJGeV?Y<E,vE,YRE,GW')')'-'- @t%ACBPH%G6HIkGV?Y<E,vhE,Y6RFh(>BDD?ACEG6HIJG'')-UhM&ACGCMZP`G*E,ZUhMoZ[.D?JMZffGAMoZ%aG6HELVBZP`GCM?ZtBZffM&BE`ORUffE,G6E,Y_tMZE UMZ}a@ACBPHG6HIJGuV?YuE,vE,Y6R--LFh'- c^rOsAF?@')-nn`^'- @'C-6-`=c%M&A"\ce?Y<E,vhE,Y6R>BDD?ACEG6HIJG('CM&Afc?YE,vE,Y6R'CNdG6?]E^G6HEBZffM&BE`ORgUffE,G6E,Y6_tMZE UVXBZP`GFMo?hZ@MGuM&AfI8_^? UffE`O4?JVKcMYACG @ACE,Gf')JEtP`?ZACG6Y6BP`G*G6HEMZGE,Y6DY6E,GIJGFMo?hZ}a-'M&A\BZffM&hBE`OoRgUffE,G6E,Y6_8MoZE UN]ffR}a%--6 h' G6HEfZffB_t]E,Yu?JV-8g^ @#Mc!Ec@nGHE^ZB_t]#E,Y"?JVfUhM&ACGCMZP`G^ACGIJYGCMZ[D?JMZffGA*MZgadc?hY6Y6E,ACD#?ZUhMZ[}G?}@LUffE`SZE5y''-]ffRG6HE\?hYUffE,YCMZ[?hZE,ZUhMoZ[D#?JMZG`Au?JVW'E,_^_IqcQc^?G6EtG6HIJG"t-e')')--L' ')-nFh'IAVX?JOQO?JwfA,@UffE,DE,ZUhMZ[?Z'- @IJZU.V?YfIOQO.%-L')z( @IJZUIVXGE,Y6w<IJYUAuDY6?JvEG6HIJG@ AFE,Gfa ')-L@#ACE,G^%-.%-6-=-nq' z')--=@ACE,Gh '')-nz -n''C#z -='C- cfi##Nd````m`JC6`C",C,y N6^6ffJuJffu,fi6^f`J.ffoJu6`6,oC\, C6gJ "!#%$%&(')* *L,+6.hJff-*C,0/213!#045$5&/6!#879$;: <<+,>=?@*C,C6J-sk6 Cu,A!#?F$E:'/ 1 !A? 4 $B&C/D!# 7 $E::!HG,I'!#?F$J)$LKNO*5P= `C6`C;*%^Q.ff`R6kCTS=Tg<+,U= J 66,6^h6*L.ff,^J.h JffLu6ff WVYX!#?F$t6,`-.E*k. 6|.ff,C2C`J6CgkoffLJ6.ff,Fs,m Z/k.[/\1 uffff/\#1 ,Q]=^JC`_-ba XhffCJC^JffLb=[c,. ed *J.P=fc ,. hg *i/ 1 ft.iff. ` kja\6k kVl!#,4$ bA=.^,6C&, 0m,]=*\` <J4<t^6"`h+,ff,ffh66J6`< |5}.~Ck6C#J%moh<Q*fk.VY}J ,.hog#JnYoEpPqsr,ptvuxwzyF{ u<r,qEq \6N+\ff]=6| } ,C*T`"OV } ,CykA=ff^^,6C&,6 C`]= yg66ffJfJ,6, *9u` JNCJ`a&N#`Qo-.ff]=~=6`&JC0Y6JCTzh=!z$!$!zL$!>%$L&-9-->!>k $%K>C^6k 8 ,mj]=6JC`_-.RC`J6CJffLl=TC^.i.ff`/ `/PL.FJ6CJffL*Jeoff6,>+J<*;uNp6J*6`&JC%.Q%C^ C "`,6|h ff,fh-fix3Q QQ]BQBQiPNQP-@QiP,LUQRb-,xObHPQ[%QRQQ@]BQN<N~RUAQ->@]>Q<8[-%O%[-UR5`] >NA]T-NZ,>]"3AN]LP<"QPBRALNUA]QOPL<Qj]R>Q0Q>PN;NxQ<><]xP<UQQP>5N<Q<LH]AQ%LNff2ULHPUA]z>eQ-%YN P]<UA]QYeQ>NA]kPe]O>QN]Q>Q]kU-A]>NA]z>D]QORNk<<>Y]ANffQUNA`sNP]NLZA,e;AQNT>N5T,]k,i5>A`sNP]kPA>>A]QY%QP\j]L"BA<\]#F9BD# 0S <<>2<R~RH]R,ffAUT>ND# Lj]B~YUQN>-AAL>A]QRN]8]YQ<ZA<O #k6 Cz%<<>[~ kP]#SO;L@lkQ<Q<<k # B LUQ<fz<#8>A`-l]f jF5e]QO>NA]PPkQ<fN]ffk> QN@>Nff # # LEN>bP[A>>"^ LEN[ffUNA`-EBPk 0YQPxN5N UQ%>-AP]kzNe]Nff<k><R,]>OAQNT>Nb]A]>QP%,]<QL<Q]%U>-A]AN]-5>N"#sNPe]AlSB"LN>A]QON<Qfffifi"!$#%fi&'() < <LHj<QLk>%Q<-P-S>QY>>-UQ->Q>PN>* +,.- /10/32 -5476'859;:2 -<+=?>@2 ACBD/'-EF0/32 -GH:2 -<7+=IJ ]<;LK "MDN PORQSTUWVXOLQY[Z;\]S^_'\]QNPYK 0N`"MDN NjUQ%z>baNLdceafKkQ<>hgiaj2gA<lk?mnM N >,l>OXOLQSTU;2V p^NPRPRYPA]R]<<PL]"[k ,]>-P]ek* +,.- /10/32 -5476]qr9RstuD+Fvuw3E-7+Iyx{z}|~U|7p^SU ]CM N ffYQFz <QAfA<0PQ-^[M Ne AEBzff8eQ-%N]PQY, ]^N> N N%PM* +,.- /10/32 -547619Rw'A"27W0>@2 -<+=I"<kimMDN %U,[UR^YjQ;_HORQSTUWV0SNP[;LK kEN0AbP]>]RNPNB>QP[YPA]k@NRK >%Q]ek 2l= EAuDw3+46p QYA<k MDdc #;LK LP` RK RZ`ffHlAkPbv2uD27/30/32 -46]4 ffPlP><L"-A]N;P]>][ N ,]AkPfA<k,]AkP;v22L <dk7N U;k7HlARA<BN]<k k7EjAk7P59NffRKkxQ<;L[K nkS%<<> ggE YP0P]>]ZR@N>QPZYPA]%NkZNeKN>0Q"kQk`]%k]P><LA-P]R8P]>%PQY<NjA<<P]lP]>]RNPYP]NA]0N>%U]P-z>k N >Q%>-"PbzNeNff kQ zNe]HQl[<Q<L,e>NA]NE< T-@NN>AN UiAU vLP%kPU%`]Pee-Z<L`][B>QOQ>PNBP[;>";ONLbP;ZLFS>P[>R,]PAP[A<L<fi.FFF FLRC 71r;jD[e1[{LLe;;j[Rh[{;F;j'1 FF;}F;L{Lde i}L[L1?;}1 1 X }F[11[[ 1Lff [F PFj1F@3F ff.fiFrpff7%F;F;PL{LffP b}idFF{1HF;"Fj1'p1{ 1L1l pir 7 dpF 7 1}11PFF;F1H'pW {;FF{ % !#"".$"ff%!"P[ F 3f 1 &("' [!$"' ff)d3lF; 1 ;* ;}Fp1Fff+ [;{,. -1 /"0!1l3}PFXLLCLj11@2!43;{;FL1F;XL{Rfi, ;R LR5,n1 [{ Fj1[l [LR15,lDF;6!2" D11 "Fff}FL 7(!8H{, 1{};RL {{;Fd 1@[{:9}L ffj1R;[}F{}dFd1[h;X;R@ff ,(d};[d14;1Ljh{.L{L }F; 1< 91L1ff1{R ,2l3} 1FH[;j;R {h{;Fj ~L{LL1 [H ;ff11 ;LF=HF1l p1;?>F"ffF@[ 1 FF ;; pffA9hF$.CB;[F; XLR1D1"1< 91L1 { L{L Lj11} 1[L1;[;{L;FFhF; FFE}{fFFG FfiHF [F@C 7IH;?J"[A97@Kd/LNMh1;POQJSR " 2U J"A9{WVF;d@ p 1F1d}XJYHF; POQJSR 1[{L{LL5Z "F[9 .Kl2LNM hL{Le;5[bP{;F WHOQJSR [ \ [ ]P11BX% !8" POQJSRR ' % !8"[h}F;;;L{LCLX1 C@:"0!hH1 POAJRFLLP [[7!2"^' [Of0L1F;12[ F+ RRF;2!0" 4_ [4`;5,Fp1FX+ [;{d. -11!PHF{;}3@FX4_L1F;LR1?, 1;RLL?, 1[{lFj1d;FFL{L1,d1L!0"e' _ba }{ _ ;R LR7,el[{F@@ F};ff11 ff1{R , h;X;R 4_~@ {H}[;j;R HPOQJSRRY>C 7dcr; X[@A971X;l:Kl/LffMd;h1;PO2R $" U ;;8J" @A9&eVF;d@ p 1F1d} P F;"POf(RD1[dL{LL?Ll1L1 }b;[ff4FgfXE 11FFhFF=>HF'p1hd}F B;ff}1d'dFL1L}LFHDFXd1F7 7dk; XhA971j;dPKd/LNMd;h1;l1m F@dD1l 1C Sl3 9FF;7n Kl/LNMldijn' U ' V d}A971oVprqfistIu1vw0x8yztd{Py|}P~y<wy<|r$o<|.y1fi|r|.o5| u%o<~y/ twv0xow~tb$};td{P=+0&<do5.W1o1<41 /(b <do.dofibAC<oW+%4+Pddo1=C:^o?<1r&0W+4#GY;&<1<ddoN%5+:ddo1=o<b<5 (b78o4<d+4+< o# <1+<b8 h 7=<1+%X+7 ddo1b6 h Nr<d .d+<40 4;2W+4$GS.d4<5o<oeS1<W+48hN4Wo o4fi<1+<b4 ;7+^0&# Wo88oo4doN1185r<d=gd7+?=<1+%db+oo0r/fio<bfidoo.glCbA<ggo=4orr<Y5.doodgd7+W 1< dood)dr2orddorbA<ggdd%d.do++o<44+b+.gdo=<611Cdd21^+1d6%d doodr)SdordorbA<ggdo=+1%d .do++5.W1=o1<71PbPCbA<doP=+ +SgdoobPbA<do<Y1Addo8G=<1fi 8+oo+5r4d0YAd1/ 1 $1/1r0oX $1bAC<oo1<+# .d C gd6 ;1+4$2;^fiffo11do/C: ddroo1 Y4<b?P 1r 8 o<bfi:^+r<1Ad=+o+ )G518lo11doY6$. $b=.bbA<do11#<15 b bA<do5o<l11do8^gd4r <#r:bdo1;?<b81.ob#d<44<&18<1?+o=rrAd15+/ =o<b8o=%<do 1ro+<do.doodo+++o% 1C b=o?bAC<oW1#1;d7o++ 4r<d41C d+ r;gdrl.X1++rW ;gdb= bA<do%:o%Addo/G) Pgd 1<doC15<?o11do4N dr!Po =1.o#"o% $&!'( )*/ &,+gd4 ; 4?o4+<PoP%oo$l bPbA<d Sg4) o1Ad=+o+G-#.?=+fid+.g2CbA<do5d%d N+/01? <$%<do1Ad12(b?dX%d.do+1#<1? =o<b815bA<do1o<C4o74doN;=13Yb==d+.gdbA<dod1fiX.dod <<r=o?r=dgd4 1<+& . '879+ & ff 7: <; =6bbA<d= o#P4<> @?( .dro< <21ff+P<bS=4<o$I^ ?21.gPo11l8d<++doB> > C1CA ?<b$d+.g2CbA1rDE &4o<Ne+ 1d<d.P1$1=o7o4 4 >fi' & +<Qo%.gdr+1%ddB> 11&+#F#1.<d.1/1 oo4 8GF A' +oQo%brld1C<=dBA^Hfioo=+o+ 41+I> ' + A' +P1J> ' & + >fi' & +N LK F K?25+ 1I>Wgg:CbA1r51Ad15 <+?o8+1d%d b;b<++ NdB> 1J>I1(1fid4bA1r 06;Ad1C> 1M> d1<$o0%d .+4oo+6P7: ffN&0 .b01rdQ> 5Ad1 165 1Ad1o11do>fi' +SRT>U' & +#bA1r(o5++ 42;4<bfibfi/#&o > d+.gb, VodW&W18<b7ob? o1?5 od <ro?rr==r<dCd7+5XYfiZ\[^]^_a`cbGda[^`cbMegfch^bGi0ihbjk lNnpo)lGqsrptvuauxwzy|{c}c~,|^|L~^GG}:y|N^}c ()y*co)nmnG0\^~0:GEv}c~1:}9D|y|^S(y|:~,y|1a}:y|P^}9 ()y:G N1~}cG}NE|,|}c^P}#(y|^^S^y}N}c.a4,\44y|^ }.cL(300^Mc1P,|SDc^4~1:~S:~04z/@:Gy|^I#}#0:cI}cNy|Sa}:y|P^}9 ()y@,|ScNPG^zy}N}c:cG}:y|N^}c ()y@,|ScH^zGG)y@,}cy|^JL(y}1a}:y|P^}cyv*1E4c4Jy|^:~4aN~}cG}NE|,|}cB^^^:GJ^#~,Ny|Iv}:yy|}4nmonm(Go)6rmtvu^=M4E(^v}c~@,:~,|^{IG}:|Ny{94^~c4::GDM0E\^v}c~@4G9|^{a}:|Py|{c4^~94N(I,}:y|::Ny|D|G}:y|N^}c ()yH,|Sc)o)nmnG0I^~}9^4}c~4 ^ :GC^4}9~4 ^|9c^}9~D|G,0:G010WII^4~C}cNy|x0}cN)|G G}N1)y|{c4^~0}9~ NycHC4:/G,HD4^ |G,c}:IppS 4^ y|^DJ:GW^mE|G0Cp%H8 Ic^^}cNy|Ca}:|PDy{94^~v}c~ Ny(:S}C:GMwzy{9}c~,|^^|Jy}B0}cN)|G#}9NyG}:|Ny{94^~v}c~ Ny(:c1N)yy|}:!v}c~ GJG44~z\}9~,4c0}c*Ny0N|,cpc\DG)yy,4cnmonm(Go)6rmtvuPO%wIy|{c}c~^^|LG, HD4^ |G,9J}:Ipm@S! 4^ y^L1GC^| I0}c*Ny0N|,JG0}cS|BJ0o)nmnG0I^#G~0,~:GEv}c~1,|}cy|:~yJ0:cIJH,|Sc^#|N|,()y\:G*GG)yH,0:c4JI,|ScHNH~}cG}P8}9^^H:G.^Sy|}N}cM(D0^0^6Ja,|SHcc|^{.,|ScPG4^#~,Ny|,|^{C0}cSNy|0N|8(IJ 0}cG:N}#^}cG)cI^~}P}:GG:^,I)y|{c4^~cH:~^cG)y|{c4^~0c IN(S:~:~,|^{}c~L4G9^{G}:|Ny{94^~c|/wzyy4@#|N4~:)y)y|{c4^~^JE,44#y|c0y|MG:D^4~^}cNy(.aS}c~C)y|{c4^~c*|O^C:*B,~G0^~cI^B9N:N:{c}:#^C~Ny0S^~4P|ON(G:a4~*G:*}cG0.,0:~,|^{.}c~4G9|^{/G}:|NC)y|{c4^~( v}c^G 8:G^~}:cM}MGW}c^:G}9a}:y|P^}cyv*B)y|{c}c~^v}c~ :,(Ep:Ny|,:G^J0^4GE|}cM}WS4~,(*4Sa}c~)y|N}9~1:,|}cC~#}c^)|^}c~~4cfffiff!#"%$&'()*)*!+),04N,y|c@^ ,:~Jv}c~I~c0:Ny| ,^G)y|{c4^~c}wIyy|4@z|P4~)y)y|{c4^~G9Ia0}cSD*}c~, ^,41,(:@NCv}^0GE|^{B}9WGG9|^{B~c0:Ny|1y{94^~c#G::~.-0/:*12-0/c|^1,4G,G:^}C)y|{c4^~,~0y.0}cN)|N|^{|(~c0NycL^DN|}c^44~,|^{W}c~JN 4a0y\:G436^5 ~94~8 797cNHIc!} GGC1)N)y~90:Ny|D,^py(c#0}cP0)|N^{J)yy^LN|~44GcE(#~0y(:}9G4^;:=<'> ?#@0S)y|{c4^~^IN(|Cc^9|,|}c^AN+1CB8ANI)P|1yy{94^~ 0}cP0)|N^{)yy^GcE(3~0y(:,|}cG4I^* ,'D Ez}c~By{94^~S0}cN)|GFcF ~0y(:}9G4HG}c~#~04Pyc ~0:c4^{c~4:GJI}cG,}c 8 797cNG9 (N4P,GN^S}c~S1)N|1)y\~c0:Ny|1y{94^~c4 0|{cND}:IIN(:~z}:EL K4#^*MNFc:G }c^I}EL K4OP7MPPEI}:4c4~:^y(:4~}9^GS}#aI}:@^}DGcPE|G0#:P|G,:G0#}:,(EpNy|,Sv}c~G:)y|{c4^~3(I)y|I)!:,(Ep:Ny|c^^Ny||I0}cP0)|G^~0y(:}9Q ^3}9~S4~I)y|{c4^~ccC0}9P^~4#Gc83~0y(:,|}cG4E6H~}ca}PE|,|}cOGR OM.) G1^W,0y|cC^}c^)P|1y3)y|{c4^~0c}: ~0:c4^{c~4O:GI:}cG,}c/S 77cN\~ |Gy|GN^1)y|{c4^~9}:\^0^~~4N#G:G4~Ez}:4c4~a|D~4)|G#}^I^4^4~^4J:~#1)N|1)y}9~\^}9I^L}:H^D1}N}:y(!}9~:G)y|^E|^{11P|1)y ~c0Ny|,(;T)*UVA@, 0S@W/9X1(c}cC^^y(c,z}:^)y|{c4^~^IN(^~,4~9~c00:Ny|,cYNZfi[]\C^+_(`4acb(d(\Leffb(fhgffi(bkj`*b(lf8monp(lkjfSb+qrqsmtqvu(wyxzf8fSm{]|Rq}xzfN^ mli(b~6\`(_4aym`(i(\2jog&\Leffmc9HL8L*S+0c(=(0 s(.S*V6*'(+0r Lr8L*+4LLPRLP(L8(+SL(rzsv(29(s0L(8 }tSL(=]zssLt8h(+(6s(} r*L+=(6;s8L=9'ksr L(r*L;8LrHz(*LN(}SP88CJc=(sk0=&02 (02SLL(0= }*+(0=ffP2 L6(0= 2}S+}' +6( rsr89r=(ySL;*2&9 *L(0Lr*L*6s(*L*=L(.9 L(+N9(rz*%cc9HL8Lr6*Pt4++(]S+v.*;008Lr=Lfffi fi+(;*+;.+(0fi !"}SP88$#k =2;Sr k HC.S=*+ok =W0SH*}S%9 L}S+J(6;;*+.*&z+}*+6( rs;rSr*+y N=&%*L(0o*++*0Lvr8 'rffzk8 H sN9yNtLySL;*(}(SL(r9}SP88)(=(N9(r&*Sr+*S(-,S.+/,*6ySLySr9r*L}S+&;((L(;(v(L&021"34oWz+H*+o6( s88 'r'24(*8=0LLyS(+ L+*H(s28 t(9L(42* 9+9 (L(;(sLt (*ff+s2(+ L+6H(8SL(6rSL4s(}*=( LySL(=;*+;v}0*(68 z**t; LL65(8 7(=&L 9+HJ(* +*;(48 2L+*c=((; s8;r*sL( *+ +9L( *LtL9y*L*0(s*;Lh82S'9(rSLL( r*LW=9+=;'*tJ:< > =z4SL(r((rWv( ;:< >=z;SL(r((*+}SP88L +sc+*'o2&('}(+=*( ;? 6(6=*L+r*+8A@ !BDC fi+fiEGF+*-HJI(0'sffr*'(sKE ySrSL;L < :.L.MNQP L fi N/RSC ff=(o(}* *L L 96.? L}S+H& +LL+9trNc'sL;(r 2( ;:< >=z;SL(r ff*L+(0 8 L L !E+=*4 8z(0+ 2v2*LT;t*+4s(N P 26SL*=8;L&UVfiWYX[Z[\^]`_.a^X[]`_cbed`f[_.ggfQ_hi.j2hlkmhAkonYkqp.rtsmu.v"wxvykmpGzY{}|>hk~nAwxj`nDk$sm `wk$.wxv hti.j2h `;rphjkqp.nAjs$shi[w.j`nDk~rws~j2hkm`p.n>u.nDkmp[w`{.{hi[wu[hk$skmhy`Q"w^wsjp.v [u r`wthx.x`"`jp.vhi"u.n zrphjkqp.njs$s.j`nDk~rws~j2hkqp.n{kmp.rwj2pSnu[rts~j`nnA2Assmwp8njsqw[jrphjkqp"kmp[ js$s-hti[wK.j`nDk~rws~j2hkm`p.nAi.j`nht.w/r`phjkmp[wxvkmphti[wS;>A`pcjsm`w[jkmp`v"wKhy.whj`rhj"sqw`}j2p.vkon/>r`"sqwhtw`hti[wk~nwyw^wsj2p.v u[rt`whxx``">r`"smwhwp[wxntnA2s$sm2;n{wxn"kmhwhi"k~nwxnu"sqh`kmhnwwn^nnDkm"smwhw[[wxnnlr`p.nhjkqp"hn`pS`"`~K2kmp"hwjsonkqhti[`u[hwxnhtk~rhkmp[Khi[wkmYj.n2smu[hw^nDkmhkm`p/kmphkmw`j2p.vnhk$s$s.`[hjkmpj^2smp[`kojsqhkqwKjsm``kmhi[S[u[hhi"k~nkonYsqwhA`lu[hu[wY{A2K[`p[w/km`i"hK`u[wxnhkqpShi[w/wsmwjp.rw2hi"k~nYphti[wK`u[p.v[nhi.jh;hi"k~nA/km`i"h;^w.u nhwkm`i"h}`u[hhi[u.nj2p.v[nl>``w2..hj`rhj"sqwnu[.jsm`w[jn{i.j2hk~n2w`u"s~vs$km`whi.j`wjwxnu"smhnDkm/k$s~j2h/hi[wu[p"k~`u[wjkmjs$kmhtwxnu"smhYhi[w;>prts~j`ntn[ni[2kmp[hti.j2hhi[wxnwj sm`w[jnYjwhi[w`p"smjsm`w[j`nnj2hk~nD`kmp[n`wn.wxrtk$r/rkmhwkm`p 2}wsmwj2p.rw`{l|>p>j`rhx"wxrwp"hwxnu"smhn"hi[wYj2u[hti[`n}j2`wp[`wpKjp.vK2`p.ntn`p[x``.nhj2hwhti.j2hj2p"hj`rhj2"smwYnu[rtsojnn}hi.j2hk~np[`h`wh"p[Ap kmp&hi[wskmhwj2hu[wrj2p[p[`hr`p"hjkmpS`wKhti.j2pShi[twwK.j`nDk~rws~j2hkm`pykmp.rtsmu.vkmp[r`p"`wnwxn>htwxri[p"k~rjs$sm`kmhrj2p[p[`hr`p"hjkmpc.j`nDk~rws~j2hkm`p.n`hti[whti.j2pT;j2p.v;`[t.`{i"k~nwxj2p.n-`kmp.nhj2p.rw`hti.j2hKhi[whSjsm`w[j`nzj2p.vc;j2whi[w`p"sm6j"kmjshjrhj2"smwjsm`w[j`nr`phjkmp"kqp[yhi[w/ws~j2hkm`p}j2p.v6hi.jhKj2py`whu[p[[u["s$k~ni[wxvhjrhj2"smwnu[rts~j`nni.jnh.wsmwxnnw[[wxnnDkm`wkmp&hwtnhi[wKp"u[/.w2.j`nkorws~j2hkqp.nhi.j2phi[w[wxnwph;jsqw[j`nr`phjkmp"kqp[.`w.j`nkorws~j2hkm`p.n{&D2[22>|>hnwwnlj2[[`[k~j2htwYhtnu[j2k~nwhi[w;nhj2hu.n}2hi[w;nwxj2ri/`jkmjs.htj`rhj2"smw;nu[rts~j`nnwxn2s$smwp8nAkmp"hwjs-jsm`w[j[i[wwkqihp[wj"kmjshtj`rhj2"smwKnu[.jsqw[j`nA[wxnwp"hwxvkmp6hi"k~n.j2^w/kmp.rwxj`nw hi[wp"u[^w/2ru[wp"hsm&"p[2pjkmjshtj`rhj2"smw nu[rts~j`ntnwxn/hywkqihwwpkmp.rtsmu.vkqp[yhi[w;>prts~j`nnw^ws-j2p.v [u rt`whxx`""j2p.vhi[wp"kmp[wjsm`w[j`nl`u[p.vj2wp[`wpSj2p.v 2p.nn`p6``"{p[wjp[hwhi.j2hhti[wwk~njr`p.nDk~v"wj2"smw2`wsoj .whwwpShi[wxnw`nDkmp.rwKhti[wnDkmwxn2hi[wjsm`w[jnj2w``>p[w2`[2>wkm`i"h"`[x>wkm`i"h`j2p.v/"`">`p[w22hi[wnu[2hti[wnkqwxnl^wkqp[/u.ri`twhi.j2p [x`Q{[kmp.nhj2p.rw`QYwni[2YwxvkqpSj2`wp[`wpj2p.v`p.nn`pyx`"hi.j2hlhi[w`p"sm/ws~j2hkm`p.n2hi[w;>A`pjsm`w[jhi.j2h}k~np[`h}kmp.rtsqu.v"wxvkmpjp2hi[wjsm`w[j`nvk~nru.nnwxvkmpShi.jh.j2.wj2whi[wws~j2hkqp.nj2p.vy {r`u[nw`}hi[wu"smhkmj2hw`jslk~nKhtrts~j`nnDk$hti[wSnwhK;j"kmjsYhtj`rhj2"smwnu[[j sm`w[jn[u[hSnDkmp.rw&hi[ww&j2w&2Snu[rts~j`nnwxnhckmpwxnhkmj2hw`Ahi"k~nk~nSrtsmwxj2sqffjcp[`p"hkmk~jshj`n{wxrwphwxnu"sqhn`pShti[w`fiff `;n.j2hk~jswxjn`p"kmp[S2`p.nnpSj2p.vSj`wp[`wpx``;ni[2ehi.jhK[u[hw)`rwwhi[[v[nrjp&i.j`wnu.rrwxnnkmprti.j2j`rhwkonkqp[6hi[wr`"smwhw nwh2hjrhj2"smwnu[rtsojnnwxn{Si[w[wxnwp"hK["sqw k~ni.j2v"wkmhi nw`wjs`v"wn2j`p"kmhu.v"w`i[2w`wxnkqp.rwhi[w >Sjsqw[jSr`p"hjkmp.n`p"sm& twsojhkm`p.n{ wwhi[wsmwxnn}kmhk~nwp.r`u[tj 2kmp[hp[`htwhi.j2hhi[wtwj2w`p"smu[j"kmjshj`rhj2"smwnu[rts~j`nnwxn-hi[w/>jsm`w[j[2`u[h2hi[wj[[kmj2htwsq6 [x nu[rts~j`ntnwxn{ynwphkqp[wxvTj2.2`w`wxrwph/wxnu"sqhn"&hi[wj2u[hi[nj`wp[`wp j2p.v 2`p.ntn`px"`js~n[2`k~v"wKj/.j2thk~js-rts~j`nnDk$rj2hkqp-hj`rhj2"k$s$kmhkmpSAs$sqwp njsm`w[j["u.nDkmp[ nDkm/k$sojwhi[[v[n{l`p.rwp"kmp[whkorhkqw`"kmh;nhk$s$swjkqp.nh/[2`k~v"wKhti[w;p"kmp[wKjkmjs htj`rhj2"smwKjsm`w[j`n2j`wp[`wp/j2p.v/2`p.nnpx``"^kmhin`wkqp.v2.whk~rlhw^`js"kmp"j2hkm`p{}nDkm"smww.j2/kmp.j2hkm`pni[2;nhi.j2hYw rj2p[p[`h/u.nwhi[w[wxnwp"h/hwxri[p"k~u[w`Ynkqp.rw hti"kon`u"s~vGj2`whi[wfi "!$# % '&(# )+*(, #.-/# 0/)214365 0.-/)7#8891:8<; =?>)2)716@Afi8B>)C160/, #EDF "!?16 , G-4*H'&(1J2KML/N'OMP'Q RES7N'R6JUT IVS6KWYX[Z]\V^6_`/N'JUOJ$a'bMLKMOS6c c4OJfegLS7NhP'OSOMP'i6JIJVNGSOMP'^6QKP'Qc/L\VJ2cjT:klI9JVNFSmOMP'^6QKn^6QMK OSmIOMP'Q R^6IJUQcgP'Q Rl`C^P'Q:OKpoIL "Q q/r6s:tvu:w$axWJUTJVN(SQcEy{zL I\9|6JUIO7o~}266.o:SQc+i6JUIMPhklOdSOYSONJ2SgKMO^6Q J^mOJYWnXZ]\V^g_`/N'JUOJYS7N'R6JUT SgK^~XI^6`C^:KP'OMP'^6Ql fiPGKP'Q\9N'Lc/J2cCoK^n^6IO9d/PFKpo:KM^6_J^6OJUI|gP'Qc^JV.`J2K9KP'i6P'OMklPGKQ JUJ2c/J2c6J2SI\9d/P'Q Rl^6In^6OJUIBKMOSmIOMP'Q R?^gIJUQcgPQ R4`^P'Q/OBS7N'R6JUT IS6K\V^gL/NFcjS7NGKM^TJ<IL/P'OML/NvLJUI2ovP'OKMJUJU_$K`C^:KKP'T/N'JOdSOnOJ<OJ2\Q/PGegL J2K`J2KJUQ:OJ2c+d JUIJ\USQSNFK^?TCJfLKJ2c^6IJVJUQcgP'Q R?OJ`C^P'Q:O9ZPQ/OJUIiS7N(S7N'R6JUT IS$a]PhNGS7P'Q~o}266/P'Odl_JUOIMPG\OMP'_J6$?~H ]H~(J"dS7i6Jl^6L QcJVP'R6d/OlQ JU_?S7/P_$S7NO9IS6\VOST/N'JKML T\9NFSgKKMJ2Kl^mBNhN'JUQ~K$P'Q/OJUIiS7NfS7N'R6JUT onSQc`^igPFc/J2c4OJU_P'Od4_JUOIMPG\O9JU_`^6IVS7N~P'Q/^gI_?SOMP'^6Q4^6QKOSIOMP'Q R$^6IJUQcgP'Q Rl`^mPQ/OKn^P'Q:O9JUIiS7NGKUoLKP'Q ROJ[^6I9_?S7NhPGKM_^^6I9Qf~KHaM^6QKKM^gQfSQcynS6z \9|.KMO9I2^6z _Eo6}766/n`SIOI^6_IJU` I9J2KMJUQ:OPQ R`^6RgIJ2KKP'Q$OJnIJ2KMJ2SI\9d?S7P'_P'Q RSOSB\V^6_`/N'JUOJ\9dSIS6\VOJUIPFK9SOMP'^6Q$^~OJOISg\VOST/N'JKL T\9NGS6KKMJ2KH^NN'JUQ~KPQ/OJUIiS7NS7N'R6JUT gd/PGKH^6`JUQKH^6ISB\V^6_T/P'QSOMP'^6Q$TJUOMJUJUQ?O9d JYJV `J2KKP'igP'Oxk^OJYnZ^6IQlS7N'R6JUT ISSQc$S7N'R6JUT S6Kd/PF\9dE\USQ$JV.` I9J2KKV2/2CG6hTJUOMJUJUQ$P'Q:OJUI9iS7NGKUo ` I9^igPGc/J2c$OdSO^6Q/N'kEKMOSmIOMP'Q R^6IJUQcgP'Q R?`C^P'Q:OVK^P'Q:O9JUIiS7NGKnSIJIJVNGSO9J2clP'Od"YnZ]^6IQ4IJVNGSOMP'^6QKU6(vE]C(~C6dSQ | KHO^Hd IMPGKMOJUIynS6z \| KMOI7^6z _Eo:JUQklSL6o SQcOJnOx^SQ ^6Q/k:_^gLKIJUigP'JUJUIVK^6Id JVN'`/L/N\V^6__JUQ:OKpg( CnYn]Z]v}a}76 }/M2VV6:M:766Gg6(gUU2M2CH6f{ 7G6gC2h67VYn{6monQSd JVP'_EoH(o{6fY_JUIPF\USmQKKM^ \9PGSOMP'^6Qj^6InIOMPh\9PGS7N]Q/OJVNhNhP'R6JUQ\VJ6o(nnYX[IJ2KKV4 X[IJ2KKUnYn]Z]g4a}266.<M2VV6:mBM:E67~g66C6(6p7x7V6{ 7G6C2Fg2V?nY{g9mo/X^6IOMNGSQcoYo{6 Y_JUIMPG\USQEKKM^ \9PGSOMP'^6Ql^6InIOMPh\9PGS7NQ:O9JVNNhP'R6JUQ\VJ6NhNJUQ~o Ca}26g/~"S7P'Q:OVS7P'Q/PQ R$|/Q ^NJ2c/RgJBST^6L OOJU_`^6ISNP'Q/OJUIiS7NGKU(6/66vM:[o 6/a}g}6g7.7:NhNJUQ~o~aV}26 }V UJ _`^6ISN(IJ2S6KM^6Q/P'Q R"SQc"`/NGSQ Q/P'Q RQNN'JUQ~o(v'o~SL6oB'oXJVNGS2igP'Q~oFoSQc UJ Q JUQ/TJUI9Ro 'J2cgP'O^6IVKUonVU6:":96/<h6 Uo(\9dS`JUI"}6oH`SR6J2Kl}V /:4^6IR:SQSL/_?SQ Q~yHJUQ UJUI2oHa}766/4QOJ$O^6`^mN^gR6k"^YOJ$R6JUQ JUOMPG\Q JEKMOL\VOL I9J6l]Qx7VV6G/M/666CYV667M7G7VU'og`SR6J2K}2/U}2gnJ2\9d:O9JUI2o'o4JVP'IMP]on'oSQcXJ2SINovna}26 }mJU_`C^6IS7NB\V^6QKMOIVS7P'Q:O$Q JUOM^gI|.Kp 7GgC2hg2V2o/ }V 6nJVN'R6ISmQc/J6o XSQcYL ` OSvo:a}766/IJU`J2KMJUQ/OSOP^gQ$^6IJ\9P'JUQ:OnOJU_`C^6IS7N~IJ2S6K^6Q/P'Q RQa]nYn]Z]g o}266/Vo:`SmR6J2K6 }.66nISm|6JUQ R6IJUQ~o ~SQc"^6QK9KM^6Q~oXa}766/"S7/P'_?S7NOIS6\VOSmT/NJKML T\9NGS6KKMJ2K<^(NhNJUQ~KP'Q/OJUIiS7NS7N'R6JUT IVS (XI9JVNP'_P'QSI9klIJU`^6I9O2]Qja]nYn]Z]6vo}766/o/`SRgJ2K667 6fififf ff"!#%$&'#%$)(+*-,+.$/10.2$34352$)()67,)89;::=<>,?*@2.AB./3BDC2EGF=HI#%J4#KC4HL3'3NMPOQC%.J5MR2$S2.TfiJ'CJ.U=MPHPMRJWVMR$YXZHPHR#%$)[\3] HI&#%U,7^_$S`fia5b;cddefhgji"klbnmpohqjdsrt.ohqDugovd;agwovfLbgwxybfhgoZz{bg%m%d;a5d|gcd-bgD}-aovf ~fic|fLwxugovd;xhxPfid;gcd%+u'y+z}uK%,{*@2K.FF#;.;,#%'#%MR$=M_(X,R(jC'=U#%4J;({,R(.$/jC4.#)#%;(,89;::=>,D*)#%EGF2 Hfi'#;3n2$=MR$&YMR$*MREs#%&.F^ j^5^,Zu;{}-l=xhxd|ovfLg(=8W=>9,2.HREpU=MLC.(+,+],.$/.EMR;(+-,+89|::=>,l{2EsF=HR#=MIJ5VY.$/|HR&25MRJ'E3T2B'#;352$=MI$&D.U2JJ5MREs#X&.FvJ'#%2'#%JnMC.FF'2jC'),ybjagwx)b5mpohq=d?}z(=j=85=>R99||Q99%,0.2$3'352$)(+67,Q.$/C 4!3nJ';2 EY(],+89;::=>,XHPMR$#;.'vF'2&.EsEMI$&Y"FF'2jC4YJ'2J'#%EsF2|H7'#;.352$=MI$&,^_$S8_X]XX^__:(@9;::=>(F.&#;39;|+9;.j,0.2$3'352$)(=6,=.$/.!#%$&4#%$)(*-,89|::=<>,XC2EsF=HR#%J'#?C4HL343NMPOQC%.J5MR2$D2.T)J'CJ.U=MPHPMIJ5VMR$DZB{_,yb=agwx)b5m]}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdd%k%dwa5cqj(j999,-.J4(,.$/1@/=!MR$)(67,789;::9.>,^_$=J'#%&.JnMI$&Es#%J'5MLCs"$/J'#%EsF2|Hfi|HPMRJ.J5MR#J'#%EsF2|H'#;352$=MR$&,^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B.9.j,2U".!M3({,89;::=>,D#%$35#J5MREs#Y.$/SJ'#%EsF2|HBC2$35J' MI$=J3AMRJ' ,Y^N$AB.'J'2J|(,.$/Z#%U#H_(,R(#;/MRJ'23%(`a5b;cddefhgji.k-b5msohqjda5eDugovd;agwovfhbgwx{zbg%m%d;a5d;gcdbgS`fiafhgc;fQxPd%kbggbxde;idfidnQa5d%k%d;govwovfLbgwgeDfidw.k%bgfhgji-Bn""(@F.&#;3-."(@fi.EU5ML/=&#()X()-X,2'&=.$-"=TEK"$$),2U".!M3(B,89|::=>,*@CJ"U=HI#/ML3hW$CJnMI2$32.T]HPMR$#;.YC2$3nJ'|MR$=J3%,^N$`fia5b|cddefLg=i.kKb5mohqjd-geugovd;agwovfhbgwx+z{bgmd|aWd|gcdBbg`fiafLgc;fQxPd%kBwge`aWwc;ovfhcd7m%baz{bgk%ova5wfhgo+`aWbia5wfLg=i(F.&#;3B:=<%=<j(fi.EU5ML/=&#(Xp,)3'35#%(0,_,=.$/CXZHR2j2$)(,89;::=>,XC%"$2$=MLC%|H+T24ETv2{&#%$#%|HPMI%#;/GHPMR$#;.]C2$35J'|MR$=J3%,yb=agwx)b5m-+ s4bxPfLcz{bB+jovwovfhbg()9;R9Q9%,#MR5M_(^,89|::9.>,=2EU=MI$=MR$&|HPMRJ.JnMI#l"$/p.$=J5MRJ.J5MR#BC2$3nJ'|MR$=J3+MR$J'#%EsF2|H'#;3n2$=MR$&,^N$18_XX]X^__:9(+9;::9.>(jF"&#;3B =<j,Z#%U#H_(],.$/- C4!#%'J;(,_0,89;::=>,2.TvJ5AB.'#T2pEC'=MR$#Y343NML35J'#;/.$|HRV3WM32.T]XZHHR#%$)[\3MR$=J'#%' H|HR&#%U,.X].|MPHL.U=HR#T42EJ'#.J'23UjV.$2$jV=Es23TvJ'FT'2E.+.fi5=+j)j|l53?;=j+|Q|Q.j.j+ .j"=j@%)N.{5,Z#%U#H_(],7.$/- C'!#%4J;(,_0,89;::=>,D#;3n2$=MR$&.U2JJ'#%EsF2|H'#HL.J5MR2$3%GXEK|=MREK|HJ'CJ.U=HR#35U+C4H3'3B2"TXZHPHI#%$)[3MR$=J'#%' H|HR&#%U,yb=agwx7b5mohqjd}z(j=89.>j|,j.$/=#%AB|HPH_(+B,89;::">,)dwov=aWdkwgeG{xPjd|gohk%,=T2/YZ$=MR#%3NMRJ5V6'#;3'3%,2$&(fi,{"$/{2#%$)(B-,89;:=>,*l#DMR$jJ4#%'F'#%J.JnMI2$2.T?J4#%EsF2|H]'#HL.J5MR2$3MR$$.4.J5MR#,^N$1`fia5b|cddefLg=i.k-b5mpohqjd%ohq;@-wovfLbgwxz{bgmd|aWd|gcdbgD}-aovf ~fic;fhwx+ugovd;xhxPfid;gcdL}}]}u'4(F.&#;3B<|j|< (J;,6.=H_((Xp,X]Es#%nMC%"$DX?3'3n2C4ML.J5MR2$Tv2X'J5MPOQC4ML|H^N$jJ4#HHPMR&#%$C#()2'&j"$Y-.=TE.$$),..$p#%#%!+( 67,89;::>,%XFF'2|jMREK.JnMI2$p|HR&2nMIJ4EK3Tv2)J'#%EsF2|H='#;352$=MR$&,.^N$5ML/=..$)(.,",R(#;/MRJ'2|(B`aWb|cddefLg=i.kKbnmYohqjd1rr.ohqugovd;agwovfhbgwxybfLgosz{bg%m%d;a5d;gcdDbg}-aovf ~fic;fhwxugovd;xhxfPid|gcdu'y+z}-u4 4(F"&#;3-9;:9Q9;:(#%J''2.MRJ;(^(-X,2'&j"$-.=TvEK.$$),fififf !"$#%!&'(')"*',+-/.0&"123'4.05ff6"!879 : /" ;$< "= > ?8@<ABABCEDFHGJILKMMNOLGQPRA>SUT?V?WX> YT[Z\^][Z>&_`V\(> \UV=A,\ABacb6Td(>&_JV?efT[da/> \UVT?QGhg9iLjlk monkfipq6r(s6jltqfiquk:vw[tsnLtDxyz{N[M|B}~N[G= > ?@<ABABCJDoFHGh> ?TAB?QDPGILKMMOLG8H>L\c> ?> bbdT&Va/> \Acd)A>SUT?V?W> Y6TZ\\ABacb6Td(>&_dAL_;> \VT[?SBG90Ejlpjlkfisp[qQr(s6jltqfiq`kuw[tsnLtDI~O(zK&~N&}EKB[GV`_:>5V?QDQG@GQILKMyNOLGQSUSU\ABaelTdd)A>SUT?V?W/> Y6TZ\\UVacAGh?Ri&n(tLtLk;sw 4jfi*tcs6&Q[pjlkfispqst&it&snLtsg9i(jlk mon&k;p[qr(sjlt&q;q`k`wts6n(t,;gggrv LD b> WASK&M|B}NKDFHV\\(SYZdWQD*F6DGacABdV:B>?89SSUT)V:>\UVT?XelTdRd)\UV`E)V:>5_?*\AL_`_`VWAB?LAGV`_:>5V?QDG@GD59>Z\D5,GBGD > ?9= > ?@<ABABCJDFGG I(K&MyMO(G[T?S\d(>&V?\QbdTb> W> \UVT?4>&_WTdV\)a/SelTdc\ABabTd(>5_dA>SUT[?V?W6zdAB=[V;SUAdABbT[d\G?otLpkfis*w8k;spq`k;jlpjlkfitotLp [skfis*wp*)j<*&kfin(p[qJ&jlt&4BDb> WAS~|5~&}~yKG*$TdW> ?9>Zefa/>??QD > ?8> \ABTD6G5fi