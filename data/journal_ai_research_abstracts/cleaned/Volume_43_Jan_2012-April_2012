f  stulp a  fedrizzi l  m246senlechner and m  beetz 2012 learning and reasoning with actionrelated places for robust mobile manipulation volume 43 pages 142

we propose the concept of actionrelated place arplace as a powerful and flexible representation of taskrelated place in the context of mobile manipulation arplace represents robot base locations not as a single position but rather as a collection of positions each with an associated probability that the manipulation action will succeed when located there arplaces are generated using a predictive model that is acquired through experiencebased learning and take into account the uncertainty the robot has about its own location and the location of the object to be manipulated
when executing the task rather than choosing one specific goal position based only on the initial knowledge about the task context the robot instantiates an arplace and bases its decisions on this arplace which is updated as new information about the task becomes available to show the advantages of this leastcommitment approach we present a transformational planner that reasons about arplaces in order to optimize symbolic plans  our empirical evaluation demonstrates that using arplaces leads to more robust and efficient mobile manipulation in the face of state estimation uncertainty on our simulated robot



n  fu hc  lau p  varakantham and f  xiao 2012 robust local search for solving rcpspmax with durational uncertainty volume 43 pages 4386

scheduling problems in manufacturing logistics and project management have frequently been modeled using the framework of resource constrained project scheduling problems with minimum and maximum time lags rcpspmax due to the importance of these problems providing scalable solution schedules for rcpspmax problems is a topic of extensive research however all existing methods for solving rcpspmax assume that durations of activities are known with certainty an assumption that does not hold in real world scheduling problems where unexpected external events such as manpower availability weather changes etc lead to delays or advances in completion of activities thus in this paper our focus is on providing a scalable method for solving rcpspmax problems with durational uncertainty to that end we introduce the robust local search method consisting of three key ideas a introducing and studying the properties of two decision rule approximations used to compute start times of activities with respect to dynamic realizations of the durational uncertainty b deriving the expression for robust makespan of an execution strategy based on decision rule approximations and c a robust local search mechanism to efficiently compute activity execution strategies that are robust against durational uncertainty furthermore we also provide enhancements to local search that exploit temporal dependencies between activities our experimental results illustrate that robust local search is able to provide robust execution strategies efficiently



a  sadilek and h  kautz 2012 locationbased reasoning about complex multiagent behavior volume 43 pages 87133

recent research has shown that surprisingly rich models of human activity can be learned from gps positional data however most effort to date has concentrated on modeling single individuals or statistical properties of groups of people moreover prior work focused solely on modeling actual successful executions and not failed or attempted executions of the activities of interest we in contrast take on the task of understanding human interactions attempted interactions and intentions from noisy sensor data in a fully relational multiagent setting we use a realworld game of capture the flag to illustrate our approach in a welldefined domain that involves many distinct cooperative and competitive joint activities we model the domain using markov logic a statisticalrelational language and learn a theory that jointly denoises the data and infers occurrences of highlevel activities such as a player capturing an enemy our unified model combines constraints imposed by the geometry of the game area the motion model of the players and by the rules and dynamics of the game in a probabilistically and logically sound fashion we show that while it may be impossible to directly detect a multiagent activity due to sensor noise or malfunction the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it further we show that given a model of successfully performed multiagent activities along with a set of examples of failed attempts at the same activities our system automatically learns an augmented model that is capable of recognizing success and failure as well as goals of peoples actions with high accuracy we compare our approach with other alternatives and show that our unified model which takes into account not only relationships among individual players but also relationships among activities over the entire length of a game although more computationally costly is significantly more accurate finally we demonstrate that explicitly modeling unsuccessful attempts boosts performance on other important recognition tasks




t  flati and r  navigli 2012 the cqc algorithm cycling in graphs to semantically enrich and enhance a bilingual dictionary volume 43 pages 135171

bilingual machinereadable dictionaries are knowledge resources useful in many automatic tasks however compared to monolingual computational lexicons like wordnet bilingual dictionaries typically provide a lower amount of structured information such as lexical and semantic relations and often do not cover the entire range of possible translations for a word of interest in this paper we present cycles and quasicycles cqc a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machinereadable dictionary the dictionary is represented as a graph and cyclic patterns are sought in the graph to assign an appropriate sense tag to each translation in a lexical entry further we use the algorithms output to improve the quality of the dictionary itself by suggesting accurate solutions to structural problems such as misalignments partial alignments 
and missing entries finally we successfully apply cqc to the task of synonym extraction



g  pesant c  quimper and a  zanarini 2012 countingbased search branching heuristics for constraint satisfaction problems volume 43 pages 173210

designing a search heuristic for constraint programming that is reliable across problem domains has been an important research topic in recent years this paper concentrates on one family of candidates countingbased search such heuristics seek to make branching decisions that preserve most of the solutions by determining what proportion of solutions to each individual constraint agree with that decision whereas most generic search heuristics in constraint programming rely on local information at the level of the individual variable our search heuristics are based on more global information at the constraint level we design several algorithms that are used to count the number of solutions to specific families of constraints and propose some search heuristics exploiting such information the experimental part of the paper considers eight problem domains ranging from wellestablished benchmark puzzles to rostering and sport scheduling an initial empirical analysis identifies heuristic maxsd as a robust candidate among our proposalsewe then evaluate the latter against the state of the art including the latest generic search heuristics restarts and discrepancybased tree traversals experimental results show that countingbased search generally outperforms other generic heuristics



y  zeng and p  doshi 2012 exploiting model equivalences for solving interactive dynamic influence diagrams volume 43 pages 211255

 we focus on  the problem of sequential decision  making in partially observable environments shared with  other agents of uncertain types having  similar or  conflicting objectives   this problem  has been previously  formalized by multiple  frameworks one  of which  is the interactive  dynamic   influence   diagram  idid   which generalizes  the  wellknown  influence  diagram to  the  multiagent setting  idids are graphical models and may be used to compute the policy  of an agent  given its  belief over  the physical  state and others models which changes as  the agent acts and observes in the  multiagent setting
as we may  expect solving idids is computationally  hard  this is predominantly due to the large space of candidate models ascribed to the other agents  and its exponential growth over  time  we present two methods  for reducing the size  of the model  space and stemming its  exponential  growth  both  these  methods involve  aggregating individual models into equivalence classes  our first method groups together behaviorally equivalent models and selects only those  models for  updating which will result in  predictive behaviors that are distinct  from others  in the updated  model space   the second method further compacts  the model space by focusing  on portions of the   behavioral  predictions    specifically   we  cluster  actionally equivalent models  that prescribe identical actions at a  single  time step  exactly  identifying  the equivalences  would require us to solve all models in the initial set  we avoid this by selectively  solving  some of  the  models  thereby introducing  an approximation    we   discuss   the   error   introduced   by   the approximation and  empirically demonstrate the  improved efficiency in solving idids due to the equivalences



jhm  lee and k  l leung 2012 consistency techniques for flowbased projectionsafe global cost functions in weighted constraint satisfaction volume 43 pages 257292

many combinatorial problems deal with preferences and violations the goal of which is to find solutions with the minimum cost  weighted constraint satisfaction is a framework for modeling such problems which consists of a set of cost functions to measure the degree of violation or preferences of different combinations of variable assignments  typical solution methods for weighted constraint satisfaction problems wcsps are based on branchandbound search which are made practical through the use of powerful consistency techniques such as ac fdac edac to deduce hidden cost information and value pruning during search  these techniques however are designed to be efficient only on binary and ternary cost functions which are represented in table form  in tackling many reallife problems high arity or global cost functions are required  we investigate efficient representation scheme and algorithms to bring the benefits of the consistency techniques to also high arity cost functions which are often derived from hard global constraints from classical constraint satisfaction
the literature suggests some global cost functions can be represented as flow networks and the minimum cost flow algorithm can be used to compute the minimum costs of such networks in polynomial time  we show that naive adoption of this flowbased algorithmic method for global cost functions can result in a stronger form of nullinverse consistency  we further show how the method can be modified to handle cost projections and extensions to maintain generalized versions of ac and fdac for cost functions with more than two variables  similar generalization for the stronger edac is less straightforward  we reveal the oscillation problem when enforcing edac on cost functions sharing more than one variable  to avoid oscillation we propose a weak version of edac and generalize it to weak edgac for nonbinary cost functions using various benchmarks involving the soft variants of hard global constraints alldifferent gcc same and regular empirical results demonstrate that our proposal gives improvements of up to an order of magnitude when compared with the traditional constraint optimization approach both in terms of time and pruning 



r  huang y  chen and w  zhang 2012 sas planning as satisfiability volume 43 pages 293328




aaai 2010 outstanding paper award

planning as satisfiability is a principal approach to planning with many eminent advantages the existing planning as satisfiability techniques usually use encodings compiled from strips we introduce a novel sat encoding scheme sase based on the sas formalism the new scheme exploits the structural information in sas resulting in an encoding that is both more compact and efficient for planning we prove the correctness of the new encoding by establishing an isomorphism between the solution plans of sase and that of strips based encodings we further analyze the transition variables newly introduced in sase to explain why it accommodates modern sat solving algorithms and improves performance we give empirical statistical results to support our analysis we also develop a number of techniques to further reduce the encoding size of sase and conduct experimental studies to show the strength of each individual technique finally we report extensive experimental results to demonstrate significant improvements of sase over the stateoftheart strips based encoding schemes in terms of both time and memory efficiency




p  jeavons and j  petke 2012 local consistency and satsolvers volume 43 pages 329351

local consistency techniques such as kconsistency are a key  component of specialised solvers for constraint satisfaction problems in this paper we show that the power of using kconsistency techniques on a constraint satisfaction problem is precisely captured by using a particular inference rule which we call negativehyperresolution on the standard direct encoding of the problem into boolean clauses we also show that current clauselearning satsolvers will discover in expected polynomial time any inconsistency that can be deduced from a given set of clauses using negativehyperresolvents of a fixed size we combine these two results to show that without being explicitly designed to do so current clauselearning satsolvers efficiently simulate kconsistency techniques for all fixed values of k we then give some experimental results to show that this feature allows clauselearning satsolvers to efficiently solve certain families of constraint problems which are challenging for conventional constraintprogramming solvers




l  r planken m  m de weerdt and r  pj van der krogt 2012 computing allpairs shortest paths by leveraging low treewidth volume 43 pages 353388




icaps 2011 honorable mention for best student paper

we present two new and efficient algorithms for computing allpairs shortest paths  the algorithms operate on directed graphs with real possibly negative weights  they make use of directed path consistency along a vertex ordering d both algorithms run in on2 wd time where wd is the graph width induced by this vertex ordering  for graphs of constant treewidth this yields on2 time which is optimal  on chordal graphs the algorithms run in onm time in addition we present a variant that exploits graph separators to arrive at a run time of  on wd2  n2 sd on general graphs where sd  wd is the size of the largest minimal separator induced by the vertex ordering d we show empirically that on both constructed and realistic benchmarks in many cases the algorithms outperform floydwarshalls as well as johnsons algorithm which represent the current state of the art with a run time of on3 and onm  n2 log n respectively our algorithms can be used for spatial and temporal reasoning such as for the simple temporal problem which underlines their relevance to the planning and scheduling community



f  s225nchezmart237nez r  c carrasco m  a mart237nezprieto and j  adiego 2012 generalized biwords for bitext compression and translation spotting volume 43 pages 389418

large bilingual parallel texts also known as bitexts are usually stored in a compressed form and previous work has shown that they can be more efficiently compressed if the fact that the two texts are mutual translations is exploited for example a bitext can be seen as a sequence of biwords pairs of parallel words with a high probability of cooccurrence that can be used as an intermediate representation in the compression process  however the simple biword approach described in the literature can only exploit onetoone word alignments and cannot tackle the reordering of words we therefore introduce a generalization of biwords which can describe multiword expressions and reorderings  we also describe some methods for the binary compression of generalized biword sequences and compare their performance when different schemes are applied to the extraction of the biword sequence in addition we show that this generalization of biwords allows for the implementation of an efficient algorithm to look on the compressed bitext for words or text segments in one of the texts and retrieve their counterpart translations in the other text an application usually referred to as translation spotting with only some minor modifications in the compression algorithm



b  cuenca grau b  motik g  stoilos and i  horrocks 2012 completeness guarantees for incomplete ontology reasoners theory and practice volume 43 pages 419476




aaai 2010 outstanding paper award

to achieve scalability of query answering the developers of semantic web applications are often forced to use incomplete owl 2 reasoners which fail to derive all answers for at least one query ontology and data set the lack of completeness guarantees however may be unacceptable for applications in areas such as health care and defence where missing answers can adversely affect the applications functionality furthermore even if an application can tolerate some level of incompleteness it is often advantageous to estimate how many and what kind of answers are being lost
our results thus provide a theoretical and practical foundation for the design of future ontologybased information systems that maximise scalability while minimising or even eliminating incompleteness of query answers



j  baum a  e nicholson and t  i dix 2012 proximitybased nonuniform abstractions for approximate planning volume 43 pages 477522

in a deterministic world a planning agent can be certain of the consequences of its planned sequence of actions not so however in dynamic stochastic domains where markov decision processes are commonly used unfortunately these suffer from the curse of dimensionality if the state space is a cartesian product of many small sets dimensions planning is exponential in the number of those dimensions




c  hernandez and j  a baier 2012 avoiding and escaping depressions in realtime heuristic search volume 43 pages 523570

heuristics used for solving hard realtime search problems have regions with depressions  such regions are bounded areas of the search space in which the heuristic function is inaccurate compared to the actual cost to reach a solution early realtime search algorithms like lrta easily become trapped in those regions since the heuristic values of their states may need to be updated multiple times which results in costly solutions stateoftheart realtime search algorithms like lsslrta or lrtak improve lrtas mechanism to update the heuristic resulting in improved performance those algorithms however do not guide search towards avoiding depressed regions this paper presents depression avoidance a simple realtime search principle to guide search towards avoiding states that have been marked as part of a heuristic depression we propose two ways in which depression avoidance can be implemented markandavoid and movetoborder we implement these strategies on top of lsslrta and rtaa producing 4 new realtime heuristic search algorithms alsslrta dalsslrta artaa and dartaa when the objective is to find a single solution by running the realtime search algorithm once we show that dalsslrta and dartaa outperform their predecessors sometimes by one order of magnitude of the four new algorithms dartaa produces the best solutions given a fixed deadline on the average time allowed per planning episode we prove all our algorithms have good theoretical properties in finite search spaces they find a solution if one exists and converge to an optimal after a number of trials




j  lee and r  palla 2012 reformulating the situation calculus and the event calculus in the general theory of stable models and in answer set programming volume 43 pages 571620

circumscription and logic programs under the stable model semantics are two wellknown nonmonotonic formalisms the former has served as a basis of classical logic based action formalisms such as the situation calculus the event calculus and temporal action logics the latter has served as a basis of a family of action languages such as language a and several of its descendants based on the discovery that circumscription and the stable model semantics coincide on a class of canonical formulas we reformulate the situation calculus and the event calculus in the general theory of stable models we also present a translation that turns the reformulations further into answer set programs so that efficient answer set solvers can be applied to compute the situation calculus and the event calculus 



m  vasirani and s  ossowski 2012 a marketinspired approach for intersection management in urban road traffic networks volume 43 pages 621659

traffic congestion in urban road networks is a costly problem that affects all major cities in developed countries to tackle this problem it is possible i to act on the supply side increasing the number of roads or lanes in a network ii to reduce the demand restricting the access to urban areas at specific hours or to specific vehicles or iii to improve the efficiency of the existing network by means of a widespread use of socalled intelligent transportation systems its in line with the recent advances in smart transportation management infrastructures its has turned out to be a promising field of application for artificial intelligence techniques in particular multiagent systems seem to be the ideal candidates for the design and implementation of its in fact drivers can be naturally modelled as autonomous agents that interact with the transportation management infrastructure thereby generating a largescale open agentbased system to regulate such a system and maintain a smooth and efficient flow of traffic decentralised mechanisms for the management of the transportation infrastructure are needed
in this article we propose a distributed marketinspired mechanism for the management of a future urban road network where intelligent autonomous vehicles operated by software agents on behalf of their human owners interact with the infrastructure in order to travel safely and efficiently through the road network building on the reservationbased intersection control model proposed by dresner and stone we consider two different scenarios one with a single intersection and one with a network of intersections in the former we analyse the performance of a novel policy based on combinatorial auctions for the allocation of reservations in the latter we analyse the impact that a traffic assignment strategy inspired by competitive markets has on the drivers route choices finally we propose an adaptive management mechanism that integrates the auctionbased traffic control policy with the competitive traffic assignment strategy



srk  branavan d  silver and r  barzilay 2012 learning to win by reading manuals in a montecarlo framework volume 43 pages 661704

domain knowledge is crucial for effective performance in autonomous control systems  typically human effort is required to encode this knowledge into a control algorithm  in this paper we present an approach to language grounding which automatically interprets text in the context of a complex control application such as a game and uses domain knowledge extracted from the text to improve control performance  both text analysis and control strategies are learned jointly using only a feedback signal inherent to the application  to effectively leverage textual information our method automatically extracts the text segment most relevant to the current game state and labels it with a taskcentric predicate structure  this labeled text is then used to bias an action selection policy for the game guiding it towards promising regions of the action space  we encode our model for text analysis and game playing in a multilayer neural network representing linguistic decisions via latent variables in the hidden layers and game action quality via the output layer  operating within the montecarlo search framework we estimate model parameters using feedback from simulated games  we apply our approach to the complex strategy game civilization ii using the official game manual as the text guide  our results show that a linguisticallyinformed gameplaying agent significantly outperforms its languageunaware counterpart yielding a 34 absolute improvement and winning over 65 of games when playing against the builtin ai of civilization

