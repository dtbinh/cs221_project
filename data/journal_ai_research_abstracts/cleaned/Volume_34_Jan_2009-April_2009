s  chernova and m  veloso 2009 interactive policy learning through confidencebased autonomy volume 34 pages 125

we present confidencebased autonomy cba an interactive algorithm for policy learning from demonstration  the cba algorithm consists of two components which take advantage of the complimentary abilities of humans and computer agents  the first component confident execution enables the agent to identify states in which demonstration is required to request a demonstration from the human teacher and to learn a policy based on the acquired data  the algorithm selects demonstrations based on a measure of action selection confidence and our results show that using confident execution the agent requires fewer demonstrations to learn the policy than when demonstrations are selected by a human teacher  the second algorithmic component corrective demonstration enables the teacher to correct any mistakes made by the agent through additional demonstrations in order to improve the policy and future task performance  cba and its individual components are compared and evaluated in a complex simulated driving domain  the complete cba algorithm results in the best overall learning performance successfully reproducing the behavior of the teacher while balancing the tradeoff between number of demonstrations and number of incorrect actions during learning



n  meuleau e  benazera r  i brafman e  a hansen and   mausam 2009 a heuristic search approach to planning with continuous resources in stochastic domains volume 34 pages 2759

we consider the problem of optimal planning in stochastic domains with resource constraints where the resources are continuous and the choice of action at each step depends on resource availability  we introduce the hao algorithm a generalization of the ao algorithm that performs search in a hybrid state space that is modeled using both discrete and continuous state variables where the continuous variables represent monotonic resources  like other heuristic search algorithms hao leverages knowledge of the start state and an admissible heuristic to focus computational effort on those parts of the state space that could be reached from the start state by following an optimal policy  we show that this approach is especially effective when resource constraints limit how much of the state space is reachable  experimental results demonstrate its effectiveness in the domain that motivates our research automated planning for planetary exploration rovers




a  gershman a  meisels  and r  zivan 2009 asynchronous forward bounding for distributed cops volume 34 pages 6188

a new search algorithm for solving distributed constraint optimization problems discops is presented agents assign variables sequentially and compute bounds on partial assignments asynchronously the asynchronous bounds computation is based on the propagation of partial assignments the asynchronous forwardbounding algorithm afb is a distributed optimization search algorithm that keeps one consistent partial assignment at all times the algorithm is described in detail and its correctness proven experimental evaluation shows that afb outperforms synchronous branch and bound by many orders of magnitude and produces a phase transition as the tightness of the problem increases this is an analogous effect to the phase transition that has been observed when local consistency maintenance is applied to maxcsps the afb algorithm is further enhanced by the addition of a backjumping mechanism resulting in the afbbj algorithm  distributed backjumping is based on accumulated information on bounds of all values and on processing concurrently a queue of candidate goals for the next move back the afbbj algorithm is compared experimentally to other discop algorithms adopt dpop optapo and is shown to be a very efficient algorithm for discops



d  s bernstein c  amato e  a hansen and s  zilberstein 2009 policy iteration for decentralized control of markov decision processes volume 34 pages 89132

coordination of distributed agents is required for problems arising in many areas including multirobot systems networking and ecommerce  as a formal framework for such problems we use the decentralized partially observable markov decision process decpomdp  though much work has been done on optimal dynamic programming algorithms for the singleagent version of the problem optimal algorithms for the multiagent case have been elusive  the main contribution of this paper is an optimal policy iteration algorithm for solving decpomdps  the algorithm uses stochastic finitestate controllers to represent policies  the solution can include a correlation device which allows agents to correlate their actions without communicating  this approach alternates between expanding the controller and performing valuepreserving transformations which modify the controller without sacrificing value  we present two efficient valuepreserving transformations one can reduce the size of the controller and the other can improve its value while keeping the size fixed  empirical results demonstrate the usefulness of valuepreserving transformations in increasing value while keeping controller size to a minimum to broaden the applicability of the approach we also present a heuristic version of the policy iteration algorithm which sacrifices convergence to optimality  this algorithm further reduces the size of the controllers at each step by assuming that probability distributions over the other agents actions are known while this assumption may not hold in general it helps produce higher quality solutions in our test problems



m  binshtok r  i brafman c  domshlak and s  e shiomony 2009 generic preferences over subsets of structured objects volume 34 pages 133164

various tasks in decision making and decision support systems require selecting a preferred subset of a given set of items here we focus on problems where the individual items are described using a set of characterizing attributes and a generic preference specification is required that is a specification that can work with an arbitrary set of items for example preferences over the content of an online newspaper should have this form at each viewing the newspaper contains a subset of the set of articles currently available our preference specification over this subset should be provided offline but we should be able to use it to select a subset of any currently available set of articles eg based on their tags  we present a general approach for lifting formalisms for specifying preferences over objects with multiple attributes into ones that specify preferences over subsets of such objects we also show how we can compute an optimal subset given such a specification in a relatively efficient manner we provide an empirical evaluation of the approach as well as some worstcase complexity results



s  a wallace 2009 behavior bounding an efficient method for highlevel behavior comparison volume 34 pages 165208

in this paper we explore methods for comparing agent behavior with human behavior to assist with validation our exploration begins by considering a simple method of behavior comparison motivated by shortcomings in this initial approach we introduce behavior bounding an automated modelbased approach for comparing behavior that is inspired in part by mitchells version spaces we show that behavior bounding can be used to compactly represent both human and agent behavior we argue that relatively low amounts of human e64256ort are required to build maintain and use the data structures that underlie behavior bounding and we provide a theoretical basis for these arguments using notions of pac learnability next we show empirical results indicating that this approach is e64256ective at identifying differences in certain types of behaviors and that it performs well when compared against our initial benchmark methods finally we demonstrate that behavior bounding can produce information that allows developers to identify and 64257x problems in an agents behavior much more e64259ciently than standard debugging techniques



r  jurca and b  faltings 2009 mechanisms for making crowds truthful volume 34 pages 209253

we consider schemes for obtaining truthful reports on a common but hidden signal from large groups of rational selfinterested agents one example are online feedback mechanisms where users provide observations about the quality of a product or service so that other users can have an accurate idea of what quality they can expect however i providing such feedback is costly and ii there are many motivations for providing incorrect feedback
in this paper we extend existing methods for designing incentivecompatible rewards by also considering collusion we analyze different scenarios where for example some or all of the agents collude for each scenario we investigate whether a collusionresistant incentivecompatible reward scheme exists and use automated mechanism design to specify an algorithm for deriving an efficient reward mechanism



a  yates and o  etzioni 2009 unsupervised methods for determining object and relation synonyms on the web volume 34 pages 255296

the task of identifying synonymous relations and objects or synonym resolution is critical for highquality information extraction this paper investigates synonym resolution in the context of unsupervised information extraction where neither handtagged training examples nor domain knowledge is available the paper presents a scalable fullyimplemented system that runs in okn log n time in the number of extractions n and the maximum number of synonyms per word k the system called resolver  introduces a probabilistic relational model for predicting whether two strings are coreferential based on the similarity of the assertions containing them on a set of two million assertions extracted from the web resolver resolves objects with 78 precision and 68 recall and resolves relations with 90 precision and 35 recall several variations of resolvers probabilistic model are explored and experiments demonstrate that under appropriate conditions these variations can improve f1 by 5 an extension to the basic resolver system allows it to handle polysemous names with 97 precision and 95 recall on a data set from the trec corpus



p  doshi and p  j gmytrasiewicz 2009 monte carlo sampling methods for approximating interactive pomdps volume 34 pages 297337

partially observable markov decision processes pomdps provide a principled framework for sequential planning in uncertain single agent settings an extension of pomdps to multiagent settings called interactive pomdps ipomdps replaces pomdp belief spaces with interactive hierarchical belief systems which represent an agents belief about the physical world about beliefs of other agents and about their beliefs about others beliefs this modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute we describe a general method for obtaining approximate solutions of ipomdps based on particle filtering pf we introduce the interactive pf which descends the levels of the interactive belief hierarchies and samples and propagates beliefs at each level the interactive pf is able to mitigate the belief space complexity but it does not address the policy space complexity to mitigate the policy space complexity  sometimes also called the curse of history  we utilize a complementary method based on sampling likely observations while building the look ahead reachability tree while this approach does not completely address the curse of history it beats back the curses impact substantially we provide experimental results and chart future work



y  li p  musilek m  reformat and l  wyardscott 2009 identification of pleonastic it using the web volume 34 pages 339389

in a significant minority of cases certain pronouns especially the pronoun it can be used without referring to any specific entity this phenomenon of pleonastic pronoun usage poses serious problems for systems aiming at even a shallow understanding of natural language texts in this paper a novel approach is proposed to identify such uses of it the extrapositional cases are identified using a series of queries against the web and the cleft cases are identified using a simple set of syntactic rules the system is evaluated with four sets of news articles containing 679 extrapositional cases as well as 78 cleft constructs the identification results are comparable to those obtained by human efforts



f  bacchus s  dalmao and t  pitassi 2009 solving sat and bayesian inference with backtracking search volume 34 pages 391442

inference in bayes nets bayes is an important problem with numerous applications in probabilistic reasoning counting the number of satisfying assignments of a propositional formula sat is a closely related problem of fundamental theoretical importance both these problems and others are members of the class of sumofproducts sumprod problems in this paper we show that standard backtracking search when augmented with a simple memoization scheme caching can solve any sumofproducts problem with time complexity that is at least as good any other stateoftheart exact algorithm and that it can also achieve the best known timespace tradeoff furthermore backtrackings ability to utilize more flexible variable orderings allows us to prove that it can achieve an exponential speedup over other standard algorithms for sumprod on some instances
the ideas presented here have been utilized in a number of solvers that have been applied to various types of sumofproduct problems these systems have exploited the fact that backtracking can naturally exploit more of the problems structure to achieve improved performance on a range of probleminstances empirical evidence of this performance gain has appeared in published works describing these solvers and we provide references to these works



e  gabrilovich and s  markovitch 2009 wikipediabased semantic interpretation for natural language processing volume 34 pages 443498




2014 ijcaijair best paper prize

adequate representation of natural language semantics requires access to vast amounts of common sense and domainspecific world knowledge prior work in the field was based on purely statistical techniques that did not make use of background knowledge on limited lexicographic knowledge bases such as wordnet or on huge manual efforts such as the cyc project here we propose a novel method called explicit semantic analysis esa for finegrained semantic interpretation of unrestricted natural language texts our method represents meaning in a highdimensional space of concepts derived from wikipedia the largest encyclopedia in existence we explicitly represent the meaning of any text in terms of wikipediabased concepts we evaluate the effectiveness of our method on text categorization and on computing the degree of semantic relatedness between fragments of natural language text using esa results in significant improvements over the previous state of the art in both tasks importantly due to the use of natural concepts the esa model is easy to explain to human users



v  ruiz de angulo and c  torras 2009 exploiting singlecycle symmetries in continuous constraint problems volume 34 pages 499520

symmetries in discrete constraint satisfaction problems have been explored and exploited in the last years but symmetries in continuous constraint problems have not received the same attention here we focus on permutations of the variables consisting of one single cycle we propose a procedure that takes advantage of these symmetries by interacting with a continuous constraint solver without interfering with it a key concept in this procedure are the classes of symmetric boxes formed by bisecting a ndimensional cube at the same point in all dimensions at the same time we analyze these classes and quantify them as a function of the cube dimensionality moreover we propose a simple algorithm to generate the representatives of all these classes for any number of variables at very high rates a problem example from the chemical 64257eld and the cyclic nroots problem are used to show the performance of the approach in practice



t  rahwan s  d ramchurn n  r jennings and a  giovannucci 2009 an anytime algorithm for optimal coalition structure generation volume 34 pages 521567

coalition formation is a fundamental type of interaction that involves the creation of coherent groupings of distinct autonomous agents in order to efficiently achieve their individual or collective goals forming effective coalitions is a major research challenge in the field of  multiagent systems central to this endeavour is the problem of determining which of the many possible coalitions to form in order to achieve some goal this usually requires calculating a value for every possible coalition known as the coalition value which indicates how beneficial that coalition would be if it was formed once these values  are calculated the agents usually need to find a combination of  coalitions in which every agent belongs to exactly one coalition and by which the overall outcome of the system is maximized however this coalition structure generation problem is extremely challenging due to the number of possible solutions that need to be examined which grows exponentially with the number of agents involved to date therefore many algorithms have been proposed to solve this problem using different techniques ranging from dynamic programming to integer programming to stochastic search all of which suffer from major limitations relating to execution time solution quality and memory requirements
with this in mind we develop an anytime algorithm to solve the coalition structure generation problem specifically the algorithm uses a novel representation of the search space which partitions the space of possible solutions into subspaces such that it is possible to compute upper and lower bounds on the values of the best coalition structures in them these bounds are then used to identify the subspaces that have no potential of containing the optimal solution so that they can be pruned the algorithm then searches through the remaining subspaces very efficiently using a branchandbound technique to avoid examining all the solutions within the searched subspaces in this setting we prove that our algorithm enumerates all coalition structures efficiently by avoiding redundant and invalid solutions automatically moreover in order to effectively test our algorithm we develop a new type of input distribution which allows us to generate more reliable benchmarks compared to the input distributions previously used in the field given this new distribution we show that for 27 agents our algorithm is able to find solutions that are optimal in 0175 of the time required by the fastest available algorithm in the literature the algorithm is anytime and if interrupted before it would have normally terminated it can still provide a solution that is guaranteed to be within a bound from the optimal one moreover the guarantees we provide on the quality of the solution are significantly better than those provided by the previous state of the art algorithms designed for this purpose for example for the worst case distribution given 25 agents our algorithm is able to find a 90 efficient solution in around 10 of time it takes to find the optimal solution



s  r k branavan h  chen j  eisenstein and r  barzilay 2009 learning documentlevel semantic properties from freetext annotations volume 34 pages 569603

this paper presents a new method for inferring the semantic properties of documents by leveraging freetext keyphrase annotations  such annotations are becoming increasingly abundant due to the recent dramatic growth in semistructured usergenerated online content one especially relevant domain is product reviews which are often annotated by their authors with proscons keyphrases such as a real bargain or good value these annotations are representative of the underlying semantic properties however unlike expert annotations they are noisy lay authors may use different labels to denote the same property and some labels may be missing  to learn using such noisy annotations we find a hidden paraphrase structure which clusters the keyphrases  the paraphrase structure is linked with a latent topic model of the review texts enabling the system to predict the properties of unannotated documents and to effectively aggregate the semantic properties of multiple reviews  our approach is implemented as a hierarchical bayesian model with joint inference  we find that joint inference increases the robustness of the keyphrase clustering and encourages the latent topics to correlate with semantically meaningful properties  multiple evaluations demonstrate that our model substantially outperforms alternative approaches for summarizing single and multiple documents into a set of semantically salient keyphrases



f  s225nchezmart237nez and m  l forcada 2009 inferring shallowtransfer machine translation rules from small parallel corpora volume 34 pages 605635

this paper describes a method for the automatic inference of structural transfer rules to be used in a shallowtransfer machine translation mt system from small parallel corpora the structural transfer rules are based on alignment templates like those used in statistical mt alignment templates are extracted from sentencealigned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the mt system and control their application as transfer rules the experiments conducted using three different language pairs in the freeopensource mt platform apertium show that translation quality is improved as compared to wordforword translation when no transfer rules are used and that the resulting translation quality is close to that obtained using handcoded transfer rules the method we present is entirely unsupervised and benefits from information in the rest of modules of the mt system in which the inferred rules are applied




t  a cohn and m  lapata 2009 sentence compression as tree transduction volume 34 pages 637674

this paper presents a treetotree transduction method for sentence compression our model is based on synchronous tree substitution grammar a formalism that allows local distortion of the tree topology and can thus naturally capture structural mismatches we describe an algorithm for decoding in this framework and show how the model can be trained discriminatively within a large margin framework  experimental results on sentence compression bring significant improvements over a stateoftheart model



o  gim233nez and a  jonsson 2009 planning over chain causal graphs for variables with domains of size 5 is nphard volume 34 pages 675706

recently considerable focus has been given to the problem of determining the boundary between tractable and intractable planning problems in this paper we study the complexity of planning in the class cn of planning problems characterized by unary operators and directed path causal graphs although this is one of the simplest forms of causal graphs a planning problem can have we show that planning is intractable for cn unless p  np even if the domains of state variables have bounded size in particular we show that plan existence for cnk is nphard for k5 by reduction from cnfsat here k denotes the upper bound on the size of the state variable domains our result reduces the complexity gap for the class cnk to cases k3 and k4 only since cn2 is known to be tractable



a  singh a  krause c  guestrin and w  j kaiser 2009 efficient informative sensing using multiple robots volume 34 pages 707755

the need for efficient monitoring of spatiotemporal dynamics in large environmental applications such as the water quality monitoring in rivers and lakes motivates the use of robotic sensors in order to achieve sufficient spatial coverage typically these robots have bounded resources such as limited battery or limited amounts of time to obtain measurements thus careful coordination of their paths is required in order to maximize the amount of information collected while respecting the resource constraints in this paper we present an efficient approach for nearoptimally solving the nphard optimization problem of planning such informative paths in particular we first develop esip efficient singlerobot informative path planning an approximation algorithm for optimizing the path of a single robot hereby we use a gaussian process to model the underlying phenomenon and use the mutual information between the visited locations and remainder of the space to quantify the amount of information collected we prove that the mutual information collected using paths obtained by using esip is close to the information obtained by an optimal solution we then provide a general technique sequential allocation which can be used to extend any single robot planning algorithm such as esip for the multirobot problem this procedure approximately generalizes any guarantees for the singlerobot problem to the multirobot case we extensively evaluate the effectiveness of our approach on several experiments performed infield for two important environmental sensing applications lake and river monitoring and simulation experiments performed using several real world sensor network data sets



m  zaffalon and e  miranda 2009 conservative inference rule for uncertain reasoning under incompleteness volume 34 pages 757821

in this paper we formulate the problem of inference under incomplete information in very general terms this includes modelling the process responsible for the incompleteness which we call the incompleteness process we allow the process behaviour to be partly unknown then we use walleys theory of coherent lower previsions a generalisation of the bayesian theory to imprecision to derive the rule to update beliefs under incompleteness that logically follows from our assumptions and that we call conservative inference rule this rule has some remarkable properties it is an abstract rule to update beliefs that can be applied in any situation or domain it gives us the opportunity to be neither too optimistic nor too pessimistic about the incompleteness process which is a necessary condition to draw reliable while strong enough conclusions and it is a coherent rule in the sense that it cannot lead to inconsistencies we give examples to show how the new rule can be applied in expert systems in parametric statistical inference and in pattern classification and discuss more generally the view of incompleteness processes defended here as well as some of its consequences
