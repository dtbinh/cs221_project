d  r wilson and  t  r martinez 1997 improved heterogeneous distance functions volume 6 pages 134

instancebased learning techniques typically handle    continuous and linear input values well but often do not handle    nominal input attributes appropriately  the value difference metric    vdm was designed to find reasonable distance values between nominal    attribute values but it largely ignores continuous attributes    requiring discretization to map continuous values into nominal values    this paper proposes three new heterogeneous distance functions called    the heterogeneous value difference metric hvdm the interpolated    value difference metric ivdm and the windowed value difference    metric wvdm  these new distance functions are designed to handle    applications with nominal attributes continuous attributes or both    in experiments on 48 applications the new distance metrics achieve    higher classification accuracy on average than three previous distance    functions on those datasets that have both nominal and continuous    attributes



s  wermter and  v  weber 1997 screen learning a flat syntactic and semantic spoken language analysis using artificial neural networks volume 6 pages 3585

previous approaches of analyzing spontaneously spoken    language often have been based on encoding syntactic and semantic    knowledge manually and symbolically while there has been some    progress using statistical or connectionist language models many    current spoken language systems still use a relatively brittle    handcoded symbolic grammar or symbolic semantic component        in contrast we describe a socalled screening approach for learning    robust processing of spontaneously spoken language  a screening    approach is a flat analysis which uses shallow sequences of category    representations for analyzing an utterance at various syntactic    semantic and dialog levels  rather than using a deeply structured    symbolic analysis we use a flat connectionist analysis  this    screening approach aims at supporting speech and language processing    by using 1 datadriven learning and 2 robustness of connectionist    networks  in order to test this approach we have developed the    screen system which is based on this new robust learned and flat    analysis        in this paper we focus on a detailed description of screens    architecture the flat syntactic and semantic analysis the    interaction with a speech recognizer and a detailed evaluation    analysis of the robustness under the influence of noisy or incomplete    input  the main result of this paper is that flat representations    allow more robust processing of spontaneous spoken language than    deeply structured representations  in particular we show how the    faulttolerance and learning capability of connectionist networks can    support a flat analysis for providing more robust spokenlanguage    processing within an overall hybrid symbolicconnectionist framework



g  de giacomo and  m  lenzerini 1997 a uniform framework for concept definitions in description logics volume 6 pages 87110

most modern formalisms used in databases and artificial    intelligence for describing an application domain are based on the    notions of class or concept and relationship among classes  one    interesting feature of such formalisms is the possibility of defining    a class ie providing a set of properties that precisely    characterize the instances of the class  many recent articles point    out that there are several ways of assigning a meaning to a class    definition containing some sort of recursion  in this paper we argue    that instead of choosing a single style of semantics we achieve    better results by adopting a formalism that allows for different    semantics to coexist we demonstrate the feasibility of our argument    by presenting a knowledge representation formalism the description    logic mualcq with the above characteristics  in addition to the    constructs for conjunction disjunction negation quantifiers and    qualified number restrictions mualcq includes special fixpoint    constructs to express suitably interpreted recursive definitions    these constructs enable the usual framebased descriptions to be    combined with definitions of recursive data structures such as    directed acyclic graphs lists streams etc  we establish several    properties of mualcq including the decidability and the computational    complexity of reasoning by formulating a correspondence with a    particular modal logic of programs called the modal mucalculus



p  agre and  i  horswill 1997 lifeworld analysis volume 6 pages 111145

we argue that the analysis of agentenvironment interactions should be extended to include the conventions and invariants maintained by agents throughout their activity  we refer to this thicker notion of environment as a lifeworld and present a partial set of formal tools for describing structures of lifeworlds and the ways in which they computationally simplify activity  as one specific example we apply the tools to the analysis of the toast system and show how versions of the system with very different control structures in fact implement a common control structure together with different conventions for encoding task state in the positions or states of objects in the environment



a  darwiche and  g  provan 1997 query dags a practical paradigm for implementing beliefnetwork inference volume 6 pages 147176

we describe a new paradigm for implementing inference in    belief networks which consists of two steps 1 compiling a belief    network into an arithmetic expression called a query dag qdag and    2 answering queries using a simple evaluation algorithm each node    of a qdag represents a numeric operation a number or a symbol for    evidence  each leaf node of a qdag represents the answer to a    network query that is the probability of some event of interest it    appears that qdags can be generated using any of the standard    algorithms for exact inference in belief networks we show how they    can be generated using clustering and conditioning algorithms the    time and space complexity of a qdag generation algorithm is no worse    than the time complexity of the inference algorithm on which it is    based the complexity of a qdag evaluation algorithm is linear in the    size of the qdag and such inference amounts to a standard evaluation    of the arithmetic expression it represents the intended value of    qdags is in reducing the software and hardware resources required to    utilize belief networks in online realworld applications the    proposed framework also facilitates the development of online    inference on different software and hardware platforms due to the    simplicity of the qdag evaluation algorithm interestingly enough    qdags were found to serve other purposes simple techniques for    reducing qdags tend to subsume relatively complex optimization    techniques for beliefnetwork inference such as networkpruning and    computationcaching



d  w opitz and  j  w shavlik 1997 connectionist theory refinement genetically searching the space of network topologies volume 6 pages 177209

an algorithm that learns from a set of examples should    ideally be able to exploit the available resources of a abundant    computing power and b domainspecific knowledge to improve its    ability to generalize  connectionist theoryrefinement systems which    use background knowledge to select a neural networks topology and    initial weights have proven to be effective at exploiting    domainspecific knowledge however most do not exploit available    computing power this weakness occurs because they lack the ability to    refine the topology of the neural networks they produce thereby    limiting generalization especially when given impoverished domain    theories we present the regent algorithm which uses a domainspecific     knowledge to help create an initial population of knowledgebased    neural networks and b genetic operators of crossover and mutation    specifically designed for knowledgebased networks to continually    search for better network topologies experiments on three realworld    domains indicate that our new algorithm is able to significantly    increase generalization compared to a standard connectionist    theoryrefinement system as well as our previous algorithm for    growing knowledgebased networks



t  drakengren and  p  jonsson 1997 a complete classification of tractability in rcc5 volume 6 pages 211221

we investigate the computational properties of the spatial    algebra rcc5 which is a restricted version of the rcc framework for    spatial reasoning  the satisfiability problem for rcc5 is known to    be npcomplete but not much is known about its approximately four    billion subclasses we provide a complete classification of    satisfiability for all these subclasses into polynomial and    npcomplete respectively in the process we identify all maximal    tractable subalgebras which are four in total



m  e pollack  d  joslin and  m  paolucci 1997 flaw selection strategies for partialorder planning volume 6 pages 223262

several recent studies have compared the relative efficiency    of alternative flaw selection strategies for partialorder causal link    pocl planning  we review this literature and present new    experimental results that generalize the earlier work and explain some    of the discrepancies in it  in particular we describe the leastcost    flaw repair lcfr strategy developed and analyzed by joslin and    pollack 1994 and compare it with other strategies including    gerevini and schuberts 1996 zlifo strategy  lcfr and zlifo make    very different and apparently conflicting claims about the most    effective way to reduce searchspace size in pocl planning  we    resolve this conflict arguing that much of the benefit that gerevini    and schubert ascribe to the lifo component of their zlifo strategy is    better attributed to other causes  we show that for many problems a    strategy that combines leastcost flaw selection with the delay of    separable threats will be effective in reducing searchspace size and    will do so without excessive computational overhead  although such a    strategy thus provides a good default we also show that certain    domain characteristics may reduce its effectiveness
