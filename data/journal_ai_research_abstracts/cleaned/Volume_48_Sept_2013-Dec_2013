m  alabbas and a  ramsay 2013 natural language inference for arabic using extended tree edit distance with subtrees volume 48 pages 122

many natural language processing nlp applications require the computation of similarities between pairs of syntactic or semantic trees many researchers have used tree edit distance for this task but this technique suffers from the drawback that it deals with single node operations only we have extended the standard tree edit distance algorithm to deal with subtree transformation operations as well as single nodes the extended algorithm with subtree operations tedst is more effective and flexible than the standard algorithm especially for applications that pay attention to relations among nodes eg in linguistic trees deleting a modifier subtree should be cheaper than the sum of deleting its components individually we describe the use of tedst for checking entailment between two arabic text snippets the preliminary results of using tedst were encouraging when compared with two stringbased approaches and with the standard algorithm



c  yuan and b  malone 2013 learning optimal bayesian networks a shortest path perspective volume 48 pages 2365

in this paper learning a bayesian network structure that optimizes a scoring function for a given dataset is viewed as a shortest path problem in an implicit statespace search graph this perspective highlights the importance of two research issues the development of search strategies for solving the shortest path problem and the design of heuristic functions for guiding the search this paper introduces several techniques for addressing the issues one is an a search algorithm that learns an optimal bayesian network structure by only searching the most promising part of the solution space the others are mainly two heuristic functions the first heuristic function represents a simple relaxation of the acyclicity constraint of a bayesian network although admissible and consistent the heuristic may introduce too much relaxation and result in a loose bound the second heuristic function reduces the amount of relaxation by avoiding directed cycles within some groups of variables empirical results show that these methods constitute a promising approach to learning optimal bayesian network structures



d  m roijers p  vamplew s  whiteson and r  dazeley 2013 a survey of multiobjective sequential decisionmaking volume 48 pages 67113

sequential decisionmaking problems with multiple objectives arise naturally in practice and pose unique challenges for research in decisiontheoretic planning and learning which has largely focused on singleobjective settings this article surveys algorithms designed for sequential decisionmaking problems with multiple objectives though there is a growing body of literature on this subject little of it makes explicit under what circumstances special methods are needed to solve multiobjective problems therefore we identify three distinct scenarios in which converting such a problem to a singleobjective one is impossible infeasible or undesirable furthermore we propose a taxonomy that classifies multiobjective methods according to the applicable scenario the nature of the scalarization function which projects multiobjective values to scalar ones and the type of policies considered we show how these factors determine the nature of an optimal solution which can be a single policy a convex hull or a pareto front using this taxonomy we survey the literature on multiobjective methods for planning and learning finally we discuss key applications of such methods and outline opportunities for future work



a  cal236 g  gottlob and m  kifer 2013 taming the infinite chase query answering under expressive relational constraints volume 48 pages 115174

the chase algorithm is a fundamental tool for query evaluation and for testing query containment under tuplegenerating dependencies tgds and equalitygenerating dependencies egds  so far most of the research on this topic has focused on cases where the chase procedure terminates  this paper introduces expressive classes of tgds defined via syntactic restrictions guarded tgds gtgds and weakly guarded sets of tgds wgtgds  for these classes the chase procedure is not guaranteed to terminate and thus may have an infinite outcome nevertheless we prove that the problems of conjunctivequery answering and query containment under such tgds are decidable  we provide decision procedures and tight complexity bounds for these problems  then we show how egds can be incorporated into our results by providing conditions under which egds do not harmfully interact with tgds and do not affect the decidability and complexity of query answering  we show applications of the aforesaid classes of constraints to the problem of answering conjunctive queries in flogic lite an objectoriented ontology language and in some tractable description logics




v  robu e  h gerding s  stein d  c parkes a  rogers and n  r jennings 2013 an online mechanism for multiunit demand and its application to plugin hybrid electric vehicle charging volume 48 pages 175230

we develop an online mechanism for the allocation of an expiring resource to a dynamic agent population each agent has a nonincreasing marginal valuation function for the resource and an upper limit on the number of units that can be allocated in any period we propose two versions on a truthful allocation mechanism each modifies the decisions of a greedy online assignment algorithm by sometimes cancelling an allocation of resources one version makes this modification immediately upon an allocation decision while a second waits until the point at which an agent departs the market adopting a priorfree framework we show that the second approach has better worstcase allocative efficiency and is more scalable on the other hand the first approach with immediate cancellation may be easier in practice because it does not need to reclaim units previously allocated we consider an application to recharging plugin hybrid electric vehicles phevs using data from a realworld trial of phevs in the uk we demonstrate higher system performance than a fixed price system performance comparable with a standard but nontruthful scheduling heuristic and the ability to support 50 more vehicles at the same fuel cost than a simple randomized policy



i  p gent 2013 optimal implementation of watched literals and more general techniques volume 48 pages 231252

i prove that an implementation technique for scanning lists in backtracking search algorithms is optimal  the result applies to a simple general framework which i present applications include watched literal unit propagation in sat and a number of examples in constraint satisfaction  techniques like watched literals are known to be highly space efficient and effective in practice  when implemented in the circular approach described here  these techniques also have optimal run time per branch in bigo terms when amortized across a search tree  this also applies when multiple list elements must be found  the constant factor overhead of the worst case is only 2  replacing the existing nonoptimal implementation of unit propagation in minisat speeds up propagation by 29 though this is not enough to improve overall run time significantly



i  kollia and b  glimm 2013 optimizing sparql query answering over owl ontologies volume 48 pages 253303

the sparql query language is currently being extended by the world wide web consortium w3c with socalled entailment regimes an entailment regime defines how queries are evaluated under more expressive semantics than sparqls standard simple entailment which is based on subgraph matching the queries are very expressive since variables can occur within complex concepts and can also bind to concept or role names
we provide a prototypical implementation and evaluate the efficiency of the proposed optimizations our experimental study shows that the static ordering usually outperforms the dynamic one when accurate statistics are available this changes however when the statistics are less accurate eg due to nondeterministic reasoning decisions for queries that go beyond conjunctive instance queries we observe an improvement of up to three orders of magnitude due to the proposed optimizations



i  konstas and m  lapata 2013 a global model for concepttotext generation volume 48 pages 305346

  concepttotext generation refers to the task of automatically producing textual output from nonlinguistic input we present a joint model that captures content selection what to say and surface realization how to say in an unsupervised domainindependent fashion  rather than breaking up the generation process into a sequence of local decisions we define a probabilistic contextfree grammar that globally describes the inherent structure of the input a corpus of database records and text describing some of them  we recast generation as the task of finding the best derivation tree for a set of database records and describe an algorithm for decoding in this framework that allows to intersect the grammar with additional information capturing fluency and syntactic wellformedness constraints experimental evaluation on several domains achieves results competitive with stateoftheart systems that use domain specific constraints explicit feature engineering or labeled data



b  ten cate e  franconi and i  seylan 2013 beth definability in expressive description logics volume 48 pages 347414

the beth definability property a wellknown property from classical logic is investigated in the context of description logics if a general ltbox implicitly defines an lconcept in terms of a given signature where l is a description logic then does there always exist over this signature an explicit definition in l for the concept this property has been studied before and used to optimize reasoning in description logics in this paper a complete classification of beth definability is provided for extensions of the basic description logic alc with transitive roles inverse roles role hierarchies andor functionality restrictions both on arbitrary and on finite structures moreover we present a tableaubased algorithm which computes explicit definitions of at most double exponential size this algorithm is optimal because it is also shown that the smallest explicit definition of an implicitly defined concept may be double exponentially long in the size of the input tbox finally if explicit definitions are allowed to be expressed in firstorder logic then we show how to compute them in single exponential time



g  casini and u  straccia 2013 defeasible inheritancebased description logics volume 48 pages 415473

defeasible inheritance networks are a nonmonotonic framework that deals with hierarchical knowledge on the other hand rational closure is acknowledged as a landmark of the preferential approach to nonmonotonic reasoning we will combine these two approaches and define a new nonmonotonic closure operation for propositional knowledge bases that combines the advantages of both then we redefine such a procedure for description logics dls a family of logics wellsuited to model structured information in both cases we will provide a simple reasoning method that is built on top of the classical entailment relation and thus is amenable of an implementation based on existing reasoners eventually we evaluate our approach on wellknown landmark test examples



j  p delgrande and r  wassermann 2013 horn clause contraction functions volume 48 pages 475511

in classical agmstyle belief change it is assumed that the underlying logic contains classical propositional logic this is clearly a limiting assumption particularly in artificial intelligence consequently there has been recent interest in studying belief change in approaches where the full expressivity of classical propositional logic is not obtained in this paper we investigate belief contraction in horn knowledge bases we point out that the obvious extension to the horn case involving horn remainder sets as a starting point is problematic not only do horn remainder sets have undesirable properties but also some desirable horn contraction functions are not captured by this approach for horn belief set contraction we develop an account in terms of a modeltheoretic characterisation involving weak remainder sets maxichoice and partial meet horn contraction is specified and we show that the problems arising with earlier work are resolved by these approaches as well constructions of the specific operators and sets of postulates are provided and representation results are obtained we also examine horn package contraction or contraction by a set of formulas again we give a construction and postulate set linking them via a representation result last we investigate the closelyrelated notion of forgetting in horn clauses this work is arguably interesting since horn clauses have found widespread use in ai as well the results given here may potentially be extended to other areas which make use of hornlike reasoning such as logic programming rulebased systems and description logics finally since horn reasoning is weaker than classical reasoning this work sheds light on the foundations of belief change



jd  fernandez and f  vico 2013 ai methods in algorithmic composition a comprehensive survey volume 48 pages 513582

algorithmic composition is the partial or total automation of the process of music composition by using computers since the 1950s different computational techniques related to artificial intelligence have been used for algorithmic composition including grammatical representations probabilistic methods neural networks symbolic rulebased systems constraint programming and evolutionary algorithms this survey aims to be a comprehensive account of research on algorithmic composition presenting a thorough view of the field for researchers in artificial intelligence




f  fang a  x jiang and m  tambe 2013 protecting moving targets with multiple mobile resources volume 48 pages 583634

in recent years stackelberg security games have been successfully applied to solve resource allocation and scheduling problems in several security domains however previous work has mostly assumed that the targets are stationary relative to the defender and the attacker leading to discrete game models with finite numbers of pure strategies this paper in contrast focuses on protecting mobile targets that leads to a continuous set of strategies for the players the problem is motivated by several realworld domains including protecting ferries with escort boats and protecting refugee supply lines our contributions include i a new game model for multiple mobile defender resources and moving targets with a discretized strategy space for the defender and a continuous strategy space for the attacker ii an efficient linearprogrammingbased solution that uses a compact representation for the defenders mixed strategy while accurately modeling the attackers continuous strategy using a novel subinterval analysis method iii discussion and analysis of multiple heuristic methods for equilibrium refinement to improve robustness of defenders mixed strategy iv discussion of approaches to sample actual defender schedules from the defenders mixed strategy iv detailed experimental analysis of our algorithms in the ferry protection domain



d  calvanese m  ortiz m  simkus and g  stefanoni 2013 reasoning about explanations for negative query answers in dllite volume 48 pages 635669

in order to meet usability requirements most logicbased applications provide explanation facilities for reasoning services this holds also for description logics where research has focused on the explanation of both tbox reasoning and more recently query answering besides explaining the  presence of a tuple in a query answer it is important to explain also why a   given tuple is missing we address the latter problem for instance and  conjunctive query answering over dllite ontologies by adopting abductive  reasoning that is we look for additions to the abox that force a given  tuple to be in the result as reasoning tasks we consider existence and recognition of an explanation and relevance and necessity of a given  assertion for an explanation we characterize the computational complexity of  these problems for arbitrary subset minimal and cardinality minimal
explanations



i  androutsopoulos g  lampouras and d  galanis 2013 generating natural language descriptions from owl ontologies the naturalowl system volume 48 pages 671715

we present naturalowl a natural language generation system that produces texts describing individuals or classes of owl ontologies unlike simpler owl verbalizers which typically express a single axiom at a time in controlled often not entirely fluent natural language primarily for the benefit of domain experts we aim to generate fluent and coherent multisentence texts for endusers with a system like naturalowl one can publish information in owl on the web along with automatically produced corresponding texts in multiple languages making the information accessible not only to computer programs and domain experts but also endusers we discuss the processing stages of naturalowl the optional domaindependent linguistic resources that the system can use at each stage and why they are useful we also present trials showing that when the domaindependent llinguistic resources are available naturalowl produces significantly better texts compared to a simpler verbalizer and that the resources can be created with relatively light effort



jl  p233rez de la cruz l  mandow and e  machuca 2013 a case of pathology in multiobjective heuristic search volume 48 pages 717732

this article considers the performance of the moa multiobjective search algorithm with heuristic information it is shown that in certain cases blind search can be more efficient than perfectly informed search in terms of both node and label expansions
a class of simple graph search problems is defined for which the number of nodes grows linearly with problem size and the number of nondominated labels grows quadratically it is proved that for these problems the number of node expansions performed by blind moa grows linearly with problem size while the number of such expansions performed with a perfectly informed heuristic grows quadratically it is also proved that the number of label expansions grows quadratically in the blind case and cubically in the informed case



t  xiao and j  zhu 2013 unsupervised subtree alignment for treetotree translation volume 48 pages 733782

this article presents a probabilistic subtree alignment model and its application to treetotree machine translation unlike previous work we do not resort to surface heuristics or expensive annotated data but instead derive an unsupervised model to infer the syntactic correspondence between two languages more importantly the developed model is syntacticallymotivated and does not rely on word alignments as a byproduct our model outputs a subtree alignment matrix encoding a large number of diverse alignments between syntactic structures from which machine translation systems can efficiently extract translation rules that are often filtered out due to the errors in 1best alignment experimental results show that the proposed approach outperforms three stateoftheart baseline approaches in both alignment accuracy and grammar quality when applied to machine translation our approach yields a 10 bleu improvement and a 09 ter reduction on the nist machine translation evaluation corpora with tree binarization and fuzzy decoding it even outperforms a stateoftheart hierarchical phrasebased system




c  domshlak and a  nazarenko 2013 the complexity of optimal monotonic planning the bad the good and the causal graph volume 48 pages 783812

for almost two decades monotonic or delete free relaxation has been one of the key auxiliary tools in the practice of domainindependent deterministic planning in the particular contexts of both satisficing and optimal planning it  underlies most stateoftheart heuristic functions while satisficing planning for monotonic tasks is polynomialtime optimal planning for monotonic tasks is npequivalent here we establish both negative and positive results on the complexity of some wide fragments of optimal monotonic planning with the fragments being defined around the causal graph topology our results shed some light on the link between the complexity of general  optimal planning and the complexity of optimal planning for the respective  monotonic relaxations



a  dhurandhar and j  wang 2013 single network relational transductive learning volume 48 pages 813839

relational classification on a single connected network has been of particular interest in the machine learning and data mining communities in the last decade or so this is mainly due to the explosion in popularity of social networking sites such as facebook linkedin and google amongst others in statistical relational learning many techniques have been developed to address this problem where we have a connected unweighted homogeneousheterogeneous graph that is partially labeled and the goal is to propagate the labels to the unlabeled nodes in this paper we provide a different perspective by enabling the effective use of graph transduction techniques for this problem we thus exploit the strengths of this class of methods for relational learning problems we accomplish this by providing a simple procedure for constructing a weight matrix that serves as input to a rich class of graph transduction techniques our procedure has multiple desirable properties for example the weights it assigns to edges between unlabeled nodes naturally relate to a measure of association commonly used in statistics namely the gamma test statistic we further portray the efficacy of our approach on synthetic as well as real data by comparing it with stateoftheart relational learning algorithms and graph transduction techniques with an adjacency matrix or a real valued weight matrix computed using available attributes as input in these experiments we see that our approach consistently outperforms other approaches when the graph is sparsely labeled and remains competitive with the best when the proportion of known labels increases



a  guez d  silver and p  dayan 2013 scalable and efficient bayesadaptive reinforcement learning based on montecarlo tree search volume 48 pages 841883

bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty trading off exploration and exploitation in an ideal way unfortunately planning optimally in the face of uncertainty is notoriously taxing since the search space is enormous in this paper we introduce a tractable samplebased method for approximate bayesoptimal planning which exploits montecarlo tree search our approach avoids expensive applications of bayes rule within the search tree by sampling models from current beliefs and furthermore performs this sampling in a lazy manner this enables it to outperform previous bayesian modelbased reinforcement learning algorithms by a significant margin on several wellknown benchmark problems  as we show our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in bayesian exploration



e  franconi v  kerhet and n  ngo 2013 exact query reformulation over databases with firstorder and description logics ontologies volume 48 pages 885922

we study a general framework for query rewriting in the presence of an arbitrary firstorder logic ontology over a database signature the framework supports deciding the existence of a saferange firstorder equivalent reformulation of a query in terms of the database signature and if so it provides an effective approach to construct the reformulation based on interpolation using standard theorem proving techniques eg tableau since the reformulation is a saferange formula it is effectively executable as an sql query at the end we present a nontrivial application of the framework with ontologies in the very expressive alchoiq description logic by providing effective means to compute saferange firstorder exact reformulations of queries



e  mossel a  d procaccia and m  z racz 2013 a smooth transition from powerlessness to absolute power volume 48 pages 923951

we study the phase transition of the coalitional manipulation problem for generalized scoring rules previously it has been shown that under some conditions on the distribution of votes if the number of manipulators is osqrtn where n is the number of voters then the probability that a random profile is manipulable by the coalition goes to zero as the number of voters goes to infinity whereas if the number of manipulators is omegasqrtn then the probability that a random profile is manipulable goes to one here we consider the critical window where a coalition has size csqrtn and we show that as c goes from zero to infinity the limiting probability that a random profile is manipulable goes from zero to one in a smooth fashion ie there is a smooth phase transition between the two regimes this result analytically validates recent empirical results and suggests that deciding the coalitional manipulation problem may be of limited computational hardness in practice



f  campeotto a  dal pal249 a  dovier f  fioretto and e  pontelli 2013 a constraint solver for flexible protein model volume 48 pages 9531000

this paper proposes the formalization and implementation of a novel class of constraints aimed at modeling problems related to placement of multibody systems in the 3dimensional space each multibody is a system composed of body elements connected by joint relationships and constrained by geometric properties the emphasis of this investigation is the use of multibody systems to model native conformations of protein structureswhere each body represents an entity of the protein eg an amino acid a small peptide and the geometric constraints are related to the spatial properties of the composing atoms the paper explores the use of the proposed class of constraints to support a variety of different structural analysis of proteins such as loop modeling and structure prediction
the declarative nature of a constraintbased encoding provides elaboration tolerance and the ability to make use of any additional knowledge in the analysis studies the filtering capabilities of the proposed constraints also allow to control the number of representative solutions that are withdrawn from the conformational space of the protein by means of criteria driven by uniform distribution sampling principles in this scenario it is possible to select the desired degree of precision andor number of solutions the filtering component automatically excludes configurations that violate the spatial and geometric properties of the composing multibody system the paper illustrates the implementation of a constraint solver based on the multibody perspective and its empirical evaluation on protein  structure analysis problems
