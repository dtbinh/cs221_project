j  y halpern and r  pucella 2006 a logic for reasoning about evidence volume 26 pages 134

we introduce a logic for reasoning about evidence that essentially




d  bryce s  kambhampati and d  e smith 2006 planning graph heuristics for belief space search volume 26 pages 3599

some recent works in conditional planning have proposed reachability heuristics to improve planner scalability but many lack a formal description of the properties of their distance estimates to place previous work in context and extend work on heuristics for conditional planning we provide a formal basis for distance estimates between belief states  we give a definition for the distance between belief states that relies on aggregating underlying state distance measures  we give several techniques to aggregate state distances and their associated properties  many existing heuristics exhibit a subset of the properties but in order to provide a standardized comparison we present several generalizations of planning graph heuristics that are used in a single planner  we compliment our belief state distance estimate framework by also investigating efficient planning graph data structures that incorporate bdds to compute the most effective heuristics
we developed two planners to serve as testbeds for our investigation  the first caltalt is a conformant regression planner that uses a search  the second pond is a conditional progression planner that uses ao search we show the relative effectiveness of our heuristic techniques within these planners we also compare the performance of these planners with several state of the art approaches in conditional planning 



h  daume iii and d  marcu 2006 domain adaptation for statistical classifiers volume 26 pages 101126

the most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution  unfortunately in many applications the indomain test data is drawn from a distribution that is related but not identical to the outofdomain distribution of the training data we consider the common case in which labeled outofdomain data is plentiful but labeled indomain data is scarce  we introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts  we present efficient inference algorithms for this special case based on the technique of conditional expectation maximization  our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain 



r  booth and t  meyer 2006 admissible and restrained revision volume 26 pages 127151

as partial justification of their framework for iterated belief revision darwiche and pearl convincingly argued against boutiliers natural revision and provided a prototypical revision operator that fits into their scheme  we show that the darwichepearl arguments lead naturally to the acceptance of a smaller class of operators which we refer to as admissible admissible revision ensures that the penultimate input is not ignored completely thereby eliminating natural revision but includes the darwichepearl operator nayaks lexicographic revision operator and a newly introduced operator called restrained revision we demonstrate that restrained revision is the most conservative of admissible revision operators  effecting as few changes as possible while lexicographic revision is the least conservative and point out that restrained revision can also be viewed as a composite operator consisting of natural revision preceded by an application of a backwards revision operator previously studied by papini finally we propose the establishment of a principled approach for choosing an appropriate revision operator in different contexts and discuss future work 



t  heskes 2006 convexity arguments for efficient minimization of the bethe and kikuchi free energies volume 26 pages 153190

loopy and generalized belief propagation are popular algorithms for approximate inference in markov random fields and bayesian networks fixed points of these algorithms have been shown to correspond to extrema of the bethe and kikuchi free energy both of which are approximations of the exact helmholtz free energy however belief propagation does not always converge which motivates approaches that explicitly minimize the kikuchibethe free energy such as cccp and ups
here we describe a class of algorithms that solves this typically nonconvex constrained minimization problem through a sequence of  convex constrained minimizations of upper bounds on the kikuchi free energy intuitively one would expect tighter bounds to lead to faster algorithms which is indeed convincingly demonstrated in our simulations several ideas are applied to obtain tight convex bounds that yield dramatic speedups over cccp



m  helmert 2006 the fast downward planning system volume 26 pages 191246




honorable mention for the 2009 ijcaijair best paper prize

fast downward is a classical planning system based on heuristic search it can deal with general deterministic planning problems encoded in the propositional fragment of pddl22 including advanced features like adl conditions and effects and derived predicates axioms like other wellknown planners such as hsp and ff fast downward is a progression planner searching the space of world states of a planning task in the forward direction however unlike other pddl planning systems fast downward does not use the propositional pddl representation of a planning task directly instead the input is first translated into an alternative representation called multivalued planning tasks which makes many of the implicit constraints of a propositional planning task explicit exploiting this alternative representation fast downward uses hierarchical decompositions of planning tasks for computing its heuristic function called the causal graph heuristic which is very different from traditional hsplike heuristics based on ignoring negative interactions of operators




m  j streeter and s  f smith 2006 how the landscape of random job shop scheduling instances depends on the ratio of jobs to machines volume 26 pages 247287

we characterize the search landscape of random instances of the job shop scheduling problem jsp  specifically we investigate how the expected values of 1 backbone size 2 distance between nearoptimal schedules and 3 makespan of random schedules vary as a function of the job to machine ratio nm  for the limiting cases nm approaches 0 and nm approaches infinity we provide analytical results while for intermediate values of nm we perform experiments  we prove that as nm approaches 0 backbone size approaches 100 while as nm approaches infinity the backbone vanishes  in the process we show that as nm approaches 0 resp nm approaches infinity simple priority rules almost surely generate an optimal schedule providing theoretical evidence of an easyhardeasy pattern of typicalcase instance difficulty in job shop scheduling  we also draw connections between our theoretical results and the big valley picture of jsp landscapes



a  ramani i  l markov k  a sakallah and f  a aloul 2006 breaking instanceindependent symmetries in exact graph coloring volume 26 pages 289322

code optimization and high level synthesis can be posed as constraint satisfaction and optimization problems  such as graph coloring used in register allocation  graph coloring is also used to model more traditional csps relevant to ai such as planning timetabling and scheduling  provably optimal solutions may be desirable for commercial and defense applications additionally for applications such as register allocation and code optimization naturallyoccurring instances    of graph coloring are often small and can be solved optimally a recent  wave of improvements in algorithms for boolean satisfiability sat and 01 integer linear programming ilp suggests generic problemreduction  methods rather than problemspecific heuristics because 1 heuristics may be upset by new constraints 2 heuristics tend to ignore structure and 3 many relevant problems are provably inapproximable 




y  chen b  w wah and c  hsu 2006 temporal planning using subgoal partitioning and resolution in sgplan volume 26 pages 323369

in this paper we present the partitioning of mutualexclusion mutex constraints in temporal planning problems and its implementation in the sgplan4 planner based on the strong locality of mutex constraints observed in many benchmarks of the fourth international planning competition ipc4 we propose to partition the constraints of a planning problem into groups based on their subgoals constraint partitioning leads to significantly easier subproblems that are similar to the original problem and that can be efficiently solved by the same planner with some modifications to its objective function we present a partitionandresolve strategy that looks for locally optimal subplans in constraintpartitioned temporal planning subproblems and that resolves those inconsistent global constraints across the subproblems we also discuss some implementation details of sgplan4 which include the resolution of violated global constraints techniques for handling producible resources landmark analysis path finding and optimization searchspace reduction and modifications of metricff when used as a basic planner in sgplan4  last we show results on the sensitivity of each of these techniques in qualitytime tradeoffs and experimentally demonstrate that sgplan4 is effective for solving the ipc3 and ipc4 benchmarks



e  giunchiglia m  narizzano and a  tacchella 2006 clauseterm resolution and learning in the evaluation of quantified boolean formulas volume 26 pages 371416

resolution is the rule of inference at the basis of most procedures for automated reasoning in these procedures the input formula is first translated into an equisatisfiable formula in conjunctive normal form cnf and then represented as a set of clauses deduction starts by inferring new clauses by resolution and goes on until the empty clause is generated or satisfiability of the set of clauses is proven eg because no new clauses can be generated




d  davidov and s  markovitch 2006 multiplegoal heuristic search volume 26 pages 417451

this paper presents a new framework for anytime heuristic search




j  hoffmann s  edelkamp s  thiebaux r  englert f  liporace and s  trueg 2006 engineering benchmarks for planning the domains used in the  deterministic part of ipc4 volume 26 pages 453541

in a field of research about general reasoning mechanisms it is essential to have appropriate benchmarks ideally the benchmarks should reflect possible applications of the developed technology in ai planning researchers more and more tend to draw their testing examples from the benchmark collections used in the international planning competition ipc in the organization of the deterministic part of the fourth ipc  ipc4 the authors therefore invested significant effort to create a useful set of benchmarks they come from five different potential realworld applications of planning airport ground traffic control oil derivative transportation in pipeline networks modelchecking safety properties power supply restoration and umts call setup adapting and preparing such an application for use as a benchmark in the ipc involves at the time inevitable often drastic simplifications as well as careful choice between and engineering of domain encodings for the first time in the ipc we used compilations to formulate complex domain features in simple languages such as strips rather than just dropping the more interesting problem constraints in the simpler language subsets the article explains and discusses the five application domains and their adaptation to form the pddl test suites used in ipc4 we summarize known theoretical results on structural properties of the domains regarding their computational complexity and provable properties of their topology under the h function an idealized version of the relaxed plan heuristic we present new empirical results illuminating properties such as the quality of the most widespread heuristic functions planning graph serial planning graph and relaxed plan the growth of propositional representations over instance size and the number of actions available to achieve each fact we discuss these data in conjunction with the best results achieved by the different kinds of planners participating in ipc4
