a  artale d  calvanese r  kontchakov and m  zakharyaschev 2009 the dllite family and relations volume 36 pages 169

the recently introduced series of description logics under the common moniker dllite has attracted attention of the description logic and semantic web communities due to the low computational complexity of inference on the one hand and the ability to represent  conceptual modeling formalisms on the other  the main aim of this article is to carry out a thorough and systematic investigation of inference in extensions of the original dllite logics along five axes by i adding the boolean connectives and ii number restrictions to concept constructs iii allowing role hierarchies iv allowing role disjointness symmetry asymmetry reflexivity irreflexivity and transitivity constraints and v adopting or dropping  the unique same assumption  we analyze the combined complexity of satisfiability for the resulting logics as well as the data complexity of instance checking and answering positive existential queries  our approach is based on embedding dllite logics in suitable fragments of the onevariable firstorder logic which provides useful insights into their properties and in particular computational behavior



m  bienvenu 2009 prime implicates and prime implicants from propositional to modal logic volume 36 pages 71128

prime implicates and prime implicants have proven relevant to a number of areas of artificial intelligence most notably abductive reasoning and knowledge compilation the purpose of this paper is to examine how these notions might be appropriately extended from propositional logic to the modal logic k we begin the paper by considering a number of potential definitions of clauses and terms for k the different definitions are evaluated with respect to a set of syntactic semantic and complexitytheoretic properties characteristic of the propositional definition  we then compare the definitions with respect to the properties of the notions of prime implicates and prime implicants that they induce while there is no definition that perfectly generalizes the propositional notions we show that there does exist one definition which satisfies many of the desirable properties of the propositional case in the second half of the paper we consider the computational properties of the selected definition to this end we provide sound and complete algorithms for generating and recognizing prime implicates and we show the prime implicate recognition task to be pspacecomplete we also prove upper and lower bounds on the size and number of prime implicates while the paper focuses on the logic k all of our results hold equally well for multimodal k and for concept expressions in the description logic alc 



h  chen srk  branavan r  barzilay and d  r karger 2009 content modeling using latent permutations volume 36 pages 129163

we present a novel bayesian topic model for learning discourselevel document structure our model leverages insights from discourse theory to constrain latent topic assignments in a way that reflects the underlying organization of document topics we propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents we show that this space of orderings can be effectively represented using a distribution over permutations called the generalized mallows model we apply our method to three complementary discourselevel tasks crossdocument alignment document segmentation and information ordering our experiments show that incorporating our permutationbased model in these applications yields substantial improvements in performance over previously proposed methods



b  motik r  shearer and i  horrocks 2009 hypertableau reasoning for description logics volume 36 pages 165228

we present a novel reasoning calculus for the description logic shoiqa knowledge representation formalism with applications in areas such as the semantic web unnecessary nondeterminism and the construction of large models are two primary sources of inefficiency in the tableaubased reasoning calculi used in stateoftheart reasoners in order to reduce nondeterminism we base our calculus on hypertableau and hyperresolution calculi which we extend with a blocking condition to ensure termination in order to reduce the size of the constructed models we introduce anywhere pairwise blocking we also present an improved nominal introduction rule that ensures termination in the presence of nominals inverse roles and number restrictionsa combination of dl constructs that has proven notoriously difficult to handle our implementation shows significant performance improvements over stateoftheart reasoners on several wellknown ontologies




hl  chieu and ws  lee 2009 relaxed survey propagation for the weighted maximum satisfiability problem volume 36 pages 229266

the survey propagation sp algorithm has been shown to work well on large instances of the random 3sat problem near its phase transition it was shown that sp estimates marginals over covers that represent clusters of solutions the spy algorithm generalizes sp to work on the maximum satisfiability maxsat problem but the cover interpretation of sp does not generalize to spy in this paper  we formulate the relaxed survey propagation rsp algorithm which extends the sp algorithm to apply to the  weighted maxsat problem we show that rsp has an interpretation of  estimating marginals over covers violating a set of clauses with  minimal weight this naturally generalizes the cover  interpretation of sp empirically we show that rsp outperforms  spy and other stateoftheart maxsat solvers on random maxsat instances rsp also outperforms stateoftheart weighted maxsat solvers on random weighted maxsat instances



f   hutter h   h hoos k   leytonbrown and t   stuetzle 2009 paramils an automatic algorithm configuration framework volume 36 pages 267306

the identification of performanceoptimizing parameter settings is an important part of the development and application of algorithms we describe an automatic framework for this algorithm configuration problem more formally we provide methods for optimizing a target algorithms performance on a given class of problem instances by varying a set of ordinal andor categorical parameters we review a family of localsearchbased algorithm configuration procedures and present novel techniques for accelerating them by adaptively limiting the time spent for evaluating individual configurations we describe the results of a comprehensive experimental evaluation of our methods based on the configuration of prominent complete and incomplete algorithms for sat we also present what is to our knowledge the first published work on automatically configuring the cplex mixed integer programming solver all the algorithms we considered had default parameter settings that were manually identified with considerable effort nevertheless using our automated algorithm configuration procedures we achieved substantial and consistent performance improvements



s  pado and m  lapata 2009 crosslingual annotation projection for semantic roles volume 36 pages 307340

 this article considers the task of automatically inducing rolesemantic annotations in the framenet paradigm for new languages  we propose a general framework that is based on annotation projection phrased as a graph optimization problem it is relatively inexpensive and has the potential to reduce the human effort involved in creating rolesemantic resources within this framework we present projection models that exploit lexical and syntactic information we provide an experimental evaluation on an englishgerman parallel corpus which demonstrates the feasibility of inducing highprecision german semantic role annotation both for manually and automatically annotated english data




t  naseem b  snyder j  eisenstein and r  barzilay 2009 multilingual partofspeech tagging two unsupervised approaches volume 36 pages 341385

we demonstrate the effectiveness of multilingual learning for unsupervised partofspeech tagging the central assumption of our work is that by combining cues from multiple languages the structure of each becomes more apparent we consider two ways of applying this intuition to the problem of unsupervised partofspeech tagging a model that directly merges tag structures for a pair of languages into a single sequence and a second model which instead incorporates multilingual context using latent variables both approaches are formulated as hierarchical bayesian models using markov chain monte carlo sampling techniques for inference our results demonstrate that by incorporating multilingual evidence we can achieve impressive performance gains across a range of scenarios we also found that performance improves steadily as the number of available languages increases



m  feldman and t  tamir 2009 approximate strong equilibrium in job scheduling games volume 36 pages 387414

a nash equilibrium ne is a strategy profile resilient to unilateral deviations and is predominantly used in the analysis of multiagent systems a downside of ne is that it is not necessarily stable against deviations by coalitions yet as we show in this paper in some cases ne does exhibit stability against coalitional deviations in that the benefits from a joint deviation are bounded in this sense ne approximates strong equilibrium
our results indicate that lpt performs better than a general ne  however lpt is not the best possible approximation in particular we present a polynomial time approximation scheme ptas for the makespan minimization problem which provides a schedule with irmin of 1epsilon for any given epsilon with respect to computational complexity we show that given an ne on m  3 identical machines or m  2 unrelated machines it is nphard to determine whether a given coalition can deviate such that every member decreases its cost



c  domshlak j  hoffmann and a  sabharwal 2009 friends or foes on planning as satisfiability and abstract cnf encodings volume 36 pages 415469

planning as satisfiability as implemented in for instance the satplan tool is a highly competitive method for finding parallel stepoptimal plans a bottleneck in this approach is to prove the absence of plans of a certain length specifically if the optimal plan has n steps then it is typically very costly to prove that there is no plan of length n1 we pursue the idea of leading this proof within solution length preserving abstractions overapproximations of the original planning task this is promising because the abstraction may have a much smaller state space related methods are highly successful in model checking in particular we design a novel abstraction technique based on which one can in several widely used planning benchmarks construct abstractions that have exponentially smaller state spaces while preserving the length of an optimal plan




a  jonsson 2009 the role of macros in tractable planning volume 36 pages 471511

this paper presents several new tractability results for planning based on macros we describe an algorithm that optimally solves planning problems in a class that we call inverted tree reducible and is provably tractable for several subclasses of this class by using macros to store partial plans that recur frequently in the solution the algorithm is polynomial in time and space even for exponentially long plans we generalize the inverted tree reducible class in several ways and describe modifications of the algorithm to deal with these new classes theoretical results are validated in experiments



a  greenwald s  lee and v  naroditskiy 2009 roxybot06 stochastic prediction and optimization in tac travel volume 36 pages 513546

in this paper we describe our autonomous bidding agent roxybot who emerged victorious in the travel division of the 2006 trading agent competition in a photo finish  at a high level the design of many successful trading agents can be summarized as follows i price prediction build a model of market prices and ii optimization solve for an approximately optimal set of bids given this model  to predict roxybot builds a stochastic model of market prices by simulating simultaneous ascending auctions  to optimize roxybot relies on the sample average approximation method a stochastic optimization technique 



e  keyder and h  geffner 2009 soft goals can be compiled away volume 36 pages 547556

soft goals extend the classical model of planning with a simple model of preferences the best plans are then not the ones with least cost but the ones with maximum utility where the utility of a plan is the sum of the utilities of the soft goals achieved minus the plan cost finding plans with high utility appears to involve two linked problems choosing a subset of soft goals to achieve and finding a lowcost plan to achieve them  new search algorithms and heuristics have been developed for planning with soft goals and a new track has been introduced in the international planning competition ipc to test their performance in this note we show however that these extensions are not needed soft goals do not increase the expressive power of the basic model of planning with action costs as they can easily be compiled away we apply this compilation to the problems of the netbenefit track of the most recent ipc and show that optimal and satisficing costbased planners do better on the compiled problems than optimal and satisficing netbenefit planners on the original problems with explicit soft goals furthermore we show that penalties or negative preferences expressing conditions to avoid can also be compiled away using a similar idea
