m  p wellman 1993 a marketoriented programming environment and its application to distributed multicommodity flow problems volume 1 pages 123




2012 ifaamas award for influential papers in autonomous agents and multiagent systems

market price systems constitute a wellunderstood class of mechanisms that under certain conditions provide effective decentralization of decision making with minimal communication overhead  in a imarketoriented programmingi approach to distributed problem solving we derive the activities and resource allocations for a set of computational agents by computing the competitive equilibrium of an artificial economy  walras provides basic constructs for defining computational market structures and protocols for deriving their corresponding price equilibria  in a particular realization of this approach for a form of multicommodity flow problem we see that careful construction of the decision process according to economic principles can lead to efficient distributed resource allocation and that the behavior of the system can be meaningfully analyzed in economic terms



m  l ginsberg 1993 dynamic backtracking volume 1 pages 2546

because of their occasional need to return to shallow points in a search tree existing backtracking methods can sometimes erase meaningful progress toward solving a search problem in this paper we present a method by which backtrack points can be moved deeper in the search space thereby avoiding this difficulty the technique developed is a variant of dependencydirected backtracking that uses only polynomial space while still providing useful control information and retaining the completeness guarantees provided by earlier approaches



i  p gent and  t  walsh 1993 an empirical analysis of search in gsat volume 1 pages 4759

we describe an extensive study of search in gsat an approximation procedure for propositional satisfiability gsat performs greedy hillclimbing on the number of satisfied clauses in a truth assignment  our experiments provide a more complete picture of gsats search than previous accounts we describe in detail the two phases of search rapid hillclimbing followed by a long plateau search  we demonstrate that when applied to randomly generated 3sat problems there is a very simple scaling with problem size for both the mean number of satisfied clauses and the mean branching rate  our results allow us to make detailed numerical conjectures about the length of the hillclimbing phase the average gradient of this phase and to conjecture that both the average score and average branching rate decay exponentially during plateau search we end by showing how these results can be used to direct future theoretical analysis  this work provides a case study of how computer experiments can be used to improve understanding of the theoretical properties of algorithms



j  c schlimmer and  l  a hermens 1993 software agents completing patterns and constructing user interfaces volume 1 pages 6189

to support the goal of allowing users to record and retrieve information this paper describes an interactive notetaking system for penbased computers with two distinctive features first it actively predicts what the user is going to write second it automatically constructs a custom buttonbox user interface on request the system is an example of a learningapprentice software agent a machine learning component characterizes the syntax and semantics of the users information a performance system uses this learned information to generate completion strings and construct a user interface  description of online appendix people like to record information  doing this on paper is initially efficient but lacks flexibility recording information on a computer is less efficient but more powerful in our new note taking softwre the user records information directly on a computer behind the interface an agent acts for the user to help it provides defaults and constructs a custom user interface  the demonstration is a quicktime movie of the note taking agent in action  the file is a binhexed selfextracting archive macintosh utilities for binhex are available from macarchiveumichedu quicktime is available from ftpapplecom in the dtsmacsyssoftquicktime 
as real logic programmers normally use cut  an effective learning procedure for logic programs should be able to deal with it  because the cut predicate has only a procedural meaning clauses containing cut cannot be learned using an extensional evaluation method as is done in most learning systems  on the other hand searching a space of possible programs instead of a space of independent clauses is unfeasible  an alternative solution is to generate first a candidate base program which covers the positive examples and then make it consistent by inserting cut where appropriate  the problem of learning programs with cut has not been investigated before and this seems to be a natural and reasonable approach we generalize this scheme and investigate the difficulties that arise  some of the major shortcomings are actually caused in general by the need for intensional evaluation as a conclusion the analysis of this paper suggests on precise and technical grounds that learning cut is difficult and current induction techniques should probably be restricted to purely declarative logic languages



m  buchheit  f  m donini and  a  schaerf 1993 decidable reasoning in terminological knowledge representation systems volume 1 pages 109138

terminological knowledge representation systems tkrss are tools for designing and using knowledge bases that make use of terminological languages or concept languages  we analyze from a theoretical point of view a tkrs whose capabilities go beyond the ones of presently available tkrss the new features studied often required in practical applications can be summarized in three main points  first we consider a highly expressive terminological language called alcnr including general complements of concepts number restrictions and role conjunction second we allow to express inclusion statements between general concepts and terminological cycles as a particular case  third we prove the decidability of a number of desirable tkrsdeduction services like satisfiability subsumption and instance checking through a sound complete and terminating calculus for reasoning in alcnrknowledge bases our calculus extends the general technique of constraint systems  as a byproduct of the proof we get also the result that inclusion statements in alcnr can be simulated by terminological cycles if descriptive semantics is adopted 



n  nilsson 1994 teleoreactive programs for agent control volume 1 pages 139158

a formalism is presented for computing and organizing actions for autonomous agents in dynamic environments we introduce the notion of iteleoreactive tr programsi whose execution entails the construction of circuitry for the continuous computation of the parameters and conditions on which agent action is based  in addition to continuous feedback tr programs support parameter binding and recursion  a primary difference between tr programs and many other circuitbased systems is that the circuitry of tr programs is more compact it is constructed at run time and thus does not have to anticipate all the contingencies that might arise over all possible runs  in addition tr programs are intuitive and easy to write and are written in a form that is compatible with automatic planning and learning methods  we briefly describe some experimental applications of tr programs in the control of simulated and actual mobile robots



m  koppel  r  feldman and  a  m segre 1994 biasdriven revision of logical domain theories volume 1 pages 159208

the theory revision problem is the problem of how best to go about revising a deficient domain theory using information contained in examples that expose inaccuracies  in this paper we present our approach to the theory revision problem for propositional domain theories  the approach described here called ptr uses probabilities associated with domain theory elements to numerically track the flow of proof through the theory  this allows us to measure the precise role of a clause or literal in allowing or preventing a desired or undesired derivation for a given example  this information is used to efficiently locate and repair flawed elements of the theory  ptr is proved to converge to a theory which correctly classifies all examples and shown experimentally to be fast and accurate even for deep theories



c  x ling 1994 learning the past tense of english verbs the symbolic pattern associator vs connectionist models volume 1 pages 209229

learning the past tense of english verbs  a seemingly minor aspect of language acquisition  has generated heated debates since 1986 and has become a landmark task for testing the adequacy of cognitive modeling several artificial neural networks anns have been implemented and a challenge for better symbolic models has been posed  in this paper we present a generalpurpose symbolic pattern associator spa based upon the decisiontree learning algorithm id3  we conduct extensive headtohead comparisons on the generalization ability between ann models and the spa under different representations we conclude that the spa generalizes the past tense of unseen verbs better than ann models by a wide margin and we offer insights as to why this should be the case  we also discuss a new default strategy for decisiontree learning algorithms



d  j cook and  l  b holder 1994 substructure discovery using minimum description length and background knowledge volume 1 pages 231255

the ability to identify interesting and repetitive substructures is an essential component to discovering knowledge in structural data  we describe a new version of our subdue substructure discovery system based on the minimum description length principle  the subdue system discovers substructures that compress the original data and represent structural concepts in the data  by replacing previouslydiscovered substructures in the data multiple passes of subdue produce a hierarchical description of the structural regularities in the data  subdue uses a computationallybounded inexact graph match that identifies similar but not identical instances of a substructure and finds an approximate measure of closeness of two substructures when under computational constraints in addition to the minimum description length principle other background knowledge can be used by subdue to guide the search towards more appropriate substructures  experiments in a variety of domains demonstrate subdues ability to find substructures capable of compressing the original data and to discover structural concepts important to the domain description of online appendix this is a compressed tar file containing the subdue discovery system written in c  the program accepts as input databases represented in graph form and will output discovered substructures with their corresponding value



p  m murphy and  m  j pazzani 1994 exploring the decision forest an empirical investigation of occams   razor in decision tree induction volume 1 pages 257275

we report on a series of experiments in which all decision trees consistent with the training data are constructed these experiments were run to gain an understanding of the properties of the set of consistent decision trees and the factors that affect the accuracy of individual trees in particular we investigated the relationship between the size of a decision tree consistent with some training data and the accuracy of the tree on test data the experiments were performed on a massively parallel maspar computer the results of the experiments on several artificial and two real world problems indicate that for many of the problems investigated smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees



a  borgida and  p  f patelschneider 1994 a semantics and complete algorithm for subsumption in the classic description logic volume 1 pages 277308

this paper analyzes the correctness of the subsumption algorithm used in classic a description logicbased knowledge representation system that is being used in practical applications  in order to deal efficiently with individuals in classic descriptions the developers have had to use an algorithm that is incomplete with respect to the standard modeltheoretic semantics for description logics we provide a variant semantics for descriptions with respect to which the current implementation is complete and which can be independently motivated  the soundness and completeness of the polynomialtime subsumption algorithm is established using description graphs which are an abstracted version of the implementation structures used in classic and are of independent interest



r  sebastiani 1994 applying gsatto nonclausal formulas volume 1 pages 309314

in this paper we describe how to modify gsat so that it can be applied to nonclausal formulas the idea is to use a particular score function which gives the number of clauses of the cnf conversion of a formula which are false under a given truth assignment  its value is computed in linear time without constructing the cnf conversion itself  the proposed methodology applies to most of the variants of gsat proposed so far
