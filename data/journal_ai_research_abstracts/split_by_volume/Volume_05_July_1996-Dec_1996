k  yip and  f  zhao 1996 spatial aggregation theory and applications volume 5 pages 126

visual thinking plays an important role in scientific    reasoning  based on the research in automating diverse reasoning    tasks about dynamical systems nonlinear controllers kinematic    mechanisms and fluid motion we have identified a style of visual    thinking imagistic reasoning  imagistic reasoning organizes    computations around imagelike analogue representations so that    perceptual and symbolic operations can be brought to bear to infer    structure and behavior  programs incorporating imagistic reasoning    have been shown to perform at an expert level in domains that defy    current analytic or numerical methods        we have developed a computational paradigm spatial aggregation to    unify the description of a class of imagistic problem solvers  a    program written in this paradigm has the following properties  it    takes a continuous field and optional objective functions as input    and produces highlevel descriptions of structure behavior or    control actions it computes a multilayer of intermediate    representations called spatial aggregates by forming equivalence    classes and adjacency relations  it employs a small set of generic    operators such as aggregation classification and localization to    perform bidirectional mapping between the informationrich field and    successively more abstract spatial aggregates it uses a data    structure the neighborhood graph as a common interface to modularize    computations  to illustrate our theory we describe the computational    structure of three implemented problem solvers  kam maps and    hipair  in terms of the spatial aggregation generic operators by    mixing and matching a library of commonly used routines



r  beneliyahu 1996 a hierarchy of tractable subsets for computing stable models volume 5 pages 2752

finding the stable models of a knowledge base is a    significant computational problem in artificial intelligence this    task is at the computational heart of truth maintenance systems    autoepistemic logic and default logic  unfortunately it is nphard    in this paper we present a hierarchy of classes of knowledge bases    omega1omega2 with the following properties first omega1 is    the class of all stratified knowledge bases second if a knowledge    base pi is in omegak then pi has at most k stable models and all of    them may be found in time olnk where l is the length of the    knowledge base and n the number of atoms in pi third for an    arbitrary knowledge base pi we can find the minimum k such that pi    belongs to omegak in time polynomial in the size of pi and last    where k is the class of all knowledge bases it is the case that    unioni1 to infty omegai  k that is every knowledge base    belongs to some class in the hierarchy



d  j litman 1996 cue phrase classification using machine learning volume 5 pages 5394

cue phrases may be used in a discourse sense to explicitly    signal discourse structure but also in a sentential sense to convey    semantic rather than structural information  correctly classifying    cue phrases as discourse or sentential is critical in natural language    processing systems that exploit discourse structure eg for    performing tasks such as anaphora resolution and plan recognition    this paper explores the use of machine learning for classifying cue    phrases as discourse or sentential  two machine learning programs    cgrendel and c45 are used to induce classification models from sets    of preclassified cue phrases and their features in text and speech    machine learning is shown to be an effective technique for not only    automating the generation of classification models but also for    improving upon previous results  when compared to manually derived    classification models already in the literature the learned models    often perform with higher accuracy and contain new linguistic insights    into the data  in addition the ability to automatically construct    classification models makes it easier to comparatively analyze the    utility of alternative feature representations of the data  finally    the ease of retraining makes the learning approach more scalable and    flexible than manual methods



a  gerevini and  l  schubert 1996 accelerating partialorder planners some techniques for effective search control and pruning volume 5 pages 95137

we propose some domainindependent techniques for bringing wellfounded partialorder planners closer to practicality the first two techniques are aimed at improving search control while keeping overhead costs low  one is based on a simple adjustment to the default a heuristic used by ucpop to select plans for refinement the other is based on preferring zero commitment forced plan refinements whenever possible and using lifo prioritization otherwise a more radical technique is the use of operator parameter domains to prune search these domains are initially computed from the definitions of the operators and the initial and goal conditions using a polynomialtime algorithm that propagates sets of constants through the operator graph starting in the initial conditions during planning parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats  in experiments based on modifications of ucpop our improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version crucially the hardest problems gave the greatest improvements the pruning technique based on parameter domains often gave speedups by an order of magnitude or more for difficult problems both with the default ucpop search strategy and with our improved strategy the lisp code for our techniques and for the test problems is provided in online appendices



j  r quinlan 1996 learning firstorder definitions of functions volume 5 pages 139161

firstorder learning involves finding a clauseform    definition of a relation from examples of the relation and relevant    background information  in this paper a particular firstorder    learning system is modified to customize it for finding definitions of    functional relations  this restriction leads to faster learning times    and in some cases to definitions that have higher predictive    accuracy  other firstorder learning systems might benefit from    similar specialization



g  zlotkin and  j  s rosenschein 1996 mechanisms for automated negotiation in state oriented domains volume 5 pages 163238

this paper lays part of the groundwork for a domain theory of    negotiation that is a way of classifying interactions so that it is    clear given a domain which negotiation mechanisms and strategies are    appropriate  we define state oriented domains a general category of    interaction  necessary and sufficient conditions for cooperation are    outlined  we use the notion of worth in an altered definition of    utility thus enabling agreements in a wider class of jointgoal    reachable situations an approach is offered for conflict resolution    and it is shown that even in a conflict situation partial cooperative    steps can be taken by interacting agents that is agents in    fundamental conflict might still agree to cooperate up to a certain    point     a unified negotiation protocol unp is developed that can be used in    all types of encounters it is shown that in certain borderline    cooperative situations a partial cooperative agreement ie one    that does not achieve all agents goals might be preferred by all    agents even though there exists a rational agreement that would    achieve all their goals     finally we analyze cases where agents have incomplete information on    the goals and worth of other agents first we consider the case where    agents goals are private information and we analyze what goal    declaration strategies the agents might adopt to increase their    utility  then we consider the situation where the agents goals and    therefore standalone costs are common knowledge but the worth they    attach to their goals is private information  we introduce two    mechanisms one strict the other tolerant and analyze their    affects on the stability and efficiency of negotiation outcomes



r  a helzerman and  m  p harper 1996 muse csp an extension to the constraint satisfaction problem volume 5 pages 239288

this paper describes an extension to the constraint    satisfaction problem csp called muse csp multiply segmented    constraint satisfaction problem  this extension is especially useful    for those problems which segment into multiple sets of partially    shared variables  such problems arise naturally in signal processing    applications including computer vision speech processing and    handwriting recognition  for these applications it is often    difficult to segment the data in only one way given the lowlevel    information utilized by the segmentation algorithms  muse csp can be    used to compactly represent several similar instances of the    constraint satisfaction problem  if multiple instances of a csp have    some common variables which have the same domains and constraints    then they can be combined into a single instance of a muse csp    reducing the work required to apply the constraints  we introduce the    concepts of muse node consistency muse arc consistency and muse path    consistency we then demonstrate how muse csp can be used to compactly    represent lexically ambiguous sentences and the multiple sentence    hypotheses that are often generated by speech recognition algorithms    so that grammar constraints can be used to provide parses for all    syntactically correct sentences  algorithms for muse arc and path    consistency are provided  finally we discuss how to create a muse    csp from a set of csps which are labeled to indicate when the same    variable is shared by more than a single csp



l  m de campos 1996 characterizations of decomposable dependency models volume 5 pages 289300

decomposable dependency models possess a number of    interesting and useful properties this paper presents new    characterizations of decomposable models in terms of independence    relationships which are obtained by adding a single axiom to the    wellknown set characterizing dependency models that are isomorphic to    undirected graphs we also briefly discuss a potential application of    our results to the problem of learning graphical models from data



n  l zhang and  d  poole 1996 exploiting causal independence in bayesian network inference volume 5 pages 301328

a new method is proposed for exploiting causal    independencies in exact bayesian network inference  a bayesian    network can be viewed as representing a factorization of a joint    probability into the multiplication of a set of conditional    probabilities  we present a notion of causal independence that    enables one to further factorize the conditional probabilities into a    combination of even smaller factors and consequently obtain a    finergrain factorization of the joint probability  the new    formulation of causal independence lets us specify the conditional    probability of a variable given its parents in terms of an associative    and commutative operator such as or sum or max on the    contribution of each parent  we start with a simple algorithm ve for    bayesian network inference that given evidence and a query variable    uses the factorization to find the posterior distribution of the    query we show how this algorithm can be extended to exploit causal    independence empirical studies based on the cpcs networks for    medical diagnosis show that this method is more efficient than    previous methods and allows for inference in larger networks than    previous algorithms



j  c schlimmer and  p  c wells 1996 quantitative results comparing three intelligent interfaces forinformation capture a case study adding name information into a volume 5 pages 329349

efficiently entering information into a computer is key to    enjoying the benefits of computing this paper describes three    intelligent user interfaces handwriting recognition adaptive menus    and predictive fillin in the context of adding a personus name and    address to an electronic organizer tests show handwriting recognition    is slower than typing on an onscreen soft keyboard while adaptive    menus and predictive fillin can be twice as fast this paper also    presents strategies for applying these three interfaces to other    information collection domains
