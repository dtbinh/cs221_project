franz  baader meghyn  bienvenu carsten  lutz and frank  wolter 2016 query and predicate emptiness in ontologybased data access volume 56 pages 159

in ontologybased data access obda database querying is enriched with an ontology that provides domain knowledge and additional vocabulary for query formulation we identify query emptiness and predicate emptiness as two central reasoning services in this context query emptiness asks whether a given query has an empty answer over all databases formulated in a given vocabulary predicate emptiness is defined analogously but quantifies universally over all queries that contain a given predicate in this paper we determine the computational complexity of query emptiness and predicate emptiness in the el dllite and alcfamilies of description logics investigate the connection to ontology modules and perform a practical case study to evaluate the new reasoning services



nasrin  taghizadeh and hesham  faili 2016 automatic wordnet development for lowresource languages using crosslingual wsd volume 56 pages 6187

8206wordnets are an effective resource for natural language processing and information retrieval8206 8206especially for semantic processing and meaning related tasks8206 8206so far8206 8206wordnets have been constructed for many languages8206 8206however8206 8206the automatic development of wordnets for lowresource languages has not been well studied8206 8206in this paper8206 8206an expectationmaximization algorithm is used to create high quality and large scale wordnets for poorresource languages8206 8206the proposed method benefits from possessing crosslingual word sense disambiguation and develops a wordnet by only using a bilingual dictionary and a monolingual corpus8206 8206the proposed method has been executed with persian language and the resulting wordnet has been evaluated through several experiments8206 8206the results show that the induced wordnet has a precision score of 90 and a recall score of 358206



daniel  damir harabor alban  grastien dindar  214z and vural  aksakalli 2016 optimal anyangle pathfinding in practice volume 56 pages 89118

anyangle pathfinding is a fundamental problem in robotics and computer games the goal is to find a shortest path between a pair of points on a grid map such that the path is not artificially constrained to the points of the grid prior research has focused on approximate online solutions a number of exact methods exist but they all require superlinear space and preprocessing time  in this study we describe anya a new and optimal anyangle pathfinding algorithm where other works find approximate anyangle paths by searching over individual points from the grid anya finds optimal paths by searching over sets of states represented as intervals each interval is identified onthefly from each interval anya selects a single representative point that it uses to compute an admissible cost estimate for the entire set  anya always returns an optimal path if one exists  moreover it does so without any offline preprocessing or the introduction of additional memory overheads  in a range of empirical comparisons we show that anya is competitive with several recent suboptimal online and preprocessing based techniques and is up to an order of magnitude faster than the most common benchmark algorithm a gridbased implementation of a




javad  azimi xiaoli  fern and alan  fern 2016 budgeted optimization with constrained experiments volume 56 pages 119152

motivated by a realworld problem we study a novel budgeted optimization problem where the goal is to optimize an unknown function f given a budget by requesting a sequence of samples from the function in our setting however evaluating the function at precisely specified points is not practically possible due to prohibitive costs instead we can only request constrained experiments a constrained experiment denoted by q specifies a subset of the input space for the experimenter to sample the function from the outcome of q includes a sampled experiment x and its function output fx importantly as the constraints of q become looser the cost of fulfilling the request decreases but the uncertainty about the location x increases our goal is to manage this tradeoff by selecting a set of constrained experiments that best optimize f within the budget  we study this problem in two different settings the nonsequential or batch setting where a set of constrained experiments is selected at once and the sequential setting where experiments are selected one at a time we evaluate our proposed methods for both settings using synthetic and real functions the experimental results demonstrate the efficacy of the proposed methods



kenji  kawaguchi yu  maruyama and xiaoyu  zheng 2016 global continuous optimization with error bound and fast convergence volume 56 pages 153195

this paper considers global optimization with a blackbox unknown objective function that can be nonconvex and nondifferentiable such a difficult optimization problem arises in many realworld applications such as parameter tuning in machine learning engineering design problem and planning with a complex physics simulator this paper proposes a new global optimization algorithm called locally oriented global optimization logo to aim for both fast convergence in practice and finitetime error bound in theory the advantage and usage of the new algorithm are illustrated via theoretical analysis and an experiment conducted with 11 benchmark test functions further we modify the logo algorithm to specifically solve a planning problem via policy search with continuous stateaction space and long time horizon while maintaining its finitetime error bound we apply the proposed planning method to accident management of a nuclear power plant the result of the application study demonstrates the practical utility of our method



diana  grooters and henry  prakken 2016 two aspects of relevance in structured argumentation minimality and paraconsistency volume 56 pages 197245

this paper studies two issues concerning relevance in structured argumentation in the context of the aspic framework arising from the combined use of strict and defeasible inference rules one issue arises if the strict inference rules correspond to classical logic  a longstanding problem is how the trivialising effect of the classical ex falso principle can be avoided while satisfying consistency and closure postulates in this paper this problem is solved by disallowing chaining of strict rules resulting in a variant of the aspic framework called aspic and then disallowing the application of strict rules to inconsistent sets of formulas thus in effect rescher  manors paraconsistent notion of weak consequence is embedded in aspic
finally the combined results of this paper are shown to be a proper extension of classicallogic argumentation with preferences and defeasible rules



zenglin  xu  shandian  zhe yuan  qi and peng  yu 2016 association discovery and diagnosis of alzheimers disease with bayesian multiview learning volume 56 pages 247268

the analysis and diagnosis of alzheimers disease ad can be based on genetic variations eg single nucleotide polymorphisms snps and phenotypic traits eg magnetic resonance imaging mri features we consider two important and related tasks i to select genetic and phenotypical markers for ad diagnosis and ii to identify associations between genetic and phenotypical data while previous studies treat these two tasks separately they are tightly coupled because underlying associations between genetic variations and phenotypical features contain the biological basis for a disease here we present a new sparse bayesian approach for joint association study and disease diagnosis in this approach common latent features are extracted from different data sources based on sparse projection matrices and used to predict multiple disease severity levels in return the disease status can guide the discovery of relationships between data sources the sparse projection matrices not only reveal interactions between data sources but also select groups of biomarkers related to the disease moreover to take advantage of the linkage disequilibrium ld measuring the nonrandom association of alleles we incorporate a graph laplacian type of prior in the model to learn the model from data we develop an efficient variational inference algorithm analysis on an imaging genetics dataset for the study of alzheimers disease ad indicates that our model identifies biologically meaningful associations between genetic variations and mri features and achieves significantly higher accuracy for predicting ordinal ad stages than the competing methods



maximilian  fickert joerg  hoffmann and marcel  steinmetz 2016 combining the delete relaxation with criticalpath heuristics a direct characterization volume 56 pages 269327

recent work has shown how to improve delete relaxation heuristics by computing relaxed plans ie the hff heuristic in a compiled planning task pic which represents a given set c of fact conjunctions explicitly while this compilation view of such partial delete relaxation is simple and elegant its meaning with respect to the original planning task is opaque and the size of pic grows exponentially in c we herein provide a direct characterization without compilation making explicit how the approach arises from a combination of the deleterelaxation with criticalpath heuristics designing equations characterizing a novel view on h on the one hand and a generalized version hc of hm on the other hand we show that hpic can be characterized in terms of a combined hcplus equation this naturally generalizes the standard deleterelaxation framework understanding that framework as a relaxation over singleton facts as atomic subgoals one can refine the relaxation by using the conjunctions c as atomic subgoals instead thanks to this explicit view we identify the precise source of complexity in hffpic namely maximization of sets of supported atomic subgoals during relaxed plan extraction which is easy for singletonfact subgoals but is npcomplete in the general case approximating that problem greedily we obtain a polynomialtime hcff version of hffpic superseding the pic compilation and superseding the modified picce compilation which achieves the same complexity reduction but at an information loss experiments on ipc benchmarks show that these theoretical advantages can translate into empirical ones



zhiqiang  zhuang zhe  wang kewen  wang and guilin  qi 2016 dllite contraction and revision volume 56 pages 329378

two essential tasks in managing description logic knowledge bases are eliminating problematic axioms and incorporating newly formed ones such elimination and incorporation are formalised as the operations of contraction and revision in belief change in this paper we deal with contraction and revision for the dllite family through a modeltheoretic approach standard description logic semantics yields an infinite number of models for dllite knowledge bases thus it is difficult to develop algorithms for contraction and revision that involve dl models  the key to our approach is the introduction of an alternative semantics called type semantics which can replace the standard semantics in characterising the standard inference tasks of dllite type semantics has several advantages over the standard one it is more succinct and importantly with a finite signature the semantics always yields a finite number of models we then define modelbased contraction and revision functions for dllite knowledge bases under type semantics and provide representation theorems for them finally the finiteness and succinctness of type semantics allow us to develop tractable algorithms for instantiating the functions



petr  savick253 and petr  ku269era 2016 generating models of a matched formula with a polynomial delay volume 56 pages 379402

a matched formula is a cnf formula whose incidence graph admits a matching which matches a distinct variable to every clause such a formula is always satisfiable matched formulas are used for example in the area of parametrized complexity we prove that the problem of counting the number of the models satisfying assignments of a matched formula is pcomplete on the other hand we define a class of formulas generalizing the matched formulas and prove that for a formula in this class one can choose in polynomial time a variable suitable for splitting the tree for the search of the models of the formula as a consequence the models of a formula from this class in particular of any matched formula can be generated sequentially with a delay polynomial in the size of the input on the other hand we prove that this task cannot be performed efficiently for linearly satisfiable formulas which is a generalization of matched formulas containing the class considered above 




xiaowang  zhang jan  van den bussche and fran231ois  picalausa 2016 on the satisfiability problem for sparql patterns volume 56 pages 403428

the satisfiability problem for sparql 10 patterns is undecidable in general since the relational algebra can be emulated using such patterns the goal of this paper is to delineate the boundary of decidability of satisfiability in terms of the constraints allowed in filter conditions the classes of constraints considered are boundconstraints negated bound constraints equalities nonequalities constantequalities and constantnonequalities the main result of the paper can be summarized by saying that as soon as inconsistent filter conditions can be formed satisfiability is undecidable the key insight in each case is to find a way to emulate the set difference operation undecidability can then be obtained from a known undecidability result for the algebra of binary relations with union composition and set difference when no inconsistent filter conditions can be formed satisfiability is decidable by syntactic checks on bound variables and on the use of literals although the problem is shown to be npcomplete it is experimentally shown that the checks can be implemented efficiently in practice the paper also points out that satisfiability for the socalled lsquowelldesignedrsquo  patterns can be decided by a check on bound variables and a check for inconsistent filter conditions



xujin  chen xiaodong  hu tieyan  liu weidong  ma tao  qin pingzhong  tang changjun  wang and bo  zheng 2016 efficient mechanism design for online scheduling volume 56 pages 429461

this paper concerns the mechanism design for online scheduling in a strategic setting in this setting each job is owned by a selfinterested agent who may misreport the release time deadline length and value of her job while we need to determine not only the schedule of the jobs but also the payment of each agent we focus on the design of incentive compatible ic mechanisms and study the maximization of social welfare ie the aggregated value of completed jobs by competitive analysis we first derive two lower bounds on the competitive ratio of any deterministic ic mechanism to characterize the landscape of our research we then propose a deterministic ic mechanism and show that such a simple mechanism works very well for both the preemptionrestart model and the preemptionresume model we show the mechanism can achieve the optimal competitive ratio of 5 for equallength jobs and a near optimal competitive ratio within a constant factor for unequallength jobs




thomas  eiter michael  fink and daria  stepanova 2016 computing repairs of inconsistent dlprograms over el ontologies volume 56 pages 463515

description logic dl ontologies and nonmonotonic rules are two prominent knowledge representation kr formalisms with complementary features that are essential for various applications nonmonotonic description logic dl programs combine these formalisms thus providing support for rulebased reasoning on top of dl ontologies using a welldefined query interface represented by socalled dlatoms unfortunately interaction of the rules and the ontology may incur inconsistencies such that a dlprogram lacks answer sets ie models and thus yields no information this issue is addressed by recently defined repair answer sets for computing which an effective practical algorithm was proposed for dllite a ontologies that reduces a repair computation to constraint matching based on socalled support sets however the algorithm exploits particular features of dllite a and can not be readily applied to repairing dlprograms over other prominent dls like el compared to dllite a  in el support sets may neither be small nor only few support sets might exist and completeness of the algorithm may need to be given up when the support information is bounded we thus provide an approach for computing repairs for dlprograms over el ontologies based on partial incomplete support families the latter are constructed using datalog query rewriting techniques as well as ontology approximation based on logical difference between elterminologies we show how the maximal size and number of support sets for a given dlatom can be estimated by analyzing the properties of a support hypergraph which characterizes a relevant set of tbox axioms needed for query derivation we present a declarative implementation of the repair approach and experimentally evaluate it on a set of benchmark problems the promising results witness practical feasibility of our repair approach 



matteo  venanzi john  guiver pushmeet  kohli and nicholas  r jennings 2016 timesensitive bayesian information aggregation for crowdsourcing systems volume 56 pages 517545

many aspects of the design of efficient crowdsourcing processes such as defining workers bonuses fair prices and time limits of the tasks involve knowledge of the likely duration of the task at hand in this work we introduce a new timesensitive bayesian aggregation method that simultaneously estimates a tasks duration and obtains reliable aggregations of crowdsourced judgments our method called bcctime uses latent variables to represent the uncertainty about the workers completion time the tasks duration and the workers accuracy to relate the quality of a judgment to the time a worker spends on a task our model assumes that each task is completed within a latent time window within which all workers with a propensity to genuinely attempt the labelling task ie no spammers are expected to submit their judgments in contrast workers with a lower propensity to valid labelling such as spammers bots or lazy labellers are assumed to perform tasks considerably faster or slower than the time required by normal workers specifically we use efficient messagepassing bayesian inference to learn approximate posterior probabilities of i the confusion matrix of each worker ii the propensity to valid labelling of each worker iii the unbiased duration of each task and iv the true label of each task using two real world public datasets for entity linking tasks we show that bcctime produces up to 11 more accurate classifications and up to 100 more informative estimates of a tasks duration compared to stateoftheart methods



carlos  hern225ndez jorge  a baier and roberto  as237n 2016 timebounded bestfirst search for reversible and nonreversible search graphs volume 56 pages 547571

timebounded a is a realtime singleagent deterministic search algorithm that expands states of a graph in the same order as a does but that unlike a interleaves search and action execution  known to outperform stateoftheart realtime search algorithms based on korfs learning realtime a lrta in some benchmarks it has not been studied in detail and is sometimes not considered as a true realtime search algorithm since it fails in nonreversible problems even it the goal is still reachable from the current state  in this paper we propose and study timebounded bestfirst search tbbfs a straightforward generalization of the timebounded approach to any bestfirst search algorithm furthermore we propose restarting timebounded weighted a tbrwa an algorithm that deals more adequately with nonreversible search graphs eliminating  backtracking moves and incorporating search restarts and heuristic learning in nonreversible problems we prove that tbbfs terminates and we deduce cost bounds for the solutions returned by timebounded weighted a tbwa an instance of tbbfs furthermore we prove tbrwa under reasonable conditions terminates  we evaluate tbwa in both grid pathfinding and the 15puzzle in addition we evaluate tbrwa on the racetrack problem we compare our algorithms to lsslrtwa a variant of lrta that can exploit lookahead search and a weighted heuristic a general observation is that the performance of both tbwa and tbrwa improves as the weight parameter is increased in addition our timebounded algorithms almost always outperform lsslrtwa by a significant margin




haris  aziz casey  cahan charles  gretton philip  kilby nicholas  mattei and toby  walsh 2016 a study of proxies for shapley allocations of transport costs volume 56 pages 573611

we survey existing rules of thumb propose novel methods  and comprehensively evaluate a number of solutions to the problem of calculating the cost to serve each location in a singlevehicle transport setting cost to serve analysis has applications both strategically and operationally in transportation settings the problem is formally modeled as the traveling salesperson game tsg a cooperative transferable utility game in which agents correspond to locations in a traveling salesperson problem tsp the total cost to serve all locations in the tsp is the length of an optimal tour an allocation divides the total cost among individual locations thus providing the cost to serve each of them as one of the most important normative division schemes in cooperative games the shapley value gives a principled and fair allocation for a broad variety of games including the tsg we consider a number of direct and samplingbased procedures for calculating the shapley value and  prove that approximating the shapley value of the tsg within a constant factor is nphard treating the shapley value as an ideal baseline allocation we survey six proxies for it that are each relatively easy to compute some of these proxies are rules of thumb and some are procedures international delivery companies used as cost allocation methods we perform an experimental evaluation using synthetic euclidean games as well as games derived from realworld tours calculated for scenarios involving fastmoving goods where deliveries are made on a road network every day we explore several computationally tractable allocation techniques that are good proxies for the shapley value in problem instances of a size and complexity that is commercially relevant



cristhian  ariel d deagustini maria vanina  martinez marcelo  a falappa and guillermo  r simari 2016 datalog ontology consolidation volume 56 pages 613656

knowledge bases in the form of ontologies are receiving increasing attention as they allow to clearly represent both the available knowledge which includes the knowledge in itself and the constraints imposed to it by the domain or the users in particular datalog177 ontologies are attractive because of their property of decidability and the possibility of dealing with the massive amounts of data in real world environments however as it is the case with many other ontological languages their application in collaborative environments often lead to inconsistency related issues in this paper we introduce the notion of incoherence regarding datalog177 ontologies in terms of satisfiability of sets of constraints and show how under specific conditions incoherence leads to inconsistent datalog177 ontologies the main contribution of this work is a novel approach to restore both consistency and coherence in datalog177 ontologies the proposed approach is based on kernel contraction and restoration is performed by the application of incision functions that select formulas to delete nevertheless instead of working  over minimal incoherentinconsistent sets encountered in the ontologies our operators produce incisions over nonminimal structures called clusters we present a construction for consolidation operators along with the properties expected to be satisfied by them finally we establish the relation between the construction and the properties by means of a representation theorem although this proposal is presented for datalog177 ontologies consolidation these operators can be applied to other types of ontological languages such as description logics making  them apt to be used in collaborative environments like the semantic web



isabel  cenamor tom225s  de la rosa and fernando  fern225ndez 2016 the ibacop planning system instancebased configured portfolios volume 56 pages 657691

sequential planning portfolios are very powerful in exploiting the complementary strength of different automated planners the main challenge of a portfolio planner is to define which base planners to run to assign the running time for each planner and to decide in what order they should be carried out to optimize a planning metric portfolio configurations are usually derived empirically from training benchmarks and remain fixed for an evaluation phase in this work we create a perinstance configurable portfolio which is able to adapt itself to every planning task the proposed system preselects a group of candidate planners using a paretodominance filtering approach and then it decides which planners to include and the time assigned according to predictive models these models estimate whether a base planner will be able to solve the given problem and if so how long it will take we define different portfolio strategies to combine the knowledge generated by the models the experimental evaluation shows that the resulting portfolios provide an improvement when compared with noninformed strategies one of the proposed portfolios was the winner of the sequential satisficing track of the international planning competition held in 2014



heshan  du and natasha  alechina 2016 qualitative spatial logics for buffered geometries volume 56 pages 693745

this paper describes a series of new qualitative spatial logics for checking consistency of sameas and partof matches between spatial objects from different geospatial datasets especially from crowdsourced datasets since geometries in crowdsourced data are usually not very accurate or precise we buffer geometries by a margin of error or a level of tolerance and define spatial relations for buffered geometries the spatial logics formalize the notions of buffered equal intuitively corresponding to possibly sameas buffered part of possibly partof near possibly connected and far definitely disconnected a sound and complete axiomatisation of each logic is provided with respect to models based on metric spaces for each of the logics the satisfiability problem is shown to be npcomplete finally we briefly describe how the logics are used in a system for generating and debugging matches between spatial objects and report positive experimental evaluation results for the system
