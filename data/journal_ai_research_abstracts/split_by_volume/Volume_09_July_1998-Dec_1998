m  l littman  j  goldsmith and   mundhenk m 1998 the computational complexity of probabilistic planning volume 9 pages 136




honorable mention for the 2003 ijcaijair best paper prize

we examine the computational complexity of testing and    finding small plans in probabilistic planning domains with both flat    and propositional representations  the complexity of plan evaluation    and existence varies with the plan type sought we examine totally    ordered plans acyclic plans and looping plans and partially ordered    plans under three natural definitions of plan value  we show that    problems of interest are complete for a variety of complexity classes    pl p np conp pp nppp conppp and pspace  in the process of    proving that certain planning problems are complete for nppp we    introduce a new basic npppcomplete problem emajsat which    generalizes the standard boolean satisfiability problem to    computations involving probabilistic quantities our results suggest    that the development of good heuristics for emajsat could be    important for the creation of efficient algorithms for a wide variety    of problems



o  ledeniov and  s  markovitch 1998 the divideandconquer subgoalordering algorithm for speeding up logic inference volume 9 pages 3797

it is common to view programs as a combination of logic and    control the logic part defines what the program must do the control    part  how to do it  the logic programming paradigm was developed    with the intention of separating the logic from the control    recently extensive research has been conducted on automatic    generation of control for logic programs  only a few of these works    considered the issue of automatic generation of control for improving    the efficiency of logic programs  in this paper we present a novel    algorithm for automatic finding of lowestcost subgoal orderings  the    algorithm works using the divideandconquer strategy  the given set    of subgoals is partitioned into smaller sets based on cooccurrence    of free variables the subsets are ordered recursively and merged    yielding a provably optimal order  we experimentally demonstrate the    utility of the algorithm by testing it in several domains and discuss    the possibilities of its cooperation with other existing methods



c  backstrom 1998 computational aspects of reordering plans volume 9 pages 99137

this article studies the problem of modifying the action    ordering of a plan in order to optimise the plan according to various    criteria  one of these criteria is to make a plan less constrained    and the other is to minimize its parallel execution time  three    candidate definitions are proposed for the first of these criteria    constituting a sequence of increasing optimality guarantees  two of    these are based on deordering plans which means that ordering    relations may only be removed not added while the third one uses    reordering where arbitrary modifications to the ordering are allowed    it is shown that only the weakest one of the three criteria is    tractable to achieve the other two being nphard and even difficult    to approximate  similarly optimising the parallel execution time of    a plan is studied both for deordering and reordering of plans  in the    general case both of these computations are nphard  however it is    shown that optimal deorderings can be computed in polynomial time for    a class of planning languages based on the notions of producers    consumers and threats which includes most of the commonly used    planning languages  computing optimal reorderings can potentially    lead to even faster parallel executions but this problem remains    nphard and difficult to approximate even under quite severe restrictions



d  j cook and  r  c varnell 1998 adaptive parallel iterative deepening search volume 9 pages 139165

many of the artificial intelligence techniques developed to    date rely on heuristic search through large spaces  unfortunately    the size of these spaces and the corresponding computational effort    reduce the applicability of otherwise novel and effective algorithms    a number of parallel and distributed approaches to search have    considerably improved the performance of the search process        our goal is to develop an architecture that automatically selects    parallel search strategies for optimal performance on a variety of    search problems  in this paper we describe one such architecture    realized in the eureka system which combines the benefits of    many different approaches to parallel heuristic search  through    empirical and theoretical analyses we observe that features of the    problem space directly affect the choice of optimal parallel search    strategy  we then employ machine learning techniques to select the    optimal parallel search strategy for a given problem space  when a    new search task is input to the system eureka uses features    describing the search space and the chosen architecture to    automatically select the appropriate search strategy  eureka    has been tested on a mimd parallel processor a distributed network of    workstations and a single workstation using multithreading  results    generated from fifteen puzzle problems robot arm motion problems    artificial search spaces and planning problems indicate that     eureka outperforms any of the tested strategies used exclusively for    all problem instances and is able to greatly reduce the search time    for these applications



a  ruiz  p  e lopezdeteruel and  m  c garrido 1998 probabilistic inference from arbitrary uncertainty using mixtures of factorized generalized gaussians volume 9 pages 167217

this paper presents a general and efficient framework for    probabilistic inference and learning from arbitrary uncertain    information it exploits the calculation properties of finite mixture    models conjugate families and factorization both the joint    probability density of the variables and the likelihood function of    the objective or subjective observation are approximated by a    special mixture model in such a way that any desired conditional    distribution can be directly obtained without numerical    integration we have developed an extended version of the expectation    maximization em algorithm to estimate the parameters of mixture    models from uncertain training examples indirect observations as a    consequence any piece of exact or uncertain information about both    input and output values is consistently handled in the inference and    learning stages this ability extremely useful in certain situations    is not found in most alternative methods the proposed framework is    formally justified from standard probabilistic principles and    illustrative examples are provided in the fields of nonparametric    pattern classification nonlinear regression and pattern    completion finally experiments on a real application and comparative    results over standard databases provide empirical evidence of the    utility of the method in a wide range of applications



b  vandegriend and  j  culberson 1998 the gnm phase transition is not hard for the hamiltonian cycle problem volume 9 pages 219245

using an improved backtrack algorithm with sophisticated    pruning techniques we revise previous observations correlating a high    frequency of hard to solve hamiltonian cycle instances with the gnm    phase transition between hamiltonicity and nonhamiltonicity instead    all tested graphs of 100 to 1500 vertices are easily solved       when we artificially restrict the degree sequence with a bounded    maximum degree although there is some increase in difficulty the    frequency of hard graphs is still low  when we consider more regular    graphs based on a generalization of knights tours we observe    frequent instances of really hard graphs but on these the average    degree is bounded by a constant  we design a set of graphs with a    feature our algorithm is unable to detect and so are very hard for our    algorithm but in these we can vary the average degree from o1 to    on  we have so far found no class of graphs correlated with the    gnm phase transition which asymptotically produces a high frequency    of hard instances



j  m wiebe t  p ohara thorsten  ohrstromsandgren and k  j mckeever 1998 an empirical approach to temporal reference resolution volume 9 pages 247293

scheduling dialogs during which people negotiate the    times of appointments are common in everyday life  this paper    reports the results of an indepth empirical investigation of    resolving explicit temporal references in scheduling dialogs  there    are four phases of this work data annotation and evaluation model    development system implementation and evaluation and model    evaluation and analysis  the system and model were developed    primarily on one set of data and then applied later to a much more    complex data set to assess the generalizability of the model for the    task being performed  many different types of empirical methods are    applied to pinpoint the strengths and weaknesses of the approach    detailed annotation instructions were developed and an intercoder    reliability study was performed showing that naive annotators can    reliably perform the targeted annotations  a fully automatic system    has been developed and evaluated on unseen test data with good    results on both data sets  we adopt a pure realization of a    recencybased focus model to identify precisely when it is and is not    adequate for the task being addressed  in addition to system results    an indepth evaluation of the model itself is presented based on    detailed manual annotations  the results are that few errors occur    specifically due to the model of focus being used and the set of    anaphoric relations defined in the model are low in ambiguity for both    data sets



e  mazer  j  m ahuactzin and  p  bessiere 1998 the ariadnes clew algorithm volume 9 pages 295316

we present a new approach to path planning called the    ariadnes clew algorithm it is designed to find paths in    highdimensional continuous spaces and applies to robots with many    degrees of freedom in static as well as dynamic environments  ones    where obstacles may move the ariadnes clew algorithm comprises two    subalgorithms called search and explore applied in an interleaved    manner explore builds a representation of the accessible space while    search looks for the target both are posed as optimization problems    we describe a real implementation of the algorithm to plan paths for a    six degrees of freedom arm in a dynamic environment where another six    degrees of freedom arm is used as a moving obstacle experimental    results show that a path is found in about one second without any    preprocessing



g  di caro and  m  dorigo 1998 antnet distributed stigmergetic control for communications networks volume 9 pages 317365

this paper introduces antnet a novel approach to the    adaptive learning of routing tables in communications networks    antnet is a distributed mobile agents based monte carlo system that    was inspired by recent work on the ant colony metaphor for solving    optimization problems antnets agents concurrently explore the    network and exchange collected information  the communication among    the agents is indirect and asynchronous mediated by the network    itself this form of communication is typical of social insects and is    called stigmergy  we compare our algorithm with six stateoftheart    routing algorithms coming from the telecommunications and machine    learning fields  the algorithms performance is evaluated over a set    of realistic testbeds  we run many experiments over real and    artificial ip datagram networks with increasing number of nodes and    under several paradigmatic spatial and temporal traffic distributions    results are very encouraging  antnet showed superior performance    under all the experimental conditions with respect to its competitors    we analyze the main characteristics of the algorithm and try to    explain the reasons for its superiority



m  fox and  d  long 1998 the automatic inference of state invariants in tim volume 9 pages 367421

as planning is applied to larger and richer domains the    effort involved in constructing domain descriptions increases and    becomes a significant burden on the human application designer if    general planners are to be applied successfully to large and complex    domains it is necessary to provide the domain designer with some    assistance in building correctly encoded domains  one way of doing    this is to provide domainindependent techniques for extracting from    a domain description knowledge that is implicit in that description    and that can assist domain designers in debugging domain    descriptions this knowledge can also be exploited to improve the    performance of planners several researchers have explored the    potential of state invariants in speeding up the performance of    domainindependent planners in this paper we describe a process by    which state invariants can be extracted from the automatically    inferred type structure of a domain these techniques are being    developed for exploitation by stan a graphplan based planner that    employs state analysis techniques to enhance its performance



j  rintanen 1998 complexity of prioritized default logics volume 9 pages 423461

in default reasoning usually not all possible ways of    resolving conflicts between default rules are acceptable  criteria    expressing acceptable ways of resolving the conflicts may be hardwired    in the inference mechanism for example specificity in inheritance    reasoning can be handled this way or they may be given abstractly as    an ordering on the default rules  in this article we investigate    formalizations of the latter approach in reiters default logic  our    goal is to analyze and compare the computational properties of three    such formalizations in terms of their computational complexity the    prioritized default logics of baader and hollunder and brewka and a    prioritized default logic that is based on lexicographic comparison    the analysis locates the propositional variants of these logics on the    second and third levels of the polynomial hierarchy and identifies    the boundary between tractable and intractable inference for    restricted classes of prioritized default theories



a  artale and  e  franconi 1998 a temporal description logic for reasoning about actions and plans volume 9 pages 463506

a class of intervalbased temporal languages for uniformly    representing and reasoning about actions and plans is presented    actions are represented by describing what is true while the action    itself is occurring and plans are constructed by temporally relating    actions and world states  the temporal languages are members of the    family of description logics which are characterized by high    expressivity combined with good computational properties  the    subsumption problem for a class of temporal description logics is    investigated and sound and complete decision procedures are given the    basic language tlf is considered first it is the composition of a    temporal logic tl  able to express interval temporal networks     together with the nontemporal logic f  a feature description logic    it is proven that subsumption in this language is an npcomplete    problem then it is shown how to reason with the more expressive    languages tlufu and tlalcf the former adds disjunction both at the    temporal and nontemporal sides of the language the latter extends    the nontemporal side with setvalued features ie roles and a    propositionally complete language
