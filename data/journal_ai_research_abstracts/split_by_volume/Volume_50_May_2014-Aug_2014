m  zhang x  xiao d  xiong and q  liu 2014 topicbased dissimilarity and sensitivity models for translation rule selection volume 50 pages 130

translation rule selection is a task of selecting appropriate translation rules for an ambiguous sourcelanguage segment as translation ambiguities are pervasive in statistical machine translation we introduce two topicbased models for translation rule selection which incorporates global topic information into translation disambiguation we associate each synchronous translation rule with source and targetside topic distributionswith these topic distributions we propose a topic dissimilarity model to select desirable less dissimilar rules by imposing penalties for rules with a large value of dissimilarity of their topic distributions to those of given documents in order to encourage the use of nontopic specific translation rules we also present a topic sensitivity model to balance translation rule selection between generic rules and topicspecific rules furthermore we project targetside topic distributions onto the sourceside topic model space so that we can benefit from topic information of both the source and target language we integrate the proposed topic dissimilarity and sensitivity model into hierarchical phrasebased machine translation for synchronous translation rule selection experiments show that our topicbased translation rule selection model can substantially improve translation quality



y  wang y  zhang y  zhou and m  zhang 2014 knowledge forgetting in answer set programming volume 50 pages 3170

the ability of discarding or hiding irrelevant information has been
recognized as an important feature for knowledge based systems including answer set programming the notion of strong equivalence in answer set programming plays an important role for different problems as it gives rise to a substitution principle and amounts to knowledge equivalence of logic programs in this paper we uniformly propose a semantic knowledge forgetting  called ht and flpforgetting for logic programs under stable model and flpstable model semantics respectively our proposed knowledge forgetting discards exactly the knowledge of a logic program which is relevant to forgotten variables thus it preserves strong equivalence in the sense that strongly equivalent logic programs will remain strongly equivalent after forgetting the same variables we show that this semantic forgetting result is always expressible and we prove a representation theorem stating that the ht and flpforgetting can be precisely characterized by zhangzhous four forgetting postulates under the ht and flpmodel semantics respectively we also reveal underlying connections between the proposed forgetting and the forgetting of propositional logic and provide complexity results for decision problems in relation to the forgetting an application of the proposed forgetting is also considered in a conflict solving scenario



a  fern s  natarajan k  judah and p  tadepalli 2014 a decisiontheoretic model of assistance volume 50 pages 71104

there is a growing interest in intelligent assistants for a variety of applications from sorting email to helping people with disabilities to do their daily chores in this paper we formulate the problem of intelligent assistance in a decisiontheoretic framework and present both theoretical and empirical results we first introduce a class of pomdps called hiddengoal mdps hgmdps which formalizes the problem of interactively assisting an agent whose goal is hidden and whose actions are observable in spite of its restricted nature we show that optimal action selection for hgmdps is pspacecomplete even for deterministic dynamics we then introduce a more restricted model called helper action mdps hamdps which are sufficient for modeling many realworld problems we show classes of hamdps for which efficient algorithms are possible more interestingly for general hamdps we show that a simple myopic policy achieves a near optimal regret compared to an oracle assistant that knows the agents goal we then introduce more sophisticated versions of this policy for the general case of hgmdps that we combine with a novel approach for quickly learning about the agent being assisted we evaluate our approach in two gamelike computer environments where human subjects perform tasks and in a realworld domain of providing assistance during folder navigation in a computer desktop environment the results show that in all three domains the framework results in an assistant that substantially reduces user effort with only modest computation



b  de keijzer t  b klos and y  zhang 2014 finding optimal solutions for voting game design problems volume 50 pages 105140

in many circumstances where multiple agents need to make a joint decision voting is used to aggregate the agents preferences each agents vote carries a weight and if the sum of the weights of the  agents in favor of some outcome is larger than or equal to a given quota then this outcome is decided upon the distribution of weights leads to a certain distribution of power several power indices have been proposed to measure such power in the socalled inverse problem we are given a target distribution of power and are asked to come up with a game in the form of a quota plus an assignment of weights to the players whose power distribution is as close as possible to the target distribution according to some specied distance measure
we first present a doubly exponential algorithm for enumerating the set of simple games we then improve on this algorithm for the class of weighted voting games and obtain a quadratic exponential ie 2on2 algorithm for enumerating them we show that this improved algorithm runs in outputpolynomial time making it the fastest possible enumeration algorithm up to a polynomial factor finally we propose an exact anytimealgorithm that runs in exponential time for the power index weighted voting game design problem the inverse problem we implement this algorithm to find a weighted voting game with a normalized banzhaf power distribution closest to a target power index and perform experiments to obtain some insights about the set of weighted voting games we remark that our algorithm is applicable to optimizing any exponentialtime computable function the distance of the normalized banzhaf index to a target power index is merely taken as an example



m  goldenberg a  felner r  stern g  sharon n  sturtevant r  c holte and j  schaeffer 2014 enhanced partial expansion a volume 50 pages 141187

when solving instances of problem domains that feature a large branching factor a may generate a large number of nodes whose cost is greater than the cost of the optimal solution we designate such nodes as surplus generating surplus nodes and adding them to the open list may dominate both time and memory of the search a recently introduced variant of a called partial expansion a pea deals with the memory aspect of this problem when expanding a node n pea generates all of its children and puts into open only the children with f  f n n is reinserted in the open list with the f cost of the best discarded child this guarantees that surplus nodes are not inserted into open
in this paper we present a novel variant of a called enhanced partial expansion a epea that advances the idea of pea to address the time aspect given a priori domain and heuristic specific knowledge epea generates only the nodes with f  fn although epea is not always applicable or practical we study several variants of epea which make it applicable to a large number of domains and heuristics in particular the ideas of epea are applicable to ida and to the domains where pattern databases are traditionally used experimental studies show significant improvements in runtime and memory performance for several standard benchmark applications we provide several theoretical studies to facilitate an understanding of the new algorithm



j  de bock and g  de cooman 2014 an efficient algorithm for estimating state sequences in imprecise hidden markov models volume 50 pages 189233

we present an efficient exact algorithm for estimating state sequences from outputs or observations in imprecise hidden markov models ihmms the uncertainty linking one state to the next and that linking a state to its output is represented by a set of probability mass functions instead of a single such mass function we consider as best estimates for state sequences the maximal sequences for the posterior joint state model conditioned on the observed output sequence associated with a gain function that is the indicator of the state sequence this corresponds to and generalises finding the state sequence with the highest posterior probability in preciseprobabilistic hmms thereby making our algorithm a generalisation of the one by viterbi we argue that the computational complexity of our algorithm is at worst quadratic in the length of the ihmm cubic in the number of states and essentially linear in the number of maximal state sequences an important feature of our imprecise approach is that there may be more than one maximal sequence typically in those instances where its preciseprobabilistic counterpart is sensitive to the choice of prior for binary ihmms we investigate experimentally how the number of maximal state sequences depends on the model parameters we also present an application in optical character recognition demonstrating that our algorithm can be usefully applied to robustify the inferences made by its preciseprobabilistic counterpart



n  rivera l  illanes j  a baier and c  hernandez 2014 reconnection with the ideal tree a new approach to realtime search volume 50 pages 235264

many applications ranging from video games to dynamic robotics require solving singleagent deterministic search problems in partially known environments under very tight time constraints realtime heuristic search rths algorithms are specifically designed for those applications as a subroutine most of them invoke a standard but bounded search algorithm that searches for the goal in this paper we present frit a simple approach for singleagent deterministic search problems under tight constraints and partially known environments that unlike traditional rths does not search for the goal but rather searches for a path that connects the current state with a socalled ideal tree t  when the agent observes that an arc in the tree cannot be traversed in the actual environment it removes such an arc from t and then carries out a reconnection search whose objective is to find a path between the current state and any node in t  the reconnection search is done using an algorithm that is passed as a parameter to frit if such a parameter is an rths algorithm then the resulting algorithm can be an rths algorithm we show in addition that frit may be fed with a bounded complete blindsearch algorithm we evaluate our approach over grid pathfinding benchmarks including game maps and mazes our results show that frit used with rtaa a standard rths algorithm outperforms rtaa significantly by one order of magnitude under tight time constraints in addition fritdartaa substantially outperforms dartaa a stateoftheart rths algorithm usually obtaining solutions 50 cheaper on average when performing the same search effort finally fritbfs ie frit using breadthfirstsearch obtains bestquality solutions when time is limited compared to adaptive a and repeated a finally we show that bug2 a pathfindingspecific navigation algorithm outperforms fritbfs when planning time is extremely limited but when given more time the situation reverses



m  suda 2014 property directed reachability for automated planning volume 50 pages 265319

property directed reachability pdr is a very promising recent method for deciding reachability in symbolically represented transition systems while originally conceived as a model checking algorithm for hardware circuits it has already been successfully applied in several other areas this paper is the first investigation of pdr from the perspective of automated planning
similarly to the planning as satisfiability paradigm pdr draws its strength from internally employing an efficient satsolver we show that most standard encoding schemes of planning into sat can be directly used to turn pdr into a planning algorithm as a nonobvious alternative we propose to replace the satsolver inside pdr by a planningspecific procedure implementing the same interface this satsolver free variant is not only more efficient but offers additional insights and opportunities for further improvements an experimental comparison to the state of the art planners finds it highly competitive solving most problems on several domains



fm  delle fave ax  jiang z  yin c  zhang m  tambe s  kraus and j  p sullivan 2014 gametheoretic patrolling with dynamic execution uncertainty and a case study on a real transit system volume 50 pages 321367




aamas 2013 best paper award finalist

attackerdefender stackelberg security games ssgs have emerged as an important research area in multiagent systems however existing ssgs models yield fixed static schedules which fail in dynamic domains where defenders face execution uncertainty ie in domains where defenders may face unanticipated disruptions of their schedules a concrete example is an application involving checking fares on trains where a defenders schedule is frequently interrupted by fare evaders making static schedules useless
to address this shortcoming this paper provides four main contributions first we present a novel general bayesian stackelberg game model for security resource allocation in dynamic uncertain domains in this new model execution uncertainty is handled by using a markov decision process mdp for generating defender policies second we study the problem of computing a stackelberg equilibrium for this game and exploit problem structure to reduce it to a polynomialsized optimization problem shifting to evaluation our third contribution shows in simulation that our mdpbased policies overcome the failures of previous ssg algorithms in so doing we can now build a complete system that enables handling of schedule interruptions and consequently to conduct some of the first controlled experiments on ssgs in the field hence as our final contribution we present results from a realworld experiment on metro trains in los angeles validating our mdpbased model and most importantly concretely measuring the benefits of ssgs for security resource allocation



jr  doppa a  fern and p  tadepalli 2014 hcsearch a learning framework for searchbased structured prediction volume 50 pages 369407




aaai 2013 outstanding paper award

structured prediction is the problem of learning a function that maps structured inputs to structured outputs prototypical examples of structured prediction include partofspeech tagging and semantic segmentation of images inspired by the recent successes of searchbased structured prediction we introduce a new framework for structured prediction called hcsearch given a structured input the framework uses a search procedure guided by a learned heuristic h to uncover high quality candidate outputs and then employs a separate learned cost function c to select a final prediction among those outputs the overall loss of this prediction architecture decomposes into the loss due to h not leading to high quality outputs and the loss due to c not selecting the best among the generated outputs guided by this decomposition we minimize the overall loss in a greedy stagewise manner by first training h to quickly uncover high quality outputs via imitation learning and then training c to correctly rank the outputs generated via h according to their true losses importantly this training procedure is sensitive to the particular loss function of interest and the timebound allowed for predictions experiments on several benchmark domains show that our approach significantly outperforms several stateoftheart methods



r  bredereck j  chen s  hartung s  kratsch r  niedermeier o  suchy and g  j woeginger 2014 a multivariate complexity analysis of lobbying in multiple referenda volume 50 pages 409446

assume that each of n voters may or may not approve each of m issues if an agent the lobby may influence up to k voters then the central question of the nphard lobbying problem is whether the lobby can choose the voters to be influenced so that as a result each issue gets a majority of approvals this problem can be modeled as a simple matrix modification problem can one replace k rows of a binary n x mmatrix by k all1 rows such that each column in the resulting matrix has a majority of 1s significantly extending on previous work that showed parameterized intractability w2completeness with respect to the number k of modified rows we study how natural parameters such as n m k or the maximum number of 1s missing for any column to have a majority of 1s referred to as gap value g govern the computational complexity of lobbying among other results we prove that lobbying is fixedparameter tractable for parameter m and provide a greedy logarithmicfactor approximation algorithm which solves lobbying even optimally if m  5 we also show empirically that this greedy algorithm performs well on general instances as a further key result we prove that lobbying is logsnpcomplete for constant values g0 thus providing a first natural complete problem from voting for this complexity class of limited nondeterminism



m  cooper f  maris and p  r233gnier 2014 monotone temporal planning tractability extensions and applications volume 50 pages 447485

this paper describes a polynomiallysolvable class of temporal planning problems polynomiality follows from two assumptions firstly by supposing that each subgoal fluent can be established by at most one action we can quickly determine which actions are necessary in any plan secondly the monotonicity of subgoal fluents allows us to express planning as an instance of stp8800 simple temporal problem with difference constraints this class includes temporallyexpressive problems requiring the concurrent execution of actions with potential applications in the chemical pharmaceutical and construction industries 
we also show that any temporal planning problem has a monotone relaxation which can lead to the polynomialtime detection of its unsolvability in certain cases indeed we show that our relaxation is orthogonal to relaxations based on the ignoredeletes approach used in classical planning since it preserves deletes and can also exploit temporal information



e  keyder j  hoffmann and p  haslum 2014 improving delete relaxation heuristics through explicitly represented conjunctions volume 50 pages 487533




icaps 2012 best paper award

heuristic functions based on the delete relaxation compute upper and lower bounds on the optimal deleterelaxation heuristic h and are of paramount importance in both optimal and satisficing planning here we introduce a principled and flexible technique for improving h by augmenting deleterelaxed planning tasks with a limited amount of delete information this is done by introducing special fluents that explicitly represent conjunctions of fluents in the original planning task rendering h the perfect heuristic h in the limit previous work has introduced a method in which the growth of the task is potentially exponential in the number of conjunctions introduced we formulate an alternative technique relying on conditional effects limiting the growth of the task to be linear in this number we show that this method still renders h the perfect heuristic h in the limit we propose techniques to find an informative set of conjunctions to be introduced in different settings and analyze and extend existing methods for lowerbounding and upperbounding h in the presence of conditional effects we evaluate the resulting heuristic functions empirically on a set of ipc benchmarks and show that they are sometimes much more informative than standard deleterelaxation heuristics




d  terekhov t  t tran d  g down and jc  beck 2014 integrating queueing theory and scheduling for dynamic scheduling problems volume 50 pages 535572

dynamic scheduling problems consist of both challenging combinatorics as found in classical scheduling problems and stochastics due to uncertainty about the arrival times resource requirements and processing times of jobs to address these two challenges we investigate the integration of queueing theory and scheduling the former reasons about longrun stochastic system characteristics whereas the latter typically deals with shortterm combinatorics we investigate two simple problems to isolate the core differences and potential synergies between the two approaches a twomachine dynamic flowshop and a flexible queueing network we show for the first time that stability a fundamental characteristic in queueing theory can be applied to approaches that periodically solve combinatorial scheduling problems  we empirically demonstrate that for a dynamic flowshop the use of combinatorial reasoning has little impact on schedule quality beyond queueing approaches in contrast for the more complicated flexible queueing network a novel algorithm that combines longterm guidance from queueing theory with shortterm combinatorial decision making outperforms all other tested approaches to our knowledge this is the first time that such a hybrid of queueing theory and scheduling techniques has been proposed and evaluated 



a  rey and j  rothe 2014 falsename manipulation in weighted voting games is hard for probabilistic polynomial time volume 50 pages 573601

falsename manipulation refers to the question of whether a player in a weighted voting game can increase her power by splitting into several players and distributing her weight among these false identities  relatedly the beneficial merging problem asks whether a coalition of players can increase their power in a weighted voting game by merging their weights  for the problems of whether merging or splitting players in weighted voting games is beneficial in terms of the shapleyshubik and the normalized banzhaf index merely nphardness lower bounds are known leaving the question about their exact complexity open  for the shapleyshubik and the probabilistic banzhaf index we raise these lower bounds to hardness for pp probabilistic polynomial time a class considered to be by far a larger class than np  for both power indices we provide matching upper bounds for beneficial merging and whenever the new players weights are given also for beneficial splitting thus resolving previous conjectures in the affirmative  relatedly we consider the beneficial annexation problem asking whether a single player can increase her power by taking over other players weights  it is known that annexation is never disadvantageous for the shapleyshubik index and that beneficial annexation is nphard for the normalized banzhaf index  we show that annexation is never disadvantageous for the probabilistic banzhaf index either and for both the shapleyshubik index and the probabilistic banzhaf index we show that it is npcomplete to decide whether annexing another player is advantageous  moreover we propose a general framework for merging and splitting that can be applied to different classes and representations of games



d  d maua c  p de campos a  benavoli and a  antonucci 2014 probabilistic inference in credal networks new complexity results volume 50 pages 603637




uai 2013 best student paper

credal networks are graphbased statistical models whose parameters take values in a set instead of being sharply specified as in traditional statistical models eg bayesian networks the computational complexity of inferences on such models depends on the irrelevanceindependence concept adopted in this paper we study inferential complexity under the concepts of epistemic irrelevance and strong independence we show that inferences under strong independence are nphard even in trees with binary variables except for a single ternary one we prove that under epistemic irrelevance the polynomialtime complexity of inferences in credal trees is not likely to extend to more general models eg singly connected topologies these results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard and settle several open questions regarding their computational complexity we show that these results remain valid even if we disallow the use of zero probabilities we also show that the computation of bounds on the probability of the future state in a hidden markov model is the same whether we assume epistemic irrelevance or strong independence and we prove a similar result for inference in naive bayes structures these inferential equivalences are important for practitioners as hidden markov models and naive bayes structures are used in real applications of imprecise probability



a  gerevini a  saetti and m  vallati 2014 planning through automatic portfolio configuration the pbp approach volume 50 pages 639696

in the field of domainindependent planning several powerful planners implementing different techniques have been developed however no one of these systems outperforms all others in every known benchmark domain in this work we propose a multiplanner approach that automatically configures a portfolio of planning techniques for each given domain the configuration process for a given domain uses a set of training instances to i compute and analyze some alternative sets of macroactions for each planner in the portfolio identifying a possibly empty useful set ii select a cluster of planners each one with the identified useful set of macroactions that is expected to perform best and iii derive some additional information for configuring the execution scheduling of the selected planners at planning time the resulting planning system called pbp portfolio based planner has two variants focusing on speed and plan quality different versions of pbp entered and won the learning track of the sixth and seventh international planning competitions in this paper we experimentally analyze pbp considering planning speed and plan quality in depth we provide a collection of results that help to understand pbps behavior and demonstrate the effectiveness of our approach to configuring a portfolio of planners with macroactions



d  bergman a  a cire and w  van hoeve 2014 mdd propagation for sequence constraints volume 50 pages 697722

we study propagation for the sequence constraint in the context of constraint programming based on limitedwidth mdds our first contribution is proving that establishing mddconsistency for sequence is nphard yet we also show that this task is fixed parameter tractable with respect to the length of the subsequences in addition we propose a partial filtering algorithm that relies on a specific decomposition of the constraint and a novel extension of mdd filtering to node domains we experimentally evaluate the performance of our proposed filtering algorithm and demonstrate that the strength of the mdd propagation increases as the maximum width is increased in particular mdd propagation can outperform conventional domain propagation for sequence by reducing the search tree size and solving time by several orders of magnitude similar improvements are observed with respect to the current best mdd approach that applies the decomposition of sequence into among constraints



s  kiritchenko x  zhu and s  m mohammad 2014 sentiment analysis of short informal texts volume 50 pages 723762

we describe a stateoftheart sentiment analysis system that detects a the sentiment of short informal textual messages such as tweets and sms messagelevel task and b the sentiment of a word or a phrase within a message termlevel task  the system is based on a supervised statistical text classification approach leveraging a variety of surfaceform semantic and sentiment features  the sentiment features are primarily derived from novel highcoverage tweetspecific sentiment lexicons  these lexicons are automatically generated from tweets with sentimentword hashtags and from tweets with emoticons  to adequately capture the sentiment of words in negated contexts a separate sentiment lexicon is generated for negated words




a  m s barreto j  pineau and d  precup 2014 policy iteration based on stochastic factorization volume 50 pages 763803

when a transition probability matrix is represented as the product of two stochastic matrices one can swap the factors of the multiplication to obtain another transition matrix that retains some fundamental characteristics of the original since the derived matrix can be much smaller than its precursor this property can be exploited to create a compact version of a markov decision process mdp and hence to reduce the computational cost of dynamic programming building on this idea this paper presents  an approximate policy iteration algorithm called policy iteration based on stochastic factorization or pisf for short in terms of computational complexity pisf replaces standard policy iterations cubic dependence on the size of the mdp with a function that grows only linearly with the number of states in the model the proposed algorithm also enjoys nice theoretical properties it always terminates after a finite number of iterations and returns a decision policy whose performance only depends on the quality of the stochastic factorization in particular if the approximation error in the factorization is sufficiently small  pisf computes the optimal value function of the mdp the paper also discusses practical ways of factoring an mdp and illustrates the usefulness of the proposed algorithm with an application involving a largescale decision problem of real economical interest



u  thayasivam and p  doshi 2014 speeding up iterative ontology alignment using blockcoordinate descent volume 50 pages 805845

in domains such as  biomedicine ontologies are prominently utilized for annotating data   consequently aligning ontologies facilitates integrating  data   several   algorithms  exist  for  automatically aligning  ontologies   with  diverse  levels   of  performance   as alignment   applications  evolve   and  exhibit   online   run  time constraints performing the alignment in a reasonable amount of time without  compromising the  quality  of the  alignment  is a  crucial challenge  a  large class of alignment algorithms  is iterative and often consumes more time than others in delivering solutions of high quality we present a novel and general approach for speeding up the multivariable  optimization process  utilized  by these  algorithms specifically  we  use  the  technique of  blockcoordinate  descent bcd  which exploits  the subdimensions  of the  alignment problem identified using a partitioning  scheme  we integrate this approach into  multiple wellknown  alignment  algorithms and  show that  the enhanced  algorithms  generate  similar  or improved  alignments  in significantly  less  time on  a  comprehensive  testbed of  ontology pairs  because  bcd does not  overly constrain how we  partition or order the  parts we vary  the partitioning and ordering  schemes in order  to empirically  determine the  best schemes  for each  of the selected  algorithms  as biomedicine  represents a  key application domain  for  ontologies  we  introduce a  comprehensive  biomedical ontology testbed  for the community  in order to  evaluate alignment algorithms  because biomedical ontologies tend to be large default iterative  techniques find it  difficult to  produce a  good quality alignment within a reasonable amount of time we align a significant number  of  ontology  pairs  from this  testbed  using  bcdenhanced algorithms   our contributions represent  an important  step toward making a  significant class of  alignment techniques computationally feasible



y  zick e  markakis and e  elkind 2014 arbitration and stability in cooperative games with overlapping coalitions volume 50 pages 847884

overlapping coalition formation ocf games introduced by chalkiadakis elkind markakis polukarov and jennings in 2010 are cooperative games where players can simultaneously participate in several coalitions capturing the notion of stability in ocf games is a difficult taskdeviating players may continue to contribute resources to joint projects with nondeviators and the crucial question is what payoffs the deviators expect to receive from such projects chalkiadakis et al introduce three stability concepts for ocf gamesthe conservative core the refined core and the optimistic corethat are based on different answers to this question in this paper we propose a unified framework for the study of stability in the ocf setting which encompasses the stability concepts considered by chalkiadakis et al as well as a wide variety of alternative stability concepts  our approach is based on the notion of arbitration functions which determine the payoff obtained by the deviators given their deviation and the current allocation of resources we provide a characterization of stable outcomes under arbitration we then conduct an indepth study of four types of arbitration functions which correspond to four notions of the core these include the three notions of the core considered by chalkiadakis et al our results complement those of chalkiadakis et al and answer questions left open by their work in particular we show that ocf games with the conservative arbitration function are essentially equivalent to nonocf games by relating the conservative core of an ocf game to the core of a nonoverlapping cooperative game and use this result to obtain a strictly weaker sufficient condition for conservative core nonemptiness than the one given by chalkiadakis et al



a  veit y  xu r  zheng n  chakraborty and k  sycara 2014 demand side energy management via multiagent coordination in consumer cooperatives volume 50 pages 885922

a key challenge in creating a sustainable and energyefficient society is to make consumer demand adaptive to the supply of energy especially to the renewable supply in this article we propose a partiallycentralized organization of consumers or agents namely a consumer cooperative that purchases electricity from the market in the cooperative a central coordinator buys the electricity for the whole group  the technical challenge is that consumers make their own demand decisions based on their private demand constraints and preferences which they do not share with the coordinator or other agents we propose a novel multiagent coordination algorithm to shape the energy demand of the cooperative to coordinate individual consumers under incomplete information the coordinator determines virtual price signals that it sends to the consumers to induce them to shift their demands when required we prove that this algorithm converges to the central optimal solution and minimizes the electric energy cost of the cooperative  additionally we present results on the time complexity of the iterative algorithm and its implications for agents incentive compatibility furthermore we perform simulations based on real world consumption data to a characterize the convergence properties of our algorithm and b understand the effect of differing demand characteristics of participants as well as of different price functions on the cost reduction the results show that the convergence time scales linearly with the agent population size and length of the optimization horizon finally we observe that as participants flexibility of shifting their demands increases cost reduction increases and that the cost reduction is not sensitive to variation in consumption patterns of the consumers



b  bonet and h  geffner 2014 belief tracking for planning with sensing width complexity and approximations volume 50 pages 923970

we consider the problem of belief tracking in a planning setting where states are valuations over a set of variables that are partially observable and beliefs stand for the sets of states that are possible while the problem is intractable in the worst case it has been recently shown that in deterministic conformant and contingent problems belief tracking is exponential in a width parameter that is often bounded and small in this work we extend these results in two ways first we introduce a width notion that applies to nondeterministic problems as well develop a factored belief tracking algorithm that is exponential in the problem width and show how it applies to existing benchmarks second we introduce a meaningful powerful and sound approximation scheme beam tracking that is exponential in a smaller parameter  the problem causal width and has much broader applicability we illustrate the value of this algorithm over large instances of problems such as battleship minesweeper and wumpus where it yields stateoftheart performance in realtime
