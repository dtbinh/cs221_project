<cite>R.  J. Mooney and  M.  E. Califf (1995) "Induction of First-Order Decision Lists: Results on Learning the Past Tense of English Verbs", Volume 3, pages 1-24</cite>
<p class="media"><a href="/media/148/live-148-1451-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/148/live-148-1450-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.148'>doi:10.1613/jair.148</a></p>
<p>This paper presents a method for inducing logic programs    from examples that learns a new class of concepts called first-order    decision lists, defined as ordered lists of clauses each ending in a    cut.  The method, called FOIDL, is based on FOIL (Quinlan, 1990) but    employs intensional background knowledge and avoids the need for    explicit negative examples.  It is particularly useful for problems    that involve rules with specific exceptions, such as learning the    past-tense of English verbs, a task widely studied in the context of    the symbolic/connectionist debate.  FOIDL is able to learn concise,    accurate programs for this problem from significantly fewer examples    than previous methods (both connectionist and symbolic).</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Induction of First-Order Decision Lists: Results on Learning the Past Tense of English Verbs">
<meta name="citation_author" content="Mooney,  R. J.">
<meta name="citation_author" content="Califf,  M. E.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="24">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/148/live-148-1451-jair.pdf">

<cite>M.  Veloso and  P.  Stone (1995) "FLECS: Planning with a Flexible Commitment Strategy", Volume 3, pages 25-52</cite>
<p class="media"><a href="/media/131/live-131-1442-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/131/live-131-1441-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.131'>doi:10.1613/jair.131</a>
<br/><a href="/media/131/live-131-1444-jair.tar.Z">Appendix </a> - data file</p>
<p>There has been evidence that least-commitment planners can    efficiently handle planning problems that involve difficult goal    interactions.  This evidence has led to the common belief that    delayed-commitment is the "best" possible planning strategy.  However,    we recently found evidence that eager-commitment planners can handle a    variety of planning problems more efficiently, in particular those    with difficult operator choices.  Resigned to the futility of trying    to find a universally successful planning strategy, we devised a    planner that can be used to study which domains and problems are best    for which planning strategies. In this article we introduce this new    planning algorithm, FLECS, which uses a FLExible Commitment Strategy    with respect to plan-step orderings.  It is able to use any strategy    from delayed-commitment to eager-commitment.  The combination of    delayed and eager operator-ordering commitments allows FLECS to take    advantage of the benefits of explicitly using a simulated execution    state and reasoning about planning constraints.  FLECS can vary its    commitment strategy across different problems and domains, and also    during the course of a single planning problem.  FLECS represents a    novel contribution to planning in that it explicitly provides the    choice of which commitment strategy to use while planning.  FLECS    provides a framework to investigate the mapping from planning domains    and problems to efficient planning strategies.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="FLECS: Planning with a Flexible Commitment Strategy">
<meta name="citation_author" content="Veloso,  M.">
<meta name="citation_author" content="Stone,  P.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="25">
<meta name="citation_lastpage" content="52">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/131/live-131-1442-jair.pdf">

<cite>R.  Bergmann and  W.  Wilke (1995) "Building and Refining Abstract Planning Cases by Change of Representation Language", Volume 3, pages 53-118</cite>
<p class="media"><a href="/media/160/live-160-1460-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/160/live-160-1459-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.160'>doi:10.1613/jair.160</a>
<br/><a href="/media/160/live-160-1462-jair.txt">Appendix </a> - data file</p>
<p>Abstraction is one of the most promising approaches to improve the    performance of problem solvers. In several domains abstraction by    dropping sentences of a domain description -- as used in most    hierarchical planners -- has proven useful. In this paper we present    examples which illustrate significant drawbacks of abstraction by    dropping sentences. To overcome these drawbacks, we propose a more    general view of abstraction involving the change of representation    language. We have developed a new abstraction methodology and a    related sound and complete learning algorithm that allows the complete    change of representation language of planning cases from concrete to    abstract.  However, to achieve a powerful change of the representation    language, the abstract language itself as well as rules which describe    admissible ways of abstracting states must be provided in the domain    model. This new abstraction approach is the core of Paris (Plan    Abstraction and Refinement in an Integrated System), a system in which    abstract planning cases are automatically learned from given concrete    cases. An empirical study in the domain of process planning in    mechanical engineering shows significant advantages of the proposed    reasoning from abstract cases over classical hierarchical planning.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Building and Refining Abstract Planning Cases by Change of Representation Language">
<meta name="citation_author" content="Bergmann,  R.">
<meta name="citation_author" content="Wilke,  W.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="53">
<meta name="citation_lastpage" content="118">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/160/live-160-1460-jair.pdf">

<cite>Q.  Zhao and  T.  Nishida (1995) "Using Qualitative Hypotheses to Identify Inaccurate Data", Volume 3, pages 119-145</cite>
<p class="media"><a href="/media/170/live-170-1469-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/170/live-170-1468-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.170'>doi:10.1613/jair.170</a></p>
<p>Identifying inaccurate data has long been regarded as a    significant and difficult problem in AI. In this paper, we present a    new method for identifying inaccurate data on the basis of qualitative    correlations among related data. First, we introduce the definitions    of related data and qualitative correlations among related data.  Then    we put forward a new concept called support coefficient function    (SCF). SCF can be used to extract, represent, and calculate    qualitative correlations among related data within a dataset. We    propose an approach to determining dynamic shift intervals of    inaccurate data, and an approach to calculating possibility of    identifying inaccurate data, respectively. Both of the approaches are    based on SCF. Finally we present an algorithm for identifying    inaccurate data by using qualitative correlations among related data    as confirmatory or disconfirmatory evidence. We have developed a    practical system for interpreting infrared spectra by applying the    method, and have fully tested the system against several hundred real    spectra. The experimental results show that the method is    significantly better than the conventional methods used in many    similar systems.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Using Qualitative Hypotheses to Identify Inaccurate Data">
<meta name="citation_author" content="Zhao,  Q.">
<meta name="citation_author" content="Nishida,  T.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="119">
<meta name="citation_lastpage" content="145">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/170/live-170-1469-jair.pdf">

<cite>C.  G. Giraud-Carrier and  T.  R. Martinez (1995) "An Integrated Framework for Learning and Reasoning", Volume 3, pages 147-185</cite>
<p class="media"><a href="/media/93/live-93-1417-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/93/live-93-1415-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.93'>doi:10.1613/jair.93</a>
<br/><a href="/media/93/live-93-1418-jair.tar">Appendix </a> - source code and data</p>
<p>Learning and reasoning are both aspects of what is    considered to be intelligence. Their studies within AI have been    separated historically, learning being the topic of machine learning    and neural networks, and reasoning falling under classical (or    symbolic) AI.  However, learning and reasoning are in many ways    interdependent. This paper discusses the nature of some of these    interdependencies and proposes a general framework called FLARE, that    combines inductive learning using prior knowledge together with    reasoning in a propositional setting. Several examples that test the    framework are presented, including classical induction, many important    reasoning protocols and two simple expert systems.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="An Integrated Framework for Learning and Reasoning">
<meta name="citation_author" content="Giraud-Carrier,  C. G.">
<meta name="citation_author" content="Martinez,  T. R.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="147">
<meta name="citation_lastpage" content="185">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/93/live-93-1417-jair.pdf">

<cite>K.  Woods,  D.  Cook,  L.  Hall,  K.  Bowyer and  L.  Stark (1995) "Learning Membership Functions in a Function-Based Object Recognition System", Volume 3, pages 187-222</cite>
<p class="media"><a href="/media/236/live-236-1514-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/236/live-236-1513-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.236'>doi:10.1613/jair.236</a></p>
<p>Functionality-based recognition systems recognize objects at    the category level by reasoning about how well the objects support the    expected function. Such systems naturally associate a ``measure of    goodness'' or ``membership value'' with a recognized object.  This    measure of goodness is the result of combining individual measures, or    membership values, from potentially many primitive evaluations of    different properties of the object's shape. A membership function is    used to compute the membership value when evaluating a primitive of a    particular physical property of an object.  In previous versions of a    recognition system known as Gruff, the membership function for each of    the primitive evaluations was hand-crafted by the system designer.  In    this paper, we provide a learning component for the Gruff system,    called Omlet, that automatically learns membership functions given a    set of example objects labeled with their desired category measure.    The learning algorithm is generally applicable to any problem in which    low-level membership values are combined through an and-or tree    structure to give a final overall membership value.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Learning Membership Functions in a Function-Based Object Recognition System">
<meta name="citation_author" content="Woods,  K.">
<meta name="citation_author" content="Cook,  D.">
<meta name="citation_author" content="Hall,  L.">
<meta name="citation_author" content="Bowyer,  K.">
<meta name="citation_author" content="Stark,  L.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="187">
<meta name="citation_lastpage" content="222">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/236/live-236-1514-jair.pdf">

<cite>G.  Pinkas and  R.  Dechter (1995) "Improving Connectionist Energy Minimization", Volume 3, pages 223-248</cite>
<p class="media"><a href="/media/130/live-130-1439-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/130/live-130-1438-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.130'>doi:10.1613/jair.130</a></p>
<p>Symmetric networks designed for energy minimization such as    Boltzman machines and Hopfield nets are frequently investigated for    use in optimization, constraint satisfaction and approximation of    NP-hard problems. Nevertheless, finding a global solution (i.e., a    global minimum for the energy function) is not guaranteed and even a    local solution may take an exponential number of steps.  We propose an    improvement to the standard local activation function used for such    networks.  The improved algorithm guarantees that a global minimum is    found in linear time for tree-like subnetworks. The algorithm, called    activate, is uniform and does not assume that the network is    tree-like.  It can identify tree-like subnetworks even in cyclic    topologies (arbitrary networks) and avoid local minima along these    trees.  For acyclic networks, the algorithm is guaranteed to converge    to a global minimum from any initial state of the system    (self-stabilization) and remains correct under various types of    schedulers.  On the negative side, we show that in the presence of    cycles, no uniform algorithm exists that guarantees optimality even    under a sequential asynchronous scheduler.  An asynchronous scheduler    can activate only one unit at a time while a synchronous scheduler can    activate any number of units in a single time step.  In addition, no    uniform algorithm exists to optimize even acyclic networks when the    scheduler is synchronous.  Finally, we show how the algorithm can be    improved using the cycle-cutset scheme.  The general algorithm, called    activate-with-cutset, improves over activate and has some performance    guarantees that are related to the size of the network's cycle-cutset.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Improving Connectionist Energy Minimization">
<meta name="citation_author" content="Pinkas,  G.">
<meta name="citation_author" content="Dechter,  R.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="223">
<meta name="citation_lastpage" content="248">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/130/live-130-1439-jair.pdf">

<cite>Y.  Bengio and  P.  Frasconi (1995) "Diffusion of Context and Credit Information in Markovian Models", Volume 3, pages 249-270</cite>
<p class="media"><a href="/media/233/live-233-1512-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/233/live-233-1510-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.233'>doi:10.1613/jair.233</a></p>
<p>This paper studies the problem of ergodicity of transition    probability matrices in Markovian models, such as hidden Markov models    (HMMs), and how it makes very difficult the task of learning to    represent long-term context for sequential data.  This phenomenon    hurts the forward propagation of long-term context information, as    well as learning a hidden state representation to represent long-term    context, which depends on propagating credit information backwards in    time.  Using results from Markov chain theory, we show that this    problem of diffusion of context and credit is reduced when the    transition probabilities approach 0 or 1, i.e., the transition    probability matrices are sparse and the model essentially    deterministic.  The results found in this paper apply to learning    approaches based on continuous optimization, such as gradient descent    and the Baum-Welch algorithm.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Diffusion of Context and Credit Information in Markovian Models">
<meta name="citation_author" content="Bengio,  Y.">
<meta name="citation_author" content="Frasconi,  P.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="249">
<meta name="citation_lastpage" content="270">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/233/live-233-1512-jair.pdf">

<cite>S.  B. Huffman and  J.  E. Laird (1995) "Flexibly Instructable Agents", Volume 3, pages 271-324</cite>
<p class="media"><a href="/media/150/live-150-1454-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/150/live-150-1453-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.150'>doi:10.1613/jair.150</a></p>
<p>This paper presents an approach to learning from situated,    interactive tutorial instruction within an ongoing agent.  Tutorial    instruction is a flexible (and thus powerful) paradigm for teaching    tasks because it allows an instructor to communicate whatever types of    knowledge an agent might need in whatever situations might arise.  To    support this flexibility, however, the agent must be able to learn    multiple kinds of knowledge from a broad range of instructional    interactions.  Our approach, called situated explanation, achieves    such learning through a combination of analytic and inductive    techniques.  It combines a form of explanation-based learning that is    situated for each instruction with a full suite of contextually guided    responses to incomplete explanations.  The approach is implemented in    an agent called Instructo-Soar that learns hierarchies of new tasks    and other domain knowledge from interactive natural language    instructions.  Instructo-Soar meets three key requirements of flexible    instructability that distinguish it from previous systems: (1) it can    take known or unknown commands at any instruction point; (2) it can    handle instructions that apply to either its current situation or to a    hypothetical situation specified in language (as in, for instance,    conditional instructions); and (3) it can learn, from instructions,    each class of knowledge it uses to perform tasks.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Flexibly Instructable Agents">
<meta name="citation_author" content="Huffman,  S. B.">
<meta name="citation_author" content="Laird,  J. E.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="271">
<meta name="citation_lastpage" content="324">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/150/live-150-1454-jair.pdf">

<cite>A.  Broggi and  S.  Berte (1995) "Vision-Based Road Detection in Automotive Systems: A Real-Time Expectation-Driven Approach", Volume 3, pages 325-348</cite>
<p class="media"><a href="/media/185/live-185-1481-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/185/live-185-1480-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.185'>doi:10.1613/jair.185</a></p>
<p>The main aim of this work is the development of a    vision-based road detection system fast enough to cope with the    difficult real-time constraints imposed by moving vehicle    applications.  The hardware platform, a special-purpose massively    parallel system, has been chosen to minimize system production and    operational costs. <p>          This paper presents a novel approach to expectation-driven low-level    image segmentation, which can be mapped naturally onto mesh-connected    massively parallel SIMD architectures capable of handling hierarchical    data structures.  The input image is assumed to contain a distorted    version of a given template; a multiresolution stretching process is    used to reshape the original template in accordance with the acquired    image content, minimizing a potential function.  The distorted    template is the process output.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Vision-Based Road Detection in Automotive Systems: A Real-Time Expectation-Driven Approach">
<meta name="citation_author" content="Broggi,  A.">
<meta name="citation_author" content="Berte,  S.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="325">
<meta name="citation_lastpage" content="348">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/185/live-185-1481-jair.pdf">

<cite>R.  Khardon (1995) "Translating between Horn Representations and their Characteristic Models", Volume 3, pages 349-372</cite>
<p class="media"><a href="/media/183/live-183-1479-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/183/live-183-1477-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.183'>doi:10.1613/jair.183</a></p>
<p>Characteristic models are an alternative, model based,    representation for Horn expressions. It has been shown that these two    representations are incomparable and each has its advantages over the    other. It is therefore natural to ask what is the cost of translating,    back and forth, between these representations. Interestingly, the same    translation questions arise in database theory, where it has    applications to the design of relational databases. This paper studies    the computational complexity of these problems. <p>       Our main result is that the two translation problems are equivalent under    polynomial reductions, and that they are equivalent to the corresponding    decision problem. Namely, translating is equivalent to deciding whether a    given set of models is the set of characteristic models for a given Horn    expression.  <p>          We also relate these problems to the hypergraph transversal problem, a    well known problem which is related to other applications in AI and for    which no polynomial time algorithm is known. It is shown that in general    our translation problems are at least as hard as the hypergraph    transversal problem, and in a special case they are equivalent to it.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Translating between Horn Representations and their Characteristic Models">
<meta name="citation_author" content="Khardon,  R.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="349">
<meta name="citation_lastpage" content="372">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/183/live-183-1479-jair.pdf">

<cite>M.  Buro (1995) "Statistical Feature Combination for the Evaluation of Game Positions", Volume 3, pages 373-382</cite>
<p class="media"><a href="/media/179/live-179-1475-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/179/live-179-1474-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.179'>doi:10.1613/jair.179</a></p>
<p>This article describes an application of three well-known    statistical methods in the field of game-tree search: using a large    number of classified Othello positions, feature weights for evaluation    functions with a game-phase-independent meaning are estimated by means    of logistic regression, Fisher's linear discriminant, and the    quadratic discriminant function for normally distributed    features. Thereafter, the playing strengths are compared by means of    tournaments between the resulting versions of a world-class Othello    program. In this application, logistic regression - which is used here    for the first time in the context of game playing - leads to better    results than the other approaches.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Statistical Feature Combination for the Evaluation of Game Positions">
<meta name="citation_author" content="Buro,  M.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="373">
<meta name="citation_lastpage" content="382">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/179/live-179-1475-jair.pdf">

<cite>S.  M. Weiss and  N.  Indurkhya (1995) "Rule-based Machine Learning Methods for Functional Prediction", Volume 3, pages 383-403</cite>
<p class="media"><a href="/media/199/live-199-1490-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/199/live-199-1489-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.199'>doi:10.1613/jair.199</a></p>
<p>We describe a machine learning method for predicting the    value of a real-valued function, given the values of multiple input    variables. The method induces solutions from samples in the form of    ordered disjunctive normal form (DNF) decision rules. A central    objective of the method and representation is the induction of    compact, easily interpretable solutions.  This rule-based decision    model can be extended to search efficiently for similar cases prior to    approximating function values. Experimental results on real-world data    demonstrate that the new techniques are competitive with existing    machine learning and statistical methods and can sometimes yield    superior regression performance.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Rule-based Machine Learning Methods for Functional Prediction">
<meta name="citation_author" content="Weiss,  S. M.">
<meta name="citation_author" content="Indurkhya,  N.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="383">
<meta name="citation_lastpage" content="403">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/199/live-199-1490-jair.pdf">

<cite>D.  Heckerman and  R.  Shachter (1995) "Decision-Theoretic Foundations for Causal Reasoning", Volume 3, pages 405-430</cite>
<p class="media"><a href="/media/202/live-202-1493-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/202/live-202-1492-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.202'>doi:10.1613/jair.202</a></p>
<p>We present a definition of cause and effect in terms of    decision-theoretic primitives and thereby provide a principled    foundation for causal reasoning.  Our definition departs from the    traditional view of causation in that causal assertions may vary with    the set of decisions available.  We argue that this approach provides    added clarity to the notion of cause.  Also in this paper, we examine    the encoding of causal relationships in directed acyclic graphs.  We    describe a special class of influence diagrams, those in canonical    form, and show its relationship to Pearl's representation of cause and    effect.  Finally, we show how canonical form facilitates    counterfactual reasoning.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Decision-Theoretic Foundations for Causal Reasoning">
<meta name="citation_author" content="Heckerman,  D.">
<meta name="citation_author" content="Shachter,  R.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="405">
<meta name="citation_lastpage" content="430">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/202/live-202-1493-jair.pdf">

<cite>G.  I. Webb (1995) "OPUS: An Efficient Admissible Algorithm for Unordered Search", Volume 3, pages 431-465</cite>
<p class="media"><a href="/media/227/live-227-1499-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/227/live-227-1498-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.227'>doi:10.1613/jair.227</a></p>
<p>OPUS is a branch and bound search algorithm that enables    efficient admissible search through spaces for which the order of    search operator application is not significant.  The algorithm's    search efficiency is demonstrated with respect to very large machine    learning search spaces.  The use of admissible search is of potential    value to the machine learning community as it means that the exact    learning biases to be employed for complex learning tasks can be    precisely specified and manipulated.  OPUS also has potential for    application in other areas of artificial intelligence, notably, truth    maintenance.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="OPUS: An Efficient Admissible Algorithm for Unordered Search">
<meta name="citation_author" content="Webb,  G. I.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="431">
<meta name="citation_lastpage" content="465">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/227/live-227-1499-jair.pdf">

<cite>P.  Idestam-Almquist (1995) "Generalization of Clauses under Implication", Volume 3, pages 467-489</cite>
<p class="media"><a href="/media/194/live-194-1485-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/194/live-194-1483-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.194'>doi:10.1613/jair.194</a></p>
<p>In the area of inductive learning, generalization is a main    operation, and the usual definition of induction is based on logical    implication.  Recently there has been a rising interest in clausal    representation of knowledge in machine learning. Almost all inductive    learning systems that perform generalization of clauses use the    relation theta-subsumption instead of implication. The main reason is    that there is a well-known and simple technique to compute least    general generalizations under theta-subsumption, but not under    implication.  However generalization under theta-subsumption is    inappropriate for learning recursive clauses, which is a crucial    problem since recursion is the basic program structure of logic    programs. <p>    We note that implication between clauses is undecidable, and we    therefore introduce a stronger form of implication, called    T-implication, which is decidable between clauses. We show that for    every finite set of clauses there exists a least general    generalization under T-implication.  We describe a technique to reduce    generalizations under implication of a clause to generalizations under    theta-subsumption of what we call an expansion of the original    clause. Moreover we show that for every non-tautological clause there    exists a T-complete expansion, which means that every generalization    under T-implication of the clause is reduced to a generalization under    theta-subsumption of the expansion.</p>
<a href="/vol/vol3.html">Click here to return to Volume 3 contents list</a>
<meta name="citation_title" content="Generalization of Clauses under Implication">
<meta name="citation_author" content="Idestam-Almquist,  P.">
<meta name="citation_publication_date" content="1995">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="467">
<meta name="citation_lastpage" content="489">
<meta name="citation_volume" content="3">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/194/live-194-1485-jair.pdf">
