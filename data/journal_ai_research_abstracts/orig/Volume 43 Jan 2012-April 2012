<cite>F.  Stulp, A.  Fedrizzi, L.  M&#246;senlechner and M.  Beetz (2012) "Learning and Reasoning with Action-Related Places for Robust Mobile Manipulation", Volume 43, pages 1-42</cite>
<p class="media"><a href="/media/3451/live-3451-6080-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3451/live-3451-6079-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3451'>doi:10.1613/jair.3451</a></p>
<p>We propose the concept of Action-Related Place (ARPlace) as a powerful and flexible representation of task-related place in the context of mobile manipulation. ARPlace represents robot base locations not as a single position, but rather as a collection of positions, each with an associated probability that the manipulation action will succeed when located there. ARPlaces are generated using a predictive model that is acquired through experience-based learning, and take into account the uncertainty the robot has about its own location and the location of the object to be manipulated.<br />
<br />
When executing the task, rather than choosing one specific goal position based only on the initial knowledge about the task context, the robot instantiates an ARPlace, and bases its decisions on this ARPlace, which is updated as new information about the task becomes available. To show the advantages of this least-commitment approach, we present a transformational planner that reasons about ARPlaces in order to optimize symbolic plans.  Our empirical evaluation demonstrates that using ARPlaces leads to more robust and efficient mobile manipulation in the face of state estimation uncertainty on our simulated robot.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Learning and Reasoning with Action-Related Places for Robust Mobile Manipulation">
<meta name="citation_author" content="Stulp, F.">
<meta name="citation_author" content="Fedrizzi, A.">
<meta name="citation_author" content="M&#246;senlechner, L.">
<meta name="citation_author" content="Beetz, M.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="42">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3451/live-3451-6080-jair.pdf">

<cite>N.  Fu, H.C.  Lau, P.  Varakantham and F.  Xiao (2012) "Robust Local Search for Solving RCPSP/max with Durational Uncertainty", Volume 43, pages 43-86</cite>
<p class="media"><a href="/media/3424/live-3424-6087-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3424/live-3424-6086-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3424'>doi:10.1613/jair.3424</a></p>
<p>Scheduling problems in manufacturing, logistics and project management have frequently been modeled using the framework of Resource Constrained Project Scheduling Problems with minimum and maximum time lags (RCPSP/max). Due to the importance of these problems, providing scalable solution schedules for RCPSP/max problems is a topic of extensive research. However, all existing methods for solving RCPSP/max assume that durations of activities are known with certainty, an assumption that does not hold in real world scheduling problems where unexpected external events such as manpower availability, weather changes, etc. lead to delays or advances in completion of activities. Thus, in this paper, our focus is on providing a scalable method for solving RCPSP/max problems with durational uncertainty. To that end, we introduce the robust local search method consisting of three key ideas: (a) Introducing and studying the properties of two decision rule approximations used to compute start times of activities with respect to dynamic realizations of the durational uncertainty; (b) Deriving the expression for robust makespan of an execution strategy based on decision rule approximations; and (c) A robust local search mechanism to efficiently compute activity execution strategies that are robust against durational uncertainty. Furthermore, we also provide enhancements to local search that exploit temporal dependencies between activities. Our experimental results illustrate that robust local search is able to provide robust execution strategies efficiently.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Robust Local Search for Solving RCPSP/max with Durational Uncertainty">
<meta name="citation_author" content="Fu, N.">
<meta name="citation_author" content="Lau, H.C.">
<meta name="citation_author" content="Varakantham, P.">
<meta name="citation_author" content="Xiao, F.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="43">
<meta name="citation_lastpage" content="86">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3424/live-3424-6087-jair.pdf">

<cite>A.  Sadilek and H.  Kautz (2012) "Location-Based Reasoning about Complex Multi-Agent Behavior", Volume 43, pages 87-133</cite>
<p class="media"><a href="/media/3421/live-3421-6099-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3421/live-3421-6098-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3421'>doi:10.1613/jair.3421</a></p>
<p>Recent research has shown that surprisingly rich models of human activity can be learned from GPS (positional) data. However, most effort to date has concentrated on modeling single individuals or statistical properties of groups of people. Moreover, prior work focused solely on modeling actual successful executions (and not failed or attempted executions) of the activities of interest. We, in contrast, take on the task of understanding human interactions, attempted interactions, and intentions from noisy sensor data in a fully relational multi-agent setting. We use a real-world game of capture the flag to illustrate our approach in a well-defined domain that involves many distinct cooperative and competitive joint activities. We model the domain using Markov logic, a statistical-relational language, and learn a theory that jointly denoises the data and infers occurrences of high-level activities, such as a player capturing an enemy. Our unified model combines constraints imposed by the geometry of the game area, the motion model of the players, and by the rules and dynamics of the game in a probabilistically and logically sound fashion. We show that while it may be impossible to directly detect a multi-agent activity due to sensor noise or malfunction, the occurrence of the activity can still be inferred by considering both its impact on the future behaviors of the people involved as well as the events that could have preceded it. Further, we show that given a model of successfully performed multi-agent activities, along with a set of examples of failed attempts at the same activities, our system automatically learns an augmented model that is capable of recognizing success and failure, as well as goals of people's actions with high accuracy. We compare our approach with other alternatives and show that our unified model, which takes into account not only relationships among individual players, but also relationships among activities over the entire length of a game, although more computationally costly, is significantly more accurate. Finally, we demonstrate that explicitly modeling unsuccessful attempts boosts performance on other important recognition tasks.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Location-Based Reasoning about Complex Multi-Agent Behavior">
<meta name="citation_author" content="Sadilek, A.">
<meta name="citation_author" content="Kautz, H.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="87">
<meta name="citation_lastpage" content="133">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3421/live-3421-6099-jair.pdf">

<cite>T.  Flati and R.  Navigli (2012) "The CQC Algorithm: Cycling in Graphs to Semantically Enrich and Enhance a Bilingual Dictionary", Volume 43, pages 135-171</cite>
<p class="media"><a href="/media/3456/live-3456-6114-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3456/live-3456-6115-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3456'>doi:10.1613/jair.3456</a></p>
<p>Bilingual machine-readable dictionaries are knowledge resources useful in many automatic tasks. However, compared to monolingual computational lexicons like WordNet, bilingual dictionaries typically provide a lower amount of structured information, such as lexical and semantic relations, and often do not cover the entire range of possible translations for a word of interest. In this paper we present Cycles and Quasi-Cycles (CQC), a novel algorithm for the automated disambiguation of ambiguous translations in the lexical entries of a bilingual machine-readable dictionary. The dictionary is represented as a graph, and cyclic patterns are sought in the graph to assign an appropriate sense tag to each translation in a lexical entry. Further, we use the algorithm's output to improve the quality of the dictionary itself, by suggesting accurate solutions to structural problems such as misalignments, partial alignments <br />
and missing entries. Finally, we successfully apply CQC to the task of synonym extraction.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="The CQC Algorithm: Cycling in Graphs to Semantically Enrich and Enhance a Bilingual Dictionary">
<meta name="citation_author" content="Flati, T.">
<meta name="citation_author" content="Navigli, R.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="135">
<meta name="citation_lastpage" content="171">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3456/live-3456-6114-jair.pdf">

<cite>G.  Pesant, C.  Quimper and A.  Zanarini (2012) "Counting-Based Search: Branching Heuristics for Constraint Satisfaction Problems", Volume 43, pages 173-210</cite>
<p class="media"><a href="/media/3463/live-3463-6124-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3463/live-3463-6123-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3463'>doi:10.1613/jair.3463</a></p>
<p>Designing a search heuristic for constraint programming that is reliable across problem domains has been an important research topic in recent years. This paper concentrates on one family of candidates: counting-based search. Such heuristics seek to make branching decisions that preserve most of the solutions by determining what proportion of solutions to each individual constraint agree with that decision. Whereas most generic search heuristics in constraint programming rely on local information at the level of the individual variable, our search heuristics are based on more global information at the constraint level. We design several algorithms that are used to count the number of solutions to specific families of constraints and propose some search heuristics exploiting such information. The experimental part of the paper considers eight problem domains ranging from well-established benchmark puzzles to rostering and sport scheduling. An initial empirical analysis identifies heuristic maxSD as a robust candidate among our proposals.eWe then evaluate the latter against the state of the art, including the latest generic search heuristics, restarts, and discrepancy-based tree traversals. Experimental results show that counting-based search generally outperforms other generic heuristics.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Counting-Based Search: Branching Heuristics for Constraint Satisfaction Problems">
<meta name="citation_author" content="Pesant, G.">
<meta name="citation_author" content="Quimper, C.">
<meta name="citation_author" content="Zanarini, A.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="173">
<meta name="citation_lastpage" content="210">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3463/live-3463-6124-jair.pdf">

<cite>Y.  Zeng and P.  Doshi (2012) "Exploiting Model Equivalences for Solving Interactive Dynamic Influence Diagrams", Volume 43, pages 211-255</cite>
<p class="media"><a href="/media/3461/live-3461-6132-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3461/live-3461-6133-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3461'>doi:10.1613/jair.3461</a></p>
<p> We focus on  the problem of sequential decision  making in partially observable environments shared with  other agents of uncertain types having  similar or  conflicting objectives.   This problem  has been previously  formalized by multiple  frameworks one  of which  is the interactive  dynamic   influence   diagram  (I-DID),   which generalizes  the  well-known  influence  diagram to  the  multiagent setting.  I-DIDs are graphical models and may be used to compute the policy  of an agent  given its  belief over  the physical  state and others' models, which changes as  the agent acts and observes in the  multiagent setting.<br />
<br />
  As we may  expect, solving I-DIDs is computationally  hard.  This is predominantly due to the large space of candidate models ascribed to the other agents  and its exponential growth over  time.  We present two methods  for reducing the size  of the model  space and stemming its  exponential  growth.  Both  these  methods involve  aggregating individual models into equivalence classes.  Our first method groups together behaviorally equivalent models and selects only those  models for  updating which will result in  predictive behaviors that are distinct  from others  in the updated  model space.   The second method further compacts  the model space by focusing  on portions of the   behavioral  predictions.    Specifically,   we  cluster  actionally equivalent models  that prescribe identical actions at a  single  time step.  Exactly  identifying  the equivalences  would require us to solve all models in the initial set.  We avoid this by selectively  solving  some of  the  models,  thereby introducing  an approximation.    We   discuss   the   error   introduced   by   the approximation, and  empirically demonstrate the  improved efficiency in solving I-DIDs due to the equivalences.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Exploiting Model Equivalences for Solving Interactive Dynamic Influence Diagrams">
<meta name="citation_author" content="Zeng, Y.">
<meta name="citation_author" content="Doshi, P.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="211">
<meta name="citation_lastpage" content="255">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3461/live-3461-6132-jair.pdf">

<cite>J.H.M.  Lee and K.  L. Leung (2012) "Consistency Techniques for Flow-Based Projection-Safe Global Cost Functions in Weighted Constraint Satisfaction", Volume 43, pages 257-292</cite>
<p class="media"><a href="/media/3476/live-3476-6226-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3476/live-3476-6227-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3476'>doi:10.1613/jair.3476</a>
<br/><a href="/media/3476/live-3476-8897-jair.pdf">Appendix 1</a> - Erratum&nbsp;|&nbsp;<a href="/media/3476/live-3476-8898-jair.pdf">Appendix 2</a> - Revised Paper</p>
<p>Many combinatorial problems deal with preferences and violations, the goal of which is to find solutions with the minimum cost.  Weighted constraint satisfaction is a framework for modeling such problems, which consists of a set of cost functions to measure the degree of violation or preferences of different combinations of variable assignments.  Typical solution methods for weighted constraint satisfaction problems (WCSPs) are based on branch-and-bound search, which are made practical through the use of powerful consistency techniques such as AC*, FDAC*, EDAC* to deduce hidden cost information and value pruning during search.  These techniques, however, are designed to be efficient only on binary and ternary cost functions which are represented in table form.  In tackling many real-life problems, high arity (or global) cost functions are required.  We investigate efficient representation scheme and algorithms to bring the benefits of the consistency techniques to also high arity cost functions, which are often derived from hard global constraints from classical constraint satisfaction.<br />
<br />
The literature suggests some global cost functions can be represented as flow networks, and the minimum cost flow algorithm can be used to compute the minimum costs of such networks in polynomial time.  We show that naive adoption of this flow-based algorithmic method for global cost functions can result in a stronger form of null-inverse consistency.  We further show how the method can be modified to handle cost projections and extensions to maintain generalized versions of AC* and FDAC* for cost functions with more than two variables.  Similar generalization for the stronger EDAC* is less straightforward.  We reveal the oscillation problem when enforcing EDAC* on cost functions sharing more than one variable.  To avoid oscillation, we propose a weak version of EDAC* and generalize it to weak EDGAC* for non-binary cost functions. Using various benchmarks involving the soft variants of hard global constraints ALLDIFFERENT, GCC, SAME, and REGULAR, empirical results demonstrate that our proposal gives improvements of up to an order of magnitude when compared with the traditional constraint optimization approach, both in terms of time and pruning. </p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Consistency Techniques for Flow-Based Projection-Safe Global Cost Functions in Weighted Constraint Satisfaction">
<meta name="citation_author" content="Lee, J.H.M.">
<meta name="citation_author" content="Leung, K. L.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="257">
<meta name="citation_lastpage" content="292">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3476/live-3476-8898-jair.pdf">

<cite>R.  Huang, Y.  Chen and W.  Zhang (2012) "SAS+ Planning as Satisfiability", Volume 43, pages 293-328</cite>
<cite>AAAI 2010 Outstanding Paper Award</cite><p class="media"><a href="/media/3442/live-3442-6159-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3442/live-3442-6160-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3442'>doi:10.1613/jair.3442</a></p>
<p>Planning as satisfiability is a principal approach to planning with many eminent advantages. The existing planning as satisfiability techniques usually use encodings compiled from STRIPS. We introduce a novel SAT encoding scheme (SASE) based on the SAS+ formalism. The new scheme exploits the structural information in SAS+, resulting in an encoding that is both more compact and efficient for planning. We prove the correctness of the new encoding by establishing an isomorphism between the solution plans of SASE and that of STRIPS based encodings. We further analyze the transition variables newly introduced in SASE to explain why it accommodates modern SAT solving algorithms and improves performance. We give empirical statistical results to support our analysis. We also develop a number of techniques to further reduce the encoding size of SASE, and conduct experimental studies to show the strength of each individual technique. Finally, we report extensive experimental results to demonstrate significant improvements of SASE over the state-of-the-art STRIPS based encoding schemes in terms of both time and memory efficiency.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="SAS+ Planning as Satisfiability">
<meta name="citation_author" content="Huang, R.">
<meta name="citation_author" content="Chen, Y.">
<meta name="citation_author" content="Zhang, W.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="293">
<meta name="citation_lastpage" content="328">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3442/live-3442-6159-jair.pdf">

<cite>P.  Jeavons and J.  Petke (2012) "Local Consistency and SAT-Solvers", Volume 43, pages 329-351</cite>
<p class="media"><a href="/media/3531/live-3531-6168-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3531/live-3531-6169-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3531'>doi:10.1613/jair.3531</a></p>
<p>Local consistency techniques such as k-consistency are a key  component of specialised solvers for constraint satisfaction problems. In this paper we show that the power of using k-consistency techniques on a constraint satisfaction problem is precisely captured by using a particular inference rule, which we call negative-hyper-resolution, on the standard direct encoding of the problem into Boolean clauses. We also show that current clause-learning SAT-solvers will discover in expected polynomial time any inconsistency that can be deduced from a given set of clauses using negative-hyper-resolvents of a fixed size. We combine these two results to show that, without being explicitly designed to do so, current clause-learning SAT-solvers efficiently simulate k-consistency techniques, for all fixed values of k. We then give some experimental results to show that this feature allows clause-learning SAT-solvers to efficiently solve certain families of constraint problems which are challenging for conventional constraint-programming solvers.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Local Consistency and SAT-Solvers">
<meta name="citation_author" content="Jeavons, P.">
<meta name="citation_author" content="Petke, J.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="329">
<meta name="citation_lastpage" content="351">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3531/live-3531-6168-jair.pdf">

<cite>L.  R. Planken, M.  M. de Weerdt and R.  P.J. van der Krogt (2012) "Computing All-Pairs Shortest Paths by Leveraging Low Treewidth", Volume 43, pages 353-388</cite>
<cite>ICAPS 2011 Honorable Mention for Best Student Paper</cite><p class="media"><a href="/media/3509/live-3509-6172-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3509/live-3509-6173-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3509'>doi:10.1613/jair.3509</a></p>
<p>We present two new and efficient algorithms for computing all-pairs shortest paths.  The algorithms operate on directed graphs with real (possibly negative) weights.  They make use of directed path consistency along a vertex ordering d. Both algorithms run in O(n^2 w_d) time, where w_d is the graph width induced by this vertex ordering.  For graphs of constant treewidth, this yields O(n^2) time, which is optimal.  On chordal graphs, the algorithms run in O(nm) time. In addition, we present a variant that exploits graph separators to arrive at a run time of  O(n w_d^2 + n^2 s_d) on general graphs, where s_d <= w_d is the size of the largest minimal separator induced by the vertex ordering d. We show empirically that on both constructed and realistic benchmarks, in many cases the algorithms outperform Floyd-Warshall's as well as Johnson's algorithm, which represent the current state of the art with a run time of O(n^3) and O(nm + n^2 log n), respectively. Our algorithms can be used for spatial and temporal reasoning, such as for the Simple Temporal Problem, which underlines their relevance to the planning and scheduling community.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Computing All-Pairs Shortest Paths by Leveraging Low Treewidth">
<meta name="citation_author" content="Planken, L. R.">
<meta name="citation_author" content="de Weerdt, M. M.">
<meta name="citation_author" content="van der Krogt, R. P.J.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="353">
<meta name="citation_lastpage" content="388">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3509/live-3509-6172-jair.pdf">

<cite>F.  S&#225;nchez-Mart&#237;nez, R.  C. Carrasco, M.  A. Mart&#237;nez-Prieto and J.  Adiego (2012) "Generalized Biwords for Bitext Compression and Translation Spotting", Volume 43, pages 389-418</cite>
<p class="media"><a href="/media/3500/live-3500-6187-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3500/live-3500-6186-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3500'>doi:10.1613/jair.3500</a></p>
<p>Large bilingual parallel texts (also known as bitexts) are usually stored in a compressed form, and previous work has shown that they can be more efficiently compressed if the fact that the two texts are mutual translations is exploited. For example, a bitext can be seen as a sequence of biwords ---pairs of parallel words with a high probability of co-occurrence--- that can be used as an intermediate representation in the compression process.  However, the simple biword approach described in the literature can only exploit one-to-one word alignments and cannot tackle the reordering of words. We therefore introduce a generalization of biwords which can describe multi-word expressions and reorderings.  We also describe some methods for the binary compression of generalized biword sequences, and compare their performance when different schemes are applied to the extraction of the biword sequence. In addition, we show that this generalization of biwords allows for the implementation of an efficient algorithm to look on the compressed bitext for words or text segments in one of the texts and retrieve their counterpart translations in the other text ---an application usually referred to as translation spotting--- with only some minor modifications in the compression algorithm.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Generalized Biwords for Bitext Compression and Translation Spotting">
<meta name="citation_author" content="S&#225;nchez-Mart&#237;nez, F.">
<meta name="citation_author" content="Carrasco, R. C.">
<meta name="citation_author" content="Mart&#237;nez-Prieto, M. A.">
<meta name="citation_author" content="Adiego, J.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="389">
<meta name="citation_lastpage" content="418">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3500/live-3500-6187-jair.pdf">

<cite>B.  Cuenca Grau, B.  Motik, G.  Stoilos and I.  Horrocks (2012) "Completeness Guarantees for Incomplete Ontology Reasoners: Theory and Practice", Volume 43, pages 419-476</cite>
<cite>AAAI 2010 Outstanding Paper Award</cite><p class="media"><a href="/media/3470/live-3470-6190-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3470/live-3470-6194-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3470'>doi:10.1613/jair.3470</a></p>
<p>To achieve scalability of query answering, the developers of Semantic Web applications are often forced to use incomplete OWL 2 reasoners, which fail to derive all answers for at least one query, ontology, and data set. The lack of completeness guarantees, however, may be unacceptable for applications in areas such as health care and defence, where missing answers can adversely affect the application's functionality. Furthermore, even if an application can tolerate some level of incompleteness, it is often advantageous to estimate how many and what kind of answers are being lost.<br />
<br />
In this paper, we present a novel logic-based framework that allows one to check whether a reasoner is complete for a given query Q and ontology T---that is, whether the reasoner is guaranteed to compute all answers to Q w.r.t. T and an arbitrary data set A. Since ontologies and typical queries are often fixed at application design time, our approach allows application developers to check whether a reasoner known to be incomplete in general is actually complete for the kinds of input relevant for the application.<br />
<br />
We also present a technique that, given a query Q, an ontology T, and reasoners R_1 and R_2 that satisfy certain assumptions, can be used to determine whether, for each data set A, reasoner R_1 computes more answers to Q w.r.t. T and A than reasoner R_2. This allows application developers to select the reasoner that provides the highest degree of completeness for Q and T that is compatible with the application's scalability requirements.<br />
<br />
Our results thus provide a theoretical and practical foundation for the design of future ontology-based information systems that maximise scalability while minimising or even eliminating incompleteness of query answers.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Completeness Guarantees for Incomplete Ontology Reasoners: Theory and Practice">
<meta name="citation_author" content="Cuenca Grau, B.">
<meta name="citation_author" content="Motik, B.">
<meta name="citation_author" content="Stoilos, G.">
<meta name="citation_author" content="Horrocks, I.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="419">
<meta name="citation_lastpage" content="476">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3470/live-3470-6190-jair.pdf">

<cite>J.  Baum, A.  E. Nicholson and T.  I. Dix (2012) "Proximity-Based Non-uniform Abstractions for Approximate Planning", Volume 43, pages 477-522</cite>
<p class="media"><a href="/media/3414/live-3414-6200-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3414/live-3414-6201-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3414'>doi:10.1613/jair.3414</a></p>
<p>In a deterministic world, a planning agent can be certain of the consequences of its planned sequence of actions. Not so, however, in dynamic, stochastic domains where Markov decision processes are commonly used. Unfortunately these suffer from the `curse of dimensionality': if the state space is a Cartesian product of many small sets (`dimensions'), planning is exponential in the number of those dimensions.<br />
<br />
Our new technique exploits the intuitive strategy of selectively ignoring various dimensions in different parts of the state space. The resulting non-uniformity has strong implications, since the approximation is no longer Markovian, requiring the use of a modified planner. We also use a spatial and temporal proximity measure, which responds to continued planning as well as movement of the agent through the state space, to dynamically adapt the abstraction as planning progresses.<br />
<br />
We present qualitative and quantitative results across a range of experimental domains showing that an agent exploiting this novel approximation method successfully finds solutions to the planning problem using much less than the full state space. We assess and analyse the features of domains which our method can exploit.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Proximity-Based Non-uniform Abstractions for Approximate Planning">
<meta name="citation_author" content="Baum, J.">
<meta name="citation_author" content="Nicholson, A. E.">
<meta name="citation_author" content="Dix, T. I.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="477">
<meta name="citation_lastpage" content="522">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3414/live-3414-6200-jair.pdf">

<cite>C.  Hernandez and J.  A. Baier (2012) "Avoiding and Escaping Depressions in Real-Time Heuristic Search", Volume 43, pages 523-570</cite>
<p class="media"><a href="/media/3590/live-3590-6238-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3590/live-3590-6237-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3590'>doi:10.1613/jair.3590</a></p>
<p>Heuristics used for solving hard real-time search problems have regions with depressions.  Such regions are bounded areas of the search space in which the heuristic function is inaccurate compared to the actual cost to reach a solution. Early real-time search algorithms, like LRTA*, easily become trapped in those regions since the heuristic values of their states may need to be updated multiple times, which results in costly solutions. State-of-the-art real-time search algorithms, like LSS-LRTA* or LRTA*(k), improve LRTA*'s mechanism to update the heuristic, resulting in improved performance. Those algorithms, however, do not guide search towards avoiding depressed regions. This paper presents depression avoidance, a simple real-time search principle to guide search towards avoiding states that have been marked as part of a heuristic depression. We propose two ways in which depression avoidance can be implemented: mark-and-avoid and move-to-border. We implement these strategies on top of LSS-LRTA* and RTAA*, producing 4 new real-time heuristic search algorithms: aLSS-LRTA*, daLSS-LRTA*, aRTAA*, and daRTAA*. When the objective is to find a single solution by running the real-time search algorithm once, we show that daLSS-LRTA* and daRTAA* outperform their predecessors sometimes by one order of magnitude. Of the four new algorithms, daRTAA* produces the best solutions given a fixed deadline on the average time allowed per planning episode. We prove all our algorithms have good theoretical properties: in finite search spaces, they find a solution if one exists, and converge to an optimal after a number of trials.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Avoiding and Escaping Depressions in Real-Time Heuristic Search">
<meta name="citation_author" content="Hernandez, C.">
<meta name="citation_author" content="Baier, J. A.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="523">
<meta name="citation_lastpage" content="570">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3590/live-3590-6238-jair.pdf">

<cite>J.  Lee and R.  Palla (2012) "Reformulating the Situation Calculus and the Event Calculus in the General Theory of Stable Models and in Answer Set Programming", Volume 43, pages 571-620</cite>
<p class="media"><a href="/media/3489/live-3489-6241-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3489/live-3489-6240-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3489'>doi:10.1613/jair.3489</a></p>
<p>Circumscription and logic programs under the stable model semantics are two well-known nonmonotonic formalisms. The former has served as a basis of classical logic based action formalisms, such as the situation calculus, the event calculus and temporal action logics; the latter has served as a basis of a family of action languages, such as language A and several of its descendants. Based on the discovery that circumscription and the stable model semantics coincide on a class of canonical formulas, we reformulate the situation calculus and the event calculus in the general theory of stable models. We also present a translation that turns the reformulations further into answer set programs, so that efficient answer set solvers can be applied to compute the situation calculus and the event calculus. </p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Reformulating the Situation Calculus and the Event Calculus in the General Theory of Stable Models and in Answer Set Programming">
<meta name="citation_author" content="Lee, J.">
<meta name="citation_author" content="Palla, R.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="571">
<meta name="citation_lastpage" content="620">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3489/live-3489-6241-jair.pdf">

<cite>M.  Vasirani and S.  Ossowski (2012) "A Market-Inspired Approach for Intersection Management in Urban Road Traffic Networks", Volume 43, pages 621-659</cite>
<p class="media"><a href="/media/3560/live-3560-6245-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3560/live-3560-6244-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3560'>doi:10.1613/jair.3560</a></p>
<p>Traffic congestion in urban road networks is a costly problem that affects all major cities in developed countries. To tackle this problem, it is possible (i) to act on the supply side, increasing the number of roads or lanes in a network, (ii) to reduce the demand, restricting the access to urban areas at specific hours or to specific vehicles, or (iii) to improve the efficiency of the existing network, by means of a widespread use of so-called Intelligent Transportation Systems (ITS). In line with the recent advances in smart transportation management infrastructures, ITS has turned out to be a promising field of application for artificial intelligence techniques. In particular, multiagent systems seem to be the ideal candidates for the design and implementation of ITS. In fact, drivers can be naturally modelled as autonomous agents that interact with the transportation management infrastructure, thereby generating a large-scale, open, agent-based system. To regulate such a system and maintain a smooth and efficient flow of traffic, decentralised mechanisms for the management of the transportation infrastructure are needed.<br />
<br />
In this article we propose a distributed, market-inspired, mechanism for the management of a future urban road network, where intelligent autonomous vehicles, operated by software agents on behalf of their human owners, interact with the infrastructure in order to travel safely and efficiently through the road network. Building on the reservation-based intersection control model proposed by Dresner and Stone, we consider two different scenarios: one with a single intersection and one with a network of intersections. In the former, we analyse the performance of a novel policy based on combinatorial auctions for the allocation of reservations. In the latter, we analyse the impact that a traffic assignment strategy inspired by competitive markets has on the drivers' route choices. Finally we propose an adaptive management mechanism that integrates the auction-based traffic control policy with the competitive traffic assignment strategy.</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="A Market-Inspired Approach for Intersection Management in Urban Road Traffic Networks">
<meta name="citation_author" content="Vasirani, M.">
<meta name="citation_author" content="Ossowski, S.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="621">
<meta name="citation_lastpage" content="659">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3560/live-3560-6245-jair.pdf">

<cite>S.R.K.  Branavan, D.  Silver and R.  Barzilay (2012) "Learning to Win by Reading Manuals in a Monte-Carlo Framework", Volume 43, pages 661-704</cite>
<p class="media"><a href="/media/3484/live-3484-6254-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3484/live-3484-6255-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3484'>doi:10.1613/jair.3484</a></p>
<p>Domain knowledge is crucial for effective performance in autonomous control systems.  Typically, human effort is required to encode this knowledge into a control algorithm.  In this paper, we present an approach to language grounding which automatically interprets text in the context of a complex control application, such as a game, and uses domain knowledge extracted from the text to improve control performance.  Both text analysis and control strategies are learned jointly using only a feedback signal inherent to the application.  To effectively leverage textual information, our method automatically extracts the text segment most relevant to the current game state, and labels it with a task-centric predicate structure.  This labeled text is then used to bias an action selection policy for the game, guiding it towards promising regions of the action space.  We encode our model for text analysis and game playing in a multi-layer neural network, representing linguistic decisions via latent variables in the hidden layers, and game action quality via the output layer.  Operating within the Monte-Carlo Search framework, we estimate model parameters using feedback from simulated games.  We apply our approach to the complex strategy game Civilization II using the official game manual as the text guide.  Our results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 34% absolute improvement and winning over 65% of games when playing against the built-in AI of Civilization.<br />
</p>
<a href="/vol/vol43.html">Click here to return to Volume 43 contents list</a>
<meta name="citation_title" content="Learning to Win by Reading Manuals in a Monte-Carlo Framework">
<meta name="citation_author" content="Branavan, S.R.K.">
<meta name="citation_author" content="Silver, D.">
<meta name="citation_author" content="Barzilay, R.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="661">
<meta name="citation_lastpage" content="704">
<meta name="citation_volume" content="43">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3484/live-3484-6254-jair.pdf">
