<cite>Roy  Bar-Haim, Ido  Dagan and Jonathan  Berant (2015) "Knowledge-Based Textual Inference via Parse-Tree Transformations", Volume 54, pages 1-57</cite>
<p class="media"><a href="/media/4584/live-4584-8859-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4584'>doi:10.1613/jair.4584</a></p>
<p>Textual inference is an important component in many applications for understanding natural language. Classical approaches to textual inference rely on logical representations for meaning, which may be regarded as "external" to the natural language itself. However, practical applications usually adopt shallower lexical or lexical-syntactic representations, which correspond closely to language structure. In many cases, such approaches lack a principled meaning representation and inference framework. We describe an inference formalism that operates directly on language-based structures, particularly syntactic parse trees. New trees are generated by applying inference rules, which provide a unified representation for varying types of inferences. We use manual and automatic methods to generate these rules, which cover generic linguistic structures as well as specific lexical-based inferences.  We also present a novel packed data-structure and a corresponding inference algorithm that allows efficient implementation of this formalism. We proved the correctness of the new algorithm and established its efficiency analytically and empirically. The utility of our approach was illustrated on two tasks: unsupervised relation extraction from a large corpus, and the Recognizing Textual Entailment (RTE) benchmarks. </p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Knowledge-Based Textual Inference via Parse-Tree Transformations">
<meta name="citation_author" content="Bar-Haim, Roy">
<meta name="citation_author" content="Dagan, Ido">
<meta name="citation_author" content="Berant, Jonathan">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="57">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4584/live-4584-8859-jair.pdf">

<cite>Sigve  Hortemo S&#230;ther, Jan Arne  Telle and Martin   Vatshelle (2015) "Solving #SAT and MAXSAT by Dynamic Programming ", Volume 54, pages 59-82</cite>
<p class="media"><a href="/media/4831/live-4831-8861-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4831'>doi:10.1613/jair.4831</a></p>
<p>We look at dynamic programming algorithms for propositional model counting, also called #SAT, and MaxSAT. Tools from graph structure theory, in particular treewidth, have been used to successfully identify tractable cases in many subfields of AI, including SAT, Constraint Satisfaction Problems (CSP), Bayesian reasoning, and planning. In this paper we attack #SAT and MaxSAT using similar, but more modern, graph structure tools. The tractable cases will include formulas whose class of incidence graphs have not only unbounded treewidth but also unbounded clique-width. We show that our algorithms extend all previous results for MaxSAT and #SAT achieved by dynamic programming along structural decompositions of the incidence graph of the input formula. We present some limited experimental results, comparing implementations of our algorithms to state-of-the-art #SAT and MaxSAT solvers, as a proof of concept that warrants further research.<br />
</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Solving #SAT and MAXSAT by Dynamic Programming ">
<meta name="citation_author" content="S&#230;ther, Sigve Hortemo">
<meta name="citation_author" content="Telle, Jan Arne">
<meta name="citation_author" content="Vatshelle, Martin ">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="59">
<meta name="citation_lastpage" content="82">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4831/live-4831-8861-jair.pdf">

<cite>Ruben  Izquierdo, Armando  Suarez and German  Rigau (2015) "Word vs. Class-Based Word Sense Disambiguation", Volume 54, pages 83-122</cite>
<p class="media"><a href="/media/4727/live-4727-8863-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4727'>doi:10.1613/jair.4727</a></p>
<p>As empirically demonstrated by the Word Sense Disambiguation (WSD) tasks of the last SensEval/SemEval exercises, assigning the appropriate meaning to words in context has resisted all attempts to be successfully addressed. Many authors argue that one possible reason could be the use of inappropriate sets of word meanings. In particular, WordNet has been used as a de-facto standard repository of word meanings in most of these tasks. Thus, instead of using the word senses defined in WordNet, some approaches have derived semantic classes representing groups of word senses. However, the meanings represented by WordNet have been only used for WSD at a very fine-grained sense level or at a very coarse-grained semantic class level (also called SuperSenses). We suspect that an appropriate level of abstraction could be on between both levels. The contributions of this paper are manifold. First, we propose a simple method to automatically derive semantic classes at intermediate levels of abstraction covering all nominal and verbal WordNet meanings. Second, we empirically demonstrate that our automatically derived semantic classes outperform classical approaches based on word senses and more coarse-grained sense groupings. Third, we also demonstrate that our supervised WSD system benefits from using these new semantic classes as additional semantic features while reducing the amount of training examples. Finally, we also demonstrate the robustness of our supervised semantic class-based WSD system when tested on out of domain corpus.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Word vs. Class-Based Word Sense Disambiguation">
<meta name="citation_author" content="Izquierdo, Ruben">
<meta name="citation_author" content="Suarez, Armando">
<meta name="citation_author" content="Rigau, German">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="83">
<meta name="citation_lastpage" content="122">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4727/live-4727-8863-jair.pdf">

<cite>Scott  Kiesel, Ethan  Burns and Wheeler  Ruml (2015) "Achieving Goals Quickly Using Real-time Search: Experimental Results in Video Games", Volume 54, pages 123-158</cite>
<p class="media"><a href="/media/4800/live-4800-8884-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4800/live-4800-8885-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4800'>doi:10.1613/jair.4800</a></p>
<p>In real-time domains such as video games, planning happens concurrently with execution and the planning algorithm has a strictly bounded amount of time before it must return the next action for the agent to execute. We explore the use of real-time heuristic search in two benchmark domains inspired by video games. Unlike classic benchmarks such as grid pathfinding and the sliding tile puzzle, these new domains feature exogenous change and directed state space graphs. We consider the setting in which planning and acting are concurrent and we use the natural objective of minimizing goal achievement time. Using both the classic benchmarks and the new domains, we investigate several enhancements to a leading real-time search algorithm, LSS-LRTA*. We show experimentally that 1) it is better to plan after each action or to use a dynamically sized lookahead, 2) A*-based lookahead can cause undesirable actions to be selected, and 3) on-line de-biasing of the heuristic can lead to improved performance. We hope this work encourages future research on applying real-time search in dynamic domains.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Achieving Goals Quickly Using Real-time Search: Experimental Results in Video Games">
<meta name="citation_author" content="Kiesel, Scott">
<meta name="citation_author" content="Burns, Ethan">
<meta name="citation_author" content="Ruml, Wheeler">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="123">
<meta name="citation_lastpage" content="158">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4800/live-4800-8884-jair.pdf">

<cite>Llu&#237;s  Formiga, Alberto  Barr&#243;n-Cede&#241;o, Llu&#237;s  M&#224;rquez, Carlos A.  Henr&#237;quez and Jos&#233; B.  Mari&#241;o (2015) "Leveraging Online User Feedback to Improve Statistical Machine Translation", Volume 54, pages 159-192</cite>
<p class="media"><a href="/media/4716/live-4716-8890-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4716/live-4716-8891-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4716'>doi:10.1613/jair.4716</a></p>
<p>In this article we present a three-step methodology for dynamically improving a statistical machine translation (SMT) system by incorporating human feedback in the form of free edits on the system translations. We target at feedback provided by casual users, which is typically error-prone. Thus, we first propose a filtering step to automatically identify the better user-edited translations and discard the useless ones. A second step produces a pivot-based alignment between source and user-edited sentences, focusing on the errors made by the system. Finally, a third step produces a new translation model and combines it linearly with the one from the original system. We perform a thorough evaluation on a real-world dataset collected from the Reverso.net translation service and show that every step in our methodology contributes significantly to improve a general purpose SMT system. Interestingly, the quality improvement is not only due to the increase of lexical coverage, but to a better lexical selection, reordering, and morphology. Finally, we show the robustness of the methodology by applying it to a different scenario, in which the new examples come from an automatically Web-crawled parallel corpus. Using exactly the same architecture and models provides again a significant improvement of the translation quality of a general purpose baseline SMT system.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Leveraging Online User Feedback to Improve Statistical Machine Translation">
<meta name="citation_author" content="Formiga, Llu&#237;s">
<meta name="citation_author" content="Barr&#243;n-Cede&#241;o, Alberto">
<meta name="citation_author" content="M&#224;rquez, Llu&#237;s">
<meta name="citation_author" content="Henr&#237;quez, Carlos A.">
<meta name="citation_author" content="Mari&#241;o, Jos&#233; B.">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="159">
<meta name="citation_lastpage" content="192">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4716/live-4716-8890-jair.pdf">

<cite>Hannes  Strass (2015) "Expressiveness of Two-Valued Semantics for Abstract Dialectical Frameworks", Volume 54, pages 193-231</cite>
<p class="media"><a href="/media/4879/live-4879-8937-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4879/live-4879-8939-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4879'>doi:10.1613/jair.4879</a></p>
<p>We analyse the expressiveness of Brewka and Woltran's abstract dialectical frameworks for two-valued semantics. By expressiveness we mean the ability to encode a desired set of two-valued interpretations over a given propositional vocabulary A using only atoms from A. We also compare ADFs' expressiveness with that of (the two-valued semantics of) abstract argumentation frameworks, normal logic programs and propositional logic. While the computational complexity of the two-valued model existence problem for all these languages is (almost) the same, we show that the languages form a neat hierarchy with respect to their expressiveness. We then demonstrate that this hierarchy collapses once we allow to introduce a linear number of new vocabulary elements. We finally also analyse and compare the representational succinctness of ADFs (for two-valued model semantics), that is, their capability to represent two-valued interpretation sets in a space-efficient manner.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Expressiveness of Two-Valued Semantics for Abstract Dialectical Frameworks">
<meta name="citation_author" content="Strass, Hannes">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="193">
<meta name="citation_lastpage" content="231">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4879/live-4879-8937-jair.pdf">

<cite>Meir  Kalech and Shulamit  Reches (2015) "Decision Making with Dynamic Uncertain Events", Volume 54, pages 233-275</cite>
<p class="media"><a href="/media/4869/live-4869-8941-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4869'>doi:10.1613/jair.4869</a></p>
<p>When to make a decision is a key question in decision making problems characterized by uncertainty. In this paper we deal with decision making in environments where information arrives dynamically. We address the tradeoff between waiting and stopping strategies. On the one hand, waiting to obtain more information reduces uncertainty, but it comes with a cost. Stopping and making a decision based on an expected utility reduces the cost of waiting, but the decision is based on uncertain information. We propose an optimal algorithm and two approximation algorithms. We prove that one approximation is optimistic - waits at least as long as the optimal algorithm, while the other is pessimistic - stops not later than the optimal algorithm. We evaluate our algorithms theoretically and empirically and show that the quality of the decision in both approximations is near-optimal and much faster than the optimal algorithm. Also, we can conclude from the experiments that the cost function is a key factor to chose the most effective algorithm.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Decision Making with Dynamic Uncertain Events">
<meta name="citation_author" content="Kalech, Meir">
<meta name="citation_author" content="Reches, Shulamit">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="233">
<meta name="citation_lastpage" content="275">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4869/live-4869-8941-jair.pdf">

<cite>Till  Mossakowski and Reinhard  Moratz (2015) "Relations Between Spatial Calculi About Directions and Orientations", Volume 54, pages 277-308</cite>
<p class="media"><a href="/media/4631/live-4631-8942-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4631'>doi:10.1613/jair.4631</a></p>
<p>Qualitative spatial descriptions characterize essential properties of spatial objects or configurations by relying on relative comparisons rather than measuring. Typically, in qualitative approaches only relatively coarse distinctions between configurations are made. Qualitative spatial knowledge can be used to represent incomplete and underdetermined knowledge in a systematic way. This is especially useful if the task is to describe features of classes of configurations rather than individual configurations.<br />
<br />
Although reasoning with them is generally NP-hard, relative directions are important because they play a key role in human spatial descriptions and there are several approaches how to represent them using qualitative methods. In these approaches directions between spatial locations can be expressed as constraints over infinite domains, e.g. the Euclidean plane. The theory of relation algebras has been successfully applied to this field. Viewing relation algebras as universal algebras and applying and modifying standard tools from universal algebra in this work, we (re)define notions of qualitative constraint calculus, of homomorphism between calculi, and of quotient of calculi. Based on this method we derive important properties for spatial calculi from corresponding properties of related calculi. From a conceptual point of view these formal mappings between calculi are a means to translate between different granularities.<br />
</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Relations Between Spatial Calculi About Directions and Orientations">
<meta name="citation_author" content="Mossakowski, Till">
<meta name="citation_author" content="Moratz, Reinhard">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="277">
<meta name="citation_lastpage" content="308">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4631/live-4631-8942-jair.pdf">

<cite>Yujiao   Zhou, Bernardo  Cuenca Grau, Yavor  Nenov, Mark  Kaminski and Ian  Horrocks (2015) "PAGOdA: Pay-As-You-Go Ontology Query Answering Using a Datalog Reasoner", Volume 54, pages 309-367</cite>
<p class="media"><a href="/media/4757/live-4757-8949-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4757'>doi:10.1613/jair.4757</a></p>
<p>Answering conjunctive queries over ontology-enriched datasets is a core reasoning task for many applications. Query answering is, however, computationally very expensive, which has led to the development of query answering procedures that sacrifice either expressive power of the ontology language, or the completeness of query answers in order to improve scalability. In this paper, we describe a hybrid approach to query answering over OWL 2 ontologies that combines a datalog reasoner with a fully-fledged OWL 2 reasoner in order to provide scalable `pay-as-you-go' performance. The key feature of our approach is that it delegates the bulk of the computation to the datalog reasoner and resorts to expensive OWL 2 reasoning only as necessary to fully answer the query. Furthermore, although our main goal  is to efficiently answer queries over OWL 2 ontologies and data, our technical results are very general and our approach is applicable to first-order knowledge representation languages that can be captured by rules allowing for existential quantification and disjunction in the head; our only assumption is the availability of a datalog reasoner and a fully-fledged reasoner for the language of interest,  both of which are used as `black boxes'. We have implemented our techniques in the PAGOdA system, which combines the datalog reasoner RDFox and the  OWL 2 reasoner HermiT. Our extensive evaluation shows that PAGOdA succeeds in providing scalable pay-as-you-go query answering for a wide range of OWL 2 ontologies, datasets and queries.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="PAGOdA: Pay-As-You-Go Ontology Query Answering Using a Datalog Reasoner">
<meta name="citation_author" content="Zhou, Yujiao ">
<meta name="citation_author" content="Cuenca Grau, Bernardo">
<meta name="citation_author" content="Nenov, Yavor">
<meta name="citation_author" content="Kaminski, Mark">
<meta name="citation_author" content="Horrocks, Ian">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="309">
<meta name="citation_lastpage" content="367">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4757/live-4757-8949-jair.pdf">

<cite>Fazlul  Hasan Siddiqui and Patrik  Haslum (2015) "Continuing Plan Quality Optimisation", Volume 54, pages 369-435</cite>
<p class="media"><a href="/media/4980/live-4980-8969-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4980'>doi:10.1613/jair.4980</a>
<br/><a href="/media/4980/live-4980-8971-jair.tar.gz">Appendix </a> - BDPO2 source code</p>
<p>Finding high quality plans for large planning problems is hard. Although some current anytime planners are often able to improve plans quickly, they tend to reach a limit at which the plans produced are still very far from the best possible, but these planners fail to find any further improvement, even when given several hours of runtime.<br />
<br />
We present an approach to continuing plan quality optimisation at larger time scales, and its implementation in a system called BDPO2. Key to this approach is a decomposition into subproblems of improving parts of the current best plan. The decomposition is based on block deordering, a form of plan deordering which identifies hierarchical plan structure. BDPO2 can be seen as an application of the large neighbourhood search (LNS) local search strategy to planning, where the neighbourhood of a plan is defined by replacing one or more subplans with improved subplans. On-line learning is also used to adapt the strategy for selecting subplans and subplanners over the course of plan optimisation.<br />
<br />
Even starting from the best plans found by other means, BDPO2 is able to continue improving plan quality, often producing better plans than other anytime planners when all are given enough runtime. The best results, however, are achieved by a combination of different techniques working together.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Continuing Plan Quality Optimisation">
<meta name="citation_author" content="Siddiqui, Fazlul Hasan">
<meta name="citation_author" content="Haslum, Patrik">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="369">
<meta name="citation_lastpage" content="435">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4980/live-4980-8969-jair.pdf">

<cite>Igor  Rochlin and David  Sarne (2015) "Constraining Information Sharing to Improve Cooperative Information Gathering", Volume 54, pages 437-469</cite>
<p class="media"><a href="/media/4613/live-4613-8975-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4613/live-4613-8972-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4613'>doi:10.1613/jair.4613</a></p>
<p>This paper considers the problem of cooperation between self-interested agents in acquiring better information regarding the nature of the different options and opportunities available to them. By sharing individual findings with others, the agents can potentially achieve a substantial improvement in overall and individual expected benefits.  Unfortunately, it is well known that with self-interested agents equilibrium considerations often dictate solutions that are far from the fully cooperative ones, hence the agents do not manage to fully exploit the potential benefits encapsulated in such cooperation.  In this paper we introduce, analyze and demonstrate the benefit of five methods aiming to improve cooperative information gathering.  Common to all five that they constrain and limit the information sharing process.  Nevertheless, the decrease in benefit due to the limited sharing is outweighed by the resulting substantial improvement in the equilibrium individual information gathering strategies. The equilibrium analysis given in the paper, which, in itself is an important contribution to the study of cooperation between self-interested agents, enables demonstrating that for a wide range of settings an improved individual expected benefit is achieved for all agents when applying each of the five methods.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Constraining Information Sharing to Improve Cooperative Information Gathering">
<meta name="citation_author" content="Rochlin, Igor">
<meta name="citation_author" content="Sarne, David">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="437">
<meta name="citation_lastpage" content="469">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4613/live-4613-8975-jair.pdf">

<cite>Joseph  Y. Halpern (2015) "Weighted Regret-Based Likelihood: A New Approach to Describing Uncertainty", Volume 54, pages 471-492</cite>
<p class="media"><a href="/media/4859/live-4859-8977-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4859'>doi:10.1613/jair.4859</a></p>
<p>Recently, Halpern and Leung suggested representing uncertainty by a set of weighted  probability measures, and suggested a way of making decisions based on this representation of uncertainty: maximizing weighted regret.  Their paper does not answer an apparently simpler question: what it means, according to this representation of uncertainty, for an event E to be more likely than an event E'.    In this paper, a notion of comparative likelihood when uncertainty is represented by a set of weighted probability measures is defined.  It generalizes the ordering defined by probability (and by lower probability) in a natural way; a generalization of upper probability can also be defined.  A complete axiomatic characterization of this notion of regret-based likelihood is given. <br />
</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Weighted Regret-Based Likelihood: A New Approach to Describing Uncertainty">
<meta name="citation_author" content="Halpern, Joseph Y.">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="471">
<meta name="citation_lastpage" content="492">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4859/live-4859-8977-jair.pdf">

<cite>Haris  Aziz, Markus   Brill, Felix   Fischer, Paul   Harrenstein, Jerome  Lang and Hans Georg  Seedig (2015) "Possible and Necessary Winners of Partial Tournaments", Volume 54, pages 493-534</cite>
<p class="media"><a href="/media/4856/live-4856-9005-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4856/live-4856-9004-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4856'>doi:10.1613/jair.4856</a></p>
<p>We study the problem of computing possible and necessary winners for partially specified weighted and unweighted tournaments. This problem arises naturally in elections with incompletely specified votes, partially completed sports competitions, and more generally in any scenario where the outcome of some pairwise comparisons is not yet fully known. We specifically consider a number of well-known solution concepts---including the uncovered set, Borda, ranked pairs, and maximin---and show that for most of them, possible and necessary winners can be identified in polynomial time. These positive algorithmic results stand in sharp contrast to earlier results concerning possible and necessary winners given partially specified preference profiles.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Possible and Necessary Winners of Partial Tournaments">
<meta name="citation_author" content="Aziz, Haris">
<meta name="citation_author" content="Brill, Markus ">
<meta name="citation_author" content="Fischer, Felix ">
<meta name="citation_author" content="Harrenstein, Paul ">
<meta name="citation_author" content="Lang, Jerome">
<meta name="citation_author" content="Seedig, Hans Georg">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="493">
<meta name="citation_lastpage" content="534">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4856/live-4856-9005-jair.pdf">

<cite>Andreas  Steigmiller and Birte  Glimm (2015) "Pay-As-You-Go Description Logic Reasoning by Coupling Tableau and Saturation Procedures", Volume 54, pages 535-592</cite>
<p class="media"><a href="/media/4897/live-4897-9009-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4897'>doi:10.1613/jair.4897</a></p>
<p>Nowadays, saturation-based reasoners for the OWL EL profile of the Web Ontology Language are able to handle large ontologies such as SNOMED very efficiently. However, it is currently unclear how saturation-based reasoning procedures can be extended to very expressive Description Logics such as SROIQ--the logical underpinning of the current and second iteration of the Web Ontology Language. Tableau-based procedures, on the other hand, are not limited to specific Description Logic languages or OWL profiles, but even highly optimised tableau-based reasoners might not be efficient enough to handle large ontologies such as SNOMED. In this paper, we present an approach for tightly coupling tableau- and saturation-based procedures that we implement in the OWL DL reasoner Konclude. Our detailed evaluation shows that this combination significantly improves the reasoning performance for a wide range of ontologies.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Pay-As-You-Go Description Logic Reasoning by Coupling Tableau and Saturation Procedures">
<meta name="citation_author" content="Steigmiller, Andreas">
<meta name="citation_author" content="Glimm, Birte">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="535">
<meta name="citation_lastpage" content="592">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4897/live-4897-9009-jair.pdf">

<cite>Ben  Strasser, Adi  Botea and Daniel  Harabor (2015) "Compressing Optimal Paths with Run Length Encoding", Volume 54, pages 593-629</cite>
<p class="media"><a href="/media/4931/live-4931-9024-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4931'>doi:10.1613/jair.4931</a></p>
<p>We introduce a novel approach to Compressed Path Databases, space efficient oracles used to very quickly identify the first edge on a shortest path. Our algorithm achieves query running times on the 100 nanosecond scale, being significantly faster than state-of-the-art first-move oracles from the literature. Space consumption is competitive, due to a compression approach that rearranges rows and columns in a first-move matrix and then performs run length encoding (RLE) on the contents of the matrix. One variant of our implemented system was, by a convincing margin, the fastest entry in the 2014 Grid-Based Path Planning Competition.<br />
<br />
We give a first tractability analysis for the compression scheme used by our algorithm. We study the complexity of computing a database of minimum size for general directed and undirected graphs. We find that in both cases the problem is NP-complete. We also show that, for graphs which can be decomposed along articulation points, the problem can be decomposed into independent parts, with a corresponding reduction in its level of difficulty. In particular, this leads to simple and tractable algorithms with linear running time which yield optimal compression results for trees.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="Compressing Optimal Paths with Run Length Encoding">
<meta name="citation_author" content="Strasser, Ben">
<meta name="citation_author" content="Botea, Adi">
<meta name="citation_author" content="Harabor, Daniel">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="593">
<meta name="citation_lastpage" content="629">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4931/live-4931-9024-jair.pdf">

<cite>Tatsuya  Imai and Alex  Fukunaga (2015) "On a Practical,  Integer-Linear Programming Model for Delete-Free Tasks and its Use as a Heuristic for Cost-Optimal Planning", Volume 54, pages 631-677</cite>
<p class="media"><a href="/media/4936/live-4936-9030-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/4936/live-4936-9029-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4936'>doi:10.1613/jair.4936</a></p>
<p>We propose a new integer-linear programming model for the delete relaxation in cost-optimal planning. While a straightforward IP for the delete relaxation is impractical, our enhanced model incorporates variable reduction techniques based on  landmarks, relevance-based constraints, dominated action elimination, immediate action application, and inverse action constraints, resulting in an IP that can be used to directly solve delete-free planning problems. We show that our IP model is competitive with previous state-of-the-art solvers for delete-free problems. The LP-relaxation of the IP model is often a very good approximation to the IP, providing an approach to approximating the optimal value of the delete-free task that is complementary to the well-known LM-cut heuristic. We also show that constraints that partially consider delete effects can be added to our IP/LP models. We embed the new IP/LP models into a forward-search based planner, and show that the performance of the resulting planner on standard IPC benchmarks is comparable with the state-of-the-art for cost-optimal planning.</p>
<a href="/vol/vol54.html">Click here to return to Volume 54 contents list</a>
<meta name="citation_title" content="On a Practical,  Integer-Linear Programming Model for Delete-Free Tasks and its Use as a Heuristic for Cost-Optimal Planning">
<meta name="citation_author" content="Imai, Tatsuya">
<meta name="citation_author" content="Fukunaga, Alex">
<meta name="citation_publication_date" content="2015">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="631">
<meta name="citation_lastpage" content="677">
<meta name="citation_volume" content="54">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4936/live-4936-9030-jair.pdf">
