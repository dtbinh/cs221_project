<cite>K.  Yip and  F.  Zhao (1996) "Spatial Aggregation: Theory and Applications", Volume 5, pages 1-26</cite>
<p class="media"><a href="/media/315/live-315-1573-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/315/live-315-1572-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.315'>doi:10.1613/jair.315</a></p>
<p>Visual thinking plays an important role in scientific    reasoning.  Based on the research in automating diverse reasoning    tasks about dynamical systems, nonlinear controllers, kinematic    mechanisms, and fluid motion, we have identified a style of visual    thinking, imagistic reasoning.  Imagistic reasoning organizes    computations around image-like, analogue representations so that    perceptual and symbolic operations can be brought to bear to infer    structure and behavior.  Programs incorporating imagistic reasoning    have been shown to perform at an expert level in domains that defy    current analytic or numerical methods.<p>        We have developed a computational paradigm, spatial aggregation, to    unify the description of a class of imagistic problem solvers.  A    program written in this paradigm has the following properties.  It    takes a continuous field and optional objective functions as input,    and produces high-level descriptions of structure, behavior, or    control actions. It computes a multi-layer of intermediate    representations, called spatial aggregates, by forming equivalence    classes and adjacency relations.  It employs a small set of generic    operators such as aggregation, classification, and localization to    perform bidirectional mapping between the information-rich field and    successively more abstract spatial aggregates. It uses a data    structure, the neighborhood graph, as a common interface to modularize    computations.  To illustrate our theory, we describe the computational    structure of three implemented problem solvers -- KAM, MAPS, and    HIPAIR --- in terms of the spatial aggregation generic operators by    mixing and matching a library of commonly used routines.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Spatial Aggregation: Theory and Applications">
<meta name="citation_author" content="Yip,  K.">
<meta name="citation_author" content="Zhao,  F.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="26">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/315/live-315-1573-jair.pdf">

<cite>R.  Ben-Eliyahu (1996) "A Hierarchy of Tractable Subsets for Computing Stable Models", Volume 5, pages 27-52</cite>
<p class="media"><a href="/media/223/live-223-1497-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/223/live-223-1495-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.223'>doi:10.1613/jair.223</a></p>
<p>Finding the stable models of a knowledge base is a    significant computational problem in artificial intelligence. This    task is at the computational heart of truth maintenance systems,    autoepistemic logic, and default logic.  Unfortunately, it is NP-hard.    In this paper we present a hierarchy of classes of knowledge bases,    Omega_1,Omega_2,..., with the following properties: first, Omega_1 is    the class of all stratified knowledge bases; second, if a knowledge    base Pi is in Omega_k, then Pi has at most k stable models, and all of    them may be found in time O(lnk), where l is the length of the    knowledge base and n the number of atoms in Pi; third, for an    arbitrary knowledge base Pi, we can find the minimum k such that Pi    belongs to Omega_k in time polynomial in the size of Pi; and, last,    where K is the class of all knowledge bases, it is the case that    union{i=1 to infty} Omega_i = K, that is, every knowledge base    belongs to some class in the hierarchy.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="A Hierarchy of Tractable Subsets for Computing Stable Models">
<meta name="citation_author" content="Ben-Eliyahu,  R.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="27">
<meta name="citation_lastpage" content="52">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/223/live-223-1497-jair.pdf">

<cite>D.  J. Litman (1996) "Cue Phrase Classification Using Machine Learning", Volume 5, pages 53-94</cite>
<p class="media"><a href="/media/327/live-327-1589-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/327/live-327-1588-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.327'>doi:10.1613/jair.327</a></p>
<p>Cue phrases may be used in a discourse sense to explicitly    signal discourse structure, but also in a sentential sense to convey    semantic rather than structural information.  Correctly classifying    cue phrases as discourse or sentential is critical in natural language    processing systems that exploit discourse structure, e.g., for    performing tasks such as anaphora resolution and plan recognition.    This paper explores the use of machine learning for classifying cue    phrases as discourse or sentential.  Two machine learning programs    (Cgrendel and C4.5) are used to induce classification models from sets    of pre-classified cue phrases and their features in text and speech.    Machine learning is shown to be an effective technique for not only    automating the generation of classification models, but also for    improving upon previous results.  When compared to manually derived    classification models already in the literature, the learned models    often perform with higher accuracy and contain new linguistic insights    into the data.  In addition, the ability to automatically construct    classification models makes it easier to comparatively analyze the    utility of alternative feature representations of the data.  Finally,    the ease of retraining makes the learning approach more scalable and    flexible than manual methods.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Cue Phrase Classification Using Machine Learning">
<meta name="citation_author" content="Litman,  D. J.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="53">
<meta name="citation_lastpage" content="94">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/327/live-327-1589-jair.pdf">

<cite>A.  Gerevini and  L.  Schubert (1996) "Accelerating Partial-Order Planners: Some Techniques for Effective Search Control and Pruning", Volume 5, pages 95-137</cite>
<p class="media"><a href="/media/316/live-316-1576-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/316/live-316-1575-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.316'>doi:10.1613/jair.316</a>
<br/><a href="/media/316/live-316-1579-jair.txt">Appendix </a> - domain description</p>
<p>We propose some domain-independent techniques for bringing well-founded partial-order planners closer to practicality. The first two techniques are aimed at improving search control while keeping overhead costs low.  One is based on a simple adjustment to the default A* heuristic used by UCPOP to select plans for refinement. The other is based on preferring ``zero commitment'' (forced) plan refinements whenever possible, and using LIFO prioritization otherwise. A more radical technique is the use of operator parameter domains to prune search. These domains are initially computed from the definitions of the operators and the initial and goal conditions, using a polynomial-time algorithm that propagates sets of constants through the operator graph, starting in the initial conditions. During planning, parameter domains can be used to prune nonviable operator instances and to remove spurious clobbering threats.  In experiments based on modifications of UCPOP, our improved plan and goal selection strategies gave speedups by factors ranging from 5 to more than 1000 for a variety of problems that are nontrivial for the unmodified version. Crucially, the hardest problems gave the greatest improvements. The pruning technique based on parameter domains often gave speedups by an order of magnitude or more for difficult problems, both with the default UCPOP search strategy and with our improved strategy. The Lisp code for our techniques and for the test problems is provided in on-line appendices.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Accelerating Partial-Order Planners: Some Techniques for Effective Search Control and Pruning">
<meta name="citation_author" content="Gerevini,  A.">
<meta name="citation_author" content="Schubert,  L.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="95">
<meta name="citation_lastpage" content="137">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/316/live-316-1576-jair.pdf">

<cite>J.  R. Quinlan (1996) "Learning First-Order Definitions of Functions", Volume 5, pages 139-161</cite>
<p class="media"><a href="/media/308/live-308-1570-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/308/live-308-1569-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.308'>doi:10.1613/jair.308</a></p>
<p>First-order learning involves finding a clause-form    definition of a relation from examples of the relation and relevant    background information.  In this paper, a particular first-order    learning system is modified to customize it for finding definitions of    functional relations.  This restriction leads to faster learning times    and, in some cases, to definitions that have higher predictive    accuracy.  Other first-order learning systems might benefit from    similar specialization.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Learning First-Order Definitions of Functions">
<meta name="citation_author" content="Quinlan,  J. R.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="139">
<meta name="citation_lastpage" content="161">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/308/live-308-1570-jair.pdf">

<cite>G.  Zlotkin and  J.  S. Rosenschein (1996) "Mechanisms for Automated Negotiation in State Oriented Domains", Volume 5, pages 163-238</cite>
<p class="media"><a href="/media/72/live-72-1411-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/72/live-72-1410-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.72'>doi:10.1613/jair.72</a></p>
<p>This paper lays part of the groundwork for a domain theory of    negotiation, that is, a way of classifying interactions so that it is    clear, given a domain, which negotiation mechanisms and strategies are    appropriate.  We define State Oriented Domains, a general category of    interaction.  Necessary and sufficient conditions for cooperation are    outlined.  We use the notion of worth in an altered definition of    utility, thus enabling agreements in a wider class of joint-goal    reachable situations. An approach is offered for conflict resolution,    and it is shown that even in a conflict situation, partial cooperative    steps can be taken by interacting agents (that is, agents in    fundamental conflict might still agree to cooperate up to a certain    point).<p>     A Unified Negotiation Protocol (UNP) is developed that can be used in    all types of encounters. It is shown that in certain borderline    cooperative situations, a partial cooperative agreement (i.e., one    that does not achieve all agents' goals) might be preferred by all    agents, even though there exists a rational agreement that would    achieve all their goals.<p>     Finally, we analyze cases where agents have incomplete information on    the goals and worth of other agents. First we consider the case where    agents' goals are private information, and we analyze what goal    declaration strategies the agents might adopt to increase their    utility.  Then, we consider the situation where the agents' goals (and    therefore stand-alone costs) are common knowledge, but the worth they    attach to their goals is private information.  We introduce two    mechanisms, one 'strict', the other 'tolerant', and analyze their    affects on the stability and efficiency of negotiation outcomes.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Mechanisms for Automated Negotiation in State Oriented Domains">
<meta name="citation_author" content="Zlotkin,  G.">
<meta name="citation_author" content="Rosenschein,  J. S.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="163">
<meta name="citation_lastpage" content="238">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/72/live-72-1411-jair.pdf">

<cite>R.  A. Helzerman and  M.  P. Harper (1996) "MUSE CSP: An Extension to the Constraint Satisfaction Problem", Volume 5, pages 239-288</cite>
<p class="media"><a href="/media/298/live-298-1558-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/298/live-298-1557-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.washington.edu/research/jair/volume5/helzerman96a-html/muse-csp.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.298'>doi:10.1613/jair.298</a></p>
<p>This paper describes an extension to the constraint    satisfaction problem (CSP) called MUSE CSP (MUltiply SEgmented    Constraint Satisfaction Problem).  This extension is especially useful    for those problems which segment into multiple sets of partially    shared variables.  Such problems arise naturally in signal processing    applications including computer vision, speech processing, and    handwriting recognition.  For these applications, it is often    difficult to segment the data in only one way given the low-level    information utilized by the segmentation algorithms.  MUSE CSP can be    used to compactly represent several similar instances of the    constraint satisfaction problem.  If multiple instances of a CSP have    some common variables which have the same domains and constraints,    then they can be combined into a single instance of a MUSE CSP,    reducing the work required to apply the constraints.  We introduce the    concepts of MUSE node consistency, MUSE arc consistency, and MUSE path    consistency. We then demonstrate how MUSE CSP can be used to compactly    represent lexically ambiguous sentences and the multiple sentence    hypotheses that are often generated by speech recognition algorithms    so that grammar constraints can be used to provide parses for all    syntactically correct sentences.  Algorithms for MUSE arc and path    consistency are provided.  Finally, we discuss how to create a MUSE    CSP from a set of CSPs which are labeled to indicate when the same    variable is shared by more than a single CSP.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="MUSE CSP: An Extension to the Constraint Satisfaction Problem">
<meta name="citation_author" content="Helzerman,  R. A.">
<meta name="citation_author" content="Harper,  M. P.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="239">
<meta name="citation_lastpage" content="288">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/298/live-298-1558-jair.pdf">

<cite>L.  M. de Campos (1996) "Characterizations of Decomposable Dependency Models", Volume 5, pages 289-300</cite>
<p class="media"><a href="/media/329/live-329-1592-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/329/live-329-1591-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.329'>doi:10.1613/jair.329</a></p>
<p>Decomposable dependency models possess a number of    interesting and useful properties. This paper presents new    characterizations of decomposable models in terms of independence    relationships, which are obtained by adding a single axiom to the    well-known set characterizing dependency models that are isomorphic to    undirected graphs. We also briefly discuss a potential application of    our results to the problem of learning graphical models from data.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Characterizations of Decomposable Dependency Models">
<meta name="citation_author" content="de Campos,  L. M.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="289">
<meta name="citation_lastpage" content="300">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/329/live-329-1592-jair.pdf">

<cite>N.  L. Zhang and  D.  Poole (1996) "Exploiting Causal Independence in Bayesian Network Inference", Volume 5, pages 301-328</cite>
<p class="media"><a href="/media/305/live-305-1566-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/305/live-305-1565-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.ubc.ca/spider/poole/papers/ZhangPoole96/ZhangPoole96.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.305'>doi:10.1613/jair.305</a></p>
<p>A new method is proposed for exploiting causal    independencies in exact Bayesian network inference.  A Bayesian    network can be viewed as representing a factorization of a joint    probability into the multiplication of a set of conditional    probabilities.  We present a notion of causal independence that    enables one to further factorize the conditional probabilities into a    combination of even smaller factors and consequently obtain a    finer-grain factorization of the joint probability.  The new    formulation of causal independence lets us specify the conditional    probability of a variable given its parents in terms of an associative    and commutative operator, such as ``or'', ``sum'' or ``max'', on the    contribution of each parent.  We start with a simple algorithm VE for    Bayesian network inference that, given evidence and a query variable,    uses the factorization to find the posterior distribution of the    query. We show how this algorithm can be extended to exploit causal    independence. Empirical studies, based on the CPCS networks for    medical diagnosis, show that this method is more efficient than    previous methods and allows for inference in larger networks than    previous algorithms.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Exploiting Causal Independence in Bayesian Network Inference">
<meta name="citation_author" content="Zhang,  N. L.">
<meta name="citation_author" content="Poole,  D.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="301">
<meta name="citation_lastpage" content="328">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/305/live-305-1566-jair.pdf">

<cite>J.  C. Schlimmer and  P.  C. Wells (1996) "Quantitative Results Comparing Three Intelligent Interfaces forInformation Capture: A Case Study Adding Name Information into a", Volume 5, pages 329-349</cite>
<p class="media"><a href="/media/321/live-321-1584-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/321/live-321-1583-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.washington.edu/research/jair/volume5/schlimmer96a-html/schlimmer96-0.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.321'>doi:10.1613/jair.321</a>
<br/><a href="/media/321/live-321-1587-jair.hqx">Appendix </a> - Source code, bin hexed</p>
<p>Efficiently entering information into a computer is key to    enjoying the benefits of computing. This paper describes three    intelligent user interfaces: handwriting recognition, adaptive menus,    and predictive fillin. In the context of adding a personUs name and    address to an electronic organizer, tests show handwriting recognition    is slower than typing on an on-screen, soft keyboard, while adaptive    menus and predictive fillin can be twice as fast. This paper also    presents strategies for applying these three interfaces to other    information collection domains.</p>
<a href="/vol/vol5.html">Click here to return to Volume 5 contents list</a>
<meta name="citation_title" content="Quantitative Results Comparing Three Intelligent Interfaces forInformation Capture: A Case Study Adding Name Information into a">
<meta name="citation_author" content="Schlimmer,  J. C.">
<meta name="citation_author" content="Wells,  P. C.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="329">
<meta name="citation_lastpage" content="349">
<meta name="citation_volume" content="5">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/321/live-321-1584-jair.pdf">
