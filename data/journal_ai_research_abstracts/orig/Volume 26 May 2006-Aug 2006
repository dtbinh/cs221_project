<cite>J.  Y. Halpern and R.  Pucella (2006) "A Logic for Reasoning about Evidence", Volume 26, pages 1-34</cite>
<p class="media"><a href="/media/1838/live-1838-2662-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1838/live-1838-2663-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1838'>doi:10.1613/jair.1838</a></p>
<p>We introduce a logic for reasoning about evidence that essentially<br />
views evidence as a function from prior beliefs (before making an<br />
observation) to posterior beliefs (after making the observation).  <br />
We provide a sound and complete axiomatization for the logic, and<br />
consider the complexity of the decision problem.  Although the reasoning in the logic is mainly propositional, we allow variables representing numbers and quantification over them.  This expressive power seems necessary to capture important properties of evidence.<br />
</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="A Logic for Reasoning about Evidence">
<meta name="citation_author" content="Halpern, J. Y.">
<meta name="citation_author" content="Pucella, R.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="34">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1838/live-1838-2662-jair.pdf">

<cite>D.  Bryce, S.  Kambhampati and D.  E. Smith (2006) "Planning Graph Heuristics for Belief Space Search", Volume 26, pages 35-99</cite>
<p class="media"><a href="/media/1869/live-1869-2670-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1869/live-1869-2669-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume26/bryce06a-html/index.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1869'>doi:10.1613/jair.1869</a>
<br/><a href="/media/1869/live-1869-2674-jair.tgz">Appendix 1</a> - Problem Instances used in Empirical Evaluation&nbsp;|&nbsp;<a href="/media/1869/live-1869-2675-jair.tgz">Appendix 2</a> - POND planner binary.&nbsp;|&nbsp;<a href="/media/1869/live-1869-2676-jair.tgz">Appendix 3</a> - CAltAlt planner binary.</p>
<p>Some recent works in conditional planning have proposed reachability heuristics to improve planner scalability, but many lack a formal description of the properties of their distance estimates. To place previous work in context and extend work on heuristics for conditional planning, we provide a formal basis for distance estimates between belief states.  We give a definition for the distance between belief states that relies on aggregating underlying state distance measures.  We give several techniques to aggregate state distances and their associated properties.  Many existing heuristics exhibit a subset of the properties, but in order to provide a standardized comparison we present several generalizations of planning graph heuristics that are used in a single planner.  We compliment our belief state distance estimate framework by also investigating efficient planning graph data structures that incorporate BDDs to compute the most effective heuristics.<br />
<br />
We developed two planners to serve as test-beds for our investigation.  The first, CAltAlt, is a conformant regression planner that uses A* search.  The second, POND, is a conditional progression planner that uses AO* search. We show the relative effectiveness of our heuristic techniques within these planners. We also compare the performance of these planners with several state of the art approaches in conditional planning. </p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Planning Graph Heuristics for Belief Space Search">
<meta name="citation_author" content="Bryce, D.">
<meta name="citation_author" content="Kambhampati, S.">
<meta name="citation_author" content="Smith, D. E.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="35">
<meta name="citation_lastpage" content="99">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1869/live-1869-2670-jair.pdf">

<cite>H.  Daume III and D.  Marcu (2006) "Domain Adaptation for Statistical Classifiers", Volume 26, pages 101-126</cite>
<p class="media"><a href="/media/1872/live-1872-2703-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1872/live-1872-2702-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1872'>doi:10.1613/jair.1872</a></p>
<p>The most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution.  Unfortunately, in many applications, the "in-domain" test data is drawn from a distribution that is related, but not identical, to the "out-of-domain" distribution of the training data. We consider the common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is scarce.  We introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts.  We present efficient inference algorithms for this special case based on the technique of conditional expectation maximization.  Our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain. </p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Domain Adaptation for Statistical Classifiers">
<meta name="citation_author" content="Daume III, H.">
<meta name="citation_author" content="Marcu, D.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="101">
<meta name="citation_lastpage" content="126">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1872/live-1872-2703-jair.pdf">

<cite>R.  Booth and T.  Meyer (2006) "Admissible and Restrained Revision", Volume 26, pages 127-151</cite>
<p class="media"><a href="/media/1874/live-1874-2706-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1874/live-1874-2707-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1874'>doi:10.1613/jair.1874</a></p>
<p>As partial justification of their framework for iterated belief revision Darwiche and Pearl convincingly argued against Boutilier's natural revision and provided a prototypical revision operator that fits into their scheme.  We show that the Darwiche-Pearl arguments lead naturally to the acceptance of a smaller class of operators which we refer to as admissible. Admissible revision ensures that the penultimate input is not ignored completely, thereby eliminating natural revision, but includes the Darwiche-Pearl operator, Nayak's lexicographic revision operator, and a newly introduced operator called restrained revision. We demonstrate that restrained revision is the most conservative of admissible revision operators,  effecting as few changes as possible, while lexicographic revision is the least conservative, and point out that restrained revision can also be viewed as a composite operator, consisting of natural revision preceded by an application of a "backwards revision" operator previously studied by Papini. Finally, we propose the establishment of a principled approach for choosing an appropriate revision operator in different contexts and discuss future work. </p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Admissible and Restrained Revision">
<meta name="citation_author" content="Booth, R.">
<meta name="citation_author" content="Meyer, T.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="127">
<meta name="citation_lastpage" content="151">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1874/live-1874-2706-jair.pdf">

<cite>T.  Heskes (2006) "Convexity Arguments for Efficient Minimization of the Bethe and Kikuchi Free Energies", Volume 26, pages 153-190</cite>
<p class="media"><a href="/media/1933/live-1933-2716-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1933/live-1933-2715-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1933'>doi:10.1613/jair.1933</a></p>
<p>Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms have been shown to correspond to extrema of the Bethe and Kikuchi free energy, both of which are approximations of the exact Helmholtz free energy. However, belief propagation does not always converge, which motivates approaches that explicitly minimize the Kikuchi/Bethe free energy, such as CCCP and UPS.<br />
<br />
Here we describe a class of algorithms that solves this typically non-convex constrained minimization problem through a sequence of  convex constrained minimizations of upper bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to faster algorithms, which is indeed convincingly demonstrated in our simulations. Several ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP.</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Convexity Arguments for Efficient Minimization of the Bethe and Kikuchi Free Energies">
<meta name="citation_author" content="Heskes, T.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="153">
<meta name="citation_lastpage" content="190">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1933/live-1933-2716-jair.pdf">

<cite>M.  Helmert (2006) "The Fast Downward Planning System", Volume 26, pages 191-246</cite>
<cite>Honorable Mention for the 2009 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/1705/live-1705-2731-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1705/live-1705-2730-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1705'>doi:10.1613/jair.1705</a>
<br/><a href="/media/1705/live-1705-2734-jair.tar.gz">Appendix </a> - Experimental results</p>
<p>Fast Downward is a classical planning system based on heuristic search. It can deal with general deterministic planning problems encoded in the propositional fragment of PDDL2.2, including advanced features like ADL conditions and effects and derived predicates (axioms). Like other well-known planners such as HSP and FF, Fast Downward is a progression planner, searching the space of world states of a planning task in the forward direction. However, unlike other PDDL planning systems, Fast Downward does not use the propositional PDDL representation of a planning task directly. Instead, the input is first translated into an alternative representation called multi-valued planning tasks, which makes many of the implicit constraints of a propositional planning task explicit. Exploiting this alternative representation, Fast Downward uses hierarchical decompositions of planning tasks for computing its heuristic function, called the causal graph heuristic, which is very different from traditional HSP-like heuristics based on ignoring negative interactions of operators.<br />
<br />
In this article, we give a full account of Fast Downward's approach to solving multi-valued planning tasks. We extend our earlier discussion of the causal graph heuristic to tasks involving axioms and conditional effects and present some novel techniques for search control that are used within Fast Downward's best-first search algorithm: preferred operators transfer the idea of helpful actions from local search to global best-first search, deferred evaluation of heuristic functions mitigates the negative effect of large branching factors on search performance, and multi-heuristic best-first search combines several heuristic evaluation functions within a single search algorithm in an orthogonal way. We also describe efficient data structures for fast state expansion (successor generators and axiom evaluators) and present a new non-heuristic search algorithm called focused iterative-broadening search, which utilizes the information encoded in causal graphs in a novel way.<br />
<br />
Fast Downward has proven remarkably successful: It won the "classical'' (i.e., propositional, non-optimising) track of the 4th International Planning Competition at ICAPS 2004, following in the footsteps of planners such as FF and LPG. Our experiments show that it also performs very well on the benchmarks of the earlier planning competitions and provide some insights about the usefulness of the new search enhancements.<br />
</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="The Fast Downward Planning System">
<meta name="citation_author" content="Helmert, M.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="191">
<meta name="citation_lastpage" content="246">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1705/live-1705-2731-jair.pdf">

<cite>M.  J. Streeter and S.  F. Smith (2006) "How the Landscape of Random Job Shop Scheduling Instances Depends on the Ratio of Jobs to Machines", Volume 26, pages 247-287</cite>
<p class="media"><a href="/media/2013/live-2013-2749-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2013/live-2013-2755-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2013'>doi:10.1613/jair.2013</a></p>
<p>We characterize the search landscape of random instances of the job shop scheduling problem (JSP).  Specifically, we investigate how the expected values of (1) backbone size, (2) distance between near-optimal schedules, and (3) makespan of random schedules vary as a function of the job to machine ratio (N/M).  For the limiting cases N/M approaches 0 and N/M approaches infinity we provide analytical results, while for intermediate values of N/M we perform experiments.  We prove that as N/M approaches 0, backbone size approaches 100%, while as N/M approaches infinity the backbone vanishes.  In the process we show that as N/M approaches 0 (resp. N/M approaches infinity), simple priority rules almost surely generate an optimal schedule, providing theoretical evidence of an "easy-hard-easy" pattern of typical-case instance difficulty in job shop scheduling.  We also draw connections between our theoretical results and the "big valley" picture of JSP landscapes.</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="How the Landscape of Random Job Shop Scheduling Instances Depends on the Ratio of Jobs to Machines">
<meta name="citation_author" content="Streeter, M. J.">
<meta name="citation_author" content="Smith, S. F.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="247">
<meta name="citation_lastpage" content="287">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2013/live-2013-2749-jair.pdf">

<cite>A.  Ramani, I.  L. Markov, K.  A. Sakallah and F.  A. Aloul (2006) "Breaking Instance-Independent Symmetries In Exact Graph Coloring", Volume 26, pages 289-322</cite>
<p class="media"><a href="/media/1637/live-1637-2770-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1637/live-1637-2769-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1637'>doi:10.1613/jair.1637</a></p>
<p>Code optimization and high level synthesis can be posed as constraint satisfaction and optimization problems,  such as graph coloring used in register allocation.  Graph coloring is also used to model more traditional CSPs relevant to AI, such as planning, time-tabling and scheduling.  Provably optimal solutions may be desirable for commercial and defense applications. Additionally, for applications such as register allocation and code optimization, naturally-occurring instances    of graph coloring are often small and can be solved optimally. A recent  wave of improvements in algorithms for Boolean satisfiability (SAT) and 0-1 Integer Linear Programming (ILP) suggests generic problem-reduction  methods, rather than problem-specific heuristics, because (1) heuristics may be upset by new constraints, (2) heuristics tend to ignore structure, and (3) many relevant problems are provably inapproximable. <br />
<br />
Problem reductions often lead to highly symmetric SAT instances, and symmetries are known to slow down SAT solvers. In this work, we compare several avenues for symmetry breaking, in particular when certain kinds of symmetry are present in all generated instances.  Our focus on reducing CSPs to SAT allows us to leverage recent dramatic improvement in SAT solvers and automatically benefit from future progress. We can use a variety of black-box SAT solvers  without modifying their source code because our symmetry-breaking techniques are static, i.e., we detect symmetries and add symmetry breaking predicates (SBPs) during pre-processing.<br />
<br />
An important result of our work is that among the types  of instance-independent SBPs we studied and their combinations, the simplest and least complete constructions are the most effective. Our experiments also clearly indicate that instance-independent symmetries should mostly be processed together with instance-specific symmetries rather than at the specification level, contrary to what has been suggested in the<br />
literature.<br />
</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Breaking Instance-Independent Symmetries In Exact Graph Coloring">
<meta name="citation_author" content="Ramani, A.">
<meta name="citation_author" content="Markov, I. L.">
<meta name="citation_author" content="Sakallah, K. A.">
<meta name="citation_author" content="Aloul, F. A.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="289">
<meta name="citation_lastpage" content="322">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1637/live-1637-2770-jair.pdf">

<cite>Y.  Chen, B.  W. Wah and C.  Hsu (2006) "Temporal Planning using Subgoal Partitioning and Resolution in SGPlan", Volume 26, pages 323-369</cite>
<p class="media"><a href="/media/1918/live-1918-2779-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1918/live-1918-2780-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1918'>doi:10.1613/jair.1918</a></p>
<p>In this paper, we present the partitioning of mutual-exclusion (mutex) constraints in temporal planning problems and its implementation in the SGPlan4 planner. Based on the strong locality of mutex constraints observed in many benchmarks of the Fourth International Planning Competition (IPC4), we propose to partition the constraints of a planning problem into groups based on their subgoals. Constraint partitioning leads to significantly easier subproblems that are similar to the original problem and that can be efficiently solved by the same planner with some modifications to its objective function. We present a partition-and-resolve strategy that looks for locally optimal subplans in constraint-partitioned temporal planning subproblems and that resolves those inconsistent global constraints across the subproblems. We also discuss some implementation details of SGPlan4, which include the resolution of violated global constraints, techniques for handling producible resources, landmark analysis, path finding and optimization, search-space reduction, and modifications of Metric-FF when used as a basic planner in SGPlan4.  Last, we show results on the sensitivity of each of these techniques in quality-time trade-offs and experimentally demonstrate that SGPlan4 is effective for solving the IPC3 and IPC4 benchmarks.</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Temporal Planning using Subgoal Partitioning and Resolution in SGPlan">
<meta name="citation_author" content="Chen, Y.">
<meta name="citation_author" content="Wah, B. W.">
<meta name="citation_author" content="Hsu, C.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="323">
<meta name="citation_lastpage" content="369">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1918/live-1918-2779-jair.pdf">

<cite>E.  Giunchiglia, M.  Narizzano and A.  Tacchella (2006) "Clause/Term Resolution and Learning in the Evaluation of Quantified Boolean Formulas", Volume 26, pages 371-416</cite>
<p class="media"><a href="/media/1959/live-1959-2790-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1959/live-1959-2789-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1959'>doi:10.1613/jair.1959</a></p>
<p>Resolution is the rule of inference at the basis of most procedures for automated reasoning. In these procedures, the input formula is first translated into an equisatisfiable formula in conjunctive normal form (CNF) and then represented as a set of clauses. Deduction starts by inferring new clauses by resolution, and goes on until the empty clause is generated or satisfiability of the set of clauses is proven, e.g., because no new clauses can be generated.<br />
<br />
In this paper, we restrict our attention to the problem of evaluating Quantified Boolean Formulas (QBFs). In this setting, the above outlined deduction process is known to be sound and complete if given a formula in CNF and if a form of resolution, called ``Q-resolution'', is used. We introduce Q-resolution on terms, to be used for formulas in disjunctive normal form. We show that the computation performed by most of the available procedures for QBFs --based on the Davis-Logemann-Loveland procedure (DLL) for propositional satisfiability-- corresponds to a tree in which Q-resolution on terms and clauses alternate. This poses the theoretical bases for the introduction of learning, corresponding to recording Q-resolution formulas associated with the nodes of the tree. We discuss the problems related to the introduction of learning in DLL based procedures, and present solutions extending state-of-the-art proposals coming from the literature on propositional satisfiability. Finally, we show that our DLL based solver extended with learning, performs significantly better on benchmarks used in the 2003 QBF solvers comparative evaluation.<br />
</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Clause/Term Resolution and Learning in the Evaluation of Quantified Boolean Formulas">
<meta name="citation_author" content="Giunchiglia, E.">
<meta name="citation_author" content="Narizzano, M.">
<meta name="citation_author" content="Tacchella, A.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="371">
<meta name="citation_lastpage" content="416">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1959/live-1959-2790-jair.pdf">

<cite>D.  Davidov and S.  Markovitch (2006) "Multiple-Goal Heuristic Search", Volume 26, pages 417-451</cite>
<p class="media"><a href="/media/1940/live-1940-2808-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1940/live-1940-2806-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1940'>doi:10.1613/jair.1940</a></p>
<p>This paper presents a new framework for anytime heuristic search<br />
where the task is to achieve as many goals as possible within the<br />
allocated resources. We show the inadequacy of traditional<br />
distance-estimation heuristics for tasks of this type and present<br />
alternative heuristics that are more appropriate for multiple-goal<br />
search.  In particular, we introduce the marginal-utility<br />
heuristic, which estimates the cost and the benefit of exploring a<br />
subtree below a search node. We developed two methods for online<br />
learning of the marginal-utility heuristic. One is based on local<br />
similarity of the partial marginal utility of sibling nodes, and<br />
the other generalizes marginal-utility over the state feature<br />
space. We apply our adaptive and non-adaptive multiple-goal search<br />
algorithms to several problems, including focused crawling, and<br />
show their superiority over existing methods.<br />
</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Multiple-Goal Heuristic Search">
<meta name="citation_author" content="Davidov, D.">
<meta name="citation_author" content="Markovitch, S.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="417">
<meta name="citation_lastpage" content="451">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1940/live-1940-2808-jair.pdf">

<cite>J.  Hoffmann, S.  Edelkamp, S.  Thiebaux, R.  Englert, F.  Liporace and S.  Trueg (2006) "Engineering Benchmarks for Planning: the Domains Used in the  Deterministic Part of IPC-4", Volume 26, pages 453-541</cite>
<p class="media"><a href="/media/1982/live-1982-2813-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1982/live-1982-2812-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1982'>doi:10.1613/jair.1982</a></p>
<p>In a field of research about general reasoning mechanisms, it is essential to have appropriate benchmarks. Ideally, the benchmarks should reflect possible applications of the developed technology. In AI Planning, researchers more and more tend to draw their testing examples from the benchmark collections used in the International Planning Competition (IPC). In the organization of (the deterministic part of) the fourth IPC,  IPC-4, the authors therefore invested significant effort to create a useful set of benchmarks. They come from five different (potential) real-world applications of planning: airport ground traffic control, oil derivative transportation in pipeline networks, model-checking safety properties, power supply restoration, and UMTS call setup. Adapting and preparing such an application for use as a benchmark in the IPC involves, at the time, inevitable (often drastic) simplifications, as well as careful choice between, and engineering of, domain encodings. For the first time in the IPC, we used compilations to formulate complex domain features in simple languages such as STRIPS, rather than just dropping the more interesting problem constraints in the simpler language subsets. The article explains and discusses the five application domains and their adaptation to form the PDDL test suites used in IPC-4. We summarize known theoretical results on structural properties of the domains, regarding their computational complexity and provable properties of their topology under the h+ function (an idealized version of the relaxed plan heuristic). We present new (empirical) results illuminating properties such as the quality of the most wide-spread heuristic functions (planning graph, serial planning graph, and relaxed plan), the growth of propositional representations over instance size, and the number of actions available to achieve each fact; we discuss these data in conjunction with the best results achieved by the different kinds of planners participating in IPC-4.</p>
<a href="/vol/vol26.html">Click here to return to Volume 26 contents list</a>
<meta name="citation_title" content="Engineering Benchmarks for Planning: the Domains Used in the  Deterministic Part of IPC-4">
<meta name="citation_author" content="Hoffmann, J.">
<meta name="citation_author" content="Edelkamp, S.">
<meta name="citation_author" content="Thiebaux, S.">
<meta name="citation_author" content="Englert, R.">
<meta name="citation_author" content="Liporace, F.">
<meta name="citation_author" content="Trueg, S.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="453">
<meta name="citation_lastpage" content="541">
<meta name="citation_volume" content="26">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1982/live-1982-2813-jair.pdf">
