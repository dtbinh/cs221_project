<cite>P.  van Beek and  D.  W. Manchak (1996) "The Design and Experimental Analysis of Algorithms for Temporal Reasoning", Volume 4, pages 1-18</cite>
<p class="media"><a href="/media/232/live-232-1507-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/232/live-232-1506-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/vanbeek96a-html/paper.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.232'>doi:10.1613/jair.232</a></p>
<p>Many applications -- from planning and scheduling to    problems in molecular biology -- rely heavily on a temporal reasoning    component.  In this paper, we discuss the design and empirical    analysis of algorithms for a temporal reasoning system based on    Allen's influential interval-based framework for representing temporal    information.  At the core of the system are algorithms for determining    whether the temporal information is consistent, and, if so, finding    one or more scenarios that are consistent with the temporal    information.  Two important algorithms for these tasks are a path    consistency algorithm and a backtracking algorithm.  For the path    consistency algorithm, we develop techniques that can result in up to    a ten-fold speedup over an already highly optimized implementation.    For the backtracking algorithm, we develop variable and value ordering    heuristics that are shown empirically to dramatically improve the    performance of the algorithm.  As well, we show that a previously    suggested reformulation of the backtracking search problem can reduce    the time and space requirements of the backtracking search.  Taken    together, the techniques we develop allow a temporal reasoning    component to solve problems that are of practical size.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="The Design and Experimental Analysis of Algorithms for Temporal Reasoning">
<meta name="citation_author" content="van Beek,  P.">
<meta name="citation_author" content="Manchak,  D. W.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="18">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/232/live-232-1507-jair.pdf">

<cite>G.  Brewka (1996) "Well-Founded Semantics for Extended Logic Programs with Dynamic Preferences", Volume 4, pages 19-36</cite>
<p class="media"><a href="/media/284/live-284-1547-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/284/live-284-1544-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/brewka96a-html/LPR.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.284'>doi:10.1613/jair.284</a></p>
<p>The paper describes an extension of well-founded    semantics for logic programs with two types of negation. In this    extension information about preferences between rules can be expressed    in the logical language and derived dynamically. This is achieved by    using a reserved predicate symbol and a naming technique. Conflicts    among rules are resolved whenever possible on the basis of derived    preference information. The well-founded conclusions of prioritized    logic programs can be computed in polynomial time. A legal reasoning    example illustrates the usefulness of the approach.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Well-Founded Semantics for Extended Logic Programs with Dynamic Preferences">
<meta name="citation_author" content="Brewka,  G.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="19">
<meta name="citation_lastpage" content="36">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/284/live-284-1547-jair.pdf">

<cite>A.  L. Delcher,  A.  J. Grove,  S.  Kasif and  J.  Pearl (1996) "Logarithmic-Time Updates and Queries in Probabilistic Networks", Volume 4, pages 37-59</cite>
<p class="media"><a href="/media/238/live-238-1517-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/238/live-238-1516-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.238'>doi:10.1613/jair.238</a></p>
<p>Traditional databases commonly support efficient query and    update procedures that operate in time which is sublinear in the size    of the database.  Our goal in this paper is to take a first step    toward dynamic reasoning in probabilistic databases with comparable    efficiency.  We propose a dynamic data structure that supports    efficient algorithms for updating and querying singly connected    Bayesian networks.  In the conventional algorithm, new evidence is    absorbed in O(1) time and queries are processed in time O(N), where N    is the size of the network.  We propose an algorithm which, after a    preprocessing phase, allows us to answer queries in time O(log N) at    the expense of O(log N) time per evidence absorption.  The usefulness    of sub-linear processing time manifests itself in applications    requiring (near) real-time response over large probabilistic    databases. We briefly discuss a potential application of dynamic    probabilistic reasoning in computational biology.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Logarithmic-Time Updates and Queries in Probabilistic Networks">
<meta name="citation_author" content="Delcher,  A. L.">
<meta name="citation_author" content="Grove,  A. J.">
<meta name="citation_author" content="Kasif,  S.">
<meta name="citation_author" content="Pearl,  J.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="37">
<meta name="citation_lastpage" content="59">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/238/live-238-1517-jair.pdf">

<cite>L.  K. Saul,  T.  Jaakkola and  M.  I. Jordan (1996) "Mean Field Theory for Sigmoid Belief Networks", Volume 4, pages 61-76</cite>
<p class="media"><a href="/media/251/live-251-1520-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/251/live-251-1519-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.251'>doi:10.1613/jair.251</a></p>
<p>We develop a mean field theory for sigmoid belief networks    based on ideas from statistical mechanics.  Our mean field theory    provides a tractable approximation to the true probability    distribution in these networks; it also yields a lower bound on the    likelihood of evidence.  We demonstrate the utility of this framework    on a benchmark problem in statistical pattern recognition---the    classification of handwritten digits.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Mean Field Theory for Sigmoid Belief Networks">
<meta name="citation_author" content="Saul,  L. K.">
<meta name="citation_author" content="Jaakkola,  T.">
<meta name="citation_author" content="Jordan,  M. I.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="61">
<meta name="citation_lastpage" content="76">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/251/live-251-1520-jair.pdf">

<cite>J.  R. Quinlan (1996) "Improved Use of Continuous Attributes in C4.5", Volume 4, pages 77-90</cite>
<p class="media"><a href="/media/279/live-279-1538-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/279/live-279-1537-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.279'>doi:10.1613/jair.279</a></p>
<p>A reported weakness of C4.5 in domains with continuous    attributes is addressed by modifying the formation and evaluation of    tests on continuous attributes.  An MDL-inspired penalty is applied to    such tests, eliminating some of them from consideration and altering    the relative desirability of all tests.  Empirical trials show that    the modifications lead to smaller decision trees with higher    predictive accuracies.  Results also confirm that a new version of    C4.5 incorporating these changes is superior to recent approaches that    use global discretization and that construct small trees with    multi-interval splits.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Improved Use of Continuous Attributes in C4.5">
<meta name="citation_author" content="Quinlan,  J. R.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="77">
<meta name="citation_lastpage" content="90">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/279/live-279-1538-jair.pdf">

<cite>T.  Hogg (1996) "Quantum Computing and Phase Transitions in Combinatorial Search", Volume 4, pages 91-128</cite>
<p class="media"><a href="/media/204/live-204-2514-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/204/live-204-2515-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/hogg96a-html/quantumHTML.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.204'>doi:10.1613/jair.204</a>
<br/><a href="/media/204/live-204-2516-jair.txt">Appendix </a> - Matrix values </p>
<p>We introduce an algorithm for combinatorial search on quantum computers that is capable of significantly concentrating amplitude into solutions for some NP search problems, on average. This is done by exploiting the same aspects of problem structure as used by classical backtrack methods to avoid unproductive search choices. This quantum algorithm is much more likely to find solutions than the simple direct use of quantum parallelism. Furthermore, empirical evaluation on small problems shows this quantum algorithm displays the same phase transition behavior, and at the same location, as seen in many previously studied classical search methods. Specifically, difficult problem instances are concentrated near the abrupt change from underconstrained to overconstrained problems. </p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Quantum Computing and Phase Transitions in Combinatorial Search">
<meta name="citation_author" content="Hogg, T.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="91">
<meta name="citation_lastpage" content="128">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/204/live-204-2514-jair.pdf">

<cite>D.  A. Cohn,  Z.  Ghahramani and  M.  I. Jordan (1996) "Active Learning with Statistical Models", Volume 4, pages 129-145</cite>
<p class="media"><a href="/media/295/live-295-1554-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/295/live-295-1553-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/cohn96a-html/statmodels.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.295'>doi:10.1613/jair.295</a></p>
<p>For many types of machine learning algorithms, one can    compute the statistically `optimal' way to select training data.  In    this paper, we review how optimal data selection techniques have been    used with feedforward neural networks.  We then show how the same    principles may be used to select data for two alternative,    statistically-based learning architectures: mixtures of Gaussians and    locally weighted regression.  While the techniques for neural networks    are computationally expensive and approximate, the techniques for    mixtures of Gaussians and locally weighted regression are both    efficient and accurate.  Empirically, we observe that the optimality    criterion sharply decreases the number of training examples the    learner needs in order to achieve good performance.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Active Learning with Statistical Models">
<meta name="citation_author" content="Cohn,  D. A.">
<meta name="citation_author" content="Ghahramani,  Z.">
<meta name="citation_author" content="Jordan,  M. I.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="129">
<meta name="citation_lastpage" content="145">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/295/live-295-1554-jair.pdf">

<cite>D.  Fisher (1996) "Iterative Optimization and Simplification of Hierarchical Clusterings", Volume 4, pages 147-178</cite>
<p class="media"><a href="/media/276/live-276-1530-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/276/live-276-1529-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/fisher96a-html/html-final.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.276'>doi:10.1613/jair.276</a></p>
<p>Clustering is often used for discovering structure in data.    Clustering systems differ in the objective function used to evaluate    clustering quality and the control strategy used to search the space    of clusterings. Ideally, the search strategy should consistently    construct clusterings of high quality, but be computationally    inexpensive as well. In general, we cannot have it both ways, but we    can partition the search so that a system inexpensively constructs a    `tentative' clustering for initial examination, followed by iterative    optimization, which continues to search in background for improved    clusterings. Given this motivation, we evaluate an inexpensive    strategy for creating initial clusterings, coupled with several    control strategies for iterative optimization, each of which    repeatedly modifies an initial clustering in search of a better    one. One of these methods appears novel as an iterative optimization    strategy in clustering contexts. Once a clustering has been    constructed it is judged by analysts -- often according to    task-specific criteria. Several authors have abstracted these criteria    and posited a generic performance task akin to pattern completion,    where the error rate over completed patterns is used to `externally'    judge clustering utility. Given this performance task, we adapt    resampling-based pruning strategies used by supervised learning    systems to the task of simplifying hierarchical clusterings, thus    promising to ease post-clustering analysis. Finally, we propose a    number of objective functions, based on attribute-selection measures    for decision-tree induction, that might perform well on the error rate    and simplicity dimensions.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Iterative Optimization and Simplification of Hierarchical Clusterings">
<meta name="citation_author" content="Fisher,  D.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="147">
<meta name="citation_lastpage" content="178">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/276/live-276-1530-jair.pdf">

<cite>E.  Marchiori (1996) "Practical Methods for Proving Termination of General Logic Programs", Volume 4, pages 179-208</cite>
<p class="media"><a href="/media/198/live-198-1488-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/198/live-198-1486-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.198'>doi:10.1613/jair.198</a></p>
<p>Termination of logic programs with negated body atoms (here    called general logic programs) is an important topic. One reason is    that many computational mechanisms used to process negated atoms, like    Clark's negation as failure and Chan's constructive negation, are    based on termination conditions.  This paper introduces a methodology    for proving termination of general logic programs w.r.t. the Prolog    selection rule.  The idea is to distinguish parts of the program    depending on whether or not their termination depends on the selection    rule. To this end, the notions of low-, weakly up-, and up-acceptable    program are introduced.  We use these notions to develop a methodology    for proving termination of general logic programs, and show how    interesting problems in non-monotonic reasoning can be formalized and    implemented by means of terminating general logic programs.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Practical Methods for Proving Termination of General Logic Programs">
<meta name="citation_author" content="Marchiori,  E.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="179">
<meta name="citation_lastpage" content="208">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/198/live-198-1488-jair.pdf">

<cite>T.  Walsh (1996) "A Divergence Critic for Inductive Proof", Volume 4, pages 209-235</cite>
<p class="media"><a href="/media/275/live-275-1526-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/275/live-275-1525-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/walsh96a-html/Final.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.275'>doi:10.1613/jair.275</a></p>
<p>Inductive theorem provers often diverge. This paper    describes a simple critic, a computer program which monitors the    construction of inductive proofs attempting to identify diverging    proof attempts. Divergence is recognized by means of a ``difference    matching'' procedure. The critic then proposes lemmas and    generalizations which ``ripple'' these differences away so that the    proof can go through without divergence. The critic enables the    theorem prover Spike to prove many theorems completely automatically    from the definitions alone.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="A Divergence Critic for Inductive Proof">
<meta name="citation_author" content="Walsh,  T.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="209">
<meta name="citation_lastpage" content="235">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/275/live-275-1526-jair.pdf">

<cite>L.  P. Kaelbling,  M.  L. Littman and  A.  W. Moore (1996) "Reinforcement Learning:  A Survey", Volume 4, pages 237-285</cite>
<p class="media"><a href="/media/301/live-301-1562-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/301/live-301-1561-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/kaelbling96a-html/rl-survey.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.301'>doi:10.1613/jair.301</a></p>
<p>This paper surveys the field of reinforcement learning from    a computer-science perspective. It is written to be accessible to    researchers familiar with machine learning.  Both the historical basis    of the field and a broad selection of current work are summarized.    Reinforcement learning is the problem faced by an agent that learns    behavior through trial-and-error interactions with a dynamic    environment.  The work described here has a resemblance to work in    psychology, but differs considerably in the details and in the use of    the word ``reinforcement.''  The paper discusses central issues of    reinforcement learning, including trading off exploration and    exploitation, establishing the foundations of the field via Markov    decision theory, learning from delayed reinforcement, constructing    empirical models to accelerate learning, making use of generalization    and hierarchy, and coping with hidden state.  It concludes with a    survey of some implemented systems and an assessment of the practical    utility of current methods for reinforcement learning.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Reinforcement Learning:  A Survey">
<meta name="citation_author" content="Kaelbling,  L. P.">
<meta name="citation_author" content="Littman,  M. L.">
<meta name="citation_author" content="Moore,  A. W.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="237">
<meta name="citation_lastpage" content="285">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/301/live-301-1562-jair.pdf">

<cite>L.  Pryor and  G.  Collins (1996) "Planning for Contingencies: A Decision-based Approach", Volume 4, pages 287-339</cite>
<p class="media"><a href="/media/277/live-277-1534-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/277/live-277-1533-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/pryor96a-html/final-jair.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.277'>doi:10.1613/jair.277</a></p>
<p>A fundamental assumption made by classical AI planners is    that there is no uncertainty in the world: the planner has full    knowledge of the conditions under which the plan will be executed and    the outcome of every action is fully predictable.  These planners    cannot therefore construct contingency plans, i.e., plans in which    different actions are performed in different circumstances.  In this    paper we discuss some issues that arise in the representation and    construction of contingency plans and describe Cassandra, a    partial-order contingency planner.  Cassandra uses explicit    decision-steps that enable the agent executing the plan to decide    which plan branch to follow.  The decision-steps in a plan result in    subgoals to acquire knowledge, which are planned for in the same way    as any other subgoals.  Cassandra thus distinguishes the process of    gathering information from the process of making decisions.  The    explicit representation of decisions in Cassandra allows a coherent    approach to the problems of contingent planning, and provides a solid    base for extensions such as the use of different decision-making    procedures.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Planning for Contingencies: A Decision-based Approach">
<meta name="citation_author" content="Pryor,  L.">
<meta name="citation_author" content="Collins,  G.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="287">
<meta name="citation_lastpage" content="339">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/277/live-277-1534-jair.pdf">

<cite>S.  H. Nienhuys-Cheng (1996) "Least Generalizations and Greatest Specializations of Sets of Clauses", Volume 4, pages 341-363</cite>
<p class="media"><a href="/media/259/live-259-1524-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/259/live-259-1522-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.259'>doi:10.1613/jair.259</a></p>
<p>The main operations in Inductive Logic Programming (ILP) are    generalization and specialization, which only make sense in a    generality order.  In ILP, the three most important generality orders    are subsumption, implication and implication relative to background    knowledge.  The two languages used most often are languages of clauses    and languages of only Horn clauses. This gives a total of six    different ordered languages.  In this paper, we give a systematic    treatment of the existence or non-existence of least generalizations    and greatest specializations of finite sets of clauses in each of    these six ordered sets.  We survey results already obtained by others    and also contribute some answers of our own.        Our main new results are, firstly, the existence of a computable least    generalization under implication of every finite set of clauses    containing at least one non-tautologous function-free clause (among    other, not necessarily function-free clauses).  Secondly, we show that    such a least generalization need not exist under relative implication,    not even if both the set that is to be generalized and the background    knowledge are function-free.  Thirdly, we give a complete discussion    of existence and non-existence of greatest specializations in each of    the six ordered languages.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Least Generalizations and Greatest Specializations of Sets of Clauses">
<meta name="citation_author" content="Nienhuys-Cheng,  S. H.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="341">
<meta name="citation_lastpage" content="363">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/259/live-259-1524-jair.pdf">

<cite>J.  Gratch and  S.  Chien (1996) "Adaptive Problem-solving for Large-scale Scheduling Problems: A Case Study", Volume 4, pages 365-396</cite>
<p class="media"><a href="/media/177/live-177-1472-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/177/live-177-1471-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.177'>doi:10.1613/jair.177</a></p>
<p>Although most scheduling problems are NP-hard, domain    specific techniques perform well in practice but are quite expensive    to construct.  In adaptive problem-solving solving, domain specific    knowledge is acquired automatically for a general problem solver with    a flexible control architecture.  In this approach, a learning system    explores a space of possible heuristic methods for one well-suited to    the eccentricities of the given domain and problem distribution.  In    this article, we discuss an application of the approach to scheduling    satellite communications.  Using problem distributions based on actual    mission requirements, our approach identifies strategies that not only    decrease the amount of CPU time required to produce schedules, but    also increase the percentage of problems that are solvable within    computational resource limitations.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Adaptive Problem-solving for Large-scale Scheduling Problems: A Case Study">
<meta name="citation_author" content="Gratch,  J.">
<meta name="citation_author" content="Chien,  S.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="365">
<meta name="citation_lastpage" content="396">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/177/live-177-1472-jair.pdf">

<cite>G.  I. Webb (1996) "Further Experimental Evidence against the Utility of Occam's Razor", Volume 4, pages 397-417</cite>
<p class="media"><a href="/media/228/live-228-1502-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/228/live-228-1501-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/webb96a-html/webb96a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.228'>doi:10.1613/jair.228</a>
<br/><a href="/media/228/live-228-1504-jair.tar">Appendix </a> - source code</p>
<p>This paper presents new experimental evidence against the    utility of Occam's razor.  A~systematic procedure is presented for    post-processing decision trees produced by C4.5.  This procedure was    derived by rejecting Occam's razor and instead attending to the    assumption that similar objects are likely to belong to the same    class.  It increases a decision tree's complexity without altering the    performance of that tree on the training data from which it is    inferred.  The resulting more complex decision trees are demonstrated    to have, on average, for a variety of common learning tasks, higher    predictive accuracy than the less complex original decision trees.    This result raises considerable doubt about the utility of Occam's    razor as it is commonly applied in modern machine learning.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="Further Experimental Evidence against the Utility of Occam's Razor">
<meta name="citation_author" content="Webb,  G. I.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="397">
<meta name="citation_lastpage" content="417">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/228/live-228-1502-jair.pdf">

<cite>S.  Bhansali,  G.  A. Kramer and  T.  J. Hoar (1996) "A Principled Approach Towards Symbolic Geometric Constraint Satisfaction", Volume 4, pages 419-443</cite>
<p class="media"><a href="/media/292/live-292-1549-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/292/live-292-1548-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume4/bhansali96a-html/paper.htm" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.292'>doi:10.1613/jair.292</a>
<br/><a href="/media/292/live-292-1552-jair.txt">Appendix </a> - example plan fragment</p>
<p>An important problem in geometric reasoning is to find the    configuration of a collection of geometric bodies so as to satisfy a    set of given constraints. Recently, it has been suggested that this    problem can be solved efficiently by symbolically reasoning about    geometry. This approach, called degrees of freedom analysis, employs a    set of specialized routines called plan fragments that specify how to    change the configuration of a set of bodies to satisfy a new    constraint while preserving existing constraints. A potential    drawback, which limits the scalability of this approach, is concerned    with the difficulty of writing plan fragments.  In this paper we    address this limitation by showing how these plan fragments can be    automatically synthesized using first principles about geometric    bodies, actions, and topology.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="A Principled Approach Towards Symbolic Geometric Constraint Satisfaction">
<meta name="citation_author" content="Bhansali,  S.">
<meta name="citation_author" content="Kramer,  G. A.">
<meta name="citation_author" content="Hoar,  T. J.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="419">
<meta name="citation_lastpage" content="443">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/292/live-292-1549-jair.pdf">

<cite>P.  Tadepalli and  B.  K. Natarajan (1996) "A Formal Framework for Speedup Learning from Problems and Solutions", Volume 4, pages 445-475</cite>
<p class="media"><a href="/media/154/live-154-1458-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/154/live-154-1456-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.154'>doi:10.1613/jair.154</a></p>
<p>Speedup learning seeks to improve the computational    efficiency of problem solving with experience. In this paper, we    develop a formal framework for learning efficient problem solving from    random problems and their solutions. We apply this framework to two    different representations of learned knowledge, namely control rules    and macro-operators, and prove theorems that identify sufficient    conditions for learning in each representation. Our proofs are    constructive in that they are accompanied with learning algorithms.     Our framework captures both empirical and explanation-based     speedup learning in a unified fashion.  We illustrate our framework    with implementations in two domains: symbolic integration and Eight    Puzzle. This work integrates many strands of experimental and    theoretical work in machine learning, including empirical learning of    control rules, macro-operator learning, Explanation-Based Learning    (EBL), and Probably Approximately Correct (PAC) Learning.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="A Formal Framework for Speedup Learning from Problems and Solutions">
<meta name="citation_author" content="Tadepalli,  P.">
<meta name="citation_author" content="Natarajan,  B. K.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="445">
<meta name="citation_lastpage" content="475">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/154/live-154-1458-jair.pdf">

<cite>R.  I. Brafman and  M.  Tennenholtz (1996) "On Partially Controlled Multi-Agent Systems", Volume 4, pages 477-507</cite>
<p class="media"><a href="/media/318/live-318-1581-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/318/live-318-1580-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.318'>doi:10.1613/jair.318</a></p>
<p>Motivated by the control theoretic distinction between    controllable and uncontrollable events, we distinguish between two    types of agents within a multi-agent system: controllable agents,    which are directly controlled by the system's designer, and    uncontrollable agents, which are not under the designer's direct    control. We refer to such systems as partially controlled multi-agent    systems, and we investigate how one might influence the behavior of    the uncontrolled agents through appropriate design of the controlled    agents. In particular, we wish to understand which problems are    naturally described in these terms, what methods can be applied to    influence the uncontrollable agents, the effectiveness of such    methods, and whether similar methods work across different    domains. Using a game-theoretic framework, this paper studies the    design of partially controlled multi-agent systems in two contexts: in    one context, the uncontrollable agents are expected utility    maximizers, while in the other they are reinforcement learners. We    suggest different techniques for controlling agents' behavior in each    domain, assess their success, and examine their relationship.</p>
<a href="/vol/vol4.html">Click here to return to Volume 4 contents list</a>
<meta name="citation_title" content="On Partially Controlled Multi-Agent Systems">
<meta name="citation_author" content="Brafman,  R. I.">
<meta name="citation_author" content="Tennenholtz,  M.">
<meta name="citation_publication_date" content="1996">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="477">
<meta name="citation_lastpage" content="507">
<meta name="citation_volume" content="4">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/318/live-318-1581-jair.pdf">
