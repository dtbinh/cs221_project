<cite>N.  Roy,  G.  Gordon and  S.  Thrun (2005) "Finding Approximate POMDP solutions Through Belief Compression", Volume 23, pages 1-40</cite>
<p class="media"><a href="/media/1496/live-1496-2341-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1496/live-1496-2340-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/roy05a-html/roy05a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1496'>doi:10.1613/jair.1496</a></p>
<p>Standard value function approaches to finding policies for Partially Observable Markov Decision Processes (POMDPs) are generally considered to be intractable for large models. The intractability of these algorithms is to a large extent a consequence of computing an exact, optimal policy over the entire belief space.  However, in real-world POMDP problems, computing the optimal policy for the full belief space is often unnecessary for good control even for problems with complicated policy classes. The beliefs experienced by the controller often lie near a structured, low-dimensional subspace embedded in the high-dimensional belief space. Finding a good approximation to the optimal value function for only this subspace can be much easier than computing the full value function.</P> <P>  We introduce a new method for solving large-scale POMDPs by reducing the dimensionality of the belief space. We use Exponential family Principal Components Analysis (Collins, Dasgupta & Schapire, 2002) to represent sparse, high-dimensional belief spaces using small sets of learned features of the belief state. We then plan only in terms of the low-dimensional belief features. By planning in this low-dimensional space, we can find policies for POMDP models that are orders of magnitude larger than models that can be handled by conventional techniques.</P> <P> We demonstrate the use of this algorithm on a synthetic problem and on mobile robot navigation tasks.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Finding Approximate POMDP solutions Through Belief Compression">
<meta name="citation_author" content="Roy,  N.">
<meta name="citation_author" content="Gordon,  G.">
<meta name="citation_author" content="Thrun,  S.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="40">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1496/live-1496-2341-jair.pdf">

<cite>P.  E. Dunne (2005) "Extremal Behaviour in Multiagent Contract Negotiation", Volume 23, pages 41-78</cite>
<p class="media"><a href="/media/1526/live-1526-2358-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1526/live-1526-2357-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/dunne05a-html/dunne05a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1526'>doi:10.1613/jair.1526</a></p>
<p>We examine properties of a model of resource allocation in which several agents exchange resources in order to optimise their individual holdings. The schemes discussed relate to well-known negotiation protocols proposed in earlier work and we consider a number of alternative notions of ``rationality'' covering both quantitative measures, e.g. cooperative and individual rationality and more qualitative forms, e.g. Pigou-Dalton transfers. While it is known that imposing particular rationality and structural restrictions may result in some reallocations of the resource set becoming unrealisable, in this paper we address the issue of the number of restricted rational deals that may be required to implement a particular reallocation when it is possible to do so. We construct examples showing that this number may be exponential (in the number of resources m), even when all of the agent utility functions are monotonic. We further show that k agents may achieve in a single deal a reallocation requiring exponentially many rational deals if at most k-1 agents can participate, this same reallocation being unrealisable by any sequences of rational deals in which at most k-2 agents are involved.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Extremal Behaviour in Multiagent Contract Negotiation">
<meta name="citation_author" content="Dunne,  P. E.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="41">
<meta name="citation_lastpage" content="78">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1526/live-1526-2358-jair.pdf">

<cite>J.  M. Porta and  E.  Celaya (2005) "Reinforcement Learning for Agents with Many Sensors and Actuators Acting in Categorizable Environments", Volume 23, pages 79-122</cite>
<p class="media"><a href="/media/1437/live-1437-2318-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1437/live-1437-2317-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/porta05a-html/index.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1437'>doi:10.1613/jair.1437</a></p>
<p>In this paper, we confront the problem of applying reinforcement learning to agents that perceive the environment through many sensors and that can perform  parallel actions using many actuators as is the case in complex autonomous robots. We argue that reinforcement learning can only be successfully applied to this case  if strong assumptions are made on the characteristics of the environment in which  the learning is performed, so that the relevant sensor readings and motor commands can be  readily identified. The introduction of such assumptions leads to strongly-biased  learning systems that can eventually lose the generality of traditional  reinforcement-learning algorithms.</p>  <p>In this line, we observe that, in realistic situations, the reward received by the robot  depends only on a reduced subset of all the executed actions and that only a reduced  subset of the sensor inputs (possibly different in each situation and for each action)  are relevant to predict the reward. We formalize this property in the so called  'categorizability assumption' and we present an algorithm that takes advantage of  the categorizability of the environment, allowing a decrease in the learning time with  respect to existing reinforcement-learning algorithms. Results of the application of the  algorithm to a couple of simulated realistic-robotic problems (landmark-based navigation  and the six-legged robot gait generation) are reported to validate our approach and to  compare it to existing flat and generalization-based reinforcement-learning approaches.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Reinforcement Learning for Agents with Many Sensors and Actuators Acting in Categorizable Environments">
<meta name="citation_author" content="Porta,  J. M.">
<meta name="citation_author" content="Celaya,  E.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="79">
<meta name="citation_lastpage" content="122">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1437/live-1437-2318-jair.pdf">

<cite>W.  Zhang and  N.  L. Zhang (2005) "Restricted Value Iteration: Theory and Algorithms", Volume 23, pages 123-165</cite>
<p class="media"><a href="/media/1379/live-1379-2292-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1379/live-1379-2291-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1379'>doi:10.1613/jair.1379</a></p>
<p>Value iteration is a popular algorithm for finding near optimal policies for POMDPs.  It is inefficient due to the need to account for the entire belief space, which necessitates the solution of large numbers of linear programs.  In this paper, we study value iteration restricted to belief subsets. We show that, together with properly chosen belief subsets, restricted value iteration yields near-optimal policies and we give a condition for determining whether a given belief subset would bring about savings in space and time. We also apply restricted value iteration to two interesting classes of POMDPs, namely informative POMDPs and near-discernible POMDPs.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Restricted Value Iteration: Theory and Algorithms">
<meta name="citation_author" content="Zhang,  W.">
<meta name="citation_author" content="Zhang,  N. L.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="123">
<meta name="citation_lastpage" content="165">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1379/live-1379-2292-jair.pdf">

<cite>D.  Gabelaia,  R.  Kontchakov,  A.  Kurucz,  F.  Wolter and  M.  Zakharyaschev (2005) "Combining Spatial and Temporal Logics: Expressiveness vs. Complexity", Volume 23, pages 167-243</cite>
<p class="media"><a href="/media/1537/live-1537-2369-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1537/live-1537-2368-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1537'>doi:10.1613/jair.1537</a></p>
<p>In this paper, we construct and investigate a hierarchy of spatio-temporal formalisms that result from various combinations of propositional spatial and temporal logics such as the propositional temporal logic PTL, the spatial logics RCC-8, BRCC-8, S4u and their fragments. The obtained results give a clear picture of the trade-off between expressiveness and `computational realisability' within the hierarchy. We demonstrate how different combining principles as well as spatial and temporal primitives can produce NP-, PSPACE-, EXPSPACE-, 2EXPSPACE-complete, and even undecidable spatio-temporal logics out of components that are at most NP- or PSPACE-complete.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Combining Spatial and Temporal Logics: Expressiveness vs. Complexity">
<meta name="citation_author" content="Gabelaia,  D.">
<meta name="citation_author" content="Kontchakov,  R.">
<meta name="citation_author" content="Kurucz,  A.">
<meta name="citation_author" content="Wolter,  F.">
<meta name="citation_author" content="Zakharyaschev,  M.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="167">
<meta name="citation_lastpage" content="243">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1537/live-1537-2369-jair.pdf">

<cite>C.  Cayrol and  M.  C. Lagasquie-Schiex (2005) "Graduality in Argumentation", Volume 23, pages 245-297</cite>
<p class="media"><a href="/media/1411/live-1411-2308-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1411/live-1411-2307-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/cayrol05a-html/index.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1411'>doi:10.1613/jair.1411</a></p>
<p>Argumentation is based on the exchange and valuation of interacting arguments, followed by the selection of the most acceptable of them (for example, in order to take a decision, to make a choice). Starting from the framework proposed by Dung in 1995, our purpose is to introduce 'graduality' in the selection of the best arguments, i.e., to be able to partition the set of the arguments in more than the two usual subsets of 'selected' and 'non-selected' arguments in order to represent different levels of selection.  Our basic idea is that an argument is all the more acceptable if it can be preferred to its attackers.  First, we discuss general principles underlying a 'gradual' valuation of arguments based on their interactions. Following these principles, we define several valuation models for an abstract argumentation system.  Then, we introduce 'graduality' in the concept of acceptability of arguments. We propose new acceptability classes and a refinement of existing classes taking advantage of an available 'gradual' valuation.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Graduality in Argumentation">
<meta name="citation_author" content="Cayrol,  C.">
<meta name="citation_author" content="Lagasquie-Schiex,  M. C.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="245">
<meta name="citation_lastpage" content="297">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1411/live-1411-2308-jair.pdf">

<cite>A.  Montoyo,  A.  Suarez,  G.  Rigau and  M.  Palomar (2005) "Combining Knowledge- and Corpus-based Word-Sense-Disambiguation Methods", Volume 23, pages 299-330</cite>
<p class="media"><a href="/media/1529/live-1529-2362-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1529/live-1529-2361-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/montoyo05a-html/Montoyo05a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1529'>doi:10.1613/jair.1529</a></p>
<p>In this paper we concentrate on the resolution of the lexical ambiguity that arises when a given word has several different meanings. This specific task is commonly referred to as word sense disambiguation (WSD). The task of WSD consists of assigning the correct sense to words using an electronic dictionary as the source of word definitions. We present two WSD methods based on two main methodological approaches in this research area: a knowledge-based method and a corpus-based method. Our hypothesis is that word-sense disambiguation requires several knowledge sources in order to solve the semantic ambiguity of the words. These sources can be of different kinds--- for example, syntagmatic, paradigmatic or statistical information. Our approach combines various sources of knowledge, through combinations of the two WSD methods mentioned above. Mainly, the paper concentrates on how to combine these methods and sources of information in order to achieve good results in the disambiguation. Finally, this paper presents a comprehensive study and experimental work on evaluation of the methods and their combinations.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Combining Knowledge- and Corpus-based Word-Sense-Disambiguation Methods">
<meta name="citation_author" content="Montoyo,  A.">
<meta name="citation_author" content="Suarez,  A.">
<meta name="citation_author" content="Rigau,  G.">
<meta name="citation_author" content="Palomar,  M.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="299">
<meta name="citation_lastpage" content="330">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1529/live-1529-2362-jair.pdf">

<cite>N.  V. Chawla and   Karakoulas (2005) "Learning From Labeled And Unlabeled Data: An Empirical Study Across Techniques And Domains", Volume 23, pages 331-366</cite>
<p class="media"><a href="/media/1509/live-1509-2348-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1509/live-1509-2347-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1509'>doi:10.1613/jair.1509</a></p>
<p>There has been increased interest in devising learning techniques that combine unlabeled data with labeled data ? i.e. semi-supervised learning. However, to the best of our knowledge, no study has been performed across various techniques and different types and amounts of labeled and unlabeled data. Moreover, most of the published work on semi-supervised learning techniques assumes that the labeled and unlabeled data come from the same distribution. It is possible for the labeling process to be associated with a selection bias such that the distributions of data points in the labeled and unlabeled sets are different. Not correcting for such bias can result in biased function approximation with potentially poor performance. In this paper, we present an empirical study of various semi-supervised learning techniques on a variety of datasets. We attempt to answer various questions such as the effect of independence or relevance amongst features, the effect of the size of the labeled and unlabeled sets and the effect of noise. We also investigate the impact of sample-selection bias on the semi-supervised learning techniques under study and implement a bivariate probit technique particularly designed to correct for such bias.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Learning From Labeled And Unlabeled Data: An Empirical Study Across Techniques And Domains">
<meta name="citation_author" content="Chawla,  N. V.">
<meta name="citation_author" content="Karakoulas, ">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="331">
<meta name="citation_lastpage" content="366">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1509/live-1509-2348-jair.pdf">

<cite>R.  Nair and  M.  Tambe (2005) "Hybrid BDI-POMDP Framework for Multiagent Teaming", Volume 23, pages 367-420</cite>
<p class="media"><a href="/media/1549/live-1549-2381-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1549/live-1549-2380-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/nair05a-html/nair05a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1549'>doi:10.1613/jair.1549</a></p>
<p>Many current large-scale multiagent team implementations can be characterized as following the ``belief-desire-intention'' (BDI) paradigm, with explicit representation of team plans.  Despite their promise, current BDI team approaches lack tools for quantitative performance analysis under uncertainty. Distributed partially observable Markov decision problems (POMDPs) are well suited for such analysis, but the complexity of finding optimal policies in such models is highly intractable. The key contribution of this article is a hybrid BDI-POMDP approach, where BDI team plans are exploited to improve POMDP tractability and POMDP analysis improves BDI team plan performance.  Concretely, we focus on role allocation, a fundamental problem in BDI  teams: which agents to allocate to the different roles in the team. The  article provides three key contributions. First, we describe a role  allocation technique that takes into account future uncertainties in the domain; prior work in multiagent role allocation has failed to address such uncertainties. To that end, we introduce RMTDP (Role-based Markov Team Decision Problem), a new distributed POMDP model for analysis of role allocations. Our technique gains in tractability by significantly curtailing RMTDP policy search; in particular, BDI team plans provide incomplete RMTDP policies, and the RMTDP policy search fills the gaps in such incomplete policies by searching for the best role allocation. Our second key contribution is a novel decomposition technique to  further improve RMTDP policy search efficiency. Even though limited  to searching role allocations, there are still combinatorially many  role allocations, and evaluating each in RMTDP to identify the best  is extremely difficult. Our decomposition technique exploits the  structure in the BDI team plans to significantly prune the search space of role allocations. Our third key contribution is a  significantly faster policy evaluation algorithm suited for  our BDI-POMDP hybrid approach. Finally, we also present experimental  results from two domains: mission rehearsal simulation and  RoboCupRescue disaster rescue simulation.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Hybrid BDI-POMDP Framework for Multiagent Teaming">
<meta name="citation_author" content="Nair,  R.">
<meta name="citation_author" content="Tambe,  M.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="367">
<meta name="citation_lastpage" content="420">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1549/live-1549-2381-jair.pdf">

<cite>J.  Larrosa,  E.  Morancho and  D.  Niso (2005) "On the Practical use of Variable Elimination in Constraint Optimization Problems: 'Still-life' as a Case Study", Volume 23, pages 421-440</cite>
<p class="media"><a href="/media/1541/live-1541-2372-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1541/live-1541-2371-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1541'>doi:10.1613/jair.1541</a></p>
<p>Variable elimination is a general technique for constraint processing. It is often discarded because of its high space complexity. However, it can be extremely useful when combined with other techniques. In this paper we study the applicability of variable elimination to the challenging problem of finding still-lifes.  We illustrate several alternatives: variable elimination as a stand-alone algorithm, interleaved with search, and as a source of good quality lower bounds.  We show that these techniques are the best known option both theoretically and empirically. In our experiments we have been able to solve the n=20 instance, which is far beyond reach with alternative approaches.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="On the Practical use of Variable Elimination in Constraint Optimization Problems: 'Still-life' as a Case Study">
<meta name="citation_author" content="Larrosa,  J.">
<meta name="citation_author" content="Morancho,  E.">
<meta name="citation_author" content="Niso,  D.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="421">
<meta name="citation_lastpage" content="440">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1541/live-1541-2372-jair.pdf">

<cite>H.  E. Dixon,  M.  L. Ginsberg,  D.  Hofer,  E.  M. Luks and  A.  J. Parkes (2005) "Generalizing Boolean Satisfiability III: Implementation", Volume 23, pages 441-531</cite>
<p class="media"><a href="/media/1656/live-1656-2410-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1656/live-1656-2409-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1656'>doi:10.1613/jair.1656</a></p>
<p>This is the third of three papers describing ZAP, a satisfiability engine that substantially generalizes existing tools while retaining the performance characteristics of modern high-performance solvers. The fundamental idea underlying ZAP is that many problems passed to such engines contain rich internal structure that is obscured by the Boolean representation used; our goal has been to define a representation in which this structure is apparent and can be exploited to improve computational performance.  The first paper surveyed existing work that (knowingly or not) exploited problem structure to improve the performance of satisfiability engines, and the second paper showed that this structure could be understood in terms of groups of permutations acting on individual clauses in any particular Boolean theory.  We conclude the series by discussing the techniques needed to implement our ideas, and by reporting on their performance on a variety of problem instances.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Generalizing Boolean Satisfiability III: Implementation">
<meta name="citation_author" content="Dixon,  H. E.">
<meta name="citation_author" content="Ginsberg,  M. L.">
<meta name="citation_author" content="Hofer,  D.">
<meta name="citation_author" content="Luks,  E. M.">
<meta name="citation_author" content="Parkes,  A. J.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="441">
<meta name="citation_lastpage" content="531">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1656/live-1656-2410-jair.pdf">

<cite>T.  Zimmerman and  S.  Kambhampati (2005) "Using Memory to Transform Search on the Planning Graph", Volume 23, pages 533-585</cite>
<p class="media"><a href="/media/1477/live-1477-2328-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1477/live-1477-2327-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume23/zimmerman05a-html/PEGG-zimmerman-kambhampati.htm" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1477'>doi:10.1613/jair.1477</a></p>
<p>The Graphplan algorithm for generating optimal make-span plans containing parallel sets of actions remains one of the most effective ways to generate such plans.  However, despite enhancements on a range of fronts, the approach is currently dominated in terms of speed, by state space planners that employ distance-based heuristics to quickly generate serial plans.  We report on a family of strategies that employ available memory to construct a search trace so as to learn from various aspects of Graphplan?s iterative search episodes in order to expedite search in subsequent episodes.  The planning approaches can be partitioned into two classes according to the type and extent of search experience captured in the trace.  The planners using the more aggressive tracing method are able to avoid much of Graphplan?s redundant search effort, while planners in the second class trade off this aspect in favor of a much higher degree of freedom than Graphplan in traversing the space of 'states' generated during regression search on the planning graph.  The tactic favored by the second approach, exploiting the search trace to transform the depth-first, IDA* nature of Graphplan?s search into an iterative state space view, is shown to be the more powerful.  We demonstrate that distance-based, state space heuristics can be adapted to informed traversal of the search trace used by the second class of planners and develop an augmentation targeted specifically at planning graph search.  Guided by such a heuristic, the step-optimal version of the planner in this class clearly dominates even a highly enhanced version of Graphplan.  By adopting beam search on the search trace we then show that virtually optimal parallel plans can be generated at speeds quite competitive with a modern heuristic state space planner.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Using Memory to Transform Search on the Planning Graph">
<meta name="citation_author" content="Zimmerman,  T.">
<meta name="citation_author" content="Kambhampati,  S.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="533">
<meta name="citation_lastpage" content="585">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1477/live-1477-2328-jair.pdf">

<cite>S.  Schroedl (2005) "An Improved Search Algorithm for Optimal Multiple-Sequence Alignment", Volume 23, pages 587-623</cite>
<p class="media"><a href="/media/1534/live-1534-2366-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1534/live-1534-2365-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1534'>doi:10.1613/jair.1534</a></p>
<p>Multiple sequence alignment (MSA) is a ubiquitous problem in computational biology. Although it is NP-hard to find an optimal solution for an arbitrary number of sequences, due to the importance of this problem researchers are trying to push the limits of exact algorithms further. Since MSA can be cast as a classical path finding problem, it is attracting a growing number of AI researchers interested in heuristic search algorithms as a challenge with actual practical relevance. </p><p> In this paper, we first review two previous, complementary lines of research. Based on Hirschberg's algorithm, Dynamic Programming needs O(kN^(k-1)) space to store both the search frontier and the nodes needed to reconstruct the solution path, for k sequences of length N. Best first search, on the other hand, has the advantage of bounding the search space that has to be explored using a heuristic.  However, it is necessary to maintain all explored nodes up to the final solution in order to prevent the search from re-expanding them at higher cost.  Earlier approaches to reduce the Closed list are either incompatible with pruning methods for the Open list, or must retain at least the boundary of the Closed list. </p><p> In this article, we present an algorithm that attempts at combining the respective advantages; like A* it uses a heuristic for pruning the search space, but reduces both the maximum Open and Closed size to O(kN^(k-1)), as in Dynamic Programming.  The underlying idea is to conduct a series of searches with successively increasing upper bounds, but using the DP ordering as the key for the Open priority queue.  With a suitable choice of thresholds, in practice, a running time below four times that of A* can be expected. </p><p> In our experiments we show that our algorithm outperforms one of the currently most successful algorithms for optimal multiple sequence alignments, Partial Expansion A*, both in time and memory. Moreover, we apply a refined heuristic based on optimal alignments not only of pairs of sequences, but of larger subsets.  This idea is not new; however, to make it practically relevant we show that it is equally important to bound the heuristic computation appropriately, or the overhead can obliterate any possible gain. </p><p> Furthermore, we discuss a number of improvements in time and space efficiency with regard to practical implementations. </p><p> Our algorithm, used in conjunction with higher-dimensional heuristics, is able to calculate for the first time the optimal alignment for almost all of the problems in Reference 1 of the benchmark database BAliBASE.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="An Improved Search Algorithm for Optimal Multiple-Sequence Alignment">
<meta name="citation_author" content="Schroedl,  S.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="587">
<meta name="citation_lastpage" content="623">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1534/live-1534-2366-jair.pdf">

<cite>G.  Barish and  C.  A. Knoblock (2005) "An Expressive Language and Efficient Execution System for Software Agents", Volume 23, pages 625-666</cite>
<p class="media"><a href="/media/1548/live-1548-2378-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1548/live-1548-2377-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1548'>doi:10.1613/jair.1548</a></p>
<p>Software agents can be used to automate many of the tedious, time-consuming information processing tasks that humans currently have to complete manually.  However, to do so, agent plans must be capable of representing the myriad of actions and control flows required to perform those tasks.  In addition, since these tasks can require integrating multiple sources of remote information ? typically, a slow, I/O-bound process ? it is desirable to make execution as efficient as possible.  To address both of these needs, we present a flexible software agent plan language and a highly parallel execution system that enable the efficient execution of expressive agent plans. The plan language allows complex tasks to be more easily expressed by providing a variety of operators for flexibly processing the data as well as supporting subplans (for modularity) and recursion (for indeterminate looping).  The executor is based on a streaming dataflow model of execution to maximize the amount of operator and data parallelism possible at runtime.  We have implemented both the language and executor in a system called THESEUS.  Our results from testing THESEUS show that streaming dataflow execution can yield significant speedups over both traditional serial (von Neumann) as well as non-streaming dataflow-style execution that existing software and robot agent execution systems currently support.  In addition, we show how plans written in the language we present can represent certain types of subtasks that cannot be accomplished using the languages supported by network query engines.  Finally, we demonstrate that the increased expressivity of our plan language does not hamper performance; specifically, we show how data can be integrated from multiple remote sources just as efficiently using our architecture as is possible with a state-of-the-art streaming-dataflow network query engine.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="An Expressive Language and Efficient Execution System for Software Agents">
<meta name="citation_author" content="Barish,  G.">
<meta name="citation_author" content="Knoblock,  C. A.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="625">
<meta name="citation_lastpage" content="666">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1548/live-1548-2378-jair.pdf">

<cite>L.  Carsten,  C.  Areces,  I.  Horrocks and  U.  Sattler (2005) "Keys, Nominals, and Concrete Domains", Volume 23, pages 667-726</cite>
<p class="media"><a href="/media/1542/live-1542-2375-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1542/live-1542-2374-jair.ps.Z">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1542'>doi:10.1613/jair.1542</a></p>
<p>Many description logics (DLs) combine knowledge representation on an abstract, logical level with an interface to 'concrete' domains like numbers and strings with built-in predicates such as >, +, and prefix-of. These hybrid DLs have turned out to be useful in several application areas, such as reasoning about conceptual database models.  We propose to further extend such DLs with key constraints that allow the expression of statements like 'US citizens are uniquely identified by their social security number'. Based on this idea, we introduce a number of natural description logics and perform a detailed analysis of their decidability and computational complexity.  It turns out that naive extensions with key constraints easily lead to undecidability, whereas more careful extensions yield NExpTime-complete DLs for a variety of useful concrete domains.</p>
<a href="/vol/vol23.html">Click here to return to Volume 23 contents list</a>
<meta name="citation_title" content="Keys, Nominals, and Concrete Domains">
<meta name="citation_author" content="Carsten,  L.">
<meta name="citation_author" content="Areces,  C.">
<meta name="citation_author" content="Horrocks,  I.">
<meta name="citation_author" content="Sattler,  U.">
<meta name="citation_publication_date" content="2005">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="667">
<meta name="citation_lastpage" content="726">
<meta name="citation_volume" content="23">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1542/live-1542-2375-jair.pdf">
