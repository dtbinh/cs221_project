<cite>E.  Davis (1999) "Order of Magnitude Comparisons of Distance", Volume 10, pages 1-38</cite>
<p class="media"><a href="/media/520/live-520-1733-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/520/live-520-1731-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume10/davis99a-html/om-dist.jair.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.520'>doi:10.1613/jair.520</a></p>
<p>Order of magnitude reasoning - reasoning by rough    comparisons of the sizes of quantities - is often called `back of    the envelope calculation', with the implication that the calculations    are quick though approximate.  This paper exhibits an interesting    class of constraint sets in which order of magnitude reasoning is    demonstrably fast.  Specifically, we present a polynomial-time    algorithm that can solve a set of constraints of the form `Points a    and b are much closer together than points c and d.'  We prove that    this algorithm can be applied if `much closer together' is    interpreted either as referring to an infinite difference in scale or    as referring to a finite difference in scale, as long as the    difference in scale is greater than the number of variables in the    constraint set.  We also prove that the first-order theory over such    constraints is decidable.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Order of Magnitude Comparisons of Distance">
<meta name="citation_author" content="Davis,  E.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="38">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/520/live-520-1733-jair.pdf">

<cite>T.  Hogg (1999) "Solving Highly Constrained Search Problems with Quantum Computers", Volume 10, pages 39-66</cite>
<p class="media"><a href="/media/574/live-574-1773-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/574/live-574-1771-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume10/hogg99a-html/paper.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.574'>doi:10.1613/jair.574</a></p>
<p>A previously developed quantum search algorithm for solving    1-SAT problems in a single step is generalized to apply to a range    of highly constrained k-SAT problems. We identify a bound on the    number of clauses in satisfiability problems for which the    generalized algorithm can find a solution in a constant number of    steps as the number of variables increases. This performance    contrasts with the linear growth in the number of steps required by    the best classical algorithms, and the exponential number required    by classical and quantum methods that ignore the problem    structure. In some cases, the algorithm can also guarantee that    insoluble problems in fact have no solutions, unlike previously    proposed quantum search algorithms.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Solving Highly Constrained Search Problems with Quantum Computers">
<meta name="citation_author" content="Hogg,  T.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="39">
<meta name="citation_lastpage" content="66">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/574/live-574-1773-jair.pdf">

<cite>J.  Y. Halpern (1999) "A Counter Example to Theorems of Cox and Fine", Volume 10, pages 67-85</cite>
<p class="media"><a href="/media/536/live-536-2055-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/536/live-536-2053-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.536'>doi:10.1613/jair.536</a></p>
<p>Cox's well-known theorem justifying the use of probability is shown not to hold in finite domains. The counterexample also suggests that Cox's assumptions are insufficient to prove the result even in infinite domains. The same counterexample is used to disprove a result of Fine on comparative conditional probability.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="A Counter Example to Theorems of Cox and Fine">
<meta name="citation_author" content="Halpern, J. Y.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="67">
<meta name="citation_lastpage" content="85">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/536/live-536-2055-jair.pdf">

<cite>D.  Long and  M.  Fox (1999) "Efficient Implementation of the Plan Graph in STAN", Volume 10, pages 87-115</cite>
<p class="media"><a href="/media/570/live-570-1766-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/570/live-570-1764-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.570'>doi:10.1613/jair.570</a>
<br/><a href="/media/570/live-570-1767-jair.tar">Appendix </a> - Code and data</p>
<p>STAN is a Graphplan-based planner, so-called because it uses    a variety of STate ANalysis techniques to enhance its performance.    STAN competed in the AIPS-98 planning competition where it compared    well with the other competitors in terms of speed, finding solutions    fastest to many of the problems posed. Although the domain analysis    techniques STAN exploits are an important factor in its overall    performance, we believe that the speed at which STAN solved the    competition problems is largely due to the implementation of its plan    graph. The implementation is based on two insights: that many of the    graph construction operations can be implemented as bit-level logical    operations on bit vectors, and that the graph should not be explicitly    constructed beyond the fix point. This paper describes the    implementation of STAN's plan graph and provides experimental results    which demonstrate the circumstances under which advantages can be    obtained from using this implementation.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Efficient Implementation of the Plan Graph in STAN">
<meta name="citation_author" content="Long,  D.">
<meta name="citation_author" content="Fox,  M.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="87">
<meta name="citation_lastpage" content="115">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/570/live-570-1766-jair.pdf">

<cite>N.  Friedman and  J.  Y. Halpern (1999) "Modeling  Belief  in  Dynamic  Systems, Part  II:  Revision  and  Update", Volume 10, pages 117-167</cite>
<p class="media"><a href="/media/506/live-506-1711-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/506/live-506-1709-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.506'>doi:10.1613/jair.506</a></p>
<p>The study of belief change has been an active area in    philosophy and AI.  In recent years two special cases of belief    change, belief revision and belief update, have been studied in    detail.  In a companion paper (Friedman & Halpern, 1997), we introduce    a new framework to model belief change. This framework combines    temporal and epistemic modalities with a notion of plausibility,    allowing us to examine the change of beliefs over time. In this paper,    we show how belief revision and belief update can be captured in our    framework.  This allows us to compare the assumptions made by each    method, and to better understand the principles underlying them.  In    particular, it shows that Katsuno and Mendelzon's notion of belief    update (Katsuno & Mendelzon, 1991a) depends on several strong    assumptions that may limit its applicability in artificial    intelligence.  Finally, our analysis allow us to identify a notion of    minimal change that underlies a broad range of belief change    operations including revision and update.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Modeling  Belief  in  Dynamic  Systems, Part  II:  Revision  and  Update">
<meta name="citation_author" content="Friedman,  N.">
<meta name="citation_author" content="Halpern,  J. Y.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="117">
<meta name="citation_lastpage" content="167">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/506/live-506-1711-jair.pdf">

<cite>D.  Fuchs and  M.  Fuchs (1999) "Cooperation between Top-Down and Bottom-Up Theorem Provers", Volume 10, pages 169-198</cite>
<p class="media"><a href="/media/573/live-573-1770-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/573/live-573-1768-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.573'>doi:10.1613/jair.573</a></p>
<p>Top-down and bottom-up theorem proving approaches each    have specific advantages and disadvantages.  Bottom-up provers profit    from strong redundancy control but suffer from the lack of    goal-orientation, whereas top-down provers are goal-oriented but often    have weak calculi when their proof lengths are considered.  In order    to integrate both approaches, we try to achieve cooperation between a    top-down and a bottom-up prover in two different ways: The first    technique aims at supporting a bottom-up with a top-down prover. A    top-down prover generates subgoal clauses, they are then processed by    a bottom-up prover.  The second technique deals with the use of    bottom-up generated lemmas in a top-down prover. We apply our concept    to the areas of model elimination and superposition.  We discuss the    ability of our techniques to shorten proofs as well as to reorder the    search space in an appropriate manner. Furthermore, in order to    identify subgoal clauses and lemmas which are actually relevant for    the proof task, we develop methods for a relevancy-based filtering.    Experiments with the provers SETHEO and SPASS performed in the problem    library TPTP reveal the high potential of our cooperation approaches.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Cooperation between Top-Down and Bottom-Up Theorem Provers">
<meta name="citation_author" content="Fuchs,  D.">
<meta name="citation_author" content="Fuchs,  M.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="169">
<meta name="citation_lastpage" content="198">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/573/live-573-1770-jair.pdf">

<cite>T.  Lukasiewicz (1999) "Probabilistic Deduction with Conditional Constraints over Basic Events", Volume 10, pages 199-241</cite>
<p class="media"><a href="/media/577/live-577-1780-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/577/live-577-1778-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.577'>doi:10.1613/jair.577</a></p>
<p>We study the problem of probabilistic deduction with    conditional constraints over basic events. We show that globally    complete probabilistic deduction with conditional constraints over    basic events is NP-hard. We then concentrate on the special case of    probabilistic deduction in conditional constraint trees. We elaborate    very efficient techniques for globally complete probabilistic    deduction. In detail, for conditional constraint trees with point    probabilities, we present a local approach to globally complete    probabilistic deduction, which runs in linear time in the size of the    conditional constraint trees. For conditional constraint trees with    interval probabilities, we show that globally complete probabilistic    deduction can be done in a global approach by solving nonlinear    programs. We show how these nonlinear programs can be transformed into    equivalent linear programs, which are solvable in polynomial time in    the size of the conditional constraint trees.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Probabilistic Deduction with Conditional Constraints over Basic Events">
<meta name="citation_author" content="Lukasiewicz,  T.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="199">
<meta name="citation_lastpage" content="241">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/577/live-577-1780-jair.pdf">

<cite>W.  W. Cohen,  R.  E. Schapire and  Y.  Singer (1999) "Learning to Order Things", Volume 10, pages 243-270</cite>
<p class="media"><a href="/media/587/live-587-1790-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/587/live-587-1788-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.587'>doi:10.1613/jair.587</a></p>
<p>There are many applications in which it is desirable to    order rather than classify instances. Here we consider the problem of    learning how to order instances given feedback in the form of    preference judgments, i.e., statements to the effect that one instance    should be ranked ahead of another.  We outline a two-stage approach in    which one first learns by conventional means a binary preference    function indicating whether it is advisable to rank one instance    before another. Here we consider an on-line algorithm for learning    preference functions that is based on Freund and Schapire's 'Hedge'    algorithm.  In the second stage, new instances are ordered so as to    maximize agreement with the learned preference function.  We show that    the problem of finding the ordering that agrees best with a learned    preference function is NP-complete.  Nevertheless, we describe simple    greedy algorithms that are guaranteed to find a good approximation.    Finally, we show how metasearch can be formulated as an ordering    problem, and present experimental results on learning a combination of    'search experts', each of which is a domain-specific query expansion    strategy for a web search engine.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Learning to Order Things">
<meta name="citation_author" content="Cohen,  W. W.">
<meta name="citation_author" content="Schapire,  R. E.">
<meta name="citation_author" content="Singer,  Y.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="243">
<meta name="citation_lastpage" content="270">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/587/live-587-1790-jair.pdf">

<cite>K.  M. Ting and  I.  H. Witten (1999) "Issues in Stacked Generalization", Volume 10, pages 271-289</cite>
<p class="media"><a href="/media/594/live-594-1797-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/594/live-594-1795-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.594'>doi:10.1613/jair.594</a></p>
<p>Stacked generalization is a general method of using a    high-level model to combine lower-level models to achieve greater    predictive accuracy.  In this paper we address two crucial issues    which have been considered to be a `black art' in classification tasks    ever since the introduction of stacked generalization in 1992 by    Wolpert: the type of generalizer that is suitable to derive the    higher-level model, and the kind of attributes that should be used as    its input.  We find that best results are obtained when the    higher-level model combines the confidence (and not just the    predictions) of the lower-level ones.   <p>We demonstrate the effectiveness of stacked generalization for combining     three different types of learning algorithms for classification tasks.    We also compare the performance of stacked generalization with    majority vote and published results of arcing and bagging.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Issues in Stacked Generalization">
<meta name="citation_author" content="Ting,  K. M.">
<meta name="citation_author" content="Witten,  I. H.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="271">
<meta name="citation_lastpage" content="289">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/594/live-594-1797-jair.pdf">

<cite>T.  S. Jaakkola and  M.  I. Jordan (1999) "Variational Probabilistic Inference and the QMR-DT Network", Volume 10, pages 291-322</cite>
<p class="media"><a href="/media/583/live-583-1783-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/583/live-583-1781-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume10/jaakkola99a-html/paper.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.583'>doi:10.1613/jair.583</a></p>
<p>We describe a variational approximation method for efficient    inference in large-scale probabilistic models.  Variational methods    are deterministic procedures that provide approximations to marginal    and conditional probabilities of interest.  They provide alternatives    to approximate inference methods based on stochastic sampling or    search.  We describe a variational approach to the problem of    diagnostic inference in the `Quick Medical Reference' (QMR) network.    The QMR network is a large-scale probabilistic graphical model built    on statistical and expert knowledge.  Exact probabilistic inference is    infeasible in this model for all but a small set of cases.  We    evaluate our variational inference algorithm on a large set of    diagnostic test cases, comparing the algorithm to a state-of-the-art    stochastic sampling method.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Variational Probabilistic Inference and the QMR-DT Network">
<meta name="citation_author" content="Jaakkola,  T. S.">
<meta name="citation_author" content="Jordan,  M. I.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="291">
<meta name="citation_lastpage" content="322">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/583/live-583-1783-jair.pdf">

<cite>J.  Rintanen (1999) "Constructing Conditional Plans by a Theorem-Prover", Volume 10, pages 323-352</cite>
<p class="media"><a href="/media/591/live-591-1793-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/591/live-591-1791-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.591'>doi:10.1613/jair.591</a>
<br/><a href="/media/591/live-591-1794-jair.html">Appendix </a> - Errata</p>
<p>The research on conditional planning rejects the assumptions    that there is no uncertainty or incompleteness of knowledge with    respect to the state and changes of the system the plans operate on.    Without these assumptions the sequences of operations that achieve the    goals depend on the initial state and the outcomes of nondeterministic    changes in the system.  This setting raises the questions of how to    represent the plans and how to perform plan search. The answers are    quite different from those in the simpler classical framework.  In    this paper, we approach conditional planning from a new viewpoint that    is motivated by the use of satisfiability algorithms in classical    planning.  Translating conditional planning to formulae in the    propositional logic is not feasible because of inherent computational    limitations.  Instead, we translate conditional planning to quantified    Boolean formulae.  We discuss three formalizations of conditional    planning as quantified Boolean formulae, and present experimental    results obtained with a theorem-prover.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Constructing Conditional Plans by a Theorem-Prover">
<meta name="citation_author" content="Rintanen,  J.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="323">
<meta name="citation_lastpage" content="352">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/591/live-591-1793-jair.pdf">

<cite>D.  E. Joslin and  D.  P. Clements (1999) "Squeaky Wheel Optimization", Volume 10, pages 353-373</cite>
<p class="media"><a href="/media/561/live-561-1759-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/561/live-561-1757-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume10/joslin99a-html/swo.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.561'>doi:10.1613/jair.561</a></p>
<p>We describe a general approach to optimization which we term    `Squeaky Wheel' Optimization (SWO).  In SWO, a greedy algorithm is    used to construct a solution which is then analyzed to find the    trouble spots, i.e., those elements, that, if improved, are likely to    improve the objective function score.  The results of the analysis are    used to generate new priorities that determine the order in which the    greedy algorithm constructs the next solution.  This    Construct/Analyze/Prioritize cycle continues until some limit is    reached, or an acceptable solution is found.        <p> SWO can be viewed as operating on two search spaces: solutions and    prioritizations.  Successive solutions are only indirectly related,    via the re-prioritization that results from analyzing the prior    solution.  Similarly, successive prioritizations are generated by    constructing and analyzing solutions.  This `coupled search' has some    interesting properties, which we discuss.        <p> We report encouraging experimental results on two domains, scheduling    problems that arise in fiber-optic cable manufacturing, and graph    coloring problems.  The fact that these domains are very different    supports our claim that SWO is a general technique for optimization.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Squeaky Wheel Optimization">
<meta name="citation_author" content="Joslin,  D. E.">
<meta name="citation_author" content="Clements,  D. P.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="353">
<meta name="citation_lastpage" content="373">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/561/live-561-1759-jair.pdf">

<cite>S.  Chien,  A.  Stechert and  D.  Mutz (1999) "Efficient Heuristic Hypothesis Ranking", Volume 10, pages 375-397</cite>
<p class="media"><a href="/media/615/live-615-1816-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/615/live-615-1814-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.615'>doi:10.1613/jair.615</a></p>
<p>This paper considers the problem of learning the ranking of    a set of stochastic alternatives based upon incomplete information    (i.e., a limited number of samples).  We describe a system that, at    each decision cycle, outputs either a complete ordering on the    hypotheses or decides to gather additional information (i.e.,    observations) at some cost.  The ranking problem is a generalization    of the previously studied hypothesis selection problem - in selection,    an algorithm must select the single best hypothesis, while in ranking,    an algorithm must order all the hypotheses.    <p>  The central problem we address is achieving the desired ranking    quality while minimizing the cost of acquiring additional samples.  We    describe two algorithms for hypothesis ranking and their application    for the probably approximately correct (PAC) and expected loss (EL)    learning criteria.  Empirical results are provided to demonstrate the    effectiveness of these ranking procedures on both synthetic and    real-world datasets.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Efficient Heuristic Hypothesis Ranking">
<meta name="citation_author" content="Chien,  S.">
<meta name="citation_author" content="Stechert,  A.">
<meta name="citation_author" content="Mutz,  D.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="375">
<meta name="citation_lastpage" content="397">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/615/live-615-1816-jair.pdf">

<cite>A.  Borgida (1999) "Extensible Knowledge Representation: the Case of Description Reasoners", Volume 10, pages 399-434</cite>
<p class="media"><a href="/media/584/live-584-1787-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/584/live-584-1785-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.584'>doi:10.1613/jair.584</a></p>
<p>This paper offers an approach to extensible knowledge    representation and reasoning for a family of formalisms known as    Description Logics. The approach is based on the notion of adding new    concept constructors, and includes a heuristic methodology for    specifying the desired extensions, as well as a modularized software    architecture that supports implementing extensions.  The architecture    detailed here falls in the normalize-compared paradigm, and supports    both intentional reasoning (subsumption) involving concepts, and    extensional reasoning involving individuals after incremental updates    to the knowledge base.    <p>  The resulting approach can be used to extend the reasoner with    specialized notions that are motivated by specific problems or    application areas, such as reasoning about dates, plans, etc. In    addition, it provides an opportunity to implement constructors that    are not currently yet sufficiently well understood theoretically, but    are needed in practice. Also, for constructors that are provably hard    to reason with (e.g., ones whose presence would lead to    undecidability), it allows the implementation of incomplete reasoners    where the incompleteness is tailored to be acceptable for the    application at hand.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Extensible Knowledge Representation: the Case of Description Reasoners">
<meta name="citation_author" content="Borgida,  A.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="399">
<meta name="citation_lastpage" content="434">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/584/live-584-1787-jair.pdf">

<cite>D.  Barber and P.  de van Laar (1999) "Variational Cumulant Expansions for Intractable Distributions", Volume 10, pages 435-455</cite>
<p class="media"><a href="/media/567/live-567-1763-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/567/live-567-1761-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.567'>doi:10.1613/jair.567</a></p>
<p>Intractable distributions present a common difficulty in    inference within the probabilistic knowledge representation framework    and variational methods have recently been popular in providing an    approximate solution. In this article, we describe a perturbational    approach in the form of a cumulant expansion which, to lowest order,    recovers the standard Kullback-Leibler variational bound.    Higher-order terms describe corrections on the variational approach    without incurring much further computational cost.  The relationship    to other perturbational approaches such as TAP is also elucidated.  We    demonstrate the method on a particular class of undirected graphical    models, Boltzmann machines, for which our simulation results confirm    improved accuracy and enhanced stability during learning.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="Variational Cumulant Expansions for Intractable Distributions">
<meta name="citation_author" content="Barber,  D.">
<meta name="citation_author" content="de van Laar, P.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="435">
<meta name="citation_lastpage" content="455">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/567/live-567-1763-jair.pdf">

<cite>E.  Birnbaum and  E.  L. Lozinskii (1999) "The Good Old Davis-Putnam Procedure Helps Counting Models", Volume 10, pages 457-477</cite>
<p class="media"><a href="/media/601/live-601-1800-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/601/live-601-1798-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.601'>doi:10.1613/jair.601</a></p>
<p>As was shown recently, many important AI problems require    counting the number of models of propositional formulas. The problem    of counting models of such formulas is, according to present    knowledge, computationally intractable in a worst case. Based on the    Davis-Putnam procedure, we present an algorithm, CDP, that computes    the exact number of models of a propositional CNF or DNF formula    F. Let m and n be the number of clauses and variables of F,    respectively, and let p denote the probability that a literal l of F    occurs in a clause C of F, then the average running time of CDP is    shown to be O(nm^d), where d=-1/log(1-p).  The practical    performance of CDP has been estimated in a series of experiments on a    wide variety of CNF formulas.</p>
<a href="/vol/vol10.html">Click here to return to Volume 10 contents list</a>
<meta name="citation_title" content="The Good Old Davis-Putnam Procedure Helps Counting Models">
<meta name="citation_author" content="Birnbaum,  E.">
<meta name="citation_author" content="Lozinskii,  E. L.">
<meta name="citation_publication_date" content="1999">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="457">
<meta name="citation_lastpage" content="477">
<meta name="citation_volume" content="10">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/601/live-601-1800-jair.pdf">
