<cite>Simone  Villa and Fabio  Stella (2016) "Learning Continuous Time Bayesian Networks in Non-stationary Domains", Volume 57, pages 1-37</cite>
<p class="media"><a href="/media/5126/live-5126-9528-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.5126'>doi:10.1613/jair.5126</a></p>
<p>Non-stationary continuous time Bayesian networks are introduced. They allow the parents set of each node to change over continuous time. Three settings are developed for learning non-stationary continuous time Bayesian networks from data: known transition times, known number of epochs and unknown number of epochs. A score function for each setting is derived and the corresponding learning algorithm is developed. A set of numerical experiments on synthetic data is used to compare the effectiveness of non-stationary continuous time Bayesian networks to that of non-stationary dynamic Bayesian networks. Furthermore, the performance achieved by non-stationary continuous time Bayesian networks is compared to that achieved by state-of-the-art algorithms on four real-world datasets, namely drosophila, saccharomyces cerevisiae, songbird and macroeconomics. </p>
<a href="/vol/vol57.html">Click here to return to Volume 57 contents list</a>
<meta name="citation_title" content="Learning Continuous Time Bayesian Networks in Non-stationary Domains">
<meta name="citation_author" content="Villa, Simone">
<meta name="citation_author" content="Stella, Fabio">
<meta name="citation_publication_date" content="2016">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="37">
<meta name="citation_volume" content="57">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/5126/live-5126-9528-jair.pdf">

<cite>Karsten  Martiny and Ralf  M&#246;ller (2016) "PDT Logic: A Probabilistic Doxastic Temporal Logic for Reasoning about Beliefs in Multi-agent Systems", Volume 57, pages 39-112</cite>
<p class="media"><a href="/media/5182/live-5182-9531-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.5182'>doi:10.1613/jair.5182</a></p>
<p>We present Probabilistic Doxastic Temporal (PDT) Logic, a formalism to represent and reason about probabilistic beliefs and their temporal evolution in multi-agent systems. This formalism enables the quantification of agents’ beliefs through probability intervals and incorporates an explicit notion of time. We discuss how over time agents dynamically change their beliefs in facts, temporal rules, and other agents’ beliefs with respect to any new information they receive. We introduce an appropriate formal semantics for PDT Logic and show that it is decidable. Alternative options of specifying problems in PDT Logic are possible. For these problem specifications, we develop different satisfiability checking algorithms and provide complexity results for the respective decision problems. The use of probability intervals enables a formal representation of probabilistic knowledge without enforcing (possibly incorrect) exact probability values. By incorporating an explicit notion of time, PDT Logic provides enriched possibilities to represent and reason about temporal relations.</p>
<a href="/vol/vol57.html">Click here to return to Volume 57 contents list</a>
<meta name="citation_title" content="PDT Logic: A Probabilistic Doxastic Temporal Logic for Reasoning about Beliefs in Multi-agent Systems">
<meta name="citation_author" content="Martiny, Karsten">
<meta name="citation_author" content="M&#246;ller, Ralf">
<meta name="citation_publication_date" content="2016">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="39">
<meta name="citation_lastpage" content="112">
<meta name="citation_volume" content="57">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/5182/live-5182-9531-jair.pdf">

<cite>Christian  Muise, J.  Christopher Beck and Sheila  A. McIlraith (2016) "Optimal Partial-Order Plan Relaxation via MaxSAT", Volume 57, pages 113-149</cite>
<p class="media"><a href="/media/5128/live-5128-9534-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/5128/live-5128-9535-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.5128'>doi:10.1613/jair.5128</a></p>
<p>Partial-order plans (POPs) are attractive because of their least-commitment nature, which provides enhanced plan flexibility at execution time relative to sequential plans. Current research on automated plan generation focuses on producing sequential plans, despite the appeal of POPs. In this paper we examine POP generation by relaxing or modifying the action orderings of a sequential plan to optimize for plan criteria that promote flexibility. Our approach relies on a novel partial weighted MaxSAT encoding of a sequential plan that supports the minimization of deordering or reordering of actions. Using a similar technique, we further demonstrate how to remove redundant actions from the plan, and how to combine this criterion with the objective of maximizing a POP's flexibility. Our partial weighted MaxSAT encoding allows us to compute a POP from a sequential plan effectively. We compare the efficiency of our approach to previous methods for POP generation via sequential-plan relaxation. Our results show that while an existing heuristic approach consistently produces the optimal deordering of a sequential plan, our approach has greater flexibility when we consider reordering the actions in the plan while also providing a guarantee of optimality. We also investigate and confirm the accuracy of the standard flex metric typically used to predict the true flexibility of a POP as measured by the number of linearizations it represents.</p>
<a href="/vol/vol57.html">Click here to return to Volume 57 contents list</a>
<meta name="citation_title" content="Optimal Partial-Order Plan Relaxation via MaxSAT">
<meta name="citation_author" content="Muise, Christian">
<meta name="citation_author" content="Beck, J. Christopher">
<meta name="citation_author" content="McIlraith, Sheila A.">
<meta name="citation_publication_date" content="2016">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="113">
<meta name="citation_lastpage" content="149">
<meta name="citation_volume" content="57">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/5128/live-5128-9534-jair.pdf">

<cite>Alejandro  Moreo Fern&#225;ndez, Andrea  Esuli and Fabrizio  Sebastiani (2016) "Lightweight Random Indexing for Polylingual Text Classification", Volume 57, pages 151-185</cite>
<p class="media"><a href="/media/5194/live-5194-9567-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.5194'>doi:10.1613/jair.5194</a></p>
<p>Multilingual Text Classification (MLTC) is a text classification task in which documents are written each in one among a set L of natural languages, and in which all documents must be classified under the same classification scheme, irrespective of language. There are two main variants of MLTC, namely Cross-Lingual Text Classification (CLTC) and Polylingual Text Classification (PLTC). In PLTC, which is the focus of this paper, we assume (differently from CLTC) that for each language in L there is a representative set of training documents; PLTC consists of improving the accuracy of each of the |L| monolingual classifiers by also leveraging the training documents written in the other (|L| &#8722; 1) languages. The obvious solution, consisting of generating a single polylingual classifier from the juxtaposed monolingual vector spaces, is usually infeasible, since the dimensionality of the resulting vector space is roughly |L| times that of a monolingual one, and is thus often unmanageable. As a response, the use of machine translation tools or multilingual dictionaries has been proposed. However, these resources are not always available, or are not always free to use.<br />
<br />
One machine-translation-free and dictionary-free method that, to the best of our knowledge, has never been applied to PLTC before, is Random Indexing (RI). We analyse RI in terms of space and time efficiency, and propose a particular configuration of it (that we dub Lightweight Random Indexing – LRI). By running experiments on two well known public benchmarks, Reuters RCV1/RCV2 (a comparable corpus) and JRC-Acquis (a parallel one), we show LRI to outperform (both in terms of effectiveness and efficiency) a number of previously proposed machine-translation-free and dictionary-free PLTC methods that we use as baselines.</p>
<a href="/vol/vol57.html">Click here to return to Volume 57 contents list</a>
<meta name="citation_title" content="Lightweight Random Indexing for Polylingual Text Classification">
<meta name="citation_author" content="Moreo Fern&#225;ndez, Alejandro">
<meta name="citation_author" content="Esuli, Andrea">
<meta name="citation_author" content="Sebastiani, Fabrizio">
<meta name="citation_publication_date" content="2016">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="151">
<meta name="citation_lastpage" content="185">
<meta name="citation_volume" content="57">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/5194/live-5194-9567-jair.pdf">

<cite>Simone  Parisi, Matteo  Pirotta and Marcello  Restelli (2016) "Multi-objective Reinforcement Learning through Continuous Pareto Manifold Approximation", Volume 57, pages 187-227</cite>
<p class="media"><a href="/media/4961/live-4961-9579-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.4961'>doi:10.1613/jair.4961</a></p>
<p>Many real-world control applications, from economics to robotics, are characterized by the presence of multiple conflicting objectives. In these problems, the standard concept of optimality is replaced by Pareto-optimality and the goal is to find the Pareto frontier, a set of solutions representing different compromises among the objectives. Despite recent advances in multi-objective optimization, achieving an accurate representation of the Pareto frontier is still an important challenge.  In this paper, we propose a reinforcement learning policy gradient approach to learn a continuous approximation of the Pareto   frontier in multi-objective Markov Decision Problems (MOMDPs). Differently from previous policy gradient algorithms, where n optimization routines are executed to have n solutions, our approach performs a single gradient ascent run, generating at each step an improved continuous approximation of the Pareto frontier. The idea is   to optimize the parameters of a function defining a manifold in the policy parameters space, so that the corresponding image in the objectives space gets as close as possible to the true Pareto frontier. Besides deriving how to compute and estimate such gradient, we will also discuss the non-trivial issue of defining a metric to assess the quality of the candidate Pareto frontiers. Finally, the properties of the proposed approach are empirically evaluated on two problems, a linear-quadratic Gaussian regulator and a water reservoir control task.</p>
<a href="/vol/vol57.html">Click here to return to Volume 57 contents list</a>
<meta name="citation_title" content="Multi-objective Reinforcement Learning through Continuous Pareto Manifold Approximation">
<meta name="citation_author" content="Parisi, Simone">
<meta name="citation_author" content="Pirotta, Matteo">
<meta name="citation_author" content="Restelli, Marcello">
<meta name="citation_publication_date" content="2016">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="187">
<meta name="citation_lastpage" content="227">
<meta name="citation_volume" content="57">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/4961/live-4961-9579-jair.pdf">
