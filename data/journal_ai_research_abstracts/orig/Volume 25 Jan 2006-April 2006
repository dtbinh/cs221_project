<cite>N.  Onder, G.  C. Whelan and L.  Li (2006) "Engineering a Conformant Probabilistic Planner", Volume 25, pages 1-15</cite>
<p class="media"><a href="/media/1701/live-1701-2565-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1701/live-1701-2566-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume25/onder06a-html/onder06a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1701'>doi:10.1613/jair.1701</a></p>
<p>We present a partial-order, conformant, probabilistic planner, Probapop which competed in the blind track of the Probabilistic Planning Competition in IPC-4. We explain how we adapt distance based heuristics for use with probabilistic domains. Probapop also incorporates heuristics based on probability of success. We explain the successes and difficulties encountered during the design and implementation of Probapop. </p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Engineering a Conformant Probabilistic Planner">
<meta name="citation_author" content="Onder, N.">
<meta name="citation_author" content="Whelan, G. C.">
<meta name="citation_author" content="Li, L.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="15">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1701/live-1701-2565-jair.pdf">

<cite>S.  Thiebaux, C.  Gretton, J.  Slaney, D.  Price and F.  Kabanza (2006) "Decision-Theoretic Planning with non-Markovian Rewards", Volume 25, pages 17-74</cite>
<p class="media"><a href="/media/1676/live-1676-2571-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1676/live-1676-2572-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume25/thiebaux06a-html/thiebaux06a-html.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1676'>doi:10.1613/jair.1676</a></p>
<p>A decision process in which rewards depend on history rather than merely on the current state is called a decision process with non-Markovian rewards (NMRDP). In decision-theoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MDP) model. While the more tractable solution methods developed for MDPs do not directly apply in the presence of non-Markovian rewards, a number of solution methods for NMRDPs have been proposed in the literature. These all exploit a compact specification of the non-Markovian reward function in temporal logic, to automatically translate the NMRDP into an equivalent MDP which is solved using efficient MDP solution methods. This paper presents NMRDPP (Non-Markovian Reward Decision Process Planner), a software platform for the development and experimentation of methods for decision-theoretic planning with non-Markovian rewards. The current version of NMRDPP implements, under a single interface, a family of methods based on existing as well as new approaches which we describe in detail. These include dynamic programming, heuristic search, and structured methods. Using NMRDPP, we compare the methods and identify certain problem features that affect their performance. NMRDPP's treatment of non-Markovian rewards is inspired by the treatment of domain-specific search control knowledge in the TLPlan planner, which it incorporates as a special case. In the First International Probabilistic Planning Competition, NMRDPP was able to compete and perform well in both the domain-independent and hand-coded tracks, using search control knowledge in the latter. <br />
</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Decision-Theoretic Planning with non-Markovian Rewards">
<meta name="citation_author" content="Thiebaux, S.">
<meta name="citation_author" content="Gretton, C.">
<meta name="citation_author" content="Slaney, J.">
<meta name="citation_author" content="Price, D.">
<meta name="citation_author" content="Kabanza, F.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="17">
<meta name="citation_lastpage" content="74">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1676/live-1676-2571-jair.pdf">

<cite>A.  Fern, S.  Yoon and R.  Givan (2006) "Approximate Policy Iteration with a Policy Language Bias: Solving Relational Markov Decision Processes", Volume 25, pages 75-118</cite>
<cite>Honorable Mention for the 2011 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/1700/live-1700-2574-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1700/live-1700-2575-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1700'>doi:10.1613/jair.1700</a></p>
<p>We study an approach to policy selection for large relational Markov Decision Processes (MDPs). We consider a variant of approximate policy iteration (API) that replaces the usual value-function learning step with a learning step in policy space. This is advantageous in domains where good policies are easier to represent and learn than the corresponding value functions, which is often the case for the relational MDPs we are interested in. In order to apply API to such problems, we introduce a relational policy language and corresponding learner. In addition, we introduce a new bootstrapping routine for goal-based planning domains, based on random walks. Such bootstrapping is necessary for many large relational MDPs, where reward is extremely sparse, as API is ineffective in such domains when initialized with an uninformed policy. Our experiments show that the resulting system is able to find good policies for a number of classical planning domains and their stochastic variants by solving them as extremely large relational MDPs. The experiments also point to some limitations of our approach, suggesting future work.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Approximate Policy Iteration with a Policy Language Bias: Solving Relational Markov Decision Processes">
<meta name="citation_author" content="Fern, A.">
<meta name="citation_author" content="Yoon, S.">
<meta name="citation_author" content="Givan, R.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="75">
<meta name="citation_lastpage" content="118">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1700/live-1700-2574-jair.pdf">

<cite>V.  Bulitko and G.  Lee (2006) "Learning in Real-Time Search: A Unifying Framework", Volume 25, pages 119-157</cite>
<p class="media"><a href="/media/1789/live-1789-2576-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1789/live-1789-2577-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1789'>doi:10.1613/jair.1789</a></p>
<p>Real-time search methods are suited for tasks in which the agent is interacting with an initially unknown environment in real time. In such simultaneous planning and learning problems, the agent has to select its actions in a limited amount of time, while sensing only a local part of the environment centered at the agent's current location. Real-time heuristic search agents select actions using a limited lookahead search and evaluating the frontier states with a heuristic function. Over repeated experiences, they refine heuristic values of states to avoid infinite loops and to converge to better solutions. The wide spread of such settings in autonomous software and hardware agents has led to an explosion of real-time search algorithms over the last two decades. Not only is a potential user confronted with a hodgepodge of algorithms, but he also faces the choice of control parameters they use. In this paper we address both problems. The first contribution is an introduction of a simple three-parameter framework (named LRTS) which extracts the core ideas behind many existing algorithms. We then prove that LRTA*, epsilon-LRTA*, SLA*, and gamma-Trap algorithms are special cases of our framework. Thus, they are unified and extended with additional features. Second, we prove completeness and convergence of any algorithm covered by the LRTS framework. Third, we prove several upper-bounds relating the control parameters and solution quality. Finally, we analyze the influence of the three control parameters empirically in the realistic scalable domains of real-time navigation on initially unknown maps from a commercial role-playing game as well as routing in ad hoc sensor networks. <br />
</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Learning in Real-Time Search: A Unifying Framework">
<meta name="citation_author" content="Bulitko, V.">
<meta name="citation_author" content="Lee, G.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="119">
<meta name="citation_lastpage" content="157">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1789/live-1789-2576-jair.pdf">

<cite>W.  Pullan and H.  H. Hoos (2006) "Dynamic Local Search for the Maximum Clique Problem", Volume 25, pages 159-185</cite>
<p class="media"><a href="/media/1815/live-1815-2578-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1815/live-1815-2579-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1815'>doi:10.1613/jair.1815</a></p>
<p>In this paper, we introduce DLS-MC, a new stochastic local search algorithm for the maximum clique problem. DLS-MC alternates between phases of iterative improvement, during which suitable vertices are added to the current clique, and plateau search, during which vertices of the current clique are swapped with vertices not contained in the current clique. The selection of vertices is solely based on vertex penalties that are dynamically adjusted during the search, and a perturbation mechanism is used to overcome search stagnation. The behaviour of DLS-MC is controlled by a single parameter, penalty delay, which controls the frequency at which vertex penalties are reduced. We show empirically that DLS-MC achieves substantial performance improvements over state-of-the-art algorithms for the maximum clique problem over a large range of the commonly used DIMACS benchmark instances.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Dynamic Local Search for the Maximum Clique Problem">
<meta name="citation_author" content="Pullan, W.">
<meta name="citation_author" content="Hoos, H. H.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="159">
<meta name="citation_lastpage" content="185">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1815/live-1815-2578-jair.pdf">

<cite>A.  Gerevini, A.  Saetti and I.  Serina (2006) "An Approach to Temporal Planning and Scheduling in Domains with Predictable Exogenous Events", Volume 25, pages 187-231</cite>
<p class="media"><a href="/media/1742/live-1742-2580-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1742/live-1742-2581-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1742'>doi:10.1613/jair.1742</a></p>
<p>The treatment of exogenous events in planning is practically important in many real-world domains where the preconditions of certain plan actions are affected by such events. In this paper we focus on planning in temporal domains with exogenous events that happen at known times, imposing the constraint that certain actions in the plan must be executed during some predefined time windows. When actions have durations, handling such temporal constraints adds an extra difficulty to planning. We propose an approach to planning in these domains which integrates constraint-based temporal reasoning into a graph-based planning framework using local search. Our techniques are implemented in a planner that took part in the 4th International Planning Competition (IPC-4). A statistical analysis of the results of IPC-4 demonstrates the effectiveness of our approach in terms of both CPU-time and plan quality. Additional experiments show the good performance of the temporal reasoning techniques integrated into our planner. </p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="An Approach to Temporal Planning and Scheduling in Domains with Predictable Exogenous Events">
<meta name="citation_author" content="Gerevini, A.">
<meta name="citation_author" content="Saetti, A.">
<meta name="citation_author" content="Serina, I.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="187">
<meta name="citation_lastpage" content="231">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1742/live-1742-2580-jair.pdf">

<cite>P.  Haslum (2006) "Improving Heuristics Through Relaxed Search - An Analysis of TP4 and HSP*a in the 2004 Planning Competition", Volume 25, pages 233-267</cite>
<p class="media"><a href="/media/1885/live-1885-2582-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1885/live-1885-2583-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1885'>doi:10.1613/jair.1885</a></p>
<p>The <i>h<sup>m</sup></i> admissible heuristics for (sequential and temporal) regression planning are defined by a parameterized relaxation of the optimal cost function in the regression search space, where the parameter <i>m</i> offers a trade-off between the accuracy and computational cost of theheuristic. Existing methods for computing the <i>h<sup>m</sup></i> heuristic require time exponential in <i>m</i>, limiting them to small values (<i>m <= 2</i>). The <i>h<sup>m</sup></i> heuristic can also be viewed as the optimal cost function in a relaxation of the search space: this paper presents <em>relaxed search</em>, a method for computing this function partially by searching in the relaxed space. The relaxed search method, because it computes <i>h<sup>m</sup></i> only partially, is computationally cheaper and therefore usable for higher values of <i>m</i>. The (complete) <i>h<sup>m</sup></i> heuristic is combined with partial <i>h<sup>m</sup></i> heuristics, for <i>m = 3,...</i>, computed by relaxed search, resulting in a more accurate heuristic.<br />
<br />
This use of the relaxed search method to improve on the <i>h<sup>m</sup></i> heuristic is evaluated by comparing two optimal temporal planners: TP4, which does not use it, and HSP*<sub>a</sub>, which uses it but is otherwise identical to TP4. The comparison is made on the domains used in the 2004 International Planning Competition, in which both planners participated. Relaxed search is found to be cost effective in some of these domains, but not all. Analysis reveals a characterization of the domains in which relaxed search can be expected to be cost effective, in terms of two measures on the original and relaxed search spaces. In the domains where relaxed search is cost effective, expanding small states is computationally cheaper than expanding large states and small states tend to have small successor states.<br />
</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Improving Heuristics Through Relaxed Search - An Analysis of TP4 and HSP*a in the 2004 Planning Competition">
<meta name="citation_author" content="Haslum, P.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="233">
<meta name="citation_lastpage" content="267">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1885/live-1885-2582-jair.pdf">

<cite>P.  Adjiman, P.  Chatalic, F.  Goasdoue, M.  C. Rousset and L.  Simon (2006) "Distributed Reasoning in a Peer-to-Peer Setting: Application to the Semantic Web", Volume 25, pages 269-314</cite>
<p class="media"><a href="/media/1785/live-1785-2584-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1785/live-1785-2585-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1785'>doi:10.1613/jair.1785</a></p>
<p>In a peer-to-peer inference system, each peer can reason locally but can also solicit some of its acquaintances, which are peers sharing part of its vocabulary. In this paper, we consider peer-to-peer inference systems in which the local theory of each peer is a set of propositional clauses defined upon a local vocabulary. An important characteristic of peer-to-peer inference systems is that the global theory (the union of all peer theories) is not known (as opposed to partition-based reasoning systems). The main contribution of this paper is to provide the first consequence finding algorithm in a peer-to-peer setting: DeCA. It is anytime and computes consequences gradually from the solicited peer to peers that are more and more distant. We exhibit a sufficient condition on the acquaintance graph of the peer-to-peer inference system for guaranteeing the completeness of this algorithm. Another important contribution is to apply this general distributed reasoning setting to the setting of the Semantic Web through the Somewhere semantic peer-to-peer data management system. The last contribution of this paper is to provide an experimental analysis of the scalability of the peer-to-peer infrastructure that we propose, on large networks of 1000 peers. </p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Distributed Reasoning in a Peer-to-Peer Setting: Application to the Semantic Web">
<meta name="citation_author" content="Adjiman, P.">
<meta name="citation_author" content="Chatalic, P.">
<meta name="citation_author" content="Goasdoue, F.">
<meta name="citation_author" content="Rousset, M. C.">
<meta name="citation_author" content="Simon, L.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="269">
<meta name="citation_lastpage" content="314">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1785/live-1785-2584-jair.pdf">

<cite>U.  Endriss, N.  Maudet, F.  Sadri and F.  Toni (2006) "Negotiating Socially Optimal Allocations of Resources", Volume 25, pages 315-348</cite>
<p class="media"><a href="/media/1870/live-1870-2595-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1870/live-1870-2596-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1870'>doi:10.1613/jair.1870</a></p>
<p>A multiagent system may be thought of as an artificial society of autonomous software agents and we can apply concepts borrowed from welfare economics and social choice theory to assess the social welfare of such an agent society. In this paper, we study an abstract negotiation framework where agents can agree on multilateral deals to exchange bundles of indivisible resources. We then analyse how these deals affect social welfare for different instances of the basic framework and different interpretations of the concept of social welfare itself. In particular, we show how certain classes of deals are both sufficient and necessary to guarantee that a socially optimal allocation of resources will be reached eventually. </p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Negotiating Socially Optimal Allocations of Resources">
<meta name="citation_author" content="Endriss, U.">
<meta name="citation_author" content="Maudet, N.">
<meta name="citation_author" content="Sadri, F.">
<meta name="citation_author" content="Toni, F.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="315">
<meta name="citation_lastpage" content="348">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1870/live-1870-2595-jair.pdf">

<cite>G.  Gutnik and G.  A. Kaminka (2006) "Representing Conversations for Scalable Overhearing", Volume 25, pages 349-387</cite>
<p class="media"><a href="/media/1829/live-1829-2600-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1829/live-1829-2599-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume25/gutnik06a-html/gutnikg06-CPnetsForOverhearing.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1829'>doi:10.1613/jair.1829</a></p>
<p>Open distributed multi-agent systems are gaining interest in the academic community and in industry. In such open settings, agents are often coordinated using standardized agent conversation protocols. The representation of such protocols (for analysis, validation, monitoring, etc) is an important aspect of multi-agent applications. Recently, Petri nets have been shown to be an interesting approach to such representation, and radically different approaches using Petri nets have been proposed. However, their relative strengths and weaknesses have not been examined. Moreover, their scalability and suitability for different tasks have not been addressed. This paper addresses both these challenges. First, we analyze existing Petri net representations in terms of their scalability and appropriateness for overhearing, an important task in monitoring open multi-agent systems. Then, building on the insights gained, we introduce a novel representation using Colored Petri nets that explicitly represent legal joint conversation states and messages. This representation approach offers significant improvements in scalability and is particularly suitable for overhearing. Furthermore, we show that this new representation offers a comprehensive coverage of all conversation features of FIPA conversation standards. We also present a procedure for transforming AUML conversation protocol diagrams (a standard human-readable representation), to our Colored Petri net representation. <br />
</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Representing Conversations for Scalable Overhearing">
<meta name="citation_author" content="Gutnik, G.">
<meta name="citation_author" content="Kaminka, G. A.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="349">
<meta name="citation_lastpage" content="387">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1829/live-1829-2600-jair.pdf">

<cite>R.  I. Brafman, C.  Domshlak and S.  E. Shimony (2006) "On Graphical Modeling of Preference and Importance", Volume 25, pages 389-424</cite>
<p class="media"><a href="/media/1895/live-1895-2605-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1895/live-1895-2604-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1895'>doi:10.1613/jair.1895</a></p>
<p>In recent years, CP-nets have emerged as a useful tool for supporting preference elicitation, reasoning, and representation. CP-nets capture and support reasoning with qualitative conditional preference statements, statements that are relatively natural for users to express. In this paper, we extend the CP-nets formalism to handle another class of very natural qualitative statements one often uses in expressing preferences in daily life - statements of relative importance of attributes. The resulting formalism, TCP-nets, maintains the spirit of CP-nets, in that it remains focused on using only simple and natural preference statements, uses the ceteris paribus semantics, and utilizes a graphical representation of this information to reason about its consistency and to perform, possibly constrained, optimization using it. The extra expressiveness it provides allows us to better model tradeoffs users would like to make, more faithfully representing their preferences.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="On Graphical Modeling of Preference and Importance">
<meta name="citation_author" content="Brafman, R. I.">
<meta name="citation_author" content="Domshlak, C.">
<meta name="citation_author" content="Shimony, S. E.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="389">
<meta name="citation_lastpage" content="424">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1895/live-1895-2605-jair.pdf">

<cite>K.  Kersting, L.  De Raedt and T.  Raiko (2006) "Logical Hidden Markov Models", Volume 25, pages 425-456</cite>
<p class="media"><a href="/media/1675/live-1675-2623-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1675/live-1675-2622-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1675'>doi:10.1613/jair.1675</a></p>
<p>Logical hidden Markov models (LOHMMs) upgrade traditional hidden Markov models to deal with sequences of structured symbols in the form of logical atoms, rather than flat characters.<br />
<br />
This note formally introduces LOHMMs and presents solutions to the three central inference problems for LOHMMs: evaluation, most likely hidden state sequence and parameter estimation. The resulting representation and algorithms are experimentally evaluated on problems from the domain of bioinformatics.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Logical Hidden Markov Models">
<meta name="citation_author" content="Kersting, K.">
<meta name="citation_author" content="De Raedt, L.">
<meta name="citation_author" content="Raiko, T.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="425">
<meta name="citation_lastpage" content="456">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1675/live-1675-2623-jair.pdf">

<cite>B.  Blum, C.  R. Shelton and D.  Koller (2006) "A Continuation Method for Nash Equilibria in Structured Games", Volume 25, pages 457-502</cite>
<p class="media"><a href="/media/1947/live-1947-2630-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1947/live-1947-2629-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1947'>doi:10.1613/jair.1947</a></p>
<p>Structured game representations have recently attracted interest as models for multi-agent artificial intelligence scenarios, with rational behavior most commonly characterized by Nash equilibria.  This paper presents efficient, exact algorithms for computing Nash equilibria in structured game representations, including both graphical games and multi-agent influence diagrams (MAIDs).  The algorithms are derived from a continuation method for normal-form and extensive-form games due to Govindan and Wilson; they follow a trajectory through a space of perturbed games and their equilibria, exploiting game structure through fast computation of the Jacobian of the payoff function.  They are theoretically guaranteed to find at least one equilibrium of the game, and may find more.  Our approach provides the first efficient algorithm for computing exact equilibria in graphical games with arbitrary topology, and the first algorithm to exploit fine-grained structural properties of MAIDs. Experimental results are presented demonstrating the  effectiveness of the algorithms and comparing them to predecessors.  The running time of the graphical game algorithm is similar to, and often better than, the running time of previous approximate algorithms. The algorithm for MAIDs can effectively solve games that are much larger than those solvable by previous methods.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="A Continuation Method for Nash Equilibria in Structured Games">
<meta name="citation_author" content="Blum, B.">
<meta name="citation_author" content="Shelton, C. R.">
<meta name="citation_author" content="Koller, D.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="457">
<meta name="citation_lastpage" content="502">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1947/live-1947-2630-jair.pdf">

<cite>A.  Roy (2006) "Fault Tolerant Boolean Satisfiability", Volume 25, pages 503-527</cite>
<p class="media"><a href="/media/1914/live-1914-2635-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1914/live-1914-2634-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1914'>doi:10.1613/jair.1914</a></p>
<p>A delta-model is a satisfying assignment of a Boolean formula for which any small alteration, such as a single bit flip, can be repaired by flips to some small number of other bits, yielding a new satisfying assignment.  These satisfying assignments represent robust solutions to optimization problems (e.g., scheduling) where it is possible to recover from unforeseen events (e.g., a resource becoming unavailable).  The concept of delta-models was introduced by Ginsberg, Parkes and Roy (AAAI 1998) , where it was proved that finding delta-models for general Boolean formulas is NP-complete.  In this paper, we extend that result by studying the complexity of finding delta-models for classes of Boolean formulas which are known to have polynomial time satisfiability solvers.  In particular, we examine 2-SAT, Horn-SAT, Affine-SAT, dual-Horn-SAT, 0-valid and 1-valid SAT.  We see a wide variation in the complexity of finding delta-models, e.g., while 2-SAT and Affine-SAT have polynomial time tests for delta-models, testing whether a Horn-SAT formula has one is NP-complete.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Fault Tolerant Boolean Satisfiability">
<meta name="citation_author" content="Roy, A.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="503">
<meta name="citation_lastpage" content="527">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1914/live-1914-2635-jair.pdf">

<cite>R.  Mailler and V.  R. Lesser (2006) "Asynchronous Partial Overlay:  A New Algorithm for Solving Distributed Constraint Satisfaction Problems", Volume 25, pages 529-576</cite>
<p class="media"><a href="/media/1786/live-1786-2639-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1786/live-1786-2638-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1786'>doi:10.1613/jair.1786</a></p>
<p>Distributed Constraint Satisfaction (DCSP) has long been considered an important problem in multi-agent systems research.  This is because many real-world problems can be represented as constraint satisfaction and these problems often present themselves in a distributed form.  In this article, we present a new complete, distributed algorithm called Asynchronous Partial Overlay (APO) for solving DCSPs that is based on a cooperative mediation process.  The primary ideas behind this algorithm are that agents, when acting as a mediator, centralize small, relevant portions of the DCSP, that these centralized subproblems overlap, and that agents increase the size of their subproblems along critical paths within the DCSP as the problem solving unfolds.  We present empirical evidence that shows that APO outperforms other known, complete DCSP techniques.</p>
<a href="/vol/vol25.html">Click here to return to Volume 25 contents list</a>
<meta name="citation_title" content="Asynchronous Partial Overlay:  A New Algorithm for Solving Distributed Constraint Satisfaction Problems">
<meta name="citation_author" content="Mailler, R.">
<meta name="citation_author" content="Lesser, V. R.">
<meta name="citation_publication_date" content="2006">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="529">
<meta name="citation_lastpage" content="576">
<meta name="citation_volume" content="25">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1786/live-1786-2639-jair.pdf">
