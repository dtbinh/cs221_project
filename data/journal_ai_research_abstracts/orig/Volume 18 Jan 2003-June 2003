<cite>C.  Thompson (2003) "Acquiring Word-Meaning Mappings for Natural Language Interfaces", Volume 18, pages 1-44</cite>
<p class="media"><a href="/media/1063/live-1063-2094-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1063/live-1063-2092-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/thompson03a-html/thompson03a-html.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1063'>doi:10.1613/jair.1063</a></p>
<p>This paper focuses on a system, WOLFIE (WOrd Learning From    Interpreted Examples), that acquires a semantic lexicon from a corpus    of sentences paired with semantic representations.  The lexicon    learned consists of phrases paired with meaning representations.    WOLFIE is part of an integrated system that learns to transform    sentences into representations such as logical database queries. <p>       Experimental results are presented demonstrating WOLFIE's ability to    learn useful lexicons for a database interface in four different    natural languages.  The usefulness of the lexicons learned by WOLFIE    are compared to those acquired by a similar system, with results    favorable to WOLFIE.  A second set of experiments demonstrates    WOLFIE's ability to scale to larger and more difficult, albeit    artificially generated, corpora. <p>          In natural language acquisition, it is difficult to gather the    annotated data needed for supervised learning; however, unannotated    data is fairly plentiful.  Active learning methods attempt to select    for annotation and training only the most informative examples, and    therefore are potentially very useful in natural language    applications.  However, most results to date for active learning have    only considered standard classification tasks.  To reduce annotation    effort while maintaining accuracy, we apply active learning to    semantic lexicons.  We show that active learning can significantly    reduce the number of annotated examples required to achieve a given    level of performance.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Acquiring Word-Meaning Mappings for Natural Language Interfaces">
<meta name="citation_author" content="Thompson,  C.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="44">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1063/live-1063-2094-jair.pdf">

<cite>A.  T. Cemgil and  B.  Kappen (2003) "Monte Carlo Methods for Tempo Tracking and Rhythm Quantization", Volume 18, pages 45-81</cite>
<p class="media"><a href="/media/1121/live-1121-2125-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1121/live-1121-2123-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1121'>doi:10.1613/jair.1121</a></p>
<p>We present a probabilistic generative model for timing    deviations in expressive music performance. The structure of the    proposed model is equivalent to a switching state space model. The    switch variables correspond to discrete note locations as in a musical    score. The continuous hidden variables denote the tempo.  We formulate    two well known music recognition problems, namely tempo tracking and    automatic transcription (rhythm quantization) as filtering and maximum    a posteriori (MAP) state estimation tasks. Exact computation of    posterior features such as the MAP state is intractable in this model    class, so we introduce Monte Carlo methods for integration and    optimization. We compare Markov Chain Monte Carlo (MCMC) methods (such    as Gibbs sampling, simulated annealing and iterative improvement) and    sequential Monte Carlo methods (particle filters). Our simulation    results suggest better results with sequential methods.  The methods    can be applied in both online and batch scenarios such as tempo    tracking and transcription and are thus potentially useful in a number    of music applications such as adaptive automatic accompaniment, score    typesetting and music information retrieval.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Monte Carlo Methods for Tempo Tracking and Rhythm Quantization">
<meta name="citation_author" content="Cemgil,  A. T.">
<meta name="citation_author" content="Kappen,  B.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="45">
<meta name="citation_lastpage" content="81">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1121/live-1121-2125-jair.pdf">

<cite>O.  Grumberg,  S.  Livne and  S.  Markovitch (2003) "Learning to Order BDD Variables in Verification", Volume 18, pages 83-116</cite>
<p class="media"><a href="/media/1096/live-1096-2111-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1096/live-1096-2109-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1096'>doi:10.1613/jair.1096</a></p>
<p>The size and complexity of software and hardware systems    have significantly increased in the past years.  As a result, it is    harder to guarantee their correct behavior. One of the most successful    methods for automated verification of finite-state systems is model    checking. Most of the current model-checking systems use binary    decision diagrams (BDDs) for the representation of the tested model    and in the verification process of its properties. Generally, BDDs    allow a canonical compact representation of a boolean function (given    an order of its variables). The more compact the BDD is, the better    performance one gets from the verifier. However, finding an optimal    order for a BDD is an NP-complete problem. Therefore, several    heuristic methods based on expert knowledge have been developed for    variable ordering.    <p>   We propose an alternative approach in which the variable ordering     algorithm gains 'ordering experience' from training models and     uses the learned knowledge for finding good orders. Our     methodology is based on offline learning of pair precedence     classifiers from training models, that is, learning which variable     pair permutation is more likely to lead to a good order. For each     training model, a number of training sequences are evaluated. Every     training model variable pair permutation is then tagged based on     its performance on the evaluated orders. The tagged permutations     are then passed through a feature extractor and are given as     examples to a classifier creation algorithm. Given a model for     which an order is requested, the ordering algorithm consults each     precedence classifier and constructs a pair precedence table     which is used to create the order.     <p> Our algorithm was integrated with SMV, which is one of the most     widely used verification systems. Preliminary empirical evaluation of our     methodology, using real benchmark models, shows performance that     is better than random ordering and is competitive with existing     algorithms that use expert knowledge. We believe that in     sub-domains of models (alu, caches, etc.) our system will prove     even more valuable. This is because it features the ability to     learn sub-domain knowledge, something that no other ordering     algorithm does.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Learning to Order BDD Variables in Verification">
<meta name="citation_author" content="Grumberg,  O.">
<meta name="citation_author" content="Livne,  S.">
<meta name="citation_author" content="Markovitch,  S.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="83">
<meta name="citation_lastpage" content="116">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1096/live-1096-2111-jair.pdf">

<cite>J.  Peral and  A.  Ferrandez (2003) "Translation of Pronominal Anaphora between English and Spanish: Discrepancies and Evaluation", Volume 18, pages 117-147</cite>
<p class="media"><a href="/media/1115/live-1115-2121-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1115/live-1115-2119-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/peral03a-html/peral03a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1115'>doi:10.1613/jair.1115</a></p>
<p>This paper evaluates the different tasks carried out in the    translation of pronominal anaphora in a machine translation (MT)    system. The MT interlingua approach named AGIR (Anaphora Generation    with an Interlingua Representation) improves upon other proposals    presented to date because it is able to translate intersentential    anaphors, detect co-reference chains, and translate Spanish zero    pronouns into English---issues hardly considered by other systems. The    paper presents the resolution and evaluation of these anaphora    problems in AGIR with the use of different kinds of knowledge    (lexical, morphological, syntactic, and semantic). The translation of    English and Spanish anaphoric third-person personal pronouns    (including Spanish zero pronouns) into the target language has been    evaluated on unrestricted corpora. We have obtained a precision of    80.4% and 84.8% in the translation of Spanish and English pronouns,    respectively. Although we have only studied the Spanish and English    languages, our approach can be easily extended to other languages such    as Portuguese, Italian, or Japanese.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Translation of Pronominal Anaphora between English and Spanish: Discrepancies and Evaluation">
<meta name="citation_author" content="Peral,  J.">
<meta name="citation_author" content="Ferrandez,  A.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="117">
<meta name="citation_lastpage" content="147">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1115/live-1115-2121-jair.pdf">

<cite>K.  Lerman,  S.  N. Minton and  C.  A. Knoblock (2003) "Wrapper Maintenance: A Machine Learning Approach", Volume 18, pages 149-181</cite>
<p class="media"><a href="/media/1145/live-1145-2162-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1145/live-1145-2160-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1145'>doi:10.1613/jair.1145</a></p>
<p>The proliferation of online information sources has led to an    increased use of wrappers for extracting data from Web sources. While    most of the previous research has focused on quick and efficient    generation of wrappers, the development of tools for wrapper    maintenance has received less attention. This is an important research    problem because Web sources often change in ways that prevent the    wrappers from extracting data correctly.  We present an efficient    algorithm that learns structural information about data from positive    examples alone. We describe how this information can be used for two    wrapper maintenance applications: wrapper verification and    reinduction. The wrapper verification system detects when a wrapper is    not extracting correct data, usually because the Web source has    changed its format.  The reinduction algorithm automatically recovers    from changes in the Web source by identifying data on Web pages so    that a new wrapper may be generated for this source.  To validate our    approach, we monitored 27 wrappers over a period of a year. The    verification algorithm correctly discovered 35 of the 37 wrapper    changes, and made 16 mistakes, resulting in precision of 0.73 and    recall of 0.95. We validated the reinduction algorithm on ten Web    sources. We were able to successfully reinduce the wrappers, obtaining    precision and recall values of 0.90 and 0.80 on the data    extraction task.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Wrapper Maintenance: A Machine Learning Approach">
<meta name="citation_author" content="Lerman,  K.">
<meta name="citation_author" content="Minton,  S. N.">
<meta name="citation_author" content="Knoblock,  C. A.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="149">
<meta name="citation_lastpage" content="181">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1145/live-1145-2162-jair.pdf">

<cite>K.  C. Tan,  E.  F. Khor,  T.  H. Lee and  R.  Sathikannan (2003) "An Evolutionary Algorithm with Advanced Goal and Priority Specification for Multi-objective Optimization", Volume 18, pages 183-215</cite>
<p class="media"><a href="/media/842/live-842-1969-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/842/live-842-1967-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.842'>doi:10.1613/jair.842</a></p>
<p>This paper presents an evolutionary algorithm with a new    goal-sequence domination scheme for better decision support in    multi-objective optimization. The approach allows the inclusion of    advanced hard/soft priority and constraint information on each    objective component, and is capable of incorporating multiple    specifications with overlapping or non-overlapping objective functions    via logical 'OR' and 'AND' connectives to drive the search    towards multiple regions of trade-off. In addition, we propose a    dynamic sharing scheme that is simple and adaptively estimated    according to the on-line population distribution without needing any a    priori parameter setting. Each feature in the proposed algorithm is    examined to show its respective contribution, and the performance of    the algorithm is compared with other evolutionary optimization    methods. It is shown that the proposed algorithm has performed well in    the diversity of evolutionary search and uniform distribution of    non-dominated individuals along the final trade-offs, without    significant computational effort. The algorithm is also applied to the    design optimization of a practical servo control system for hard disk    drives with a single voice-coil-motor actuator. Results of the    evolutionary designed servo control system show a superior closed-loop    performance compared to classical PID or RPT approaches.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="An Evolutionary Algorithm with Advanced Goal and Priority Specification for Multi-objective Optimization">
<meta name="citation_author" content="Tan,  K. C.">
<meta name="citation_author" content="Khor,  E. F.">
<meta name="citation_author" content="Lee,  T. H.">
<meta name="citation_author" content="Sathikannan,  R.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="183">
<meta name="citation_lastpage" content="215">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/842/live-842-1969-jair.pdf">

<cite>D.  E. Wilkins,  T.  J. Lee and  P.  Berry (2003) "Interactive Execution Monitoring of Agent Teams", Volume 18, pages 217-261</cite>
<p class="media"><a href="/media/1112/live-1112-2114-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1112/live-1112-2112-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/wilkins03a-html/ex-mon-jair-l2h.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1112'>doi:10.1613/jair.1112</a></p>
<p>There is an increasing need for automated support for humans    monitoring the activity of distributed teams of cooperating agents,    both human and machine. We characterize the domain-independent    challenges posed by this problem, and describe how properties of    domains influence the challenges and their solutions. We will    concentrate on dynamic, data-rich domains where humans are ultimately    responsible for team behavior. Thus, the automated aid should    interactively support effective and timely decision making by the    human. We present a domain-independent categorization of the types of    alerts a plan-based monitoring system might issue to a user, where    each type generally requires different monitoring techniques. We    describe a monitoring framework for integrating many domain-specific    and task-specific monitoring techniques and then using the concept of    value of an alert to avoid operator overload. <p>      We use this framework to describe an execution monitoring approach we    have used to implement Execution Assistants (EAs) in two different    dynamic, data-rich, real-world domains to assist a human in    monitoring team behavior. One domain (Army small unit operations) has    hundreds of mobile, geographically distributed agents, a combination    of humans, robots, and vehicles. The other domain (teams of unmanned    ground and air vehicles) has a handful of cooperating robots. Both    domains involve unpredictable adversaries in the vicinity. Our    approach customizes monitoring behavior for each specific task, plan,    and situation, as well as for user preferences. Our EAs alert the    human controller when reported events threaten plan execution or    physically threaten team members. Alerts were generated in a timely    manner without inundating the user with too many alerts (less than    10 percent of alerts are unwanted, as judged by domain experts).</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Interactive Execution Monitoring of Agent Teams">
<meta name="citation_author" content="Wilkins,  D. E.">
<meta name="citation_author" content="Lee,  T. J.">
<meta name="citation_author" content="Berry,  P.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="217">
<meta name="citation_lastpage" content="261">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1112/live-1112-2114-jair.pdf">

<cite>D.  Poole and  N.  L. Zhang (2003) "Exploiting Contextual Independence In Probabilistic Inference", Volume 18, pages 263-313</cite>
<p class="media"><a href="/media/1122/live-1122-2128-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1122/live-1122-2126-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/poole03a-html/poole03a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1122'>doi:10.1613/jair.1122</a></p>
<p>Bayesian belief networks have grown to prominence because    they provide compact representations for many problems for which    probabilistic inference is appropriate, and there are algorithms to    exploit this compactness. The next step is to allow compact    representations of the conditional probabilities of a variable given    its parents. In this paper we present such a representation that    exploits contextual independence in terms of parent contexts; which    variables act as parents may depend on the value of other    variables. The internal representation is in terms of contextual    factors (confactors) that is simply a pair of a context and a table.    The algorithm, contextual variable elimination, is based on the    standard variable elimination algorithm that eliminates the non-query    variables in turn, but when eliminating a variable, the tables that    need to be multiplied can depend on the context. This algorithm    reduces to standard variable elimination when there is no contextual    independence structure to exploit. We show how this can be much more    efficient than variable elimination when there is structure to    exploit. We explain why this new method can exploit more structure    than previous methods for structured belief network inference and an    analogous algorithm that uses trees.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Exploiting Contextual Independence In Probabilistic Inference">
<meta name="citation_author" content="Poole,  D.">
<meta name="citation_author" content="Zhang,  N. L.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="263">
<meta name="citation_lastpage" content="313">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1122/live-1122-2128-jair.pdf">

<cite>R.  I. Brafman and  C.  Domshlak (2003) "Structure and Complexity in Planning with Unary Operators", Volume 18, pages 315-349</cite>
<p class="media"><a href="/media/1146/live-1146-2165-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1146/live-1146-2163-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1146'>doi:10.1613/jair.1146</a></p>
<p>Unary operator domains -- i.e., domains in which operators    have a single effect -- arise naturally in many control problems.  In    its most general form, the problem of STRIPS planning in unary    operator domains is known to be as hard as the general STRIPS planning    problem -- both are PSPACE-complete. However, unary operator domains    induce a natural structure, called the domain's causal graph. This    graph relates between the preconditions and effect of each domain    operator. Causal graphs were exploited by Williams and Nayak in order    to analyze plan generation for one of the controllers in NASA's    Deep-Space One spacecraft. There, they utilized the fact that when    this graph is acyclic, a serialization ordering over any subgoal can    be obtained quickly. In this paper we conduct a comprehensive study of    the relationship between the structure of a domain's causal graph and    the complexity of planning in this domain.  On the positive side, we    show that a non-trivial polynomial time plan generation algorithm    exists for domains whose causal graph induces a polytree with a    constant bound on its node indegree. On the negative side, we show    that even plan existence is hard when the graph is a directed-path    singly connected DAG.  More generally, we show that the number of    paths in the causal graph is closely related to the complexity of    planning in the associated domain.  Finally we relate our results to    the question of complexity of planning with serializable subgoals.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Structure and Complexity in Planning with Unary Operators">
<meta name="citation_author" content="Brafman,  R. I.">
<meta name="citation_author" content="Domshlak,  C.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="315">
<meta name="citation_lastpage" content="349">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1146/live-1146-2165-jair.pdf">

<cite>P.  F. Patel-Schneider and  R.  Sebastiani (2003) "A New General Method to Generate Random Modal Formulae for Testing Decision Procedures", Volume 18, pages 351-389</cite>
<p class="media"><a href="/media/1166/live-1166-2180-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1166/live-1166-2178-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1166'>doi:10.1613/jair.1166</a></p>
<p>The recent emergence of heavily-optimized modal decision    procedures has highlighted the key role of empirical testing in this    domain.  Unfortunately, the introduction of extensive empirical tests    for modal logics is recent, and so far none of the proposed test    generators is very satisfactory.  To cope with this fact, we present a    new random generation method that provides benefits over previous    methods for generating empirical tests.  It fixes and much generalizes    one of the best-known methods, the random CNF_[]m test, allowing for    generating a much wider variety of problems, covering in principle the    whole input space.  Our new method produces much more suitable test    sets for the current generation of modal decision procedures.  We    analyze the features of the new method by means of an extensive    collection of empirical tests.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="A New General Method to Generate Random Modal Formulae for Testing Decision Procedures">
<meta name="citation_author" content="Patel-Schneider,  P. F.">
<meta name="citation_author" content="Sebastiani,  R.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="351">
<meta name="citation_lastpage" content="389">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1166/live-1166-2180-jair.pdf">

<cite>J.  Lang,  P.  Liberatore and  P.  Marquis (2003) "Propositional Independence - Formula-Variable Independence and
Forgetting", Volume 18, pages 391-443</cite>
<p class="media"><a href="/media/1113/live-1113-2118-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1113/live-1113-2116-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1113'>doi:10.1613/jair.1113</a></p>
<p>Independence -- the study of what is relevant to a given    problem of reasoning -- has received an increasing attention from the    AI community. In this paper, we consider two basic forms of    independence, namely, a syntactic one and a semantic one. We show    features and drawbacks of them.  In particular, while the syntactic    form of independence is computationally easy to check, there are cases    in which things that intuitively are not relevant are not recognized    as such.  We also consider the problem of forgetting, i.e., distilling    from a knowledge base only the part that is relevant to the set of    queries constructed from a subset of the alphabet. While such process    is computationally hard, it allows for a simplification of subsequent    reasoning, and can thus be viewed as a form of compilation: once the    relevant part of a knowledge base has been extracted, all reasoning    tasks to be performed can be simplified.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Propositional Independence - Formula-Variable Independence and
Forgetting">
<meta name="citation_author" content="Lang,  J.">
<meta name="citation_author" content="Liberatore,  P.">
<meta name="citation_author" content="Marquis,  P.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="391">
<meta name="citation_lastpage" content="443">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1113/live-1113-2118-jair.pdf">

<cite>S.  Acid and L.  M. de Campos (2003) "Searching for Bayesian Network Structures in the Space of Restricted Acyclic Partially Directed Graphs", Volume 18, pages 445-490</cite>
<p class="media"><a href="/media/1061/live-1061-2090-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1061/live-1061-2088-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/acid03a-html/index.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1061'>doi:10.1613/jair.1061</a></p>
<p>Although many algorithms have been designed to construct    Bayesian network structures using different approaches and principles,    they all employ only two methods: those based on independence    criteria, and those based on a scoring function and a search procedure    (although some methods combine the two). Within the score+search    paradigm, the dominant approach uses local search methods in the space    of directed acyclic graphs (DAGs), where the usual choices for    defining the elementary modifications (local changes) that can be    applied are arc addition, arc deletion, and arc reversal. In this    paper, we propose a new local search method that uses a different    search space, and which takes account of the concept of equivalence    between network structures: restricted acyclic partially directed    graphs (RPDAGs). In this way, the number of different configurations    of the search space is reduced, thus improving efficiency. Moreover,    although the final result must necessarily be a local optimum given    the nature of the search method, the topology of the new search space,    which avoids making early decisions about the directions of the arcs,    may help to find better local optima than those obtained by searching    in the DAG space. Detailed results of the evaluation of the proposed    search method on several test problems, including the well-known Alarm    Monitoring System, are also presented.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Searching for Bayesian Network Structures in the Space of Restricted Acyclic Partially Directed Graphs">
<meta name="citation_author" content="Acid,  S.">
<meta name="citation_author" content="de Campos, L. M.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="445">
<meta name="citation_lastpage" content="490">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1061/live-1061-2090-jair.pdf">

<cite>E.  Reiter,  S.  G. Sripada and  R.  Robertson (2003) "Acquiring Correct Knowledge for Natural Language Generation", Volume 18, pages 491-516</cite>
<p class="media"><a href="/media/1176/live-1176-2191-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1176/live-1176-2189-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1176'>doi:10.1613/jair.1176</a></p>
<p>Natural language generation (NLG) systems are computer software    systems that produce texts in English and other human languages, often    from non-linguistic input data. NLG systems, like most AI systems, need    substantial amounts of knowledge.  However, our experience in two     NLG projects suggests that it is difficult to acquire correct knowledge     for NLG systems; indeed, every knowledge acquisition (KA) technique     we tried had significant problems. In general terms, these problems were     due to the complexity, novelty, and poorly understood nature of the     tasks our systems attempted, and were worsened by the fact that people    write so differently. This meant in particular that corpus-based KA     approaches suffered because it was impossible to assemble a sizable     corpus of high-quality consistent manually written texts in our domains;    and structured expert-oriented KA techniques suffered because experts     disagreed and because we could not get enough information about special     and unusual cases to build robust systems. We believe that such problems     are likely to affect many other NLG systems as well.  In the long term,     we hope that new KA techniques may emerge to help NLG system builders.      In the shorter term, we believe that understanding how individual KA     techniques can fail, and using a mixture of different KA techniques     with different strengths and weaknesses, can help developers acquire     NLG knowledge that is mostly correct.</p>
<a href="/vol/vol18.html">Click here to return to Volume 18 contents list</a>
<meta name="citation_title" content="Acquiring Correct Knowledge for Natural Language Generation">
<meta name="citation_author" content="Reiter,  E.">
<meta name="citation_author" content="Sripada,  S. G.">
<meta name="citation_author" content="Robertson,  R.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="491">
<meta name="citation_lastpage" content="516">
<meta name="citation_volume" content="18">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1176/live-1176-2191-jair.pdf">
