<cite>J.  Y. Halpern (1997) "Defining Relative Likelihood in Partially-Ordered Preferential Structures", Volume 7, pages 1-24</cite>
<p class="media"><a href="/media/391/live-391-1642-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/391/live-391-1641-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.391'>doi:10.1613/jair.391</a>
<br/><a href="/media/391/live-391-1644-jair.html">Appendix </a> - Errata</p>
<p>Starting with a likelihood or preference order on worlds, we    extend it to a likelihood ordering on sets of worlds in a natural way,    and examine the resulting logic.  Lewis earlier considered such a    notion of relative likelihood in the context of studying    counterfactuals, but he assumed a total preference order on worlds.    Complications arise when examining partial orders that are not present    for total orders.  There are subtleties involving the exact approach    to lifting the order on worlds to an order on sets of worlds.  In    addition, the axiomatization of the logic of relative likelihood in    the case of partial orders gives insight into the connection between    relative likelihood and default reasoning.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Defining Relative Likelihood in Partially-Ordered Preferential Structures">
<meta name="citation_author" content="Halpern,  J. Y.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="24">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/391/live-391-1642-jair.pdf">

<cite>T.  Drakengren and P.  Jonsson (1997) "Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time", Volume 7, pages 25-45</cite>
<p class="media"><a href="/media/340/live-340-1603-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/340/live-340-1601-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.340'>doi:10.1613/jair.340</a>
<br/><a href="/media/340/live-340-1604-jair.tar">Appendix </a> - tar file containing algebras</p>
<p>This paper combines two important directions of research in temporal resoning: that of finding maximal tractable subclasses of Allen's interval algebra, and that of reasoning with metric temporal information. Eight new maximal tractable subclasses of Allen's interval algebra are presented, some of them subsuming previously reported tractable algebras. The algebras allow for metric temporal constraints on interval starting or ending points, using the recent framework of Horn DLRs. Two of the algebras can express the notion of sequentiality between intervals, being the first such algebras admitting both qualitative and metric time.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time">
<meta name="citation_author" content="Drakengren, T.">
<meta name="citation_author" content="Jonsson, P.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="25">
<meta name="citation_lastpage" content="45">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/340/live-340-1603-jair.pdf">

<cite>D.  L. Mammen and  T.  Hogg (1997) "A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search Difficulty", Volume 7, pages 47-66</cite>
<p class="media"><a href="/media/370/live-370-1621-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/370/live-370-1620-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume7/mammen97a-html/ehe3.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.370'>doi:10.1613/jair.370</a></p>
<p>The easy-hard-easy pattern in the difficulty of combinatorial search problems as constraints are added has been explained as due to a competition between the decrease in number of solutions and increased pruning. We test the generality of this explanation by examining one of its predictions: if the number of solutions is held fixed by the choice of problems, then increased pruning should lead to a monotonic decrease in search cost. Instead, we find the easy-hard-easy pattern in median search cost even when the number of solutions is held constant, for some search methods. This generalizes previous observations of this pattern and shows that the existing theory does not explain the full range of the peak in search cost. In these cases the pattern appears to be due to changes in the size of the minimal unsolvable subproblems, rather than changing numbers of solutions.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search Difficulty">
<meta name="citation_author" content="Mammen,  D. L.">
<meta name="citation_author" content="Hogg,  T.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="47">
<meta name="citation_lastpage" content="66">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/370/live-370-1621-jair.pdf">

<cite>C.  G. Nevill-Manning and  I.  H. Witten (1997) "Identifying Hierarchical Structure in Sequences: A linear-time algorithm", Volume 7, pages 67-82</cite>
<p class="media"><a href="/media/374/live-374-1630-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/374/live-374-1629-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.374'>doi:10.1613/jair.374</a></p>
<p>SEQUITUR is an algorithm that infers a hierarchical    structure from a sequence of discrete symbols by replacing repeated    phrases with a grammatical rule that generates the phrase, and    continuing this process recursively. The result is a hierarchical    representation of the original sequence, which offers insights into    its lexical structure. The algorithm is driven by two constraints that    reduce the size of the grammar, and produce structure as a by-product.     SEQUITUR breaks new ground by operating incrementally. Moreover, the    method's simple structure permits a proof that it operates in space    and time that is linear in the size of the input. Our implementation    can process 50,000 symbols per second and has been applied to an    extensive range of real world sequences.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Identifying Hierarchical Structure in Sequences: A linear-time algorithm">
<meta name="citation_author" content="Nevill-Manning,  C. G.">
<meta name="citation_author" content="Witten,  I. H.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="67">
<meta name="citation_lastpage" content="82">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/374/live-374-1630-jair.pdf">

<cite>M.  Tambe (1997) "Towards Flexible Teamwork", Volume 7, pages 83-124</cite>
<cite>2012 IFAAMAS Award for Influential Papers in Autonomous Agents and Multiagent Systems</cite><p class="media"><a href="/media/433/live-433-1665-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/433/live-433-1663-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.433'>doi:10.1613/jair.433</a>
<br/><a href="http://www.isi.edu/soar/tambe/steam/steam.html">Appendix </a> - </p>
<p>Many AI researchers are today striving to build agent teams    for complex, dynamic multi-agent domains, with intended applications    in arenas such as education, training, entertainment, information    integration, and collective robotics.  Unfortunately, uncertainties in    these complex, dynamic domains obstruct coherent teamwork.  In    particular, team members often encounter differing, incomplete, and    possibly inconsistent views of their environment.  Furthermore, team    members can unexpectedly fail in fulfilling responsibilities or    discover unexpected opportunities.  Highly flexible coordination and    communication is key in addressing such uncertainties.  Simply fitting    individual agents with precomputed coordination plans will not do, for    their inflexibility can cause severe failures in teamwork, and their    domain-specificity hinders reusability.    <p>       Our central hypothesis is that the key to such flexibility and    reusability is providing agents with general models of teamwork.    Agents exploit such models to autonomously reason about coordination    and communication, providing requisite flexibility.  Furthermore, the    models enable reuse across domains, both saving implementation effort    and enforcing consistency.  This article presents one general,    implemented model of teamwork, called STEAM.  The basic building block    of teamwork in STEAM is joint intentions (Cohen & Levesque, 1991b);    teamwork in STEAM is based on agents' building up a (partial)    hierarchy of joint intentions (this hierarchy is seen to parallel    Grosz & Kraus's partial SharedPlans, 1996).  Furthermore, in STEAM,    team members monitor the team's and individual members' performance,    reorganizing the team as necessary.  Finally, decision-theoretic    communication selectivity in STEAM ensures reduction in communication    overheads of teamwork, with appropriate sensitivity to the    environmental conditions.  This article describes STEAM's application    in three different complex domains, and presents detailed empirical    results.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Towards Flexible Teamwork">
<meta name="citation_author" content="Tambe,  M.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="83">
<meta name="citation_lastpage" content="124">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/433/live-433-1665-jair.pdf">

<cite>L.  Leherte,  J.  Glasgow,  K.  Baxter,  E.  Steeg and  S.  Fortier (1997) "Analysis of Three-Dimensional Protein Images", Volume 7, pages 125-159</cite>
<p class="media"><a href="/media/425/live-425-1658-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/425/live-425-1657-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.425'>doi:10.1613/jair.425</a></p>
<p>A fundamental goal of research in molecular biology is to    understand protein structure. Protein crystallography is currently the    most successful method for determining the three-dimensional (3D)    conformation of a protein, yet it remains labor intensive and relies    on an expert's ability to derive and evaluate a protein scene model.    In this paper, the problem of protein structure determination is    formulated as an exercise in scene analysis.  A computational    methodology is presented in which a 3D image of a protein is segmented    into a graph of critical points.  Bayesian and certainty factor    approaches are described and used to analyze critical point graphs and    identify meaningful substructures, such as alpha-helices and    beta-sheets.  Results of applying the methodologies to protein images    at low and medium resolution are reported.  The research is related to    approaches to representation, segmentation and classification in    vision, as well as to top-down approaches to protein structure    prediction.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Analysis of Three-Dimensional Protein Images">
<meta name="citation_author" content="Leherte,  L.">
<meta name="citation_author" content="Glasgow,  J.">
<meta name="citation_author" content="Baxter,  K.">
<meta name="citation_author" content="Steeg,  E.">
<meta name="citation_author" content="Fortier,  S.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="125">
<meta name="citation_lastpage" content="159">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/425/live-425-1658-jair.pdf">

<cite>L.  H. Ihrig and  S.  Kambhampati (1997) "Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures", Volume 7, pages 161-198</cite>
<p class="media"><a href="/media/424/live-424-1654-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/424/live-424-1653-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume7/ihrig97a-html/ihrig-kambh97.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.424'>doi:10.1613/jair.424</a></p>
<p>Case-Based Planning (CBP) provides a way of scaling up    domain-independent planning to solve large problems in complex    domains.  It replaces the detailed and lengthy search for a solution    with the retrieval and adaptation of previous planning experiences.    In general, CBP has been demonstrated to improve performance over    generative (from-scratch) planning.  However, the performance    improvements it provides are dependent on adequate judgements as to    problem similarity.  In particular, although CBP may substantially    reduce planning effort overall, it is subject to a mis-retrieval    problem. The success of CBP depends on these retrieval errors being    relatively rare. This paper describes the design and implementation of    a replay framework for the case-based planner DERSNLP+EBL. DERSNLP+EBL    extends current CBP methodology by incorporating explanation-based    learning techniques that allow it to explain and learn from the    retrieval failures it encounters.  These techniques are used to refine    judgements about case similarity in response to feedback when a wrong    decision has been made.  The same failure analysis is used in building    the case library, through the addition of repairing cases. Large    problems are split and stored as single goal subproblems.  Multi-goal    problems are stored only when these smaller cases fail to be merged    into a full solution.  An empirical evaluation of this approach    demonstrates the advantage of learning from experienced retrieval    failure.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures">
<meta name="citation_author" content="Ihrig,  L. H.">
<meta name="citation_author" content="Kambhampati,  S.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="161">
<meta name="citation_lastpage" content="198">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/424/live-424-1654-jair.pdf">

<cite>N.  L. Zhang and  W.  Liu (1997) "A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains", Volume 7, pages 199-230</cite>
<p class="media"><a href="/media/419/live-419-1651-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/419/live-419-1650-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.419'>doi:10.1613/jair.419</a></p>
<p>Partially observable Markov decision processes (POMDPs) are    a natural model for planning problems where effects of actions are    nondeterministic and the state of the world is not completely    observable.  It is difficult to solve POMDPs exactly.  This paper    proposes a new approximation scheme.  The basic idea is to transform a    POMDP into another one where additional information is provided by an    oracle. The oracle informs the planning agent that the current state    of the world is in a certain region.  The transformed POMDP is    consequently said to be region observable. It is easier to solve than    the original POMDP.  We propose to solve the transformed POMDP and use    its optimal policy to construct an approximate policy for the original    POMDP.  By controlling the amount of additional information that the    oracle provides, it is possible to find a proper tradeoff between    computational time and approximation quality.  In terms of algorithmic    contributions, we study in details how to exploit region observability    in solving the transformed POMDP. To facilitate the study, we also    propose a new exact algorithm for general POMDPs.  The algorithm is    conceptually simple and yet is significantly more efficient than all    previous exact algorithms.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains">
<meta name="citation_author" content="Zhang,  N. L.">
<meta name="citation_author" content="Liu,  W.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="199">
<meta name="citation_lastpage" content="230">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/419/live-419-1651-jair.pdf">

<cite>D.  Monderer and  M.  Tennenholtz (1997) "Dynamic Non-Bayesian Decision Making", Volume 7, pages 231-248</cite>
<p class="media"><a href="/media/447/live-447-1674-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/447/live-447-1673-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.447'>doi:10.1613/jair.447</a></p>
<p>The model of a non-Bayesian agent who faces a repeated game    with incomplete information against Nature is an appropriate tool for    modeling general agent-environment interactions.  In such a model the    environment state (controlled by Nature) may change arbitrarily, and    the feedback/reward function is initially unknown. The agent is not    Bayesian, that is he does not form a prior probability neither on the    state selection strategy of Nature, nor on his reward function.  A    policy for the agent is a function which assigns an action to every    history of observations and actions.  Two basic feedback structures    are considered. In one of them -- the perfect monitoring case -- the    agent is able to observe the previous environment state as part of his    feedback, while in the other -- the imperfect monitoring case -- all    that is available to the agent is the reward obtained. Both of these    settings refer to partially observable processes, where the current    environment state is unknown.  Our main result refers to the    competitive ratio criterion in the perfect monitoring case. We prove    the existence of an efficient stochastic policy that ensures that the    competitive ratio is obtained at almost all stages with an arbitrarily    high probability, where efficiency is measured in terms of rate of    convergence.  It is further shown that such an optimal policy does not    exist in the imperfect monitoring case. Moreover, it is proved that in    the perfect monitoring case there does not exist a deterministic    policy that satisfies our long run optimality criterion.  In addition,    we discuss the maxmin criterion and prove that a deterministic    efficient optimal strategy does exist in the imperfect monitoring case    under this criterion. Finally we show that our approach to long-run    optimality can be viewed as qualitative, which distinguishes it from    previous work in this area.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Dynamic Non-Bayesian Decision Making">
<meta name="citation_author" content="Monderer,  D.">
<meta name="citation_author" content="Tennenholtz,  M.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="231">
<meta name="citation_lastpage" content="248">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/447/live-447-1674-jair.pdf">

<cite>J.  Frank,  P.  Cheeseman and  J.  Stutz (1997) "When Gravity Fails: Local Search Topology", Volume 7, pages 249-281</cite>
<p class="media"><a href="/media/445/live-445-1671-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/445/live-445-1670-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.445'>doi:10.1613/jair.445</a></p>
<p>Local search algorithms for combinatorial search problems    frequently encounter a sequence of states in which it is impossible to    improve the value of the objective function; moves through these    regions, called plateau moves, dominate the time spent in local    search.  We analyze and characterize plateaus for three different    classes of randomly generated Boolean Satisfiability problems.  We    identify several interesting features of plateaus that impact the    performance of local search algorithms.  We show that local minima    tend to be small but occasionally may be very large.  We also show    that local minima can be escaped without unsatisfying a large number    of clauses, but that systematically searching for an escape route may    be computationally expensive if the local minimum is large.  We show    that plateaus with exits, called benches, tend to be much larger than    minima, and that some benches have very few exit states which local    search can use to escape.  We show that the solutions (i.e., global    minima) of randomly generated problem instances form clusters, which    behave similarly to local minima.  We revisit several enhancements of    local search algorithms and explain their performance in light of our    results.  Finally we discuss strategies for creating the next    generation of local search algorithms.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="When Gravity Fails: Local Search Topology">
<meta name="citation_author" content="Frank,  J.">
<meta name="citation_author" content="Cheeseman,  P.">
<meta name="citation_author" content="Stutz,  J.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="249">
<meta name="citation_lastpage" content="281">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/445/live-445-1671-jair.pdf">

<cite>H.  Kaindl and  G.  Kainz (1997) "Bidirectional Heuristic Search Reconsidered", Volume 7, pages 283-317</cite>
<p class="media"><a href="/media/460/live-460-1680-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/460/live-460-1679-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.460'>doi:10.1613/jair.460</a></p>
<p>The assessment of bidirectional heuristic search has been    incorrect since it was first published more than a quarter of a    century ago.  For quite a long time, this search strategy did not    achieve the expected results, and there was a major misunderstanding    about the reasons behind it.  Although there is still wide-spread    belief that bidirectional heuristic search is afflicted by the problem    of search frontiers passing each other, we demonstrate that this    conjecture is wrong.  Based on this finding, we present both a new    generic approach to bidirectional heuristic search and a new approach    to dynamically improving heuristic values that is feasible in    bidirectional search only.  These approaches are put into perspective    with both the traditional and more recently proposed approaches in    order to facilitate a better overall understanding.  Empirical results    of experiments with our new approaches show that bidirectional    heuristic search can be performed very efficiently and also with    limited memory.  These results suggest that bidirectional heuristic    search appears to be better for solving certain difficult problems    than corresponding unidirectional search.  This provides some evidence    for the usefulness of a search strategy that was long neglected.  In    summary, we show that bidirectional heuristic search is viable and    consequently propose that it be reconsidered.</p>
<a href="/vol/vol7.html">Click here to return to Volume 7 contents list</a>
<meta name="citation_title" content="Bidirectional Heuristic Search Reconsidered">
<meta name="citation_author" content="Kaindl,  H.">
<meta name="citation_author" content="Kainz,  G.">
<meta name="citation_publication_date" content="1997">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="283">
<meta name="citation_lastpage" content="317">
<meta name="citation_volume" content="7">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/460/live-460-1680-jair.pdf">
