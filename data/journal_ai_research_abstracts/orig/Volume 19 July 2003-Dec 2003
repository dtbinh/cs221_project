<cite>B.  Zanuttini (2003) "New Polynomial Classes for Logic-Based Abduction", Volume 19, pages 1-10</cite>
<p class="media"><a href="/media/1170/live-1170-2186-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1170/live-1170-2184-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume19/zanuttini03a-html/zanuttini03a-html.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1170'>doi:10.1613/jair.1170</a>
<br/><a href="/media/1170/live-1170-2188-jair.pdf">Appendix </a> - Technical report with proofs and examples</p>
<p>We address the problem of propositional logic-based    abduction, i.e., the problem of searching for a best explanation for a    given propositional observation according to a given propositional    knowledge base. We give a general algorithm, based on the notion of    projection; then we study restrictions over the representations of the    knowledge base and of the query, and find new polynomial classes of    abduction problems.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="New Polynomial Classes for Logic-Based Abduction">
<meta name="citation_author" content="Zanuttini,  B.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="10">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1170/live-1170-2186-jair.pdf">

<cite>R.  I. Brafman and  M.  Tennenholtz (2003) "Learning to Coordinate Efficiently: A Model-based Approach", Volume 19, pages 11-23</cite>
<p class="media"><a href="/media/1154/live-1154-2171-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1154/live-1154-2169-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1154'>doi:10.1613/jair.1154</a></p>
<p>In common-interest stochastic games all players receive an identical payoff. Players participating in such games must learn to coordinate with each other in order to receive the highest-possible value. A number of reinforcement learning algorithms have been proposed for this problem, and some have been shown to converge to good solutions in the limit. In this paper we show that using very simple model-based algorithms, much better (i.e., polynomial) convergence rates can be attained. Moreover, our model-based algorithms are guaranteed to converge to the optimal value, unlike many of the existing algorithms.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Learning to Coordinate Efficiently: A Model-based Approach">
<meta name="citation_author" content="Brafman,  R. I.">
<meta name="citation_author" content="Tennenholtz,  M.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="11">
<meta name="citation_lastpage" content="23">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1154/live-1154-2171-jair.pdf">

<cite>T.  Eiter,  W.  Faber,  N.  Leone,  G.  Pfeifer and  A.  Polleres (2003) "Answer Set Planning Under Action Costs", Volume 19, pages 25-71</cite>
<p class="media"><a href="/media/1148/live-1148-2168-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1148/live-1148-2166-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1148'>doi:10.1613/jair.1148</a></p>
<p>Recently, planning based on answer set programming has been proposed as an approach towards realizing declarative planning systems. In this paper, we present the language Kc, which extends the declarative planning language K by action costs. Kc provides the notion of admissible and optimal plans, which are plans whose overall action costs are within a given limit resp. minimum over all plans (i.e., cheapest plans). As we demonstrate, this novel language allows for expressing some nontrivial planning tasks in a declarative way. Furthermore, it can be utilized for representing planning problems under other optimality criteria, such as computing ``shortest'' plans (with the least number of steps), and refinement combinations of cheapest and fastest plans. We study complexity aspects of the language Kc and provide a transformation to logic programs, such that planning problems are solved via answer set programming. Furthermore, we report experimental results on selected problems. Our experience is encouraging that answer set planning may be a valuable approach to expressive planning systems in which intricate planning problems can be naturally specified and solved.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Answer Set Planning Under Action Costs">
<meta name="citation_author" content="Eiter,  T.">
<meta name="citation_author" content="Faber,  W.">
<meta name="citation_author" content="Leone,  N.">
<meta name="citation_author" content="Pfeifer,  G.">
<meta name="citation_author" content="Polleres,  A.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="25">
<meta name="citation_lastpage" content="71">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1148/live-1148-2168-jair.pdf">

<cite>L.  Finkelstein,  S.  Markovitch and  E.  Rivlin (2003) "Optimal Schedules for Parallelizing Anytime Algorithms: The Case of Shared Resources", Volume 19, pages 73-138</cite>
<p class="media"><a href="/media/1195/live-1195-2206-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1195/live-1195-2204-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1195'>doi:10.1613/jair.1195</a></p>
<p>The performance of anytime algorithms can be improved by simultaneously solving several instances of algorithm-problem pairs. These pairs may include different instances of a problem (such as starting from a different initial state), different algorithms (if several alternatives exist), or several runs of the same algorithm (for non-deterministic algorithms). In this paper we present a methodology for designing an optimal scheduling policy based on the statistical characteristics of the algorithms involved. We formally analyze the case where the processes share resources (a single-processor model), and provide an algorithm for optimal scheduling.  We analyze, theoretically and empirically, the behavior of our scheduling algorithm for various distribution types.  Finally, we present empirical results of applying our scheduling algorithm to the Latin Square problem.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Optimal Schedules for Parallelizing Anytime Algorithms: The Case of Shared Resources">
<meta name="citation_author" content="Finkelstein,  L.">
<meta name="citation_author" content="Markovitch,  S.">
<meta name="citation_author" content="Rivlin,  E.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="73">
<meta name="citation_lastpage" content="138">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1195/live-1195-2206-jair.pdf">

<cite>M.  Leisink and  B.  Kappen (2003) "Bound Propagation", Volume 19, pages 139-154</cite>
<p class="media"><a href="/media/1130/live-1130-2136-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1130/live-1130-2134-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume19/leisink03a-html/leisink03a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1130'>doi:10.1613/jair.1130</a></p>
<p>In this article we present an algorithm to compute bounds on the marginals of a graphical model.  For several small clusters of nodes upper and lower bounds on the marginal values are computed independently of the rest of the network.  The range of allowed probability distributions over the surrounding nodes is restricted using earlier computed bounds. As we will show, this can be considered as a set of constraints in a linear programming problem of which the objective function is the marginal probability of the center nodes.  In this way knowledge about the maginals of neighbouring clusters is passed to other clusters thereby tightening the bounds on their marginals.  We show that sharp bounds can be obtained for undirected and directed graphs that are used for practical applications, but for which exact computations are infeasible.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Bound Propagation">
<meta name="citation_author" content="Leisink,  M.">
<meta name="citation_author" content="Kappen,  B.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="139">
<meta name="citation_lastpage" content="154">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1130/live-1130-2136-jair.pdf">

<cite>P.  Maynard-Zhang and  D.  Lehmann (2003) "Representing and Aggregating Conflicting Beliefs", Volume 19, pages 155-203</cite>
<p class="media"><a href="/media/1206/live-1206-2216-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1206/live-1206-2214-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1206'>doi:10.1613/jair.1206</a></p>
<p>We consider the two-fold problem of representing collective beliefs and aggregating these beliefs. We propose a novel representation for collective beliefs that uses modular, transitive relations over possible worlds. They allow us to represent conflicting opinions and they have a clear semantics, thus improving upon the quasi-transitive relations often used in social choice. We then describe a way to construct the belief state of an agent informed by a set of sources of varying degrees of reliability. This construction circumvents Arrow's Impossibility Theorem in a satisfactory manner by accounting for the explicitly encoded conflicts. We give a simple set-theory-based operator for combining the information of multiple agents. We show that this operator satisfies the desirable invariants of idempotence, commutativity, and associativity, and, thus, is well-behaved when iterated, and we describe a computationally effective way of computing the resulting belief state. Finally, we extend our framework to incorporate voting.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Representing and Aggregating Conflicting Beliefs">
<meta name="citation_author" content="Maynard-Zhang,  P.">
<meta name="citation_author" content="Lehmann,  D.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="155">
<meta name="citation_lastpage" content="203">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1206/live-1206-2216-jair.pdf">

<cite>E.  Wiewiora (2003) "Potential-Based Shaping and Q-Value Initialization are Equivalent", Volume 19, pages 205-208</cite>
<p class="media"><a href="/media/1190/live-1190-2200-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1190/live-1190-2198-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1190'>doi:10.1613/jair.1190</a></p>
<p>Shaping has proven to be a powerful but precarious means of improving reinforcement learning performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior. <p>  In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several reinforcement learning algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm's potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm's benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Potential-Based Shaping and Q-Value Initialization are Equivalent">
<meta name="citation_author" content="Wiewiora,  E.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="205">
<meta name="citation_lastpage" content="208">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1190/live-1190-2200-jair.pdf">

<cite>P.  Stone,  R.  E. Schapire,  M.  L. Littman,  J.  A. Csirik and D.  McAllester (2003) "Decision-Theoretic Bidding Based on Learned Density Models in Simultaneous, Interacting Auctions", Volume 19, pages 209-242</cite>
<p class="media"><a href="/media/1200/live-1200-2212-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1200/live-1200-2210-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume19/stone03a-html/stone03a.html" onclick="window.open(this.href);return false;">HTML</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1200'>doi:10.1613/jair.1200</a></p>
<p>Auctions are becoming an increasingly popular method for transacting business, especially over the Internet.  This article presents a general approach to building autonomous bidding agents to bid in multiple simultaneous auctions for interacting goods.  A core component of our approach learns a model of the empirical price dynamics based on past data and uses the model to analytically calculate, to the greatest extent possible, optimal bids.  We introduce a new and general boosting-based algorithm for conditional density estimation problems of this kind, i.e., supervised learning problems in which the goal is to estimate the entire conditional distribution of the real-valued label.  This approach is fully implemented as ATTac-2001, a top-scoring agent in the second Trading Agent Competition (TAC-01). We present experiments demonstrating the effectiveness of our boosting-based price predictor relative to several reasonable alternatives.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Decision-Theoretic Bidding Based on Learned Density Models in Simultaneous, Interacting Auctions">
<meta name="citation_author" content="Stone,  P.">
<meta name="citation_author" content="Schapire,  R. E.">
<meta name="citation_author" content="Littman,  M. L.">
<meta name="citation_author" content="Csirik,  J. A.">
<meta name="citation_author" content="McAllester, D.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="209">
<meta name="citation_lastpage" content="242">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1200/live-1200-2212-jair.pdf">

<cite>P.  D. Grunwald and  J.  Y. Halpern (2003) "Updating Probabilities", Volume 19, pages 243-278</cite>
<p class="media"><a href="/media/1164/live-1164-2177-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1164/live-1164-2175-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1164'>doi:10.1613/jair.1164</a></p>
<p>As examples such as the Monty Hall puzzle show, applying conditioning to update a probability distribution on a ``naive space'', which does not take into account the protocol used, can often lead to counterintuitive results.  Here we examine why.  A criterion known as CAR (``coarsening at random'') in the statistical literature characterizes when ``naive'' conditioning in a naive space works.  We show that the CAR condition holds rather infrequently, and we provide a procedural characterization of it, by giving a randomized algorithm that generates all and only distributions for which CAR holds. This substantially extends previous characterizations of CAR.  We also consider more generalized notions of update such as Jeffrey conditioning and minimizing relative entropy (MRE).  We give a generalization of the CAR condition that characterizes when Jeffrey conditioning leads to appropriate answers, and show that there exist some very simple settings in which MRE essentially never gives the right results.  This generalizes and interconnects previous results obtained in the literature on CAR and MRE.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Updating Probabilities">
<meta name="citation_author" content="Grunwald,  P. D.">
<meta name="citation_author" content="Halpern,  J. Y.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="243">
<meta name="citation_lastpage" content="278">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1164/live-1164-2177-jair.pdf">

<cite>F.  Lin (2003) "Compiling Causal Theories to Successor State Axioms and STRIPS-Like Systems", Volume 19, pages 279-314</cite>
<p class="media"><a href="/media/1135/live-1135-2143-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1135/live-1135-2141-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1135'>doi:10.1613/jair.1135</a>
<br/><a href="/media/1135/live-1135-2144-jair.tar">Appendix </a> - Benchmark action domain descriptions</p>
<p>We describe a system for specifying the effects of actions. Unlike those commonly used in AI planning, our system uses an action description language that allows one to specify the effects of actions using domain rules, which are state constraints that can entail new action effects from old ones. Declaratively, an action domain in our language corresponds to a nonmonotonic causal theory in the situation calculus. Procedurally, such an action domain is compiled into a set of    logical theories, one for each action in the domain, from which fully instantiated  successor state-like axioms and STRIPS-like systems are then generated. We expect the system to be a useful tool for knowledge engineers writing action specifications for classical AI planning systems, GOLOG systems, and other systems where formal specifications of actions are needed.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Compiling Causal Theories to Successor State Axioms and STRIPS-Like Systems">
<meta name="citation_author" content="Lin,  F.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="279">
<meta name="citation_lastpage" content="314">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1135/live-1135-2143-jair.pdf">

<cite>G.  M. Weiss and  F.  Provost (2003) "Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction", Volume 19, pages 315-354</cite>
<p class="media"><a href="/media/1199/live-1199-2209-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1199/live-1199-2207-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1199'>doi:10.1613/jair.1199</a></p>
<p>For large, real-world inductive learning problems, the number of training examples often must be limited due to the costs associated with procuring, preparing, and storing the training examples and/or the computational costs associated with learning from them. In such circumstances, one question of practical importance is: if only n training examples can be selected, in what proportion should the classes be represented?  In this article we help to answer this question by analyzing, for a fixed training-set size, the relationship between the class distribution of the training data and the performance of classification trees induced from these data. We study twenty-six data sets and, for each, determine the best class distribution for learning.  The naturally occurring class distribution is shown to generally perform well when classifier performance is evaluated using undifferentiated error rate (0/1 loss).  However, when the area under the ROC curve is used to evaluate classifier performance, a balanced distribution is shown to perform well.  Since neither of these choices for class distribution always generates the best-performing classifier, we introduce a budget-sensitive progressive sampling algorithm for selecting training examples based on the class associated with each example.  An empirical analysis of this algorithm shows that the class distribution of the resulting training set yields classifiers with good (nearly-optimal) classification performance.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction">
<meta name="citation_author" content="Weiss,  G. M.">
<meta name="citation_author" content="Provost,  F.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="315">
<meta name="citation_lastpage" content="354">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1199/live-1199-2209-jair.pdf">

<cite>R.  E. Wray and  J.  E. Laird (2003) "An Architectural Approach to Ensuring Consistency in Hierarchical Execution", Volume 19, pages 355-398</cite>
<p class="media"><a href="/media/1142/live-1142-2155-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1142/live-1142-2153-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1142'>doi:10.1613/jair.1142</a></p>
<p>Hierarchical task decomposition is a method used in many agent systems to organize agent knowledge.  This work shows how the combination of a hierarchy and persistent assertions of knowledge can lead to difficulty in maintaining logical consistency in asserted knowledge. We explore the problematic consequences of persistent assumptions in the reasoning process and introduce novel potential solutions.  Having implemented one of the possible solutions, Dynamic Hierarchical Justification, its effectiveness is demonstrated with an empirical analysis.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="An Architectural Approach to Ensuring Consistency in Hierarchical Execution">
<meta name="citation_author" content="Wray,  R. E.">
<meta name="citation_author" content="Laird,  J. E.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="355">
<meta name="citation_lastpage" content="398">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1142/live-1142-2155-jair.pdf">

<cite>C.  Guestrin,  D.  Koller,  R.  Parr and  S.  Venkataraman (2003) "Efficient Solution Algorithms for Factored MDPs", Volume 19, pages 399-468</cite>
<cite>2007 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/1000/live-1000-2072-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1000/live-1000-2070-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1000'>doi:10.1613/jair.1000</a></p>
<p>This paper addresses the problem of planning under uncertainty in large Markov Decision Processes (MDPs). Factored MDPs represent a complex state space using state variables and the transition model using a dynamic Bayesian network. This representation often allows an exponential reduction in the representation size of structured MDPs, but the complexity of exact solution algorithms for such MDPs can grow exponentially in the representation size.  In this paper, we present two approximate solution algorithms that exploit structure in factored MDPs.  Both use an approximate value function represented as a linear combination of basis functions, where each basis function involves only a small subset of the domain variables.  A key contribution of this paper is that it shows how the basic operations of both algorithms can be performed efficiently in closed form, by exploiting both additive and context-specific structure in a factored MDP.  A central element of our algorithms is a novel linear program decomposition technique, analogous to variable elimination in Bayesian networks, which reduces an exponentially large LP to a provably equivalent, polynomial-sized one.  One algorithm uses approximate linear programming, and the second approximate dynamic programming. Our dynamic programming algorithm is novel in that it uses an approximation based on max-norm, a technique that more directly minimizes the terms that appear in error bounds for approximate MDP algorithms.  We provide experimental results on problems with over 10^40 states, demonstrating a promising indication of the scalability of our approach, and compare our algorithm to an existing state-of-the-art approach, showing, in some problems, exponential gains in computation time.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Efficient Solution Algorithms for Factored MDPs">
<meta name="citation_author" content="Guestrin,  C.">
<meta name="citation_author" content="Koller,  D.">
<meta name="citation_author" content="Parr,  R.">
<meta name="citation_author" content="Venkataraman,  S.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="399">
<meta name="citation_lastpage" content="468">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1000/live-1000-2072-jair.pdf">

<cite>L.  Console,  C.  Picardi and  D.  Theseider Dupr&#232; (2003) "Temporal Decision Trees: Model-based Diagnosis of Dynamic Systems On-Board", Volume 19, pages 469-512</cite>
<p class="media"><a href="/media/1194/live-1194-2203-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1194/live-1194-2201-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1194'>doi:10.1613/jair.1194</a></p>
<p>The automatic generation of decision trees based on off-line reasoning on models of a domain is a reasonable compromise between the advantages of using a model-based approach in technical domains and the constraints imposed by embedded applications.  In this paper we extend the approach to deal with temporal information. We introduce a notion of temporal decision tree, which is designed to make use of relevant information as long as it is acquired, and we present an algorithm for compiling such trees from a model-based reasoning system.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Temporal Decision Trees: Model-based Diagnosis of Dynamic Systems On-Board">
<meta name="citation_author" content="Console,  L.">
<meta name="citation_author" content="Picardi,  C.">
<meta name="citation_author" content="Theseider Dupr&#232;,  D.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="469">
<meta name="citation_lastpage" content="512">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1194/live-1194-2203-jair.pdf">

<cite>W.  E. Walsh and  M.  P. Wellman (2003) "Decentralized Supply Chain Formation: A Market Protocol and Competitive Equilibrium Analysis", Volume 19, pages 513-567</cite>
<p class="media"><a href="/media/1213/live-1213-2219-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1213/live-1213-2217-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1213'>doi:10.1613/jair.1213</a></p>
<p>Supply chain formation is the process of determining the structure and terms of exchange relationships to enable a multilevel, multiagent production activity.  We present a simple model of supply chains, highlighting two characteristic features: hierarchical subtask decomposition, and resource contention.  To decentralize the formation process, we introduce a market price system over the resources produced along the chain.  In a competitive equilibrium for this system, agents choose locally optimal allocations with respect to prices, and outcomes are optimal overall.  To determine prices, we define a market protocol based on distributed, progressive auctions, and myopic, non-strategic agent bidding policies.  In the presence of resource contention, this protocol produces better solutions than the greedy protocols common in the artificial intelligence and multiagent systems literature.  The protocol often converges to high-value supply chains, and when competitive equilibria exist, typically to approximate competitive equilibria.  However, complementarities in agent production technologies can cause the protocol to wastefully allocate inputs to agents that do not produce their outputs.  A subsequent decommitment phase recovers a significant fraction of the lost surplus.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Decentralized Supply Chain Formation: A Market Protocol and Competitive Equilibrium Analysis">
<meta name="citation_author" content="Walsh,  W. E.">
<meta name="citation_author" content="Wellman,  M. P.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="513">
<meta name="citation_lastpage" content="567">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1213/live-1213-2219-jair.pdf">

<cite>B.  Price and  C.  Boutilier (2003) "Accelerating Reinforcement Learning through Implicit Imitation", Volume 19, pages 569-629</cite>
<p class="media"><a href="/media/898/live-898-2002-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/898/live-898-2000-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.898'>doi:10.1613/jair.898</a></p>
<p>Imitation can be viewed as a means of enhancing learning in multiagent environments.  It augments an agent's ability to learn useful behaviors by making intelligent use of the knowledge implicit in behaviors demonstrated by cooperative teachers or other more experienced agents.  We propose and study a formal model of implicit imitation that can accelerate reinforcement learning dramatically in certain cases.  Roughly, by observing a mentor, a reinforcement-learning agent can extract information about its own capabilities in, and the relative value of, unvisited parts of the state space.  We study two specific instantiations of this model, one in which the learning agent and the mentor have identical abilities, and one designed to deal with agents and mentors with different action sets.  We illustrate the benefits of implicit imitation by integrating it with prioritized sweeping, and demonstrating improved performance and convergence through observation of single and multiple mentors. Though we make some stringent assumptions regarding observability and possible interactions, we briefly comment on extensions of the model that relax these restricitions.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="Accelerating Reinforcement Learning through Implicit Imitation">
<meta name="citation_author" content="Price,  B.">
<meta name="citation_author" content="Boutilier,  C.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="569">
<meta name="citation_lastpage" content="629">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/898/live-898-2002-jair.pdf">

<cite>R.  Sanchez and  S.  Kambhampati (2003) "AltAltp: Online Parallelization of Plans with Heuristic State Search", Volume 19, pages 631-657</cite>
<p class="media"><a href="/media/1168/live-1168-2183-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/1168/live-1168-2181-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.1168'>doi:10.1613/jair.1168</a></p>
<p>Despite their near dominance, heuristic state search planners still lag behind disjunctive planners in the generation of parallel plans in classical planning. The reason is that directly searching for parallel solutions in state space planners would require the planners to branch on all possible subsets of parallel actions, thus increasing the branching factor exponentially. We present a variant of our heuristic state search planner AltAlt, called AltAltp which generates parallel plans by using greedy online parallelization of partial plans. The greedy approach is significantly informed by the use of novel distance heuristics that AltAltp derives from a graphplan-style planning graph for the problem. While this approach is not guaranteed to provide optimal parallel plans, empirical results show that AltAltp is capable of generating good quality parallel plans at a fraction of the cost incurred by the disjunctive planners.</p>
<a href="/vol/vol19.html">Click here to return to Volume 19 contents list</a>
<meta name="citation_title" content="AltAltp: Online Parallelization of Plans with Heuristic State Search">
<meta name="citation_author" content="Sanchez,  R.">
<meta name="citation_author" content="Kambhampati,  S.">
<meta name="citation_publication_date" content="2003">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="631">
<meta name="citation_lastpage" content="657">
<meta name="citation_volume" content="19">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/1168/live-1168-2183-jair.pdf">
