n roy g gordon thrun 2005 finding approximate pomdp solutions belief compression 23 140

standard value function approaches finding policies partially observable markov decision processes pomdps generally considered intractable large intractability large extent consequence computing exact optimal policy entire belief space however realworld pomdp problems computing optimal policy full belief space often unnecessary good control even problems complicated policy classes beliefs experienced controller often lie near structured lowdimensional subspace embedded highdimensional belief space finding good approximation optimal value function subspace much easier computing full value functionp p introduce new method solving largescale pomdps reducing dimensionality belief space use exponential family principal components analysis collins dasgupta schapire 2002 represent sparse highdimensional belief spaces using small sets learned features belief state plan terms lowdimensional belief features lowdimensional space policies pomdp orders magnitude larger handled conventional techniquesp p demonstrate use synthetic mobile robot navigation tasks

