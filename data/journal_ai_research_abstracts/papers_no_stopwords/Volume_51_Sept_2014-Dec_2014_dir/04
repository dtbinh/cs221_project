z feldman c domshlak 2014 simple regret optimization online markov decision processes 51 165205

consider online markov decision processes mdps online agent focuses current state deliberates set possible policies state onwards interrupted uses outcome exploratory deliberation choose action perform next formally performance online assessed terms simple regret agents expected performance loss chosen action rather optimal one followed

date stateoftheart online general mdps either best effort guarantee polynomialrate reduction simple regret time introduce new montecarlo tree search brue guarantees exponentialrate smooth reduction simple regret high level brue simple yet nonstandard statespace sampling scheme mcts2e different parts sample dedicated different exploratory objectives extend brue variant learning forgetting resulting parametrized bruealpha exhibits even attractive formal guarantees brue empirical evaluation shows brue generalization bruealpha effective practice compare favorably stateoftheart

