bernstein c amato e hansen zilberstein 2009 policy iteration decentralized control markov decision processes 34 89132

coordination distributed agents required problems arising many areas including multirobot systems networking ecommerce formal framework problems use decentralized partially observable markov decision process decpomdp though much work done optimal dynamic programming singleagent version optimal multiagent case elusive main contribution optimal policy iteration solving decpomdps uses stochastic finitestate controllers represent policies solution include correlation device allows agents correlate actions without communicating alternates expanding controller performing valuepreserving transformations modify controller without sacrificing value present two efficient valuepreserving transformations one reduce size controller improve value keeping size fixed empirical demonstrate usefulness valuepreserving transformations increasing value keeping controller size minimum broaden applicability present heuristic version policy iteration sacrifices convergence optimality reduces size controllers step assuming probability distributions agents actions known assumption may hold general helps produce higher quality solutions test problems

