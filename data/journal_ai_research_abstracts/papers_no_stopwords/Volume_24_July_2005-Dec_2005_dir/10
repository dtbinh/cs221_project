r khardon roth r servedio 2005 efficiency versus convergence boolean kernels online learning 24 341356

studies machine learning problems example described using set boolean features hypotheses represented linear threshold elements one method increasing expressiveness learned hypotheses context expand feature set include conjunctions basic features done explicitly possible using kernel function focusing well known perceptron winnow demonstrates tradeoff computational efficiency run expanded feature space generalization ability corresponding learning first describe several kernel functions capture either limited forms conjunctions conjunctions kernels used efficiently run perceptron feature space exponentially many conjunctions however using kernels perceptron provably make exponential number mistakes even learning simple functions consider question whether kernel functions analogously used run multiplicativeupdate winnow expanded feature space exponentially many conjunctions known upper bounds imply winnow learn disjunctive normal form dnf formulae polynomial mistake bound setting however prove computationally hard simulate winnows behavior learning dnf feature set implies kernel functions correspond running winnow efficiently computable general construction run winnow kernels

