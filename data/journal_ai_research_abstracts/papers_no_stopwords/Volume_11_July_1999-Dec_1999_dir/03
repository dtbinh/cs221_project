c e brodley friedl 1999 identifying mislabeled training data 11 131167

presents new identifying eliminating mislabeled training instances supervised learning goal improve classification accuracies produced learning improving quality training data uses set learning create classifiers serve noise filters training data evaluate single majority vote consensus filters five datasets prone labeling errors experiments illustrate filtering significantly improves classification accuracy noise levels 30 percent analytical empirical evaluation precision shows consensus filters conservative throwing away good data expense retaining bad data majority filters better detecting bad data expense throwing away good data suggests situations paucity data consensus filters preferable whereas majority vote filters preferable situations abundance data

