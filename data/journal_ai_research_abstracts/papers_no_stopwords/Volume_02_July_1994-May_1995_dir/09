p cichosz 1995 truncating temporal differences efficient implementation tdlambda reinforcement learning 2 287318

temporal difference td methods constitute class methods learning predictions multistep prediction problems parameterized recency factor lambda currently important application methods temporal credit assignment reinforcement learning well known reinforcement learning ahc qlearning may viewed instances td learning examines issues efficient general implementation tdlambda arbitrary lambda use reinforcement learning optimizing discounted sum rewards traditional eligibility traces argued suffer inefficiency lack generality ttd truncated temporal differences procedure proposed alternative indeed approximates tdlambda requires little computation per action used arbitrary function representation methods idea derived fairly simple new probably unexplored far encouraging experimental presented suggesting using lambda 0 ttd procedure allows one obtain significant learning speedup essentially cost usual td0 learning

