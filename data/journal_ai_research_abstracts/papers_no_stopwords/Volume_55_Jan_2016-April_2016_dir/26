ivan vuli263 mariefrancine moens 2016 bilingual distributed word representations documentaligned comparable data 55 953994

propose new model learning bilingual word representations nonparallel documentaligned data following recent advances word representation learning model learns dense realvalued word vectors bilingual word embeddings bwes unlike prior work inducing bwes heavily relied parallel sentencealigned corpora andor readily available translation resources dictionaries article reveals bwes may learned solely basis documentaligned comparable data without additional lexical resources syntactic information present comparison previous stateoftheart learning bilingual word representations comparable data rely framework multilingual probabilistic topic modeling muptm well distributional local contextcounting demonstrate utility induced bwes two semantic tasks 1 bilingual lexicon extraction 2 suggesting word translations context polysemous words simple yet effective bwebased significantly outperform muptmbased contextcounting representation comparable data well prior bwebased acquire best reported tasks three tested language pairs

