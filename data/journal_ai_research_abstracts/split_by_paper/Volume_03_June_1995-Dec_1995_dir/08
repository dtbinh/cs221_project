y  bengio and  p  frasconi 1995 diffusion of context and credit information in markovian models volume 3 pages 249270

this paper studies the problem of ergodicity of transition    probability matrices in markovian models such as hidden markov models    hmms and how it makes very difficult the task of learning to    represent longterm context for sequential data  this phenomenon    hurts the forward propagation of longterm context information as    well as learning a hidden state representation to represent longterm    context which depends on propagating credit information backwards in    time  using results from markov chain theory we show that this    problem of diffusion of context and credit is reduced when the    transition probabilities approach 0 or 1 ie the transition    probability matrices are sparse and the model essentially    deterministic  the results found in this paper apply to learning    approaches based on continuous optimization such as gradient descent    and the baumwelch algorithm

