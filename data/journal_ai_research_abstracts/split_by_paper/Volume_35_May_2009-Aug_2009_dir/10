f  bromberg d  margaritis and v  honavar 2009 efficient markov network structure discovery using independence tests volume 35 pages 449484

  we present two algorithms for learning the structure of a markov network from data  gsmn and gsimn  both algorithms use statistical independence tests to infer the structure by successively constraining the set of structures consistent with the results of these tests  until very recently algorithms for structure learning were based on maximum likelihood estimation which has been proved to be nphard for markov networks due to the difficulty of estimating the parameters of the network needed for the computation of the data likelihood  the independencebased approach does not require the computation of the likelihood and thus both gsmn and gsimn can compute the structure efficiently as shown in our experiments  gsmn is an adaptation of the growshrink algorithm of margaritis and thrun for learning the structure of bayesian networks  gsimn extends gsmn by additionally exploiting pearls wellknown properties of the conditional independence relation to infer novel independences from known ones thus avoiding the performance of statistical tests to estimate them  to accomplish this efficiently gsimn uses the triangle theorem also introduced in this work which is a simplified version of the set of markov axioms  experimental comparisons on artificial and realworld data sets show gsimn can yield significant savings with respect to gsmn while generating a markov network with comparable or in some cases improved quality  we also compare gsimn to a forwardchaining implementation called gsimnfch that produces all possible conditional independences resulting from repeatedly applying  pearls theorems on the known conditional independence tests   the results of this comparison show that gsimn by the sole use of the triangle theorem is nearly optimal in terms of the set of independences tests that it infers

