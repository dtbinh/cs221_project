statespace search guided by admissible heuristic functions numerous admissible heuristics have been developed each with its own strengths and weaknesses and it is well known that there is no single best heuristic for optimal planning in general  thus which heuristic to choose for a given planning task is a difficult question this difficulty can be avoided by combining several heuristics but that requires computing numerous heuristic estimates at each state and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high we present a novel method that reduces the cost of combining admissible heuristics for optimal planning while maintaining its benefits  using an idealized search space model we formulate a decision rule for choosing the best heuristic to compute at each state we then present an active online learning approach for learning a classifier with that decision rule as the target concept and employ the learned classifier to decide  which heuristic to compute at each state we evaluate this technique empirically and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum



despite their near dominance heuristic state search planners still lag behind disjunctive planners in the generation of parallel plans in classical planning the reason is that directly searching for parallel solutions in state space planners would require the planners to branch on all possible subsets of parallel actions thus increasing the branching factor exponentially we present a variant of our heuristic state search planner altalt called altaltp which generates parallel plans by using greedy online parallelization of partial plans the greedy approach is significantly informed by the use of novel distance heuristics that altaltp derives from a graphplanstyle planning graph for the problem while this approach is not guaranteed to provide optimal parallel plans empirical results show that altaltp is capable of generating good quality parallel plans at a fraction of the cost incurred by the disjunctive planners





i  szita and a  lorincz 2007 learning to play using lowcomplexity rulebased policies illustrations through ms pacman volume 30 pages 659684



in this article we propose a method that can deal with certain combinatorial reinforcement learning tasks we demonstrate the approach in the popular ms pacman game we define a set of highlevel observation and action modules from which rulebased policies are constructed automatically in these policies actions are temporally extended and may work concurrently the policy of the agent is encoded by a compact decision list the components of the list are selected from a large pool of rules  which can be either handcrafted or generated automatically a suitable selection of rules is learnt  by the crossentropy method a recent global optimization algorithm that fits our framework smoothly  crossentropyoptimized policies perform better than our handcrafted policy and reach the score of average human players we argue that learning is successful mainly because i policies may apply concurrent actions and thus the policy space is sufficiently rich ii the search is biased towards lowcomplexity policies and therefore  solutions with a compact description can be found quickly if they exist





l  barbulescu a  e howe l  d whitley and m  roberts 2006 understanding algorithm performance on an oversubscribed scheduling application volume 27 pages 577615



the best performing algorithms for a particular oversubscribed

performance and motivate the design of a new algorithm



a nonbinary constraint satisfaction problem csp can be solved directly using extended versions of binary techniques alternatively the nonbinary problem can be translated into an equivalent binary one in this case it is generally accepted that the translated problem can be solved by applying wellestablished techniques for binary csps in this paper we evaluate the applicability of the latter approach we demonstrate that the use of standard techniques for binary csps in the encodings of nonbinary problems is problematic and results in models that are very rarely competitive with the nonbinary representation to overcome this we propose specialized arc consistency and search algorithms for binary encodings and we evaluate them theoretically and empirically we consider three binary representations the hidden variable encoding the dual encoding and the double encoding theoretical and empirical results show that for certain classes of nonbinary constraints binary encodings are a competitive option and in many cases a better one than the nonbinary representation 







knowledge bases in the form of ontologies are receiving increasing attention as they allow to clearly represent both the available knowledge which includes the knowledge in itself and the constraints imposed to it by the domain or the users in particular datalog177 ontologies are attractive because of their property of decidability and the possibility of dealing with the massive amounts of data in real world environments however as it is the case with many other ontological languages their application in collaborative environments often lead to inconsistency related issues in this paper we introduce the notion of incoherence regarding datalog177 ontologies in terms of satisfiability of sets of constraints and show how under specific conditions incoherence leads to inconsistent datalog177 ontologies the main contribution of this work is a novel approach to restore both consistency and coherence in datalog177 ontologies the proposed approach is based on kernel contraction and restoration is performed by the application of incision functions that select formulas to delete nevertheless instead of working  over minimal incoherentinconsistent sets encountered in the ontologies our operators produce incisions over nonminimal structures called clusters we present a construction for consolidation operators along with the properties expected to be satisfied by them finally we establish the relation between the construction and the properties by means of a representation theorem although this proposal is presented for datalog177 ontologies consolidation these operators can be applied to other types of ontological languages such as description logics making  them apt to be used in collaborative environments like the semantic web









j  m pe241a 2011 finding consensus bayesian network structures volume 42 pages 661687



suppose that multiple experts or learning algorithms provide us with alternative bayesian network bn structures over a domain and that we are interested in combining them into a single consensus bn structure specifically we are interested in that the consensus bn structure only represents independences all the given bn structures agree upon and that it has as few parameters associated as possible in this paper we prove that there may exist several nonequivalent consensus bn structures and that finding one of them is nphard thus we decide to resort to heuristics to find an approximated consensus bn structure in this paper we consider the heuristic proposed by matzkevich and abramson which builds upon two algorithms called methods a and b for efficiently deriving the minimal directed independence map of a bn structure relative to a given node ordering methods a and b are claimed to be correct although no proof is provided a proof is just sketched in this paper we show that methods a and b are not correct and propose a correction of them



many ai researchers and cognitive scientists have argued that analogy is the core of cognition the most influential work on computational modeling of analogymaking is structure mapping theory smt and its implementation in the structure mapping engine sme a limitation of sme is the requirement for complex handcoded representations we introduce the latent relation mapping engine lrme which combines ideas from sme and latent relational analysis lra in order to remove the requirement for handcoded representations lrme builds analogical mappings between lists of words using a large corpus of raw text to automatically discover the semantic relations among the words we evaluate lrme on a set of twenty analogical mapping problems ten based on scientific analogies and ten based on common metaphors lrme achieves humanlevel performance on the twenty problems we compare lrme with a variety of alternative approaches and find that they are not able to reach the same level of performance









we study the complexity of a combinatorial variant of the shift bribery problem in elections in the standard shift bribery problem we are given an election where each voter has a preference order over the set of candidates and where an outside agent the briber can pay each voter to rank the bribers favorite candidate a given number of positions higher the goal is to ensure the victory of the bribers preferred candidate the combinatorial variant of the problem introduced in this paper models settings where it is possible to affect the position of the preferred candidate in multiple votes either positively or negatively with a single bribery action this variant of the problem is particularly interesting in the context of largescale campaign management problems which from the technical side are modeled as bribery problems  we show that in general the combinatorial variant of the problem is highly intractable specifically nphard hard in the parameterized sense and hard to approximate nevertheless we provide parameterized algorithms and approximation algorithms for natural restricted cases









t  a cohn and m  lapata 2009 sentence compression as tree transduction volume 34 pages 637674



this paper presents a treetotree transduction method for sentence compression our model is based on synchronous tree substitution grammar a formalism that allows local distortion of the tree topology and can thus naturally capture structural mismatches we describe an algorithm for decoding in this framework and show how the model can be trained discriminatively within a large margin framework  experimental results on sentence compression bring significant improvements over a stateoftheart model







h  t dinh h  t dinh l  michel and a  russell 2012 the time complexity of a with approximate heuristics on multiplesolution search spaces volume 45 pages 685729







c  domshlak and a  nazarenko 2013 the complexity of optimal monotonic planning the bad the good and the causal graph volume 48 pages 783812



artificial intelligence research is ushering in a new era of sophisticated massmarket transportation technology while computers can already fly a passenger jet better than a trained human pilot people are still faced with the dangerous yet tedious task of driving automobiles intelligent transportation systems its is the field that focuses on integrating information technology with vehicles and transportation infrastructure to make transportation safer cheaper and more efficient recent advances in its point to a future in which vehicles themselves handle the vast majority of the driving task once autonomous vehicles become popular autonomous interactions amongst multiple vehicles will be possible current methods of vehicle coordination which are all designed to work with human drivers will be outdated the bottleneck for roadway efficiency will no longer be the drivers but rather the mechanism by which those drivers actions are coordinated while openroad driving is a wellstudied and moreorlesssolved problem urban traffic scenarios especially intersections are much more challenging

we believe current methods for controlling traffic specifically at intersections will not be able to take advantage of the increased sensitivity and precision of autonomous vehicles as compared to human drivers in this article we suggest an alternative mechanism for coordinating the movement of autonomous vehicles through intersections drivers and intersections in this mechanism are treated as autonomous agents in a multiagent system in this multiagent system intersections use a new reservationbased approach built around a detailed communication protocol which we also present we demonstrate in simulation that our new mechanism has the potential to significantly outperform current intersection control technology  traffic lights and stop signs because our mechanism can emulate a traffic light or stop sign it subsumes the most popular current methods of intersection control this article also presents two extensions to the mechanism the first extension allows the system to control humandriven vehicles in addition to autonomous vehicles the second gives priority to emergency vehicles without significant cost to civilian vehicles the mechanism including both extensions is implemented and tested in simulation and we present experimental results that strongly attest to the efficacy of this approach







aaron  hunter and james  delgrande 2015 belief change with uncertain action histories volume 53 pages 779824



heuristics used for solving hard realtime search problems have regions with depressions  such regions are bounded areas of the search space in which the heuristic function is inaccurate compared to the actual cost to reach a solution early realtime search algorithms like lrta easily become trapped in those regions since the heuristic values of their states may need to be updated multiple times which results in costly solutions stateoftheart realtime search algorithms like lsslrta or lrtak improve lrtas mechanism to update the heuristic resulting in improved performance those algorithms however do not guide search towards avoiding depressed regions this paper presents depression avoidance a simple realtime search principle to guide search towards avoiding states that have been marked as part of a heuristic depression we propose two ways in which depression avoidance can be implemented markandavoid and movetoborder we implement these strategies on top of lsslrta and rtaa producing 4 new realtime heuristic search algorithms alsslrta dalsslrta artaa and dartaa when the objective is to find a single solution by running the realtime search algorithm once we show that dalsslrta and dartaa outperform their predecessors sometimes by one order of magnitude of the four new algorithms dartaa produces the best solutions given a fixed deadline on the average time allowed per planning episode we prove all our algorithms have good theoretical properties in finite search spaces they find a solution if one exists and converge to an optimal after a number of trials









s  nofal k  atkinson and p  e dunne 2014 algorithms for argumentation semantics labeling attacks as a generalization of labeling arguments volume 49 pages 635668



a dung argumentation framework af is a pair ar a is a set of abstract arguments and r 8838 a215a is a binary relation socalled the attack relation for capturing the conflicting arguments labeling based algorithms for enumerating extensions ie sets of acceptable arguments have been set out such that arguments ie elements of a are the only subject for labeling in this paper we present implemented algorithms for listing extensions by labeling attacks ie elements of r along with arguments specifically these algorithms are concerned with enumerating all extensions of an af under a number of argumentation semantics preferred stable complete semi stable stage ideal and grounded our algorithms have impact in particular on enumerating extensions of afextended models that allow attacks on attacks to demonstrate this impact we instantiate our algorithms for an example of such models namely argumentation frameworks with recursive attacks afra thereby we end up with unified algorithms that enumerate extensions of any afafra



a novel algorithm for actively trading stocks is presented while traditional expert advice and universal algorithms as well as standard technical trading heuristics attempt to predict winners or trends our approach relies on predictable statistical relations between all pairs of stocks in the market our empirical results on historical markets provide strong evidence that this type of technical trading can beat the market and moreover can beat the best stock in the market in doing so we utilize a new idea for smoothing critical parameters in the context of expert learning







2012 ijcaijair best paper prize



conformant planning is the problem of finding a sequence of actions for achieving a goal in the presence of uncertainty in the initial state or action effects  the problem has been approached as a pathfinding problem in belief space where good belief representations and heuristics are critical for scaling up  in this work a different formulation is introduced for conformant problems with deterministic actions where they are automatically converted into classical ones and solved by an offtheshelf classical planner  the translation maps literals l and sets of assumptions t about the initial situation into new literals klt that represent that l must be true if t is initially true  we lay out a general translation scheme that is sound and establish the conditions under which the translation is also complete  we show that the complexity of the complete translation is exponential in a parameter of the problem called the conformant width which for most benchmarks is bounded the planner based on this translation exhibits good performance in comparison with existing planners and is the basis for t0 the best performing planner in the conformant track of the 2006 international planning competition





since its inception artificial intelligence has relied  upon a theoretical foundation centered around i perfect rationality i as   the desired property of intelligent systems we argue as others have   done that this foundation is inadequate because it imposes   fundamentally unsatisfiable requirements as a result there has   arisen a wide gap between theory and practice in ai hindering   progress in the field we propose instead a property called i bounded   optimalityi roughly speaking an agent is boundedoptimal if its   program is a solution to the constrained optimization problem   presented by its architecture and the task environment we show how to   construct agents with this property for a simple class of machine   architectures in a broad class of realtime environments we   illustrate these results using a simple model of an automated mail   sorting facility  we also define a weaker property i asymptotic   bounded optimalityi abo that generalizes the notion of optimality in   classical complexity theory  we then construct i universal i abo   programs ie programs that are abo no matter what realtime   constraints are applied  universal abo programs can be used as   building blocks for more complex systems we conclude with a   discussion of the prospects for bounded optimality as a theoretical   basis for ai and relate it to similar trends in philosophy   economics and game theory





l  bordeaux g  katsirelos n  narodytska and m  y vardi 2011 the complexity of integer bound propagation volume 40 pages 657676



bound propagation is an important artificial intelligence technique used in constraint programming tools to deal with numerical constraints it is typically embedded within a search procedure branch and prune and used at every node of the search tree to narrow down the search space so it is critical that it be fast the procedure invokes constraint propagators until a common fixpoint is reached but the known algorithms for this have a pseudopolynomial worstcase time complexity they are fast indeed when the variables have a small numerical range but they have the wellknown problem of being prohibitively slow when these ranges are large an important question is therefore whether stronglypolynomial algorithms exist that compute the common bound consistent fixpoint of a set of constraints this paper answers this question in particular we show that this fixpoint computation is in fact npcomplete even when restricted to binary linear constraints



i  kash a  d procaccia and n  shah 2014 no agent left behind dynamic fair division of multiple resources volume 51 pages 579603



recently fair division theory has emerged as a promising approach for allocation of multiple computational resources among agents while in reality agents are not all present in the system simultaneously previous work has studied static settings where all relevant information is known upfront our goal is to better understand the dynamic setting on the conceptual level we develop a dynamic model of fair division and propose desirable axiomatic properties for dynamic resource allocation mechanisms on the technical level we construct two novel mechanisms that provably satisfy some of these properties and analyze their performance using real data we believe that our work informs the design of superior multiagent systems and at the same time expands the scope of fair division theory by initiating the study of dynamic and fair resource allocation mechanisms





a  rey and j  rothe 2014 falsename manipulation in weighted voting games is hard for probabilistic polynomial time volume 50 pages 573601



falsename manipulation refers to the question of whether a player in a weighted voting game can increase her power by splitting into several players and distributing her weight among these false identities  relatedly the beneficial merging problem asks whether a coalition of players can increase their power in a weighted voting game by merging their weights  for the problems of whether merging or splitting players in weighted voting games is beneficial in terms of the shapleyshubik and the normalized banzhaf index merely nphardness lower bounds are known leaving the question about their exact complexity open  for the shapleyshubik and the probabilistic banzhaf index we raise these lower bounds to hardness for pp probabilistic polynomial time a class considered to be by far a larger class than np  for both power indices we provide matching upper bounds for beneficial merging and whenever the new players weights are given also for beneficial splitting thus resolving previous conjectures in the affirmative  relatedly we consider the beneficial annexation problem asking whether a single player can increase her power by taking over other players weights  it is known that annexation is never disadvantageous for the shapleyshubik index and that beneficial annexation is nphard for the normalized banzhaf index  we show that annexation is never disadvantageous for the probabilistic banzhaf index either and for both the shapleyshubik index and the probabilistic banzhaf index we show that it is npcomplete to decide whether annexing another player is advantageous  moreover we propose a general framework for merging and splitting that can be applied to different classes and representations of games







s  ross j  pineau s  paquet and b  chaibdraa 2008 online planning algorithms for pomdps volume 32 pages 663704



partially observable markov decision processes pomdps provide a rich framework for sequential decisionmaking under uncertainty in stochastic domains however solving a pomdp is often intractable except for small problems due to their complexity here we focus on online approaches that alleviate the computational complexity by computing good local policies at each decision step during the execution online algorithms generally consist of a lookahead search to find the best action to execute at each time step in an environment our objectives here are to survey the various existing online pomdp methods analyze their properties and discuss their advantages and disadvantages and to thoroughly evaluate these online approaches in different environments under various metrics return error bound reduction lower bound improvement our experimental results indicate that stateoftheart online heuristic search methods can handle large pomdp domains efficiently



motivated by the control theoretic distinction between    controllable and uncontrollable events we distinguish between two    types of agents within a multiagent system controllable agents    which are directly controlled by the systems designer and    uncontrollable agents which are not under the designers direct    control we refer to such systems as partially controlled multiagent    systems and we investigate how one might influence the behavior of    the uncontrolled agents through appropriate design of the controlled    agents in particular we wish to understand which problems are    naturally described in these terms what methods can be applied to    influence the uncontrollable agents the effectiveness of such    methods and whether similar methods work across different    domains using a gametheoretic framework this paper studies the    design of partially controlled multiagent systems in two contexts in    one context the uncontrollable agents are expected utility    maximizers while in the other they are reinforcement learners we    suggest different techniques for controlling agents behavior in each    domain assess their success and examine their relationship





c  domshlak e  karpas and s  markovitch 2012 online speedup learning for optimal planning volume 44 pages 709755



domainindependent planning is one of the foundational areas in the field of artificial intelligence a description of a planning task consists of an initial world state a goal and a set of actions for modifying the world state the objective is to find a sequence of actions that is a plan that transforms the initial world state into a goal state in optimal planning we are interested in finding not just a plan but one of the cheapest plans a prominent approach to optimal planning these days is heuristic

statespace search guided by admissible heuristic functions numerous admissible heuristics have been developed each with its own strengths and weaknesses and it is well known that there is no single best heuristic for optimal planning in general  thus which heuristic to choose for a given planning task is a difficult question this difficulty can be avoided by combining several heuristics but that requires computing numerous heuristic estimates at each state and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high we present a novel method that reduces the cost of combining admissible heuristics for optimal planning while maintaining its benefits  using an idealized search space model we formulate a decision rule for choosing the best heuristic to compute at each state we then present an active online learning approach for learning a classifier with that decision rule as the target concept and employ the learned classifier to decide  which heuristic to compute at each state we evaluate this technique empirically and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum

