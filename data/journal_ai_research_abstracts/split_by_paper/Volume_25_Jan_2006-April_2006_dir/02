s  thiebaux c  gretton j  slaney d  price and f  kabanza 2006 decisiontheoretic planning with nonmarkovian rewards volume 25 pages 1774

a decision process in which rewards depend on history rather than merely on the current state is called a decision process with nonmarkovian rewards nmrdp in decisiontheoretic planning where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states nmrdps form a more natural model than the commonly adopted fully markovian decision process mdp model while the more tractable solution methods developed for mdps do not directly apply in the presence of nonmarkovian rewards a number of solution methods for nmrdps have been proposed in the literature these all exploit a compact specification of the nonmarkovian reward function in temporal logic to automatically translate the nmrdp into an equivalent mdp which is solved using efficient mdp solution methods this paper presents nmrdpp nonmarkovian reward decision process planner a software platform for the development and experimentation of methods for decisiontheoretic planning with nonmarkovian rewards the current version of nmrdpp implements under a single interface a family of methods based on existing as well as new approaches which we describe in detail these include dynamic programming heuristic search and structured methods using nmrdpp we compare the methods and identify certain problem features that affect their performance nmrdpps treatment of nonmarkovian rewards is inspired by the treatment of domainspecific search control knowledge in the tlplan planner which it incorporates as a special case in the first international probabilistic planning competition nmrdpp was able to compete and perform well in both the domainindependent and handcoded tracks using search control knowledge in the latter 

