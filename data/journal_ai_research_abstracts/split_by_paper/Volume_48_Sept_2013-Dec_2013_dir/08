i  konstas and m  lapata 2013 a global model for concepttotext generation volume 48 pages 305346

  concepttotext generation refers to the task of automatically producing textual output from nonlinguistic input we present a joint model that captures content selection what to say and surface realization how to say in an unsupervised domainindependent fashion  rather than breaking up the generation process into a sequence of local decisions we define a probabilistic contextfree grammar that globally describes the inherent structure of the input a corpus of database records and text describing some of them  we recast generation as the task of finding the best derivation tree for a set of database records and describe an algorithm for decoding in this framework that allows to intersect the grammar with additional information capturing fluency and syntactic wellformedness constraints experimental evaluation on several domains achieves results competitive with stateoftheart systems that use domain specific constraints explicit feature engineering or labeled data

