a  guez d  silver and p  dayan 2013 scalable and efficient bayesadaptive reinforcement learning based on montecarlo tree search volume 48 pages 841883

bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty trading off exploration and exploitation in an ideal way unfortunately planning optimally in the face of uncertainty is notoriously taxing since the search space is enormous in this paper we introduce a tractable samplebased method for approximate bayesoptimal planning which exploits montecarlo tree search our approach avoids expensive applications of bayes rule within the search tree by sampling models from current beliefs and furthermore performs this sampling in a lazy manner this enables it to outperform previous bayesian modelbased reinforcement learning algorithms by a significant margin on several wellknown benchmark problems  as we show our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in bayesian exploration

