honorable mention for the 2005 ijcaijair best paper prize

stochastic sampling algorithms while an attractive alternative to    exact algorithms in very large bayesian network models have been    observed to perform poorly in evidential reasoning with extremely    unlikely evidence to address this problem we propose an adaptive    importance sampling algorithm aisbn that shows promising    convergence rates even under extreme conditions and seems to    outperform the existing sampling algorithms consistently three    sources of this performance improvement are 1 two heuristics for    initialization of the importance function that are based on the    theoretical properties of importance sampling in finitedimensional    integrals and the structural advantages of bayesian networks 2 a    smooth learning method for the importance function and 3 a dynamic    weighting function for combining samples from different stages of the    algorithm       we tested the performance of the aisbn algorithm along with two state    of the art general purpose sampling algorithms likelihood weighting    fung  chang 1989 shachter  peot 1989 and selfimportance    sampling shachter  peot 1989 we used in our tests three large    real bayesian network models available to the scientific community    the cpcs network pradhan et al 1994 the pathfinder network    heckerman horvitz  nathwani 1990 and the andes network conati    gertner vanlehn  druzdzel 1997 with evidence as unlikely as    1041 while the aisbn algorithm always performed better than the    other two algorithms in the majority of the test cases it achieved    orders of magnitude improvement in precision of the results    improvement in speed given a desired precision is even more dramatic    although we are unable to report numerical results here as the other    algorithms almost never achieved the precision reached even by the    first few iterations of the aisbn algorithm

