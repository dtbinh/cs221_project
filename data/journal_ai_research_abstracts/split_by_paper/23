







r  sanchez and  s  kambhampati 2003 altaltp online parallelization of plans with heuristic state search volume 19 pages 631657



i  bhattacharya and l  getoor 2007 querytime entity resolution volume 30 pages 621657



entity resolution is the problem of reconciling database references corresponding to the same realworld entities given the abundance of publicly available databases that have unresolved entities we motivate the problem of querytime entity resolution quick and accurate resolution for answering queries over such unclean databases at querytime  since collective entity resolution approaches  where related references are resolved jointly  have been shown to be more accurate than independent attributebased resolution for offline entity resolution we focus on developing new algorithms for collective resolution for answering entity resolution queries at querytime  for this purpose we first formally show that for collective resolution precision and recall for individual entities follow a geometric progression as neighbors at increasing distances are considered unfolding this progression leads naturally to a two stage expand and resolve query processing strategy in this strategy we first extract the related records for a query using two novel expansion operators and then resolve the extracted records collectively we then show how the same strategy can be adapted for querytime entity resolution by identifying and resolving only those database references that are the most helpful for processing the query we validate our approach on two large realworld publication databases where we show the usefulness of collective resolution and at the same time demonstrate the need for adaptive strategies for query processing we then show how the same queries can be answered in realtime using our adaptive approach while preserving the gains of collective resolution in addition to experiments on real datasets we use synthetically generated data to empirically demonstrate the validity of the performance trends predicted by our analysis of collective entity resolution over a wide range of structural characteristics in the data





o  yilmaz and a c cem  say 2006 causes of ineradicable spurious predictions in qualitative simulation volume 27 pages 551575



it was recently proved that a sound and complete qualitative simulator does not exist that is as long as the inputoutput vocabulary of the stateoftheart qsim algorithm is used there will always be input models which cause any simulator with a coverage guarantee to make spurious predictions in its output in this paper we examine whether a meaningfully expressive restriction of this vocabulary is possible so that one can build a simulator with both the soundness and completeness properties we prove several negative results all sound qualitative simulators employing subsets of the qsim representation which retain the operating region transition feature and support at least the addition and constancy constraints are shown to be inherently incomplete even when the simulations are restricted to run in a single operating region a constraint vocabulary containing just the addition constancy derivative and multiplication relations makes the construction of sound and complete qualitative simulators impossible









n  samaras and k  stergiou 2005 binary encodings of nonbinary constraint satisfaction problems algorithms and experimental results volume 24 pages 641684







cristhian  ariel d deagustini maria vanina  martinez marcelo  a falappa and guillermo  r simari 2016 datalog ontology consolidation volume 56 pages 613656



p  r conrad and b  c williams 2011 drake an efficient executive for temporal plans with choice volume 42 pages 607659



this work presents drake a dynamic executive for temporal plans with choice dynamic plan execution strategies allow an autonomous agent to react quickly to unfolding events improving the robustness of the agent prior work developed methods for dynamically dispatching simple temporal networks and further research enriched the expressiveness of the plans executives could handle including discrete choices which are the focus of this work however in some approaches to date these additional choices induce significant storage or latency requirements to make flexible execution possible 

drake is designed to leverage the low latency made possible by a preprocessing step called compilation while avoiding high memory costs through a compact representation we leverage the concepts of labels and environments taken from prior work in assumptionbased truth maintenance systems atms to concisely record the implications of the discrete choices exploiting the structure of the plan to avoid redundant reasoning or storage our labeling and maintenance scheme called the labeled value set maintenance system is distinguished by its focus on properties fundamental to temporal problems and more generally weighted graph algorithms in particular the maintenance system focuses on maintaining a minimal representation of nondominated constraints we benchmark drakes performance on random structured problems and find that drake reduces the size of the compiled representation by a factor of over 500 for large problems while incurring only a modest increase in runtime latency compared to prior work in compiled executives for temporal plans with discrete choices









p  d turney 2008 the latent relation mapping engine algorithm and experiments volume 33 pages 615655





t  leaute and b  faltings 2013 protecting privacy through distributed computation in multiagent decision making volume 47 pages 649695



as largescale theft of data from corporate servers is becoming increasingly common it becomes interesting to examine alternatives to the paradigm of centralizing sensitive data into large databases instead one could use cryptography and distributed computation so that sensitive data can be supplied and processed in encrypted form and only the final result is made known in this paper we examine how such a paradigm can be used to implement constraint satisfaction a technique that can solve a broad class of ai problems such as resource allocation planning scheduling and diagnosis most previous work on privacy in constraint satisfaction only attempted to protect specific types of information in particular the feasibility of particular combinations of decisions we formalize and extend these restricted notions of privacy by introducing four types of private information including the feasibility of decisions and the final decisions made but also the identities of the participants and the topology of the problem we present distributed algorithms that allow computing solutions to constraint satisfaction problems while maintaining these four types of privacy we formally prove the privacy properties of these algorithms and show experiments that compare their respective performance on benchmark problems 







robert  bredereck piotr  faliszewski rolf  niedermeier and nimrod  talmon 2016 largescale election campaigns combinatorial shift bribery volume 55 pages 603652



this paper describes a method for the automatic inference of structural transfer rules to be used in a shallowtransfer machine translation mt system from small parallel corpora the structural transfer rules are based on alignment templates like those used in statistical mt alignment templates are extracted from sentencealigned parallel corpora and extended with a set of restrictions which are derived from the bilingual dictionary of the mt system and control their application as transfer rules the experiments conducted using three different language pairs in the freeopensource mt platform apertium show that translation quality is improved as compared to wordforword translation when no transfer rules are used and that the resulting translation quality is close to that obtained using handcoded transfer rules the method we present is entirely unsupervised and benefits from information in the rest of modules of the mt system in which the inferred rules are applied









k  radinsky s  davidovich and s  markovitch 2012 learning to predict from textual data volume 45 pages 641684



given a current news event we tackle the problem of generating plausible predictions of future events it might cause  we present a new methodology for modeling and predicting such future news events using machine learning and data mining techniques our pundit algorithm generalizes examples of causality pairs to infer a causality predictor  to obtain precisely labeled causality examples we mine 150 years of news articles and apply semantic natural language modeling techniques to headlines containing certain predefined causality patterns  for generalization the model uses a vast number of world knowledge ontologies  empirical evaluation on real news articles shows that our pundit algorithm performs as well as nonexpert humans



t  xiao and j  zhu 2013 unsupervised subtree alignment for treetotree translation volume 48 pages 733782



this article presents a probabilistic subtree alignment model and its application to treetotree machine translation unlike previous work we do not resort to surface heuristics or expensive annotated data but instead derive an unsupervised model to infer the syntactic correspondence between two languages more importantly the developed model is syntacticallymotivated and does not rely on word alignments as a byproduct our model outputs a subtree alignment matrix encoding a large number of diverse alignments between syntactic structures from which machine translation systems can efficiently extract translation rules that are often filtered out due to the errors in 1best alignment experimental results show that the proposed approach outperforms three stateoftheart baseline approaches in both alignment accuracy and grammar quality when applied to machine translation our approach yields a 10 bleu improvement and a 09 ter reduction on the nist machine translation evaluation corpora with tree binarization and fuzzy decoding it even outperforms a stateoftheart hierarchical phrasebased system









k  dresner and p  stone 2008 a multiagent approach to autonomous intersection management volume 31 pages 591656





marius  lindauer holger  h hoos frank  hutter and torsten  schaub 2015 autofolio an automatically configured algorithm selector volume 53 pages 745778



algorithm selection as techniques  which involve choosing from a set of algorithms the one expected to solve a given problem instance most efficiently  have substantially improved the state of the art in solving many prominent ai problems such as sat csp asp maxsat and qbf although several as procedures have been introduced not too surprisingly none of them dominates all others across all as scenarios furthermore these procedures have parameters whose optimal values vary across as scenarios this holds specifically for the machine learning techniques that form the core of current as procedures and for their hyperparameters therefore to successfully apply as to new problems algorithms and benchmark sets two questions need to be answered i how to select an as approach and ii how to set its parameters effectively we address both of these problems simultaneously by using automated algorithm configuration specifically we demonstrate that we can automatically configure claspfolio 2 which implements a large variety of different as approaches and their respective parameters in a single highlyparameterized algorithm framework our approach dubbed autofolio allows researchers and practitioners across a broad range of applications to exploit the combined power of many different as methods we demonstrate autofolio can significantly improve the performance of claspfolio 2 on 8 out of the 13 scenarios from the algorithm selection library leads to new stateoftheart algorithm selectors for 7 of these scenarios and matches stateoftheart performance statistically on all other scenarios compared to the best single algorithm for each as scenario autofolio achieves average speedup factors between 13 and 154







c  hernandez and j  a baier 2012 avoiding and escaping depressions in realtime heuristic search volume 43 pages 523570





j  xu and c  r shelton 2010 intrusion detection using continuous time bayesian networks volume 39 pages 745774



intrusion detection systems idss fall into two highlevel categories networkbased systems nids that monitor network behaviors and hostbased systems hids that monitor system calls in this work we present a general technique for both systems we use anomaly detection which identifies patterns not conforming to a historic norm in both types of systems the rates of change vary dramatically over time due to burstiness and over components due to service difference to efficiently model such systems we use continuous time bayesian networks ctbns and avoid specifying a fixed update interval common to discretetime models we build generative models from the normal training data and abnormal behaviors are flagged based on their likelihood under this norm for nids we construct a hierarchical ctbn model for the network packet traces and use raoblackwellized particle filtering to learn the parameters we illustrate the power of our method through experiments on detecting real worms and identifying hosts on two publicly available network traces the mawi dataset and the lbnl dataset for hids we develop a novel learning method to deal with the finite resolution of system log file time stamps without losing the benefits of our continuous time model we demonstrate the method by detecting intrusions in the darpa 1998 bsm dataset



s  j chen a  choi and a  darwiche 2014 algorithms and applications for the samedecision probability volume 49 pages 601633



when making decisions under uncertainty the optimal choices are often difficult to discern especially if not enough information has been gathered two key questions in this regard relate to whether one should stop the information gathering process and commit to a decision stopping criterion and if not what information to gather next selection criterion in this paper we show that the recently introduced notion samedecision probability sdp can be useful as both a stopping and a selection criterion as it can provide additional insight and allow for robust decision making in a variety of scenarios this query has been shown to be highly intractable being ppppcomplete and is exemplary of a class of queries which correspond to the computation of certain expectations we propose the first exact algorithm for computing the sdp and demonstrate its effectiveness on several real and synthetic networks finally we present new complexity results such as the complexity of computing the sdp on models with a naive bayes structure  additionally we prove that computing  the nonmyopic value of information is complete for the  same complexity class as computing the sdp









a  borodin  r  elyaniv and  v  gogan 2004 can we learn to beat the best stock volume 21 pages 579594



domainspecific features are important in representing problem structure throughout machine learning and decisiontheoretic planning in planning once state features are provided domainindependent algorithms such as approximate value iteration can learn weighted combinations of those features that often perform well as heuristic estimates of state value eg distance to the goal successful applications in realworld domains often require features crafted by human experts here we propose automatic processes for learning useful domainspecific feature sets with little or no human intervention our methods select and add features that describe statespace regions of high inconsistency in the bellman equation statewise bellman error during approximate value iteration our method can be applied using any realvaluedfeature hypothesis space and corresponding learning method for selecting features from training sets of statevalue pairs we evaluate the method with hypothesis spaces defined by both relational and propositional feature languages using nine probabilistic planning domains we show that approximate value iteration using a relational feature space performs at the stateoftheart in domainindependent stochastic relational planning our method provides the first domainindependent approach that plays tetris successfully without humanengineered features





s  cai k  su c  luo and a  sattar 2013 numvc an efficient local search algorithm for minimum vertex cover volume 46 pages 687716



the minimum vertex cover mvc problem is a prominent nphard combinatorial optimization problem of great importance in both theory and application local search has proved successful for this problem however there are two main drawbacks in stateoftheart mvc local search algorithms first they select a pair of vertices to exchange simultaneously which is timeconsuming secondly although using edge weighting techniques to diversify the search these algorithms lack mechanisms for decreasing the weights to address these issues we propose two new strategies twostage exchange and edge weighting with forgetting the twostage exchange strategy selects two vertices to exchange separately and performs the exchange in two stages the strategy of edge weighting with forgetting not only increases weights of uncovered edges but also decreases some weights for each edge periodically these two strategies are used in designing a new mvc local search algorithm which is referred to as numvc

we conduct extensive experimental studies on the standard benchmarks namely dimacs and bhoslib the experiment comparing numvc with stateoftheart heuristic algorithms show that numvc is at least competitive with the nearest competitor namely pls on the dimacs benchmark and clearly dominates all competitors on the bhoslib benchmark also experimental results indicate that numvc finds an optimal solution much faster than the current best exact algorithm for maximum clique on random instances as well as some structured ones moreover we study the effectiveness of the two strategies and the runtime behaviour through experimental analysis













s  j russell and  d  subramanian 1995 provably boundedoptimal agents volume 2 pages 575609



v  aravantinos r  caferra and n  peltier 2011 decidability and undecidability results for propositional schemata volume 40 pages 599656



we define a logic of propositional formula schemata adding to the syntax of propositional logic indexed propositions and iterated connectives ranging over intervals parameterized by arithmetic variables  the satisfiability problem is shown to be undecidable for this new logic but we introduce a very general class of schemata called boundlinear for which this problem becomes decidable  this result is obtained by reduction to a particular class of schemata called regular for which we provide a sound and complete terminating proof procedure  this schemata calculus allows one to capture proof patterns corresponding to a large class of problems specified in propositional logic we also show that the satisfiability problem becomes again undecidable for slight extensions of this class thus demonstrating that boundlinear schemata represent a good compromise between expressivity and decidability





the workflow satisfiability problem wsp is a problem of practical interest that arises whenever tasks need to be performed by authorized users subject to constraints defined by business rules  we are required to decide whether there exists a plan  an assignment of tasks to authorized users  such that all constraints are satisfied  it is natural to see the wsp as a subclass of the constraint satisfaction problem csp in which the variables are tasks and the domain is the set of users  what makes the wsp distinctive is that the number of tasks is usually very small compared to the number of users so it is appropriate to ask for which constraint languages the wsp is fixedparameter tractable fpt parameterized by the number of tasks

this novel approach to the wsp using techniques from csp has enabled us to  design a generic algorithm which is fpt for several families of workflow constraints considered in the literature furthermore we prove that the union of fpt languages remains fpt if they satisfy a simple compatibility condition  lastly we identify a new fpt constraint language userindependent constraints that includes many of the constraints of interest in business processing systems   we demonstrate that our generic algorithm has provably optimal running time o2klog k for this language where k is the number of tasks







dynamic scheduling problems consist of both challenging combinatorics as found in classical scheduling problems and stochastics due to uncertainty about the arrival times resource requirements and processing times of jobs to address these two challenges we investigate the integration of queueing theory and scheduling the former reasons about longrun stochastic system characteristics whereas the latter typically deals with shortterm combinatorics we investigate two simple problems to isolate the core differences and potential synergies between the two approaches a twomachine dynamic flowshop and a flexible queueing network we show for the first time that stability a fundamental characteristic in queueing theory can be applied to approaches that periodically solve combinatorial scheduling problems  we empirically demonstrate that for a dynamic flowshop the use of combinatorial reasoning has little impact on schedule quality beyond queueing approaches in contrast for the more complicated flexible queueing network a novel algorithm that combines longterm guidance from queueing theory with shortterm combinatorial decision making outperforms all other tested approaches to our knowledge this is the first time that such a hybrid of queueing theory and scheduling techniques has been proposed and evaluated 







f  yang  j  culberson  r  holte u  zahavi and a  felner 2008 a general theory of additive state space abstractions volume 32 pages 631662



informally a set of abstractions of a state space s is additive if the distance between any two states in s is always greater than or equal to the sum of the corresponding distances in the abstract spaces the first known additive abstractions called disjoint pattern databases were experimentally demonstrated to produce state of the art performance on certain state spaces however previous applications were restricted to state spaces with special properties which precludes disjoint pattern databases from being defined for several commonly used testbeds such as rubiks cube topspin and the pancake puzzle in this paper we give a general definition of additive abstractions that can be applied to any state space and prove that heuristics based on additive abstractions are consistent as well as admissible we use this new definition to create additive abstractions for these testbeds and show experimentally that well chosen additive abstractions can reduce search time substantially for the 184topspin puzzle and by three orders of magnitude over state of the art methods for the 17pancake puzzle we also derive a way of testing if the heuristic value returned by additive abstractions is provably too low and show that the use of this test can reduce search time for the 15puzzle and topspin by roughly a factor of two









r  i brafman and  m  tennenholtz 1996 on partially controlled multiagent systems volume 4 pages 477507



b  konev m  ludwig d  walther and f  wolter 2012 the logical difference for the lightweight description logic el volume 44 pages 633708



we study a logicbased approach to versioning of ontologies under this view ontologies provide answers to queries about some vocabulary of interest the difference between two versions of an ontology is given by the set of queries that receive different answers

empty we present an implementation cex2 of the developed algorithms for subsumption and instance queries and apply it to distinct versions of snomed ct and the nci ontology



