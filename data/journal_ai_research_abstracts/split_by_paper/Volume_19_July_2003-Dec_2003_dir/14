2007 ijcaijair best paper prize

this paper addresses the problem of planning under uncertainty in large markov decision processes mdps factored mdps represent a complex state space using state variables and the transition model using a dynamic bayesian network this representation often allows an exponential reduction in the representation size of structured mdps but the complexity of exact solution algorithms for such mdps can grow exponentially in the representation size  in this paper we present two approximate solution algorithms that exploit structure in factored mdps  both use an approximate value function represented as a linear combination of basis functions where each basis function involves only a small subset of the domain variables  a key contribution of this paper is that it shows how the basic operations of both algorithms can be performed efficiently in closed form by exploiting both additive and contextspecific structure in a factored mdp  a central element of our algorithms is a novel linear program decomposition technique analogous to variable elimination in bayesian networks which reduces an exponentially large lp to a provably equivalent polynomialsized one  one algorithm uses approximate linear programming and the second approximate dynamic programming our dynamic programming algorithm is novel in that it uses an approximation based on maxnorm a technique that more directly minimizes the terms that appear in error bounds for approximate mdp algorithms  we provide experimental results on problems with over 1040 states demonstrating a promising indication of the scalability of our approach and compare our algorithm to an existing stateoftheart approach showing in some problems exponential gains in computation time

