c  lusena  j  goldsmith and  m  mundhenk 2001 nonapproximability results for partially observable markov decision processes volume 14 pages 83103

we show that for several variations of partially observable    markov decision processes polynomialtime algorithms for finding    control policies are unlikely to or simply dont have guarantees of    finding policies within a constant factor or a constant summand of    optimal  here unlikely means unless some complexity classes    collapse where the collapses considered are pnp ppspace or    pexp  until or unless these collapses are shown to hold any    controlpolicy designer must choose between such performance    guarantees and efficient computation

