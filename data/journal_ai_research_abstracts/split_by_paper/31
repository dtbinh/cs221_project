we propose a novel method for approximate inference in bayesian networks bns the idea is to sample data from a bn learn a latent tree model ltm from the data offline and when online make inference with the ltm instead of the original bn because ltms are treestructured inference takes linear time in the meantime they can represent complex relationship among leaf nodes and hence the approximation accuracy is often good empirical evidence shows that our method can achieve good approximation accuracy at low online computational cost



m  jaeger 2005 ignorability in statistical and probabilistic inference volume 24 pages 889917



when dealing with incomplete data in statistical learning or incomplete observations in probabilistic inference one needs to distinguish the fact that a certain event is observed from the fact that the observed event has happened since the modeling and computational complexities entailed by maintaining this proper distinction are often prohibitive one asks for conditions under which it can be safely ignored such conditions are given by the missing at random mar and coarsened at random car assumptions in this paper we provide an indepth analysis of several questions relating to marcar assumptions main purpose of our study is to provide criteria by which one may evaluate whether a car assumption is reasonable for a particular data collecting or observational process this question is complicated by the fact that several distinct versions of marcar assumptions exist we therefore first provide an overview over these different versions in which we highlight the distinction between distributional and coarsening variable induced versions we show that distributional versions are less restrictive and sufficient for most applications we then address from two different perspectives the question of when the marcar assumption is warranted first we provide a static analysis that characterizes the admissibility of the car assumption in terms of the support structure of the joint probability distribution of complete data and incomplete observations here we obtain an equivalence characterization that improves and extends a recent result by grunwald and halpern we then turn to a procedural analysis that characterizes the admissibility of the car assumption in terms of procedural models for the actual data or observation generating process the main result of this analysis is that the stronger coarsened completely at random ccar condition is arguably the most reasonable assumption as it alone corresponds to data coarsening procedures that satisfy a natural robustness property 





j  wu r  kalyanam and r  givan 2011 stochastic enforced hillclimbing volume 42 pages 815850





enforced hillclimbing is an effective deterministic hillclimbing technique that deals with local optima using breadthfirst search a process called basin flooding  we propose and evaluate a stochastic generalization



recently maxsat reasoning is shown very effective in computing a tight upper bound for a maximum clique mc of a unweighted graph in this paper we apply maxsat reasoning to compute a tight upper bound for a maximum weight clique mwc of a wighted graph we first study three usual encodings of mwc into weighted partial maxsat dealing with hard clauses which must be satisfied in all solutions and soft clauses which are weighted and can be falsified the drawbacks of these encodings motivate us to propose an encoding of mwc into a special weighted partial maxsat formalism called lw literalweighted encoding and dedicated for upper bounding an mwc in which both soft clauses and literals in soft clauses are weighted an optimal solution of the lw maxsat instance gives an upper bound for an mwc instead of an optimal solution for mwc we then introduce two notions called the topk literal failed clause and the topk empty clause to extend classical maxsat reasoning techniques as well as two sound transformation rules to transform an lw maxsat instance successive transformations of an lw maxsat instance driven by maxsat reasoning give a tight upper bound for the encoded mwc the approach is implemented in a branchandbound algorithm called mwclq experimental evaluations on the broadly used dimacs benchmark bhoslib benchmark random graphs and the benchmark from the winner determination problem show that our approach allows mwclq to reduce the search space significantly and to solve mwc instances effectively consequently mwclq outperforms stateoftheart exact algorithms on the vast majority of instances moreover it is surprisingly effective in solving hard and dense instances









f  campeotto a  dal pal249 a  dovier f  fioretto and e  pontelli 2013 a constraint solver for flexible protein model volume 48 pages 9531000



this paper proposes the formalization and implementation of a novel class of constraints aimed at modeling problems related to placement of multibody systems in the 3dimensional space each multibody is a system composed of body elements connected by joint relationships and constrained by geometric properties the emphasis of this investigation is the use of multibody systems to model native conformations of protein structureswhere each body represents an entity of the protein eg an amino acid a small peptide and the geometric constraints are related to the spatial properties of the composing atoms the paper explores the use of the proposed class of constraints to support a variety of different structural analysis of proteins such as loop modeling and structure prediction

the declarative nature of a constraintbased encoding provides elaboration tolerance and the ability to make use of any additional knowledge in the analysis studies the filtering capabilities of the proposed constraints also allow to control the number of representative solutions that are withdrawn from the conformational space of the protein by means of criteria driven by uniform distribution sampling principles in this scenario it is possible to select the desired degree of precision andor number of solutions the filtering component automatically excludes configurations that violate the spatial and geometric properties of the composing multibody system the paper illustrates the implementation of a constraint solver based on the multibody perspective and its empirical evaluation on protein  structure analysis problems











p  kissmann and j  hoffmann 2014 bdd ordering heuristics for classical planning volume 51 pages 779804



symbolic search using binary decision diagrams bdds can often save large amounts of memory due to its concise representation of state sets a decisive factor for this methods success is the chosen variable ordering generally speaking it is plausible that dependent variables should be brought close together in order to reduce bdd sizes in planning variable dependencies are typically captured by means of causal graphs and in preceding work these were taken as the basis for finding bdd variable orderings starting from the observation that the two concepts of dependency are actually quite different we introduce a framework for assessing the strength of variable ordering heuristics in subclasses of planning it turns out that even for extremely simple planning tasks causal graph based variable orders may be exponentially worse than optimal



we describe a stateoftheart sentiment analysis system that detects a the sentiment of short informal textual messages such as tweets and sms messagelevel task and b the sentiment of a word or a phrase within a message termlevel task  the system is based on a supervised statistical text classification approach leveraging a variety of surfaceform semantic and sentiment features  the sentiment features are primarily derived from novel highcoverage tweetspecific sentiment lexicons  these lexicons are automatically generated from tweets with sentimentword hashtags and from tweets with emoticons  to adequately capture the sentiment of words in negated contexts a separate sentiment lexicon is generated for negated words









y  wang n  l zhang and t  chen 2008 latent tree models and approximate inference in bayesian networks volume 32 pages 879900



we propose a novel method for approximate inference in bayesian networks bns the idea is to sample data from a bn learn a latent tree model ltm from the data offline and when online make inference with the ltm instead of the original bn because ltms are treestructured inference takes linear time in the meantime they can represent complex relationship among leaf nodes and hence the approximation accuracy is often good empirical evidence shows that our method can achieve good approximation accuracy at low online computational cost

