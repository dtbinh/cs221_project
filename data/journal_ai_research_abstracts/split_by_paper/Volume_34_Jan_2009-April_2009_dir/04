d  s bernstein c  amato e  a hansen and s  zilberstein 2009 policy iteration for decentralized control of markov decision processes volume 34 pages 89132

coordination of distributed agents is required for problems arising in many areas including multirobot systems networking and ecommerce  as a formal framework for such problems we use the decentralized partially observable markov decision process decpomdp  though much work has been done on optimal dynamic programming algorithms for the singleagent version of the problem optimal algorithms for the multiagent case have been elusive  the main contribution of this paper is an optimal policy iteration algorithm for solving decpomdps  the algorithm uses stochastic finitestate controllers to represent policies  the solution can include a correlation device which allows agents to correlate their actions without communicating  this approach alternates between expanding the controller and performing valuepreserving transformations which modify the controller without sacrificing value  we present two efficient valuepreserving transformations one can reduce the size of the controller and the other can improve its value while keeping the size fixed  empirical results demonstrate the usefulness of valuepreserving transformations in increasing value while keeping controller size to a minimum to broaden the applicability of the approach we also present a heuristic version of the policy iteration algorithm which sacrifices convergence to optimality  this algorithm further reduces the size of the controllers at each step by assuming that probability distributions over the other agents actions are known while this assumption may not hold in general it helps produce higher quality solutions in our test problems

