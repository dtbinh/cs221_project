p  doshi and p  j gmytrasiewicz 2009 monte carlo sampling methods for approximating interactive pomdps volume 34 pages 297337

partially observable markov decision processes pomdps provide a principled framework for sequential planning in uncertain single agent settings an extension of pomdps to multiagent settings called interactive pomdps ipomdps replaces pomdp belief spaces with interactive hierarchical belief systems which represent an agents belief about the physical world about beliefs of other agents and about their beliefs about others beliefs this modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute we describe a general method for obtaining approximate solutions of ipomdps based on particle filtering pf we introduce the interactive pf which descends the levels of the interactive belief hierarchies and samples and propagates beliefs at each level the interactive pf is able to mitigate the belief space complexity but it does not address the policy space complexity to mitigate the policy space complexity  sometimes also called the curse of history  we utilize a complementary method based on sampling likely observations while building the look ahead reachability tree while this approach does not completely address the curse of history it beats back the curses impact substantially we provide experimental results and chart future work

