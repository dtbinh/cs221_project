d  a cohn  z  ghahramani and  m  i jordan 1996 active learning with statistical models volume 4 pages 129145

for many types of machine learning algorithms one can    compute the statistically optimal way to select training data  in    this paper we review how optimal data selection techniques have been    used with feedforward neural networks  we then show how the same    principles may be used to select data for two alternative    statisticallybased learning architectures mixtures of gaussians and    locally weighted regression  while the techniques for neural networks    are computationally expensive and approximate the techniques for    mixtures of gaussians and locally weighted regression are both    efficient and accurate  empirically we observe that the optimality    criterion sharply decreases the number of training examples the    learner needs in order to achieve good performance

