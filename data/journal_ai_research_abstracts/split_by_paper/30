



the 2004 international planning competition ipc4 included a probabilistic planning track for the first time we describe the new domain specification language we created for the track our evaluation methodology the competition domains we developed and the results of the participating teams







in this paper we present a novel decentralised management technique that allows electricity microstorage devices deployed within individual homes as part of a smart electricity grid to converge to profitable and efficient behaviours specifically we propose the use of software agents residing on the users smart meters to automate and optimise the charging cycle of microstorage devices in the home to minimise its costs and we present a study of both the theoretical underpinnings and the implications of a practical solution of using software agents for such microstorage management first by formalising the strategic choice each agent makes in deciding when to charge its battery we develop a gametheoretic framework within which we can analyse the competitive equilibria of an electricity grid populated by such agents and hence predict the best consumption profile for that population given their battery properties and individual load profiles our framework also allows us to compute theoretical bounds on the amount of storage that will be adopted by the population second to analyse the practical implications of microstorage deployments in the grid we present a novel algorithm that each agent can use to optimise its battery storage profile in order to minimise its owners costs this algorithm uses a learning strategy that allows it to adapt as the price of electricity changes in realtime and we show that the adoption of these strategies results in the system converging to the theoretical equilibria finally we empirically evaluate the adoption of our microstorage management technique within a complex setting based on the uk electricity market where agents may have widely varying load profiles battery types and learning rates in this case our approach yields savings of up to 14 in energy cost for an average consumer using a storage device with a capacity of less than 45 kwh and up to a 7 reduction in carbon emissions resulting from electricity generation with only domestic consumers adopting microstorage and commercial and industrial consumers not changing their demand moreover corroborating our theoretical bound an equilibrium is shown to exist where no more than 48 of households would wish to own storage devices and where social welfare would also be improved yielding overall annual savings of nearly 16315b







the ability to associate images with natural language sentences that describe what is depicted in them is a hallmark of image understanding and a prerequisite for applications such as sentencebased image search in analogy to image search we propose to frame sentencebased image annotation as the task of ranking a given pool of captions we introduce a new benchmark collection for sentencebased image description and search consisting of 8000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events we introduce a number of systems that perform quite well on this task even though they are only based on features that can be obtained with minimal supervision our results clearly indicate the importance of training on multiple captions per image and of capturing syntactic word orderbased and semantic features of these captions we also perform an indepth comparison of human and automatic evaluation metrics for this task and propose strategies for collecting human judgments cheaply and on a very large scale allowing us to augment our collection with additional relevance judgments of which captions describe which image our analysis shows that metrics that consider the ranked list of results for each query image or sentence are significantly more robust than metrics that are based on a single response per query moreover our study suggests that the evaluation of rankingbased image description systems may be fully automated







zhiwen  fang chumin  li and ke  xu 2016 an exact algorithm based on maxsat reasoning for the maximum weight clique problem volume 55 pages 799833



e  mossel a  d procaccia and m  z racz 2013 a smooth transition from powerlessness to absolute power volume 48 pages 923951



we study the phase transition of the coalitional manipulation problem for generalized scoring rules previously it has been shown that under some conditions on the distribution of votes if the number of manipulators is osqrtn where n is the number of voters then the probability that a random profile is manipulable by the coalition goes to zero as the number of voters goes to infinity whereas if the number of manipulators is omegasqrtn then the probability that a random profile is manipulable goes to one here we consider the critical window where a coalition has size csqrtn and we show that as c goes from zero to infinity the limiting probability that a random profile is manipulable goes from zero to one in a smooth fashion ie there is a smooth phase transition between the two regimes this result analytically validates recent empirical results and suggests that deciding the coalitional manipulation problem may be of limited computational hardness in practice





t  de la rosa s  jimenez r  fuentetaja and d  borrajo 2011 scaling up heuristic planning with relational decision trees volume 40 pages 767813





current evaluation functions for heuristic planning are expensive to compute in numerous planning problems these functions provide good guidance to the solution so they are worth the expense however when  evaluation functions are misguiding or when planning problems are large enough lots of node evaluations must be computed which severely limits the scalability of heuristic planners in this paper we present a novel solution for reducing node evaluations in heuristic planning based on machine learning particularly we define the task of learning search control for heuristic planning as a relational classification task and we use an offtheshelf relational classification tool to address this learning task our relational classification task captures the preferred action to select in the different planning contexts of a specific planning domain these planning contexts are defined by the set of helpful actions of the current state the goals remaining to be achieved and the static predicates of the planning task this paper shows two methods for guiding the search of a heuristic planner with the learned classifiers the first one consists of using the resulting classifier as an action policy the second one consists of applying the classifier to generate lookahead states within a best first search algorithm experiments over a variety of domains reveal that our heuristic planner using the learned classifiers solves larger problems than stateoftheart planners



a continuoustime markov process ctmp is a collection of variables indexed by a continuous quantity time it obeys the markov property that the distribution over a future variable is independent of past variables given the state at the present time we introduce continuoustime markov process representations and algorithms for filtering smoothing expected sufficient statistics calculations and model estimation assuming no prior knowledge of continuoustime processes but some basic knowledge of probability and statistics we begin by describing flat or unstructured markov processes and then move to structured markov processes those arising from state spaces consisting of assignments to variables including kronecker decisiondiagram and continuoustime bayesian network representations we provide the first connection between decisiondiagrams and continuoustime bayesian networks











s  kiritchenko x  zhu and s  m mohammad 2014 sentiment analysis of short informal texts volume 50 pages 723762



g  m coghill a  srinivasan and r  d king 2008 qualitative system identification from imperfect data volume 32 pages 825877



experience in the physical sciences suggests that the only realistic means of understanding complex systems is through the use of mathematical models typically this has come to mean the identification of quantitative models expressed as differential equations quantitative modelling works best when the structure of the model ie the form of the equations is known and the primary concern is one of estimating the values of the parameters in the model for complex biological systems the modelstructure is rarely known and the modeler has to deal with both modelidentification and parameterestimation in this paper we are concerned with providing automated assistance to the first of these problems specifically we examine the identification by machine of the structural relationships between experimentally observed variables these relationship will be expressed in the form of qualitative abstractions of a quantitative model such qualitative models may not only provide clues to the precise quantitative model but also assist in understanding the essence of  that model our position in this paper is that background knowledge incorporating system modelling principles can be used to constrain effectively the set of good qualitative models utilising the modelidentification framework provided by inductive logic programming ilp we present empirical support for this position using a series of increasingly complex artificial datasets the results are obtained with qualitative and quantitative data subject to varying amounts of noise and different degrees of sparsity  the results also point to the presence of a set of qualitative states which we term kernel subsets that may be necessary for a qualitative modellearner to learn correct models we demonstrate scalability of the method to biological system modelling by identification of the glycolysis metabolic pathway from data



