j  eisenstein r  barzilay and r  davis 2008 gesture salience as a hidden variable for coreference resolution and keyframe extraction volume 31 pages 353398

gesture is a nonverbal modality that can contribute crucial information to the understanding of natural language but not all gestures are informative and noncommunicative hand motions may confuse natural language processing nlp and impede learning people have little diffculty ignoring irrelevant hand movements and focusing on meaningful gestures suggesting that an automatic system could also be trained to perform this task  however the informativeness of a gesture is contextdependent and labeling enough data to cover all cases would be expensive we present conditional modality fusion a conditional hiddenvariable model that learns to predict which gestures are salient for coreference resolution the task of determining whether two noun phrases refer to the same semantic entity moreover our approach uses only coreference annotations and not annotations of gesture salience itself we show that gesture features improve performance on coreference resolution and that by attending only to gestures that are salient our method achieves further significant gains in addition we show that the model of gesture salience learned in the context of coreference accords with human intuition by demonstrating that gestures judged to be salient by our model can be used successfully to create multimedia keyframe summaries of video these summaries are similar to those created by human raters and significantly outperform summaries produced by baselines from the literature

