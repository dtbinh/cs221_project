l  miclet s  bayoudh and a  delhay 2008 analogical dissimilarity definition algorithms and two experiments in machine learning volume 32 pages 793824



m  beetz and h  grosskreutz 2005 probabilistic hybrid action models for predicting concurrent perceptdriven robot behavior volume 24 pages 799849



this article develops probabilistic hybrid action models phams a realistic causal model for predicting the behavior generated by modern perceptdriven robot plans phams represent aspects of robot behavior that cannot be represented by most action models used in ai planning the temporal structure of continuous control processes their nondeterministic effects several modes of their interferences and the achievement of triggering conditions in closedloop robot plans 







p  vytelingum t  d voice s  d ramchurn a  rogers and n  r jennings 2011 theoretical and practical foundations of largescale agentbased microstorage in the smart grid volume 42 pages 765813







m  mosurovic n  krdzavac h  graves and m  zakharyaschev 2013 a decidable extension of sroiq with complex role chains and unions volume 47 pages 809851



we design a decidable extension of the description logic sroiq underlying the web ontology language owl 2 the new logic called sroiq supports a controlled use of role axioms whose righthand side may contain role chains or role unions we give a tableau algorithm for checking concept satisfiability with respect to sroiq ontologies and prove its soundness completeness and termination



alberto  garciaduran antoine  bordes nicolas  usunier and yves  grandvalet 2016 combining two and threeway embedding models for link prediction in knowledge bases volume 55 pages 715742



this paper tackles the problem of endogenous link prediction for knowledge base completion knowledge bases can be represented as directed graphs whose nodes correspond to entities and edges to relationships previous attempts either consist of powerful systems with high capacity to model complex connectivity patterns which unfortunately usually end up overfitting on rare relationships or in approaches that trade capacity for simplicity in order to fairly model all relationships frequent or not in this paper we propose tatec a happy medium obtained by complementing a highcapacity model with a simpler one both pretrained separately and then combined we present several variants of this model with different kinds of regularization and combination strategies and show that this approach outperforms existing methods on different types of relationships by achieving stateoftheart results on four benchmarks of the literature







m  zaffalon and e  miranda 2009 conservative inference rule for uncertain reasoning under incompleteness volume 34 pages 757821



in this paper we formulate the problem of inference under incomplete information in very general terms this includes modelling the process responsible for the incompleteness which we call the incompleteness process we allow the process behaviour to be partly unknown then we use walleys theory of coherent lower previsions a generalisation of the bayesian theory to imprecision to derive the rule to update beliefs under incompleteness that logically follows from our assumptions and that we call conservative inference rule this rule has some remarkable properties it is an abstract rule to update beliefs that can be applied in any situation or domain it gives us the opportunity to be neither too optimistic nor too pessimistic about the incompleteness process which is a necessary condition to draw reliable while strong enough conclusions and it is a coherent rule in the sense that it cannot lead to inconsistencies we give examples to show how the new rule can be applied in expert systems in parametric statistical inference and in pattern classification and discuss more generally the view of incompleteness processes defended here as well as some of its consequences



m  r costajuss224 c  a henr237quez and r  e banchs 2012 evaluating indirect strategies for chinesespanish statistical machine translation volume 45 pages 761780



although chinese and spanish are two of the most spoken languages in the world not much research has been done in machine translation for this language pair this paper focuses on investigating the stateoftheart of chinesetospanish statistical machine translation smt which nowadays is one of the most popular approaches to machine translation for this purpose we report details of the available parallel corpus which are basic traveller expressions corpus btec holy bible and united nations un additionally we conduct experimental work with the largest of these three corpora to explore alternative smt strategies by means of using a pivot language three alternatives are considered for pivoting cascading pseudocorpus and triangulation as pivot language we use either english arabic or french results show that for a phrasebased smt system english is the best pivot language between chinese and spanish we propose a system output combination using the pivot strategies which is capable of outperforming the direct translation strategy the main objective of this work is motivating and involving the research community to work in this important pair of languages given their demographic impact









e  franconi v  kerhet and n  ngo 2013 exact query reformulation over databases with firstorder and description logics ontologies volume 48 pages 885922



srk  branavan d  silver and r  barzilay 2012 learning to win by reading manuals in a montecarlo framework volume 43 pages 661704



domain knowledge is crucial for effective performance in autonomous control systems  typically human effort is required to encode this knowledge into a control algorithm  in this paper we present an approach to language grounding which automatically interprets text in the context of a complex control application such as a game and uses domain knowledge extracted from the text to improve control performance  both text analysis and control strategies are learned jointly using only a feedback signal inherent to the application  to effectively leverage textual information our method automatically extracts the text segment most relevant to the current game state and labels it with a taskcentric predicate structure  this labeled text is then used to bias an action selection policy for the game guiding it towards promising regions of the action space  we encode our model for text analysis and game playing in a multilayer neural network representing linguistic decisions via latent variables in the hidden layers and game action quality via the output layer  operating within the montecarlo search framework we estimate model parameters using feedback from simulated games  we apply our approach to the complex strategy game civilization ii using the official game manual as the text guide  our results show that a linguisticallyinformed gameplaying agent significantly outperforms its languageunaware counterpart yielding a 34 absolute improvement and winning over 65 of games when playing against the builtin ai of civilization







n  fernandez garcia j  arias fisteus and l  sanchez fernandez 2014 comparative evaluation of linkbased approaches for candidate ranking in linktowikipedia systems volume 49 pages 733773



in recent years the task of automatically linking pieces of text anchors  mentioned in a document to wikipedia articles that represent the meaning of these anchors has received extensive research attention typically linktowikipedia systems try to find a set of wikipedia articles that are candidates to represent the meaning of the anchor and later rank these candidates to select the most appropriate one in this ranking process the systems rely on context information obtained from the document where the anchor is mentioned andor from wikipedia in this paper we center our attention in the use of wikipedia links as context information in particular we offer a review of several candidate ranking approaches in the stateoftheart that rely on wikipedia link information in addition we provide a comparative empirical evaluation of the different approaches on five different corpora the tac 2010 corpus and four corpora built from actual  wikipedia articles and news items



e  saquete j  luis vicedo p  mart237nezbarco r  mu241oz and h  llorens 2009 enhancing qa systems with complex temporal question processing capabilities volume 35 pages 775811



this paper presents a multilayered architecture that enhances the capabilities of current qa systems and allows different types of complex questions or queries to be processed the answers to these questions need to be gathered from factual information scattered throughout different documents specifically we designed a specialized layer to process the different types of temporal questions complex temporal questions are first decomposed into simple questions according to the temporal relations expressed in the original question in the same way the answers to the resulting simple questions are recomposed fulfilling the temporal restrictions of the original complex question a novel aspect of this approach resides in the decomposition which uses a minimal quantity of resources with the final aim of obtaining a portable platform that is easily extensible to other languages in this paper we also present a methodology for evaluation of the decomposition of the questions as well as the ability of the implemented temporal layer to perform at a multilingual level the temporal layer was first performed for english then evaluated and compared with a a general purpose qa system fmeasure 6547 for qa plus english temporal layer vs 3801 for the general qa system and b a wellknown qa system much better results were obtained for temporal questions with the multilayered system this system was therefore extended to spanish and very good results were again obtained in the evaluation fmeasure 4036 for qa plus spanish temporal layer vs 2294 for the general qa system







w  li p  poupart and p  van beek 2011 exploiting structure in weighted model counting approaches to probabilistic inference volume 40 pages 729765



previous studies have demonstrated that encoding a bayesian network into a sat formula and then performing weighted model counting using a backtracking search algorithm can be an effective method for exact inference  in this paper we present techniques for improving this approach for bayesian networks with noisyor and noisymax relationstwo relations that are widely used in practice as they can dramatically reduce the number of probabilities one needs to specify in particular we present two sat encodings for noisyor and two encodings for noisymax that exploit the structure or semantics of the relations to improve both time and space efficiency and we prove the correctness of the encodings we experimentally evaluated our techniques on largescale real and randomly generated bayesian networks  on these benchmarks our techniques gave speedups of up to two orders of magnitude over the best previous approaches for networks with noisyormax relations and scaled up to larger networks as well our techniques extend the weighted model counting approach for exact inference to networks that were previously intractable for the approach



o  cepek s  gursky and p  kucera 2014 on minimum representations of matched formulas volume 51 pages 707723



a boolean formula in conjunctive normal form cnf is called matched if the system of sets of variables which appear in individual clauses has a system of distinct representatives each matched cnf is trivially satisfiable each clause can be satisfied by its representative variable another property which is easy to see is that the class of matched cnfs is not closed under partial assignment of truth values to variables this latter property leads to a fact proved here that given two matched cnfs it is conp complete to decide whether they are logically equivalent the construction in this proof leads to another result a much shorter and simpler proof of the fact that the boolean minimization problem for matched cnfs is a complete problem for the second level of the polynomial hierarchy the main result of this paper deals with the structure of clause minimum cnfs we prove here that if a boolean function f admits a representation by a matched cnf then every clause minimum cnf representation of f is matched 





a  gerevini a  saetti and m  vallati 2014 planning through automatic portfolio configuration the pbp approach volume 50 pages 639696



in the field of domainindependent planning several powerful planners implementing different techniques have been developed however no one of these systems outperforms all others in every known benchmark domain in this work we propose a multiplanner approach that automatically configures a portfolio of planning techniques for each given domain the configuration process for a given domain uses a set of training instances to i compute and analyze some alternative sets of macroactions for each planner in the portfolio identifying a possibly empty useful set ii select a cluster of planners each one with the identified useful set of macroactions that is expected to perform best and iii derive some additional information for configuring the execution scheduling of the selected planners at planning time the resulting planning system called pbp portfolio based planner has two variants focusing on speed and plan quality different versions of pbp entered and won the learning track of the sixth and seventh international planning competitions in this paper we experimentally analyze pbp considering planning speed and plan quality in depth we provide a collection of results that help to understand pbps behavior and demonstrate the effectiveness of our approach to configuring a portfolio of planners with macroactions









l  miclet s  bayoudh and a  delhay 2008 analogical dissimilarity definition algorithms and two experiments in machine learning volume 32 pages 793824

