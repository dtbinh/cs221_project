a  e howe and  e  dahlman 2002 a critical assessment of benchmark comparison in planning volume 17 pages 133

recent trends in planning research have led to empirical     comparison becoming commonplace the field has started to settle into    a methodology for such comparisons which for obvious practical    reasons requires running a subset of planners on a subset of    problems  in this paper we characterize the methodology and    examine eight implicit assumptions about the problems planners and    metrics used in many of these comparisons the problem assumptions    are pr1 the performance of a general purpose planner should not be    penalizedbiased if executed on a sampling of problems and domains    pr2 minor syntactic differences in representation do not affect    performance and pr3 problems should be solvable by strips capable    planners unless they require adl the planner assumptions are pl1    the latest version of a planner is the best one to use pl2 default    parameter settings approximate good performance and pl3 time    cutoffs do not unduly bias outcome the metrics assumptions are    m1 performance degrades similarly for each planner when run on    degraded runtime environments eg machine platform and m2 the    number of plan steps distinguishes performance we find that most of    these assumptions are not supported empirically in particular that    planners are affected differently by these assumptions we conclude    with a call to the community to devote research resources to    improving the state of the practice and especially to enhancing the    available benchmark problems

