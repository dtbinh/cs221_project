h  h bui  s  venkatesh and  g  west 2002 policy recognition in the abstract hidden markov model volume 17 pages 451499

in this paper we present a method for recognising an    agents behaviour in dynamic noisy uncertain domains and across    multiple levels of abstraction  we term this problem online plan    recognition under uncertainty and view it generally as probabilistic    inference on the stochastic process representing the execution of the    agents plan our contributions in this paper are twofold  in terms    of probabilistic inference we introduce the abstract hidden markov    model ahmm a novel type of stochastic processes provide its    dynamic bayesian network dbn structure and analyse the properties of    this network  we then describe an application of the    raoblackwellised particle filter to the ahmm which allows us to    construct an efficient hybrid inference method for this model  in    terms of plan recognition we propose a novel plan recognition    framework based on the ahmm as the plan execution model  the    raoblackwellised hybrid inference for ahmm can take advantage of the    independence properties inherent in a model of plan execution leading    to an algorithm for online probabilistic plan recognition that scales    well with the number of levels in the plan hierarchy  this    illustrates that while stochastic models for plan execution can be    complex they exhibit special structures which if exploited can lead    to efficient plan recognition algorithms  we demonstrate the    usefulness of the ahmm framework via a behaviour recognition system in    a complex spatial environment using distributed video surveillance    data

