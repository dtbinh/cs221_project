n  v chawla  k  w bowyer  l  o hall and  w  p kegelmeyer 2002 smote synthetic minority oversampling technique volume 16 pages 321357

an approach to the construction of classifiers from    imbalanced datasets is described a dataset is imbalanced if the    classification categories are not approximately equally    represented often realworld data sets are predominately composed of    normal examples with only a small percentage of abnormal or    interesting examples it is also the case that the cost of    misclassifying an abnormal interesting example as a normal example    is often much higher than the cost of the reverse    error undersampling of the majority normal class has been proposed    as a good means of increasing the sensitivity of a classifier to the    minority class this paper shows that a combination of our method of    oversampling the minority abnormal class and undersampling the    majority normal class can achieve better classifier performance in    roc space than only undersampling the majority class  this paper    also shows that a combination of our method of oversampling the    minority class and undersampling the majority class can achieve    better classifier performance in roc space than varying the loss    ratios in ripper or class priors in naive bayes our method of    oversampling the minority class involves creating synthetic minority    class examples  experiments are performed using c45 ripper and a    naive bayes classifier the method is evaluated using the area under    the receiver operating characteristic curve auc and the roc convex    hull strategy

