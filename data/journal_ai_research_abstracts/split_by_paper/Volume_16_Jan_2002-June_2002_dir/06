x  xu  h  he and  d  hu 2002 efficient reinforcement learning using recursive leastsquares methods volume 16 pages 259292

the recursive leastsquares rls algorithm is one of the    most wellknown algorithms used in adaptive filtering system    identification and adaptive control its popularity is mainly due to    its fast convergence speed which is considered to be optimal in    practice in this paper rls methods are used to solve reinforcement    learning problems where two new reinforcement learning algorithms    using linear value function approximators are proposed and    analyzed the two algorithms are called rlstdlambda and fastahc    fast adaptive heuristic critic respectively rlstdlambda can be    viewed as the extension of rlstd0 from lambda0 to general lambda    within interval 01 so it is a multistep temporaldifference td    learning algorithm using rls methods the convergence with probability    one and the limit of convergence of rlstdlambda are proved for    ergodic markov chains compared to the existing lstdlambda    algorithm rlstdlambda has advantages in computation and is more    suitable for online learning the effectiveness of rlstdlambda is    analyzed and verified by learning prediction experiments of markov    chains with a wide range of parameter settings        the fastahc algorithm is derived by applying the proposed    rlstdlambda algorithm in the critic network of the adaptive    heuristic critic method unlike conventional ahc algorithm fastahc    makes use of rls methods to improve the learningprediction efficiency    in the critic learning control experiments of the cartpole balancing    and the acrobot swingup problems are conducted to compare the data    efficiency of fastahc with conventional ahc from the experimental    results it is shown that the data efficiency of learning control can    also be improved by using rls methods in the learningprediction    process of the critic the performance of fastahc is also compared    with that of the ahc method using lstdlambda furthermore it is    demonstrated in the experiments that different initial values of the    variance matrix in rlstdlambda are required to get better    performance not only in learning prediction but also in learning    control the experimental results are analyzed based on the existing    theoretical work on the transient phase of forgetting factor rls    methods

