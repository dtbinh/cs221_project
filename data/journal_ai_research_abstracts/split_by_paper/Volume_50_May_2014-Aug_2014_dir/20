uai 2013 best student paper

credal networks are graphbased statistical models whose parameters take values in a set instead of being sharply specified as in traditional statistical models eg bayesian networks the computational complexity of inferences on such models depends on the irrelevanceindependence concept adopted in this paper we study inferential complexity under the concepts of epistemic irrelevance and strong independence we show that inferences under strong independence are nphard even in trees with binary variables except for a single ternary one we prove that under epistemic irrelevance the polynomialtime complexity of inferences in credal trees is not likely to extend to more general models eg singly connected topologies these results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard and settle several open questions regarding their computational complexity we show that these results remain valid even if we disallow the use of zero probabilities we also show that the computation of bounds on the probability of the future state in a hidden markov model is the same whether we assume epistemic irrelevance or strong independence and we prove a similar result for inference in naive bayes structures these inferential equivalences are important for practitioners as hidden markov models and naive bayes structures are used in real applications of imprecise probability

