j  hoffmann s  edelkamp s  thiebaux r  englert f  liporace and s  trueg 2006 engineering benchmarks for planning the domains used in the  deterministic part of ipc4 volume 26 pages 453541





2007 ijcaijair best paper prize



this paper addresses the problem of planning under uncertainty in large markov decision processes mdps factored mdps represent a complex state space using state variables and the transition model using a dynamic bayesian network this representation often allows an exponential reduction in the representation size of structured mdps but the complexity of exact solution algorithms for such mdps can grow exponentially in the representation size  in this paper we present two approximate solution algorithms that exploit structure in factored mdps  both use an approximate value function represented as a linear combination of basis functions where each basis function involves only a small subset of the domain variables  a key contribution of this paper is that it shows how the basic operations of both algorithms can be performed efficiently in closed form by exploiting both additive and contextspecific structure in a factored mdp  a central element of our algorithms is a novel linear program decomposition technique analogous to variable elimination in bayesian networks which reduces an exponentially large lp to a provably equivalent polynomialsized one  one algorithm uses approximate linear programming and the second approximate dynamic programming our dynamic programming algorithm is novel in that it uses an approximation based on maxnorm a technique that more directly minimizes the terms that appear in error bounds for approximate mdp algorithms  we provide experimental results on problems with over 1040 states demonstrating a promising indication of the scalability of our approach and compare our algorithm to an existing stateoftheart approach showing in some problems exponential gains in computation time



it is well known that utterances convey a great deal of information about the speaker in addition to their semantic content  one such type of information consists of cues to the speakers personality traits the most fundamental dimension of variation between humans  recent work explores the automatic detection of other types of pragmatic variation in text and conversation such as emotion deception speaker charisma dominance point of view subjectivity opinion and sentiment personality affects these other aspects of linguistic production and thus personality recognition may be useful for these tasks in addition to many other potential applications  however to date there is little work on the automatic recognition of personality traits  this article reports experimental results for recognition of all big five personality traits in both conversation and text utilising both self and observer ratings of personality  while other work reports classification results we experiment with classification regression and ranking models for each model we analyse the effect of different feature sets on accuracy results show that for some traits any type of statistical model performs significantly better than the baseline but ranking models perform best overall we also present an experiment suggesting that ranking models are more accurate than multiclass classifiers for modelling personality in addition recognition models trained on observed personality perform better than models trained using selfreports and the optimal feature set depends on the personality trait a qualitative analysis of the learned models confirms previous findings linking language and personality while revealing many new linguistic markers









g  barish and  c  a knoblock 2005 an expressive language and efficient execution system for software agents volume 23 pages 625666



software agents can be used to automate many of the tedious timeconsuming information processing tasks that humans currently have to complete manually  however to do so agent plans must be capable of representing the myriad of actions and control flows required to perform those tasks  in addition since these tasks can require integrating multiple sources of remote information  typically a slow iobound process  it is desirable to make execution as efficient as possible  to address both of these needs we present a flexible software agent plan language and a highly parallel execution system that enable the efficient execution of expressive agent plans the plan language allows complex tasks to be more easily expressed by providing a variety of operators for flexibly processing the data as well as supporting subplans for modularity and recursion for indeterminate looping  the executor is based on a streaming dataflow model of execution to maximize the amount of operator and data parallelism possible at runtime  we have implemented both the language and executor in a system called theseus  our results from testing theseus show that streaming dataflow execution can yield significant speedups over both traditional serial von neumann as well as nonstreaming dataflowstyle execution that existing software and robot agent execution systems currently support  in addition we show how plans written in the language we present can represent certain types of subtasks that cannot be accomplished using the languages supported by network query engines  finally we demonstrate that the increased expressivity of our plan language does not hamper performance specifically we show how data can be integrated from multiple remote sources just as efficiently using our architecture as is possible with a stateoftheart streamingdataflow network query engine





r  begleiter  r  elyaniv and  g  yona 2004 on prediction using variable order markov models volume 22 pages 385421



this paper is concerned with algorithms for prediction of discrete sequences over a finite alphabet using variable order markov models the class of such algorithms is large and in principle includes any lossless compression algorithm we focus on six prominent prediction algorithms including context tree weighting ctw prediction by partial match ppm and probabilistic suffix trees psts we discuss the properties of these algorithms and compare their performance using real life sequences from three domains proteins english text and music pieces the comparison is made with respect to prediction quality as measured by the average logloss we also compare classification algorithms based on these predictors with respect to a number of large protein classification tasks our results indicate that a decomposed ctw a variant of the ctw algorithm and ppm outperform all other algorithms in sequence prediction tasks somewhat surprisingly a different algorithm which is a modification of the lempelziv compression algorithm significantly outperforms all algorithms on the protein classification problems







y  zhang and r  h c yap 2006 set intersection and consistency in constraint networks volume 27 pages 441464





q  b vo and  n  y foo 2005 reasoning about action an argumentation  theoretic approach volume 24 pages 465518



we present a uniform nonmonotonic solution to the problems of reasoning about action on the basis of an argumentationtheoretic approach our theory is provably correct relative to a sensible minimisation policy introduced on top of a temporal propositional logic sophisticated problem domains can be formalised in our framework  as much attention of researchers in the field has been paid to the traditional and basic problems in reasoning about actions such as the frame the qualification and the ramification problems approaches to these problems within our formalisation lie at heart of the expositions presented in this paper





a  borgida 1999 extensible knowledge representation the case of description reasoners volume 10 pages 399434



this paper offers an approach to extensible knowledge    representation and reasoning for a family of formalisms known as    description logics the approach is based on the notion of adding new    concept constructors and includes a heuristic methodology for    specifying the desired extensions as well as a modularized software    architecture that supports implementing extensions  the architecture    detailed here falls in the normalizecompared paradigm and supports    both intentional reasoning subsumption involving concepts and    extensional reasoning involving individuals after incremental updates    to the knowledge base      the resulting approach can be used to extend the reasoner with    specialized notions that are motivated by specific problems or    application areas such as reasoning about dates plans etc in    addition it provides an opportunity to implement constructors that    are not currently yet sufficiently well understood theoretically but    are needed in practice also for constructors that are provably hard    to reason with eg ones whose presence would lead to    undecidability it allows the implementation of incomplete reasoners    where the incompleteness is tailored to be acceptable for the    application at hand



thomas  eiter michael  fink and daria  stepanova 2016 computing repairs of inconsistent dlprograms over el ontologies volume 56 pages 463515



description logic dl ontologies and nonmonotonic rules are two prominent knowledge representation kr formalisms with complementary features that are essential for various applications nonmonotonic description logic dl programs combine these formalisms thus providing support for rulebased reasoning on top of dl ontologies using a welldefined query interface represented by socalled dlatoms unfortunately interaction of the rules and the ontology may incur inconsistencies such that a dlprogram lacks answer sets ie models and thus yields no information this issue is addressed by recently defined repair answer sets for computing which an effective practical algorithm was proposed for dllite a ontologies that reduces a repair computation to constraint matching based on socalled support sets however the algorithm exploits particular features of dllite a and can not be readily applied to repairing dlprograms over other prominent dls like el compared to dllite a  in el support sets may neither be small nor only few support sets might exist and completeness of the algorithm may need to be given up when the support information is bounded we thus provide an approach for computing repairs for dlprograms over el ontologies based on partial incomplete support families the latter are constructed using datalog query rewriting techniques as well as ontology approximation based on logical difference between elterminologies we show how the maximal size and number of support sets for a given dlatom can be estimated by analyzing the properties of a support hypergraph which characterizes a relevant set of tbox axioms needed for query derivation we present a declarative implementation of the repair approach and experimentally evaluate it on a set of benchmark problems the promising results witness practical feasibility of our repair approach 









m  alviano f  calimeri w  faber n  leone and s  perri 2011 unfounded sets and wellfounded semantics of answer set programs with aggregates  volume 42 pages 487527



r  mateescu r  dechter and r  marinescu 2008 andor multivalued decision diagrams aomdds for graphical models volume 33 pages 465519



inspired by the recently introduced framework of andor search spaces for graphical models we propose to augment multivalued decision diagrams mdd with and nodes in order to capture function decomposition structure and to extend these compiled data structures to general weighted graphical models eg probabilistic models we present the andor multivalued decision diagram aomdd which compiles a graphical model into a canonical form that supports polynomial eg solution counting belief updating or constant time eg equivalence of graphical models queries we provide two algorithms for compiling the aomdd of a graphical model the first is searchbased and works by applying reduction rules to the trace of the memory intensive andor search algorithm the second is inferencebased and uses a bucket elimination schedule to combine the aomdds of the input functions via the the apply operator for both algorithms the compilation time and the size of the aomdd are in the worst case exponential in the treewidth of the graphical model rather than pathwidth as is known for ordered binary decision diagrams obdds we introduce the concept of semantic treewidth which helps explain why the size of a decision diagram is often much smaller than the worst case bound we provide an experimental evaluation that demonstrates the potential of aomdds





e  keyder and h  geffner 2009 soft goals can be compiled away volume 36 pages 547556



soft goals extend the classical model of planning with a simple model of preferences the best plans are then not the ones with least cost but the ones with maximum utility where the utility of a plan is the sum of the utilities of the soft goals achieved minus the plan cost finding plans with high utility appears to involve two linked problems choosing a subset of soft goals to achieve and finding a lowcost plan to achieve them  new search algorithms and heuristics have been developed for planning with soft goals and a new track has been introduced in the international planning competition ipc to test their performance in this note we show however that these extensions are not needed soft goals do not increase the expressive power of the basic model of planning with action costs as they can easily be compiled away we apply this compilation to the problems of the netbenefit track of the most recent ipc and show that optimal and satisficing costbased planners do better on the compiled problems than optimal and satisficing netbenefit planners on the original problems with explicit soft goals furthermore we show that penalties or negative preferences expressing conditions to avoid can also be compiled away using a similar idea



we investigate two systems of fully proportional representation suggested by chamberlin courant and monroe both systems assign a representative to each voter so that the sum of misrepresentations is  minimized the winner determination problem for both systems is known to be nphard hence this work aims at investigating whether there are variants of the proposed rules andor specific electorates for which these problems can be solved efficiently as a variation of these rules instead of minimizing the sum of misrepresentations we considered minimizing the maximal misrepresentation introducing effectively two new rules in the general case  these minimax versions of classical rules appeared to be still nphard  









raffaella  bernardi ruket  cakici desmond  elliott aykut  erdem erkut  erdem nazli  ikizlercinbis frank  keller adrian  muscat and barbara  plank 2016 automatic description generation from images a survey of models datasets and evaluation measures volume 55 pages 409442



automatic description generation from natural images is a challenging problem that has recently received a large amount of interest from the computer vision and natural language processing communities in this survey we classify the existing approaches based on how they conceptualize this problem viz models that cast description as either generation problem or as a retrieval problem over a visual or multimodal representational space we provide a detailed review of existing models highlighting their advantages and disadvantages moreover we give an overview of the benchmark image datasets and the evaluation measures that have been developed to assess the quality of machinegenerated image descriptions finally we extrapolate future directions in the area of automatic image description generation



although manipulation and bribery have been extensively studied under weighted voting there has been almost no work done on election control under weighted voting this is unfortunate since weighted voting appears in many important natural settings in this paper we study the complexity of controlling the outcome of weighted elections through adding and deleting voters we obtain polynomialtime algorithms npcompleteness results and for many npcomplete cases approximation algorithms in particular for scoring rules we completely characterize the complexity of weighted voter control our work shows that for quite a few important cases either polynomialtime exact algorithms or polynomialtime approximation algorithms exist









y  gao and j  culberson 2007 consistency and random constraint satisfaction models volume 28 pages 517557



in this paper we study the possibility of designing nontrivial random csp models by exploiting the intrinsic connection between structures and typicalcase hardness we show that constraint consistency a notion that has been developed to improve  the efficiency of csp algorithms is in fact the key to the design of random csp models that have interesting phase transition behavior and guaranteed exponential resolution complexity without putting much restriction on the parameter of constraint tightness or the domain size of the problem  we propose a very flexible framework for constructing problem instances withinteresting behavior and develop a variety of concrete methods to construct specific  random csp models that enforce different levels of constraint consistency 

a series of experimental studies with interesting observations are carried out to illustrate the effectiveness of introducing structural elements in random instances to verify the robustness of our proposal and to investigate features of some specific models based on our framework that are highly related to the behavior of backtracking search algorithms      







v  ruiz de angulo and c  torras 2009 exploiting singlecycle symmetries in continuous constraint problems volume 34 pages 499520









in recent years stackelberg security games have been successfully applied to solve resource allocation and scheduling problems in several security domains however previous work has mostly assumed that the targets are stationary relative to the defender and the attacker leading to discrete game models with finite numbers of pure strategies this paper in contrast focuses on protecting mobile targets that leads to a continuous set of strategies for the players the problem is motivated by several realworld domains including protecting ferries with escort boats and protecting refugee supply lines our contributions include i a new game model for multiple mobile defender resources and moving targets with a discretized strategy space for the defender and a continuous strategy space for the attacker ii an efficient linearprogrammingbased solution that uses a compact representation for the defenders mixed strategy while accurately modeling the attackers continuous strategy using a novel subinterval analysis method iii discussion and analysis of multiple heuristic methods for equilibrium refinement to improve robustness of defenders mixed strategy iv discussion of approaches to sample actual defender schedules from the defenders mixed strategy iv detailed experimental analysis of our algorithms in the ferry protection domain







markov decision processes capture sequential decision making under uncertainty where an agent must choose actions so as to optimize long term reward  the paper studies efficient reasoning mechanisms for relational markov decision processes rmdp where world states have an internal relational structure that can be naturally described in terms of objects and relations among them  two contributions are presented  first the paper develops first order decision diagrams fodd a new compact representation for functions over relational structures together with a set of operators to combine fodds and novel reduction techniques to keep the representation small  second the paper shows how fodds can be used to develop solutions for rmdps where reasoning is performed at the abstract level and the resulting optimal policy is independent of domain size number of objects or instantiation  in particular a variant of the value iteration algorithm is developed by using special operations over fodds and the algorithm is shown to converge to the optimal policy







compared to conventional cars electric vehicles evs still suffer from considerably shorter cruising ranges combined with the sparsity of battery loading stations the complete transition to emobility still seems a long way to go in this paper we consider the problem of placing as few loading stations as possible so that on any shortest path there are sufficiently many not to run out of energy we show how to model this problem and introduce heuristics which provide closetooptimal solutions even in large road networks







f  s225nchezmart237nez r  c carrasco m  a mart237nezprieto and j  adiego 2012 generalized biwords for bitext compression and translation spotting volume 43 pages 389418



large bilingual parallel texts also known as bitexts are usually stored in a compressed form and previous work has shown that they can be more efficiently compressed if the fact that the two texts are mutual translations is exploited for example a bitext can be seen as a sequence of biwords pairs of parallel words with a high probability of cooccurrence that can be used as an intermediate representation in the compression process  however the simple biword approach described in the literature can only exploit onetoone word alignments and cannot tackle the reordering of words we therefore introduce a generalization of biwords which can describe multiword expressions and reorderings  we also describe some methods for the binary compression of generalized biword sequences and compare their performance when different schemes are applied to the extraction of the biword sequence in addition we show that this generalization of biwords allows for the implementation of an efficient algorithm to look on the compressed bitext for words or text segments in one of the texts and retrieve their counterpart translations in the other text an application usually referred to as translation spotting with only some minor modifications in the compression algorithm









a  krause and e  horvitz 2010 a utilitytheoretic approach to privacy in online services volume 39 pages 633662



geographical location is vital to geospatial applications like local search and event detection in this paper we investigate and improve on the task of textbased geolocation prediction of twitter users previous studies on this topic have typically assumed that geographical references eg gazetteer terms dialectal words in a text are indicative of its authors location however these references are often buried in informal ungrammatical and multilingual data and are therefore nontrivial to identify and exploit we present an integrated geolocation prediction framework and investigate what factors impact on prediction accuracy first we evaluate a range of feature selection methods to obtain location indicative words we then evaluate the impact of nongeotagged tweets language and userdeclared metadata on geolocation prediction in addition we evaluate the impact of temporal variance on model generalisation and discuss how users differ in terms of their geolocatability

we achieve stateoftheart results for the textbased twitter user geolocation task and also provide the most extensive exploration of the task to date our findings provide valuable insights into the design of robust practical textbased geolocation prediction systems









h  ls younes and  r  g simmons 2003 vhpop versatile heuristic partial order planner volume 20 pages 405430



vhpop is a partial order causal link pocl planner loosely based on ucpop  it draws from the experience gained in the early to mid 1990s on flaw selection strategies for pocl planning and combines this with more recent developments in the field of domain independent planning such as distance based heuristics and reachability analysis  we present an adaptation of the additive heuristic for plan space planning and modify it to account for possible reuse of existing actions in a plan  we also propose a large set of novel flaw selection strategies and show how these can help us solve more problems than previously possible by pocl planners  vhpop also supports planning with durative actions by incorporating standard techniques for temporal constraint reasoning  we demonstrate that the same heuristic techniques used to boost the performance of classical pocl planning can be effective in domains with durative actions as well  the result is a versatile heuristic pocl planner competitive with established cspbased and heuristic state space planners





p  gorniak and  d  roy 2004 grounded semantic composition for visual scenes volume 21 pages 429470



we present a visuallygrounded language understanding model based on a study of how people verbally describe objects in scenes the emphasis of the model is on the combination of individual word meanings to produce meanings for complex referring expressions the model has been implemented and it is able to understand a broad range of spatial referring expressions we describe our implementation of word level visuallygrounded semantics and their embedding in a compositional parsing framework the implemented system selects the correct referents in response to natural language expressions for a large percentage of test cases in an analysis of the systems successes and failures we reveal how visual context influences the semantics of utterances and propose future extensions to the model that take such context into account





j  de bruijn and s  heymans 2010 logical foundations of rdfs with datatypes  volume 38 pages 535568



the resource description framework rdf is a semantic web standard that provides a data language simply called rdf as well as a lightweight ontology language called rdf schema we investigate embeddings of rdf in logic and show how standard logic programming and description logic technology can be used for reasoning with rdf we subsequently consider extensions of rdf with datatype support considering d entailment defined in the rdf semantics specification and d entailment a semantic weakening of d entailment introduced by ter horst we use the embeddings and properties of the logics to establish novel upper bounds for the complexity of deciding entailment we subsequently establish two novel lower bounds establishing that rdfs entailment is ptimecomplete and that simpled entailment is conphard when considering arbitrary datatypes both in the size of the entailing graph the results indicate that rdfs may not be as lightweight as one may expect





r  jurca and b  faltings 2007 obtaining reliable feedback for sanctioning reputation mechanisms volume 29 pages 391419



reputation mechanisms offer an effective alternative to verification authorities for building trust in electronic markets with moral hazard future clients guide their business decisions by considering the feedback from past transactions if truthfully exposed cheating behavior is sanctioned and thus becomes irrational

it therefore becomes important to ensure that rational clients have the right incentives to report honestly as an alternative to sidepayment schemes that explicitly reward truthful reports we show that honesty can emerge as a rational behavior when clients have a repeated presence in the market to this end we describe a mechanism that supports an equilibrium where truthful feedback is obtained then we characterize the set of paretooptimal equilibria of the mechanism and derive an upper bound on the percentage of false reports that can be recorded by the mechanism an important role in the existence of this bound is played by the fact that rational clients can establish a reputation for reporting honestly



this paper presents a modelbased planner called the probabilistic sulu planner  or the psulu planner which controls stochastic systems in a goal directed manner within userspecified risk bounds the objective of the psulu planner is to allow users to command continuous stochastic systems such as unmanned aerial and space vehicles in a manner that is both intuitive and safe to this end we first develop a new plan representation called a chanceconstrained qualitative state plan ccqsp through which users can specify the desired evolution of the plant state as well as the acceptable level of risk an example of a ccqsp statement is go to a through b within 30 minutes with less than 0001 probability of failure  we then develop the psulu planner which can tractably solve a ccqsp planning problem in order to enable ccqsp planning we develop the following two capabilities in this paper 1 risksensitive planning with risk bounds and 2 goaldirected planning in a continuous domain with temporal constraints the first capability is to ensures that the probability of failure is bounded the second capability is essential for the planner to solve problems with a continuous state space such as vehicle path planning we demonstrate the capabilities of the psulu planner by simulations on two realworld scenarios the path planning and scheduling of a personal aerial vehicle as well as the space rendezvous of an autonomous cargo spacecraft 









a  krause and c  guestrin 2009 optimal value of information in graphical models volume 35 pages 557591





haris  aziz markus   brill felix   fischer paul   harrenstein jerome  lang and hans georg  seedig 2015 possible and necessary winners of partial tournaments volume 54 pages 493534



we study the problem of computing possible and necessary winners for partially specified weighted and unweighted tournaments this problem arises naturally in elections with incompletely specified votes partially completed sports competitions and more generally in any scenario where the outcome of some pairwise comparisons is not yet fully known we specifically consider a number of wellknown solution conceptsincluding the uncovered set borda ranked pairs and maximinand show that for most of them possible and necessary winners can be identified in polynomial time these positive algorithmic results stand in sharp contrast to earlier results concerning possible and necessary winners given partially specified preference profiles







k  kersting l  de raedt and t  raiko 2006 logical hidden markov models volume 25 pages 425456



logical hidden markov models lohmms upgrade traditional hidden markov models to deal with sequences of structured symbols in the form of logical atoms rather than flat characters

this note formally introduces lohmms and presents solutions to the three central inference problems for lohmms evaluation most likely hidden state sequence and parameter estimation the resulting representation and algorithms are experimentally evaluated on problems from the domain of bioinformatics





j  y halpern 1999 coxs theorem revisited volume 11 pages 429435



the assumptions needed to prove coxs theorem are discussed    and examined  various sets of assumptions under which a coxstyle    theorem can be proved are provided although all are rather strong    and arguably not natural





p  david 1995 using pivot consistency to decompose and solve functional csps volume 2 pages 447474



many studies have been carried out in order to increase thesearch efficiency of constraint satisfaction problems among themsome make use of i structural i properties of the constraintnetwork others take into account i semantic i properties of theconstraints generally assuming that i all i the constraints possessthe given property  in this paper we propose a new decompositionmethod benefiting from both semantic properties of i functional iconstraints not i bijective i constraints and structuralproperties of the network furthermore not all the constraints needto be functional  we show that under some conditions the existenceof solutions can be guaranteed  we first characterize a particularsubset of the variables which we name a i root seti   we thenintroduce i pivot consistency i a new local consistency which is aweak form of path consistency and can be achieved in on2d2complexity instead of on3d3 for path consistency and wepresent associated properties in particular we show that anyconsistent instantiation of the root set can be linearly extended to a solution which leads to the presentation of the aforementioned new method for solving by decomposing functional csps





h  h bui  s  venkatesh and  g  west 2002 policy recognition in the abstract hidden markov model volume 17 pages 451499



in this paper we present a method for recognising an    agents behaviour in dynamic noisy uncertain domains and across    multiple levels of abstraction  we term this problem online plan    recognition under uncertainty and view it generally as probabilistic    inference on the stochastic process representing the execution of the    agents plan our contributions in this paper are twofold  in terms    of probabilistic inference we introduce the abstract hidden markov    model ahmm a novel type of stochastic processes provide its    dynamic bayesian network dbn structure and analyse the properties of    this network  we then describe an application of the    raoblackwellised particle filter to the ahmm which allows us to    construct an efficient hybrid inference method for this model  in    terms of plan recognition we propose a novel plan recognition    framework based on the ahmm as the plan execution model  the    raoblackwellised hybrid inference for ahmm can take advantage of the    independence properties inherent in a model of plan execution leading    to an algorithm for online probabilistic plan recognition that scales    well with the number of levels in the plan hierarchy  this    illustrates that while stochastic models for plan execution can be    complex they exhibit special structures which if exploited can lead    to efficient plan recognition algorithms  we demonstrate the    usefulness of the ahmm framework via a behaviour recognition system in    a complex spatial environment using distributed video surveillance    data



we present a case study of artificial intelligence techniques applied to the control of production printing equipment  like many other realworld applications this complex domain requires highspeed autonomous decisionmaking and robust continual operation  to our knowledge this work represents the first successful industrial application of embedded domainindependent temporal planning  our system handles execution failures and multiobjective preferences  at its heart is an online algorithm that combines techniques from statespace planning and partialorder scheduling  we suggest that this general architecture may prove useful in other applications as more intelligent systems operate in continual online settings  our system has been used to drive several commercial prototypes and has enabled a new product architecture for our industrial partner  when compared with stateoftheart offline planners our system is hundreds of times faster and often finds better plans  our experience demonstrates that domainindependent ai planning based on heuristic search can flexibly handle time resources replanning and multiple objectives in a highspeed practical application without requiring handcoded control knowledge









d  heckerman and  r  shachter 1995 decisiontheoretic foundations for causal reasoning volume 3 pages 405430



we present a definition of cause and effect in terms of    decisiontheoretic primitives and thereby provide a principled    foundation for causal reasoning  our definition departs from the    traditional view of causation in that causal assertions may vary with    the set of decisions available  we argue that this approach provides    added clarity to the notion of cause  also in this paper we examine    the encoding of causal relationships in directed acyclic graphs  we    describe a special class of influence diagrams those in canonical    form and show its relationship to pearls representation of cause and    effect  finally we show how canonical form facilitates    counterfactual reasoning





b  de wilde a  w ter mors and c  witteveen 2014 push and rotate a complete multiagent pathfinding algorithm volume 51 pages 443492



multiagent pathfinding is a relevant problem in a wide range of domains for example in robotics and video games research formally the problem considers a graph consisting of vertices and edges and a set of agents occupying vertices an agent can only move to an unoccupied neighbouring vertex and the problem of finding the minimal sequence of moves to transfer each agent from its start location to its destination is an nphard problem

in our experiments we compare our approach with the push and swap mapp and bibox algorithms the latter algorithm is restricted to a smaller class of instances as it requires biconnected graphs but can nevertheless be considered state of the art due to its strong performance our experiments show that push and swap suffers from incompleteness mapp is generally not competitive with push and rotate and bibox is better than push and rotate on randomly generated biconnected instances while push and rotate performs better on grids





m  cooper f  maris and p  r233gnier 2014 monotone temporal planning tractability extensions and applications volume 50 pages 447485



this paper describes a polynomiallysolvable class of temporal planning problems polynomiality follows from two assumptions firstly by supposing that each subgoal fluent can be established by at most one action we can quickly determine which actions are necessary in any plan secondly the monotonicity of subgoal fluents allows us to express planning as an instance of stp8800 simple temporal problem with difference constraints this class includes temporallyexpressive problems requiring the concurrent execution of actions with potential applications in the chemical pharmaceutical and construction industries 

we also show that any temporal planning problem has a monotone relaxation which can lead to the polynomialtime detection of its unsolvability in certain cases indeed we show that our relaxation is orthogonal to relaxations based on the ignoredeletes approach used in classical planning since it preserves deletes and can also exploit temporal information



we consider the problem of allocating fairly a set of indivisible goods among agents from the point of view of compact representation and computational complexity we start by assuming that agents have dichotomous preferences expressed by propositional formulae we express efficiency and envyfreeness in a logical setting which reveals unexpected connections to nonmonotonic reasoning then we identify the complexity of determining whether there exists an efficient and envyfree allocation for several notions of efficiency when preferences are represented in a succinct way as well as restrictions of this problem we first study the problem under the assumption that preferences are dichotomous and then in the general case









j  gratch and  s  chien 1996 adaptive problemsolving for largescale scheduling problems a case study volume 4 pages 365396



although most scheduling problems are nphard domain    specific techniques perform well in practice but are quite expensive    to construct  in adaptive problemsolving solving domain specific    knowledge is acquired automatically for a general problem solver with    a flexible control architecture  in this approach a learning system    explores a space of possible heuristic methods for one wellsuited to    the eccentricities of the given domain and problem distribution  in    this article we discuss an application of the approach to scheduling    satellite communications  using problem distributions based on actual    mission requirements our approach identifies strategies that not only    decrease the amount of cpu time required to produce schedules but    also increase the percentage of problems that are solvable within    computational resource limitations



local search algorithms applied to optimization problems often suffer from getting trapped in a local optimum the common solution for this deficiency is to restart the algorithm when no progress is observed alternatively one can start multiple instances of a local search algorithm and allocate computational resources in particular processing time to the instances depending on their behavior hence a multistart strategy has to decide dynamically when to allocate additional resources to a particular instance and when to start new instances in this paper we propose multistart strategies motivated by works on multiarmed bandit problems and lipschitz optimization with an unknown constant the strategies continuously estimate the potential performance of each algorithm instance by supposing a convergence rate of the local search algorithm up to an unknown constant and in every phase allocate resources to those instances that could converge to the optimum for a particular range of the constant asymptotic bounds are given on the performance of the strategies in particular we prove that at most a quadratic increase in the number of times the target function is evaluated is needed to achieve the performance of a local search algorithm started from the attraction region of the optimum experiments are provided using spsa simultaneous perturbation stochastic approximation and kmeans as local search algorithms and the results indicate that the proposed strategies work well in practice and in all cases studied need only logarithmically more evaluations of the target function as opposed to the theoretically suggested quadratic increase









j  y halpern 2001 conditional plausibility measures and bayesian networks volume 14 pages 359389



a general notion of algebraic conditional plausibility    measures is defined  probability measures ranking functions    possibility measures and under the appropriate definitions sets of    probability measures can all be viewed as defining algebraic    conditional plausibility measures it is shown that algebraic    conditional plausibility measures can be represented using bayesian    networks



the minimisation problem of a sum of unary and pairwise functions of discrete variables is a general nphard problem with wide applications such as computing map configurations in markov random fields mrf minimising gibbs energy or solving binary valued constraint satisfaction problems vcsps

furthermore we introduce a class of problems with convex cardinality functions on crossfree sets of assignments we prove that while imposing only one of the two conditions renders the problem nphard the conjunction of the two gives rise to a novel tractable class satisfying the crossfree convexity property which generalises the jointwinner property to problems of unbounded arity











j  hoffmann s  edelkamp s  thiebaux r  englert f  liporace and s  trueg 2006 engineering benchmarks for planning the domains used in the  deterministic part of ipc4 volume 26 pages 453541

