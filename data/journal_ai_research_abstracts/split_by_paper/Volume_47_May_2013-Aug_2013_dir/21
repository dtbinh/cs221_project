m  hodosh p  young and j  hockenmaier 2013 framing image description as a ranking task data models and evaluation metrics volume 47 pages 853899

the ability to associate images with natural language sentences that describe what is depicted in them is a hallmark of image understanding and a prerequisite for applications such as sentencebased image search in analogy to image search we propose to frame sentencebased image annotation as the task of ranking a given pool of captions we introduce a new benchmark collection for sentencebased image description and search consisting of 8000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events we introduce a number of systems that perform quite well on this task even though they are only based on features that can be obtained with minimal supervision our results clearly indicate the importance of training on multiple captions per image and of capturing syntactic word orderbased and semantic features of these captions we also perform an indepth comparison of human and automatic evaluation metrics for this task and propose strategies for collecting human judgments cheaply and on a very large scale allowing us to augment our collection with additional relevance judgments of which captions describe which image our analysis shows that metrics that consider the ranked list of results for each query image or sentence are significantly more robust than metrics that are based on a single response per query moreover our study suggests that the evaluation of rankingbased image description systems may be fully automated

