honorable mention for the 2014 ijcaijair best paper prize

this paper introduces a principled approach for the design of a scalable general reinforcement learning agent our approach is based on a direct approximation of aixi a bayesian optimality notion for general reinforcement learning agents previously it has been unclear whether the theory of aixi could motivate the design of practical algorithms we answer this hitherto open question in the affirmative by providing the first computationally feasible approximation to the aixi agent to develop our approximation we introduce a new montecarlo tree search algorithm along with an agentspecific extension to the context tree weighting algorithm empirically we present a set of encouraging results on a variety of stochastic and partially observable domains we conclude by proposing a number of directions for future research

