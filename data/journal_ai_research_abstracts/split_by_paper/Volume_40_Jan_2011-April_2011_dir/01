m  milani fard and j  pineau 2011 nondeterministic policies in markovian decision processes volume 40 pages 124

markovian processes have long been used to model stochastic environments reinforcement learning has emerged as a framework to solve sequential planning and decisionmaking problems in such environments in recent years attempts were made to apply methods from reinforcement learning to construct decision support systems for action selection in markovian environments although conventional methods in reinforcement learning have proved to be useful in problems concerning sequential decisionmaking they cannot be applied in their current form to decision support systems such as those in medical domains as they suggest policies that are often highly prescriptive and leave little room for the users input without the ability to provide flexible guidelines it is unlikely that these methods can gain ground with users of such systems

this paper introduces the new concept of nondeterministic policies to allow more flexibility in the users decisionmaking process while constraining decisions to remain near optimal solutions we provide two algorithms to compute nondeterministic policies in discrete domains we study the output and running time of these method on a set of synthetic and realworld problems in an experiment with human subjects we show that humans assisted by hints based on nondeterministic policies outperform both humanonly and computeronly agents in a web navigation task

