d  opitz and  r  maclin 1999 popular ensemble methods an empirical study volume 11 pages 169198

an ensemble consists of a set of individually trained    classifiers such as neural networks or decision trees whose    predictions are combined when classifying novel instances  previous    research has shown that an ensemble is often more accurate than any of    the single classifiers in the ensemble  bagging breiman 1996c and    boosting freund  shapire 1996 shapire 1990 are two relatively    new but popular methods for producing ensembles  in this paper we    evaluate these methods on 23 data sets using both neural networks and    decision trees as our classification algorithm  our results clearly    indicate a number of conclusions  first while bagging is almost    always more accurate than a single classifier it is sometimes much    less accurate than boosting  on the other hand boosting can create    ensembles that are less accurate than a single classifier     especially when using neural networks  analysis indicates that the    performance of the boosting methods is dependent on the    characteristics of the data set being examined  in fact further    results show that boosting ensembles may overfit noisy data sets thus    decreasing its performance  finally consistent with previous    studies our work suggests that most of the gain in an ensembles    performance comes in the first few classifiers combined however    relatively large gains can be seen up to 25 classifiers when boosting    decision trees

