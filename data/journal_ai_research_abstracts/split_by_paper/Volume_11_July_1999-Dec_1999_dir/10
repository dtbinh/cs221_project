s  argamonengelson and  i  dagan 1999 committeebased sample selection for probabilistic classifiers volume 11 pages 335360

in many realworld learning tasks it is expensive to    acquire a sufficient number of labeled examples for training  this    paper investigates methods for reducing annotation cost by sample    selection in this approach during training the learning program    examines many unlabeled examples and selects for labeling only those    that are most informative at each stage this avoids redundantly    labeling examples that contribute little new information       our work follows on previous research on query by committee extending    the committeebased paradigm to the context of probabilistic    classification  we describe a family of empirical methods for    committeebased sample selection in probabilistic classification    models which evaluate the informativeness of an example by measuring    the degree of disagreement between several model variants  these    variants the committee are drawn randomly from a probability    distribution conditioned by the training set labeled so far       the method was applied to the realworld natural language processing    task of stochastic partofspeech tagging  we find that all variants    of the method achieve a significant reduction in annotation cost    although their computational efficiency differs  in particular the    simplest variant a two member committee with no parameters to tune    gives excellent results  we also show that sample selection yields a    significant reduction in the size of the model used by the tagger

