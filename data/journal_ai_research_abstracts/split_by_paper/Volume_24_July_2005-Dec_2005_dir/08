v  bayerzubek and  t  g dietterich 2005 integrating learning from examples into the search for diagnostic policies volume 24 pages 263303

this paper studies the problem of learning diagnostic policies from training examples a diagnostic policy is a complete description of the decisionmaking actions of a diagnostician ie tests followed by a diagnostic decision for all possible combinations of test results  an optimal diagnostic policy is one that minimizes the expected total cost which is the sum of measurement costs and misdiagnosis costs  in most diagnostic settings there is a tradeoff between these two kinds of costs  this paper formalizes diagnostic decision making as a markov decision process mdp the paper introduces a new family of systematic search algorithms based on the ao algorithm to solve this mdp  to make ao efficient the paper describes an admissible heuristic that enables ao to prune large parts of the search space  the paper also introduces several greedy algorithms including some improvements over previouslypublished methods the paper then addresses the question of learning diagnostic policies from examples  when the probabilities of diseases and test results are computed from training data there is a great danger of overfitting to reduce overfitting regularizers are integrated into the search algorithms  finally the paper compares the proposed methods on five benchmark diagnostic data sets  the studies show that in most cases the systematic search methods produce better diagnostic policies than the greedy methods in addition the studies show that for training sets of realistic size the systematic search algorithms are practical on todays desktop computers

