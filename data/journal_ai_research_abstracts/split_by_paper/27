in this paper we explore a class of belief update operators in which the definition of the operator is compositional with respect to the sentence to be added the goal is to provide an update operator that is intuitive in that its definition is based on a recursive decomposition of the update sentences structure and that may be reasonably implemented  in addressing update we first provide a definition phrased in terms of the models of a knowledge base  while this operator satisfies a core group of the benchmark katsunomendelzon update postulates not all of the postulates are satisfied  other katsunomendelzon postulates can be obtained by suitably restricting the syntactic form of the sentence for update as we show  in restricting the syntactic form of the sentence for update we also obtain a hierarchy of update operators with winsletts standard semantics as the most basic interesting approach captured  we subsequently give an algorithm which captures this approach in the general case the algorithm is exponential but with some notunreasonable assumptions we obtain an algorithm that is linear in the size of the knowledge base  hence the resulting approach has much better complexity characteristics than other operators in some situations  we also explore other compositional belief change operators erasure is developed as a dual operator to update we show that a forget operator is definable in terms of update and we give a definition of the compositional revision operator  we obtain that compositional revision under the most natural definition yields the satoh revision operator









p  a bonatti m  faella and l  sauro 2011 defeasible inclusions in lowcomplexity dls volume 42 pages 719764



some of the applications of owl and rdf eg biomedical knowledge representation and semantic policy formulation call for extensions of these languages with nonmonotonic constructs such as inheritance with overriding  nonmonotonic description logics have been studied for many years however no practical such knowledge representation languages exist due to a combination of semantic difficulties and high computational complexity independently lowcomplexity description logics such as dllite and el have been introduced and incorporated in the owl standard  therefore it is interesting to see whether the syntactic restrictions characterizing dllite and el bring computational benefits to their nonmonotonic versions too in this paper we extensively investigate the computational complexity of circumscription when knowledge bases are formulated in dlliter el and fragments thereof  we identify fragments whose complexity ranges from p to the second level of the polynomial hierarchy as well as fragments whose complexity raises to pspace and beyond





answering conjunctive queries cqs over a set of facts extended with existential rules is a prominent problem in knowledge representation and databases this problem can be solved using the chase algorithm which extends the given set of facts with fresh facts in order to satisfy the rules if the chase terminates then cqs can be evaluated directly in the resulting set of facts the chase however does not terminate necessarily and checking whether the chase terminates on a given set of rules and facts is undecidable numerous acyclicity notions were proposed as sufficient conditions for chase termination in this paper we present two new acyclicity notions called modelfaithful acyclicity mfa and modelsummarising acyclicity msa furthermore we investigate the landscape of the known acyclicity notions and establish a complete taxonomy of all notions known to us finally we show that mfa and msa generalise most of these notions







this article discusses the quadratization of markov logic networks which enables efficient approximate map computation by means of maximum flows the procedure relies on a pseudoboolean representation of the model and allows handling models of any order the employed pseudoboolean representation can be used to identify problems that are guaranteed to be solvable in low polynomialtime results on common benchmark problems show that the proposed approach finds optimal assignments for most variables in excellent computational time and approximate solutions that match the quality of ilpbased solvers







a  singh a  krause c  guestrin and w  j kaiser 2009 efficient informative sensing using multiple robots volume 34 pages 707755



the need for efficient monitoring of spatiotemporal dynamics in large environmental applications such as the water quality monitoring in rivers and lakes motivates the use of robotic sensors in order to achieve sufficient spatial coverage typically these robots have bounded resources such as limited battery or limited amounts of time to obtain measurements thus careful coordination of their paths is required in order to maximize the amount of information collected while respecting the resource constraints in this paper we present an efficient approach for nearoptimally solving the nphard optimization problem of planning such informative paths in particular we first develop esip efficient singlerobot informative path planning an approximation algorithm for optimizing the path of a single robot hereby we use a gaussian process to model the underlying phenomenon and use the mutual information between the visited locations and remainder of the space to quantify the amount of information collected we prove that the mutual information collected using paths obtained by using esip is close to the information obtained by an optimal solution we then provide a general technique sequential allocation which can be used to extend any single robot planning algorithm such as esip for the multirobot problem this procedure approximately generalizes any guarantees for the singlerobot problem to the multirobot case we extensively evaluate the effectiveness of our approach on several experiments performed infield for two important environmental sensing applications lake and river monitoring and simulation experiments performed using several real world sensor network data sets













a  guez d  silver and p  dayan 2013 scalable and efficient bayesadaptive reinforcement learning based on montecarlo tree search volume 48 pages 841883



bayesian planning is a formally elegant approach to learning optimal behaviour under model uncertainty trading off exploration and exploitation in an ideal way unfortunately planning optimally in the face of uncertainty is notoriously taxing since the search space is enormous in this paper we introduce a tractable samplebased method for approximate bayesoptimal planning which exploits montecarlo tree search our approach avoids expensive applications of bayes rule within the search tree by sampling models from current beliefs and furthermore performs this sampling in a lazy manner this enables it to outperform previous bayesian modelbased reinforcement learning algorithms by a significant margin on several wellknown benchmark problems  as we show our approach can even work in problems with an infinite state space that lie qualitatively out of reach of almost all previous work in bayesian exploration



traffic congestion in urban road networks is a costly problem that affects all major cities in developed countries to tackle this problem it is possible i to act on the supply side increasing the number of roads or lanes in a network ii to reduce the demand restricting the access to urban areas at specific hours or to specific vehicles or iii to improve the efficiency of the existing network by means of a widespread use of socalled intelligent transportation systems its in line with the recent advances in smart transportation management infrastructures its has turned out to be a promising field of application for artificial intelligence techniques in particular multiagent systems seem to be the ideal candidates for the design and implementation of its in fact drivers can be naturally modelled as autonomous agents that interact with the transportation management infrastructure thereby generating a largescale open agentbased system to regulate such a system and maintain a smooth and efficient flow of traffic decentralised mechanisms for the management of the transportation infrastructure are needed

in this article we propose a distributed marketinspired mechanism for the management of a future urban road network where intelligent autonomous vehicles operated by software agents on behalf of their human owners interact with the infrastructure in order to travel safely and efficiently through the road network building on the reservationbased intersection control model proposed by dresner and stone we consider two different scenarios one with a single intersection and one with a network of intersections in the former we analyse the performance of a novel policy based on combinatorial auctions for the allocation of reservations in the latter we analyse the impact that a traffic assignment strategy inspired by competitive markets has on the drivers route choices finally we propose an adaptive management mechanism that integrates the auctionbased traffic control policy with the competitive traffic assignment strategy







s  w carden 2014 convergence of a qlearning variant for continuous states and actions volume 49 pages 705731



this paper presents a reinforcement learning algorithm for solving infinite horizon markov decision processes under the expected total discounted reward criterion when both the state and action spaces are continuous  this algorithm is based on watkins qlearning but uses nadarayawatson kernel smoothing to generalize knowledge to unvisited states  as expected continuity conditions must be imposed on the mean rewards and transition probabilities  using results from kernel regression theory this algorithm is proven capable of producing a qvalue function estimate that is uniformly within an arbitrary tolerance of the true qvalue function with probability one  the algorithm is then applied to an example problem to empirically show convergence as well 





as fragments of firstorder logic description logics dls do not provide nonmonotonic features such as defeasible inheritance and default rules since many applications would benefit from the availability of such features several families of nonmonotonic dls have been developed that are mostly based on default logic and autoepistemic logic in this paper we consider circumscription as an interesting alternative approach to nonmonotonic dls that in particular supports defeasible inheritance in a natural way we study dls extended with circumscription under different language restrictions and under different constraints on the sets of minimized fixed and varying predicates and pinpoint the exact computational complexity of reasoning for dls ranging from alc to alcio and alcqo  when the minimized and fixed predicates include only concept names but no role names then reasoning is complete for nexptimenp  it becomes complete for npnexptime when the number of minimized and fixed predicates is bounded by a constant  if roles can be minimized or fixed then complexity ranges from nexptimenp to undecidability







a  cimatti a  griggio and r  sebastiani 2011 computing small unsatisfiable cores in satisfiability modulo theories volume 40 pages 701728



the problem of finding small unsatisfiable cores for sat formulas has  recently received a lot of interest mostly for its applications in formal verification  however propositional logic is often not expressive  enough for representing many interesting verification problems which can be more naturally addressed in the framework of satisfiability modulo theories smt  surprisingly the problem of finding unsatisfiable cores in smt has received very little attention in the literature

we have evaluated our algorithm with a very extensive empirical test on smtlib benchmarks which confirms the validity and potential of this approach 





owl 2 el is a popular ontology language that supports role inclusionsthat is axioms that capture compositional properties of roles role inclusions closely correspond to contextfree grammars which was used to show that answering conjunctive queries cqs over owl 2 el knowledge bases with unrestricted role inclusions is undecidable however owl 2 el inherits from owl 2 dl the syntactic regularity restriction on role inclusions which ensures that role chains implying a particular role can be described using a finite automaton fa this is sufficient to ensure decidability of cq answering however the fas can be worstcase exponential in size so the known approaches do not provide a tight upper complexity bound

in this paper we solve this open problem and show that answering cqs over owl 2 el knowledge bases is pspacecomplete in combined complexity ie the complexity measured in the total size of the input to this end we use a novel encoding of regular role inclusions using boundedstack pushdown automatathat is fas extended with a stack of bounded size apart from theoretical interest our encoding can be used in practical tableau algorithms to avoid the exponential blowup due to role inclusions in addition we sharpen the lower complexity bound and show that the problem is pspacehard even if we consider only role inclusions as part of the input ie the query and all other parts of the knowledge base are fixed finally we turn our attention to navigational queries over owl 2 el knowledge bases and we show that answering positive conversefree conjunctive graph xpath queries is pspacecomplete as well this is interesting since allowing the converse operator in queries is known to make the problem exptimehard thus in this paper we present several important contributions to the landscape of the complexity of answering expressive queries over description logic knowledge bases







credal networks are graphbased statistical models whose parameters take values in a set instead of being sharply specified as in traditional statistical models eg bayesian networks the computational complexity of inferences on such models depends on the irrelevanceindependence concept adopted in this paper we study inferential complexity under the concepts of epistemic irrelevance and strong independence we show that inferences under strong independence are nphard even in trees with binary variables except for a single ternary one we prove that under epistemic irrelevance the polynomialtime complexity of inferences in credal trees is not likely to extend to more general models eg singly connected topologies these results clearly distinguish networks that admit efficient inferences and those where inferences are most likely hard and settle several open questions regarding their computational complexity we show that these results remain valid even if we disallow the use of zero probabilities we also show that the computation of bounds on the probability of the future state in a hidden markov model is the same whether we assume epistemic irrelevance or strong independence and we prove a similar result for inference in naive bayes structures these inferential equivalences are important for practitioners as hidden markov models and naive bayes structures are used in real applications of imprecise probability









j  delgrande y  jin and f  j pelletier 2008 compositional belief update volume 32 pages 757791



in this paper we explore a class of belief update operators in which the definition of the operator is compositional with respect to the sentence to be added the goal is to provide an update operator that is intuitive in that its definition is based on a recursive decomposition of the update sentences structure and that may be reasonably implemented  in addressing update we first provide a definition phrased in terms of the models of a knowledge base  while this operator satisfies a core group of the benchmark katsunomendelzon update postulates not all of the postulates are satisfied  other katsunomendelzon postulates can be obtained by suitably restricting the syntactic form of the sentence for update as we show  in restricting the syntactic form of the sentence for update we also obtain a hierarchy of update operators with winsletts standard semantics as the most basic interesting approach captured  we subsequently give an algorithm which captures this approach in the general case the algorithm is exponential but with some notunreasonable assumptions we obtain an algorithm that is linear in the size of the knowledge base  hence the resulting approach has much better complexity characteristics than other operators in some situations  we also explore other compositional belief change operators erasure is developed as a dual operator to update we show that a forget operator is definable in terms of update and we give a definition of the compositional revision operator  we obtain that compositional revision under the most natural definition yields the satoh revision operator

