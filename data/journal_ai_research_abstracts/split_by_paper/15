resolution is the rule of inference at the basis of most procedures for automated reasoning in these procedures the input formula is first translated into an equisatisfiable formula in conjunctive normal form cnf and then represented as a set of clauses deduction starts by inferring new clauses by resolution and goes on until the empty clause is generated or satisfiability of the set of clauses is proven eg because no new clauses can be generated







r  e wray and  j  e laird 2003 an architectural approach to ensuring consistency in hierarchical execution volume 19 pages 355398



j  bell 2007 natural events volume 30 pages 361412



this paper develops an inductive theory of predictive common sense reasoning the theory  provides the basis for an integrated solution to the three traditional problems of reasoning about change  the frame qualification and ramification problems the theory is also capable of representing nondeterministic events and it provides a means for stating defeasible preferences over the outcomes of conflicting simultaneous events 









y  engel and m  p wellman 2010 multiattribute auctions based on generalized additive independence volume 37 pages 479525







t  zimmerman and  s  kambhampati 2005 using memory to transform search on the planning graph volume 23 pages 533585







honorable mention for the 2008 ijcaijair best paper prize





s  s fatima m  j wooldridge and n  r jennings 2006 multiissue negotiation with deadlines volume 27 pages 381417



this paper studies bilateral multiissue negotiation between selfinterested autonomous agents now there are a number of different procedures that can be used for this process the three main ones being the package deal procedure in which all the issues are bundled and discussed together the simultaneous procedure in which the issues are discussed simultaneously but independently of each other and the sequential procedure in which the issues are discussed one after another since each of them yields a different outcome a key problem is to decide which one to use in which circumstances specifically we consider this question for a model in which the agents have time constraints in the form of both deadlines and discount factors and information uncertainty in that the agents do not know the opponents utility function for this model we consider issues that are both independent and those that are interdependent and determine equilibria for each case for each procedure in so doing we show that the package deal is in fact the optimal procedure for each party we then go on to show that although the package deal may be computationally more complex than the other two procedures it generates pareto optimal outcomes unlike the other two it has similar earliest and latest possible times of agreement to the simultaneous procedure which is better than the sequential procedure and that it like the other two procedures generates a unique outcome only under certain conditions which we define 







2008 ijcaijair best paper prize







e  reiter  s  g sripada and  r  robertson 2003 acquiring correct knowledge for natural language generation volume 18 pages 491516







d  e joslin and  d  p clements 1999 squeaky wheel optimization volume 10 pages 353373



xiaowang  zhang jan  van den bussche and fran231ois  picalausa 2016 on the satisfiability problem for sparql patterns volume 56 pages 403428



the satisfiability problem for sparql 10 patterns is undecidable in general since the relational algebra can be emulated using such patterns the goal of this paper is to delineate the boundary of decidability of satisfiability in terms of the constraints allowed in filter conditions the classes of constraints considered are boundconstraints negated bound constraints equalities nonequalities constantequalities and constantnonequalities the main result of the paper can be summarized by saying that as soon as inconsistent filter conditions can be formed satisfiability is undecidable the key insight in each case is to find a way to emulate the set difference operation undecidability can then be obtained from a known undecidability result for the algebra of binary relations with union composition and set difference when no inconsistent filter conditions can be formed satisfiability is decidable by syntactic checks on bound variables and on the use of literals although the problem is shown to be npcomplete it is experimentally shown that the checks can be implemented efficiently in practice the paper also points out that satisfiability for the socalled lsquowelldesignedrsquo  patterns can be decided by a check on bound variables and a check for inconsistent filter conditions





we consider how an agent should update her beliefs when her beliefs are represented by a set p of probability distributions given that the agent makes decisions using the minimax criterion perhaps the beststudied and most commonlyused criterion in the literature we adopt a gametheoretic framework where the agent plays against a bookie who chooses some distribution from p we consider two reasonable games that differ in what the bookie knows when he makes his choice anomalies that have been observed before like time inconsistency can be understood as arising because different games are being played against bookies with different information we characterize the important special cases in which the optimal decision rules according to the minimax criterion amount to either conditioning or simply ignoring the information finally we consider the relationship between updating and calibration when uncertainty is described by sets of probabilities our results emphasize the key role of the rectangularity condition of epstein and schneider







j  goldsmith j  lang m  truszczynski and n  wilson 2008 the computational complexity of dominance and consistency in cpnets volume 33 pages 403432



we investigate the computational complexity of testing dominance and consistency in cpnets previously the complexity of dominance has been determined for restricted classes in which the dependency graph of the  cpnet is acyclic however there are preferences of interest that define cyclic dependency graphs these are modeled with general cpnets in our main results we show here that both dominance and consistency for general cpnets are pspacecomplete we then consider the concept of strong dominance dominance equivalence and dominance incomparability and several notions of optimality and identify the complexity of the corresponding decision problems the reductions used in the proofs are from strips planning and thus reinforce the earlier established connections between both areas









j  rintanen 1998 complexity of prioritized default logics volume 9 pages 423461







c  meek 2001 finding a path is harder than finding a tree volume 15 pages 383389





a  jonsson 2009 the role of macros in tractable planning volume 36 pages 471511



this paper presents several new tractability results for planning based on macros we describe an algorithm that optimally solves planning problems in a class that we call inverted tree reducible and is provably tractable for several subclasses of this class by using macros to store partial plans that recur frequently in the solution the algorithm is polynomial in time and space even for exponentially long plans we generalize the inverted tree reducible class in several ways and describe modifications of the algorithm to deal with these new classes theoretical results are validated in experiments







j  koehler and  j  hoffmann 2000 on reasonable and forced goal orderings and their use in an agendadriven planning algorithm volume 12 pages 338386



n  taghipour d  fierens j  davis and h  blockeel 2013 lifted variable elimination decoupling the operators from the constraint language volume 47 pages 393439



lifted probabilistic inference algorithms exploit regularities in the structure of graphical models to perform inference more efficiently more specifically they identify groups of interchangeable variables and perform inference once per group as opposed to once per variable the groups are defined by means of constraints so the flexibility of the grouping is determined by the expressivity of the constraint language existing approaches for exact lifted inference use specific languages for inequality constraints which often have limited expressivity in this article we decouple lifted inference from the constraint language we define operators for lifted inference in terms of relational algebra operators so that they operate on the semantic level the constraints extension rather than on the syntactic level making them languageindependent as a result lifted inference can be performed using more powerful constraint languages which provide more opportunities for lifting we empirically demonstrate that this can improve inference efficiency by orders of magnitude allowing exact inference where until now only approximate inference was feasible









aron  culotta nirmal  kumar ravi and jennifer  cutler 2016 predicting twitter user demographics using distant supervision from website traffic data volume 55 pages 389408



athirai  a irissappane and jie   zhang 2015 a casebased reasoning framework to choose trust models for different emarketplace environments volume 52 pages 477505



the performance of trust models highly depend on the characteristics of the environments where they are applied thus it becomes challenging to choose a suitable trust model for a given emarketplace environment especially when ground truth about the agent buyer and seller behavior is unknown called unknown environment we propose a casebased reasoning framework to choose suitable trust models for unknown environments based on the intuition that if a trust model performs well in one environment it will do so in another similar environment firstly we build a case base with a number of simulated environments with known ground truth along with the trust models most suitable for each of them given an unknown environment casebased retrieval algorithms retrieve the most similar cases and the trust model of the most similar cases is chosen as the most suitable model for the unknown environment evaluation results confirm the effectiveness of our framework in choosing suitable trust models for different emarketplace environments









f  lin and y  chen 2007 discovering classes of strongly equivalent logic programs volume 28 pages 431451



inference in bayes nets bayes is an important problem with numerous applications in probabilistic reasoning counting the number of satisfying assignments of a propositional formula sat is a closely related problem of fundamental theoretical importance both these problems and others are members of the class of sumofproducts sumprod problems in this paper we show that standard backtracking search when augmented with a simple memoization scheme caching can solve any sumofproducts problem with time complexity that is at least as good any other stateoftheart exact algorithm and that it can also achieve the best known timespace tradeoff furthermore backtrackings ability to utilize more flexible variable orderings allows us to prove that it can achieve an exponential speedup over other standard algorithms for sumprod on some instances

the ideas presented here have been utilized in a number of solvers that have been applied to various types of sumofproduct problems these systems have exploited the fact that backtracking can naturally exploit more of the problems structure to achieve improved performance on a range of probleminstances empirical evidence of this performance gain has appeared in published works describing these solvers and we provide references to these works











i  ab237o r  nieuwenhuis a  oliveras e  rodr237guezcarbonell and v  mayereichberger 2012 a new look at bdds for pseudoboolean constraints volume 45 pages 443480



in classical agmstyle belief change it is assumed that the underlying logic contains classical propositional logic this is clearly a limiting assumption particularly in artificial intelligence consequently there has been recent interest in studying belief change in approaches where the full expressivity of classical propositional logic is not obtained in this paper we investigate belief contraction in horn knowledge bases we point out that the obvious extension to the horn case involving horn remainder sets as a starting point is problematic not only do horn remainder sets have undesirable properties but also some desirable horn contraction functions are not captured by this approach for horn belief set contraction we develop an account in terms of a modeltheoretic characterisation involving weak remainder sets maxichoice and partial meet horn contraction is specified and we show that the problems arising with earlier work are resolved by these approaches as well constructions of the specific operators and sets of postulates are provided and representation results are obtained we also examine horn package contraction or contraction by a set of formulas again we give a construction and postulate set linking them via a representation result last we investigate the closelyrelated notion of forgetting in horn clauses this work is arguably interesting since horn clauses have found widespread use in ai as well the results given here may potentially be extended to other areas which make use of hornlike reasoning such as logic programming rulebased systems and description logics finally since horn reasoning is weaker than classical reasoning this work sheds light on the foundations of belief change







j  eisenstein r  barzilay and r  davis 2008 gesture salience as a hidden variable for coreference resolution and keyframe extraction volume 31 pages 353398



gesture is a nonverbal modality that can contribute crucial information to the understanding of natural language but not all gestures are informative and noncommunicative hand motions may confuse natural language processing nlp and impede learning people have little diffculty ignoring irrelevant hand movements and focusing on meaningful gestures suggesting that an automatic system could also be trained to perform this task  however the informativeness of a gesture is contextdependent and labeling enough data to cover all cases would be expensive we present conditional modality fusion a conditional hiddenvariable model that learns to predict which gestures are salient for coreference resolution the task of determining whether two noun phrases refer to the same semantic entity moreover our approach uses only coreference annotations and not annotations of gesture salience itself we show that gesture features improve performance on coreference resolution and that by attending only to gestures that are salient our method achieves further significant gains in addition we show that the model of gesture salience learned in the context of coreference accords with human intuition by demonstrating that gestures judged to be salient by our model can be used successfully to create multimedia keyframe summaries of video these summaries are similar to those created by human raters and significantly outperform summaries produced by baselines from the literature





we introduce a new notion of systematicity for satisfiability algorithms with restarts saying that an algorithm is strongly systematic if it is systematic independent of restart policy but weakly systematic if it is systematic for some restart policies but not others  we show that existing satisfiability engines are generally only weakly systematic and describe flex a strongly systematic algorithm that uses an amount of memory polynomial in the size of the problem  on large number factoring problems flex appears to outperform weakly systematic approaches











h  kaindl and  g  kainz 1997 bidirectional heuristic search reconsidered volume 7 pages 283317





l  r planken m  m de weerdt and r  pj van der krogt 2012 computing allpairs shortest paths by leveraging low treewidth volume 43 pages 353388





because reinforcement learning suffers from a lack of scalability online value and q function approximation has received increasing interest this last decade this contribution introduces a novel approximation scheme namely the kalman temporal differences ktd framework that exhibits the following features sampleefficiency nonlinear approximation nonstationarity handling and uncertainty management a first ktdbased algorithm is provided for deterministic markov decision processes mdp which produces biased estimates in the case of stochastic transitions than the extended ktd framework xktd solving stochastic mdp is described convergence is analyzed for special cases for both deterministic and stochastic transitions related algorithms are experimented on classical benchmarks they compare favorably to the state of the art while exhibiting the announced features







v  belle and g  lakemeyer 2014 multiagent only knowing in dynamic systems volume 49 pages 363402



	the idea of only knowing a collection of sentences as proposed by levesque has been previously shown to be very useful in characterizing knowledgebased agents in terms of a specification a precise and perspicuous account of the beliefs and nonbeliefs is obtained in a monotonic setting levesques logic is based on a firstorder modal language with quantifyingin thus allowing for de re versus de dicto distinctions among other things however the logic and its recent dynamic extension  only deal with the case of a single agent in this work we propose a firstorder multiagent framework with knowledge actions sensing and only knowing that is shown to inherit all  the features of the single agent version most significantly we prove reduction theorems by means of which reasoning about knowledge and actions in the framework simplifies to nonepistemic nondynamic reasoning about the initial situation 









j  kvarnstr246m and  m  magnusson 2003 talplanner in ipc2002  extensions and control rules volume 20 pages 343377







b  hnich  b  m smith and  t  walsh 2004 dual modelling of permutation and injection problems volume 21 pages 357391







p  a ortega and d  a braun 2010 a minimum relative entropy principle for learning and acting volume 38 pages 475511







h  m pasula l  s zettlemoyer and l  p kaelbling 2007 learning symbolic models of stochastic domains volume 29 pages 309352



this paper presents a structured power and energyflowbased qualitative modelling approach that is applicable to a variety of system types including electrical and fluid flow the modelling is split into two parts

the novel aspects of the work are an order of magnitudeom qualitative network analyser to represent any power domain and topology including multiple power sources a feature that was not required for earlier specialised electrical versions of the approach secondly the representation of generalised energy related behaviour as statebased local models is presented as a modelling strategy that can be more vivid and intuitive for a range of topologically complex applications than qualitative equationbased representationsthe twolevel modelling strategy allows the broad system behaviour coverage of qualitative simulation to be exploited for the fmea task while limiting the difficulties of qualitative ambiguity explanation that can arise from abstracted numerical models we have used the method to support an automated fmea system with examples of an aircraft fuel system and domestic a heating system discussed in this paper











p  faliszewski e  hemaspaandra and l  a hemaspaandra 2009 how hard is bribery in elections volume 35 pages 485532



igor  rochlin and david  sarne 2015 constraining information sharing to improve cooperative information gathering volume 54 pages 437469



this paper considers the problem of cooperation between selfinterested agents in acquiring better information regarding the nature of the different options and opportunities available to them by sharing individual findings with others the agents can potentially achieve a substantial improvement in overall and individual expected benefits  unfortunately it is well known that with selfinterested agents equilibrium considerations often dictate solutions that are far from the fully cooperative ones hence the agents do not manage to fully exploit the potential benefits encapsulated in such cooperation  in this paper we introduce analyze and demonstrate the benefit of five methods aiming to improve cooperative information gathering  common to all five that they constrain and limit the information sharing process  nevertheless the decrease in benefit due to the limited sharing is outweighed by the resulting substantial improvement in the equilibrium individual information gathering strategies the equilibrium analysis given in the paper which in itself is an important contribution to the study of cooperation between selfinterested agents enables demonstrating that for a wide range of settings an improved individual expected benefit is achieved for all agents when applying each of the five methods







g  gutnik and g  a kaminka 2006 representing conversations for scalable overhearing volume 25 pages 349387



open distributed multiagent systems are gaining interest in the academic community and in industry in such open settings agents are often coordinated using standardized agent conversation protocols the representation of such protocols for analysis validation monitoring etc is an important aspect of multiagent applications recently petri nets have been shown to be an interesting approach to such representation and radically different approaches using petri nets have been proposed however their relative strengths and weaknesses have not been examined moreover their scalability and suitability for different tasks have not been addressed this paper addresses both these challenges first we analyze existing petri net representations in terms of their scalability and appropriateness for overhearing an important task in monitoring open multiagent systems then building on the insights gained we introduce a novel representation using colored petri nets that explicitly represent legal joint conversation states and messages this representation approach offers significant improvements in scalability and is particularly suitable for overhearing furthermore we show that this new representation offers a comprehensive coverage of all conversation features of fipa conversation standards we also present a procedure for transforming auml conversation protocol diagrams a standard humanreadable representation to our colored petri net representation 







a  borgida and  p  f patelschneider 1994 a semantics and complete algorithm for subsumption in the classic description logic volume 1 pages 277308







d  fox  w  burgard and  s  thrun 1999 markov localization for mobile robots in dynamic environments volume 11 pages 391427







p  d turney 1995 costsensitive classification empirical evaluation of a hybrid    genetic decision tree induction algorithm volume 2 pages 369409







a  alani and  m  deriche 2002 a new technique for combining multiple classifiers using the dempstershafer theory of evidence volume 17 pages 333361



 we offer a new understanding of some aspects of practical satsolvers that are based on dpll with unitclause propagation clauselearning and restarts we do so by analyzing a concrete algorithm which we claim is faithful to what practical solvers do in particular before making any new decision or restart the solver repeatedly applies the unitresolution rule until saturation and leaves no component to the mercy of nondeterminism except for some internal randomness we prove the perhaps surprising fact that although the solver is not explicitly designed for it with high probability it ends up behaving as widthk resolution after no more than on2k2 conflicts and restarts where n is the number of variables in other words widthk resolution can be thought of as on2k2 restarts of the unitresolution rule with learning











m  buro 1995 statistical feature combination for the evaluation of game positions volume 3 pages 373382





a  metodi r  stern m  kalech and m  codish 2014 a novel satbased approach to model based diagnosis volume 51 pages 377411



this paper introduces a novel encoding of model based diagnosis mbd to boolean satisfaction sat focusing on minimal cardinality diagnosis the encoding is based on a combination of sophisticated mbd preprocessing algorithms and the application of a sat compiler which optimizes the encoding to provide more succinct cnf representations than obtained with previous works experimental evidence indicates that our approach is superior to all published algorithms for minimal cardinality mbd in particular we can determine for the first time minimal cardinality diagnoses for the entire standard iscas85 and 74xxx benchmarks our results open the way to improve the stateoftheart on a range of similar mbd problems







aaai 2013 outstanding paper award



b  c csaji and l  monostori 2008 adaptive stochastic resource control a machine learning approach volume 32 pages 453486



the paper investigates stochastic resource allocation problems with scarce reusable resources and nonpreemtive timedependent interconnected tasks this approach is a natural generalization of several standard resource management problems such as scheduling and transportation problems first reactive solutions are considered and defined as control policies of suitably reformulated markov decision processes mdps we argue that this reformulation has several favorable properties such as it has finite state and action spaces it is aperiodic hence all policies are proper and the space of control policies can be safely restricted next approximate dynamic programming adp methods such as fitted qlearning are suggested for computing an efficient control policy in order to compactly maintain the costtogo function two representations are studied hash tables and support vector regression svr particularly nusvrs several additional improvements such as the application of limitedlookahead rollout algorithms in the initial phases action space decomposition task clustering and distributed sampling are investigated too finally experimental results on both benchmark and industryrelated data are presented









l  pryor and  g  collins 1996 planning for contingencies a decisionbased approach volume 4 pages 287339



exploiting information induced from queryspecific clustering of topretrieved documents has long been proposed as a means for improving precision at the very top ranks of the returned results we present a novel language model approach to ranking queryspecific clusters by the presumed percentage of relevant documents that they contain while most previous cluster ranking approaches focus on the cluster as a whole our model utilizes also information induced from documents associated with the cluster our model substantially outperforms previous approaches for identifying clusters containing a high relevantdocument percentage furthermore using the model to produce document ranking yields precisionattopranks performance that is consistently better than that of the initial ranking upon which clustering is performed the performance also favorably compares with that of a stateoftheart pseudofeedbackbased retrieval method











m  l ginsberg 2001 gib imperfect information in a computationally challenging game volume 14 pages 303358



j  velez g  hemann a  s huang i  posner and n  roy 2012 modelling observation correlations for active exploration and robust object detection  volume 44 pages 423453









e  giunchiglia m  narizzano and a  tacchella 2006 clauseterm resolution and learning in the evaluation of quantified boolean formulas volume 26 pages 371416



resolution is the rule of inference at the basis of most procedures for automated reasoning in these procedures the input formula is first translated into an equisatisfiable formula in conjunctive normal form cnf and then represented as a set of clauses deduction starts by inferring new clauses by resolution and goes on until the empty clause is generated or satisfiability of the set of clauses is proven eg because no new clauses can be generated

