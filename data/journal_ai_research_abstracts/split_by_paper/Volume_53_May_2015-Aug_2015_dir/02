krishna  s r dubba anthony  g cohn david  c hogg mehul   bhatt and frank  dylla 2015 learning relational event models from video volume 53 pages 4190

event models obtained automatically from video can be used in applications ranging from abnormal event detection to content based video retrieval when multiple agents are involved in the events characterizing events naturally suggests encoding interactions as relations learning event models from this kind of relational spatiotemporal data using relational learning techniques such as inductive logic programming ilp hold promise but have not been successfully applied to very large datasets which result from video data in this paper we present a novel framework remind relational event model induction for supervised relational learning of event models from large video datasets using ilp efficiency is achieved through the learning from interpretations setting and using a typing system that exploits the type hierarchy of objects in a domain the use of types also helps prevent over generalization furthermore we also present a typerefining operator and prove that it is optimal the learned models can be used for recognizing events from previously unseen videos we also present an extension to the framework by integrating an abduction step that improves the learning performance when there is noise in the input data the experimental results on several hours of video data from two challenging real world domains an airport domain and a physical action verbs domain suggest that the techniques are suitable to real world scenarios

