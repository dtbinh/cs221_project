







p  d grunwald and  j  y halpern 2003 updating probabilities volume 19 pages 243278



a  mccallum x  wang and a  corradaemmanuel 2007 topic and role discovery in social networks with experiments on enron and academic email volume 30 pages 249272



previous work in social network analysis sna has modeled the existence of links from one entity to another but not the attributes such as language content or topics on those links we present the authorrecipienttopic art model for social network analysis which learns topic distributions based on the directionsensitive messages sent between entities the model builds on latent dirichlet allocation lda and the authortopic at model adding the key attribute that distribution over topics is conditioned distinctly on both the sender and recipientsteering the discovery of topics according to the relationships between people we give results on both the enron email corpus and a researchers email archive providing evidence not only that clearly relevant topics are discovered but that the art model better predicts peoples roles and gives lower perplexity on previously unseen messages we also present the roleauthorrecipienttopic rart model an extension to art that explicitly represents peoples roles









r  aras and a  dutech 2010 an investigation into mathematical programming for finite horizon decentralized pomdps volume 37 pages 329396







r  nair and  m  tambe 2005 hybrid bdipomdp framework for multiagent teaming volume 23 pages 367420







a  felner  r  e korf and  s  hanan 2004 additive pattern database heuristics volume 22 pages 279318





m  fox and d  long 2006 modelling mixed discretecontinuous domains for planning volume 27 pages 235297



in this paper we present pddl a planning domain description language for modelling mixed discretecontinuous planning domains we describe the syntax and modelling style of pddl showing that the language makes convenient the modelling of complex timedependent effects we provide a formal semantics for pddl by mapping planning instances into constructs of hybrid automata using the syntax of has as our semantic model we construct a semantic mapping to labelled transition systems to complete the formal interpretation of pddl planning instances an advantage of building a mapping from pddl to ha theory is that it forms a bridge between the planning and real time systems research communities one consequence is that we can expect to make use of some of the theoretical properties of has for example for a restricted class of has the reachability problem which is equivalent to plan existence is decidable pddl provides an alternative to the continuous durative action model of pddl21 adding a more flexible and robust model of timedependent behaviour







p  cimiano  a  hotho and  s  staab 2005 learning concept hierarchies from text corpora using formal concept analysis volume 24 pages 305339







r  i brafman and  c  domshlak 2003 structure and complexity in planning with unary operators volume 18 pages 315349







k  m ting and  i  h witten 1999 issues in stacked generalization volume 10 pages 271289



recent work has shown how to improve delete relaxation heuristics by computing relaxed plans ie the hff heuristic in a compiled planning task pic which represents a given set c of fact conjunctions explicitly while this compilation view of such partial delete relaxation is simple and elegant its meaning with respect to the original planning task is opaque and the size of pic grows exponentially in c we herein provide a direct characterization without compilation making explicit how the approach arises from a combination of the deleterelaxation with criticalpath heuristics designing equations characterizing a novel view on h on the one hand and a generalized version hc of hm on the other hand we show that hpic can be characterized in terms of a combined hcplus equation this naturally generalizes the standard deleterelaxation framework understanding that framework as a relaxation over singleton facts as atomic subgoals one can refine the relaxation by using the conjunctions c as atomic subgoals instead thanks to this explicit view we identify the precise source of complexity in hffpic namely maximization of sets of supported atomic subgoals during relaxed plan extraction which is easy for singletonfact subgoals but is npcomplete in the general case approximating that problem greedily we obtain a polynomialtime hcff version of hffpic superseding the pic compilation and superseding the modified picce compilation which achieves the same complexity reduction but at an information loss experiments on ipc benchmarks show that these theoretical advantages can translate into empirical ones













in this paper we elucidate the equivalence between inference in game theory and machine learning our aim in so doing is to establish an equivalent vocabulary between the two domains so as to facilitate developments at the intersection of both 64257elds and as proof of the usefulness of this approach we use recent developments in each 64257eld to make useful improvements to the other more speci64257cally we consider the analogies between smooth best responses in 64257ctitious play and bayesian inference methods initially we use these insights to develop and demonstrate an improved algorithm for learning in games based on probabilistic moderation that is by integrating over the distribution of opponent strategies a bayesian approach within machine learning rather than taking a simple empirical average the approach used in standard 64257ctitious play we derive a novel moderated 64257ctitious play algorithm and show that it is more likely than standard 64257ctitious play to converge to a payoffdominant but riskdominated nash equilibrium in a simple coordination game furthermore we consider the converse case and show how insights from game theory can be used to derive two improved mean 64257eld variational learning algorithms we 64257rst show that the standard update rule of mean 64257eld variational learning is analogous to a cournot adjustment within game theory by analogy with 64257ctitious play we then suggest an improved update rule and show that this results in 64257ctitious variational play an improved mean 64257eld variational learning algorithm that exhibits better convergence in highly or strongly connected graphical models second we use a recent advance in 64257ctitious play namely dynamic 64257ctitious play to derive a derivative action variational learning algorithm that exhibits superior convergence properties on a canonical machine learning problem clustering a mixture distribution











e  mazer  j  m ahuactzin and  p  bessiere 1998 the ariadnes clew algorithm volume 9 pages 295316







j  renz and  b  nebel 2001 efficient methods for qualitative spatial reasoning volume 15 pages 289318



t  naseem b  snyder j  eisenstein and r  barzilay 2009 multilingual partofspeech tagging two unsupervised approaches volume 36 pages 341385



we demonstrate the effectiveness of multilingual learning for unsupervised partofspeech tagging the central assumption of our work is that by combining cues from multiple languages the structure of each becomes more apparent we consider two ways of applying this intuition to the problem of unsupervised partofspeech tagging a model that directly merges tag structures for a pair of languages into a single sequence and a second model which instead incorporates multilingual context using latent variables both approaches are formulated as hierarchical bayesian models using markov chain monte carlo sampling techniques for inference our results demonstrate that by incorporating multilingual evidence we can achieve impressive performance gains across a range of scenarios we also found that performance improves steadily as the number of available languages increases









j  singer  i  p gent and  a  smaill 2000 backbone fragility and the local search cost peak volume 12 pages 235270



y  bachrach e  porat and j  s  rosenschein 2013 sharing rewards in cooperative connectivity games volume 47 pages 281311



we consider how selfish agents are likely to share revenues derived from maintaining connectivity between important network servers we model a network where a failure of one node may disrupt communication between other nodes as a cooperative game called the vertex connectivity game cg in this game each agent owns a vertex and controls all the edges going to and from that vertex a coalition of agents wins if it fully connects a certain subset of vertices in the graph called the primary vertices

we also investigate finding stable payoff divisions of the revenues in cgs captured by the game theoretic solution of the core and its relaxations the epsiloncore and least core we show a polynomial algorithm for computing the core of a cg but show that testing whether an imputation is in the epsiloncore is conpcomplete finally we show that for trees it is possible to test for epsiloncore imputations in polynomial time









jan  rupnik andrej  muhic gregor  leban primoz  skraba blaz  fortuna and marko  grobelnik 2016 news across languages  crosslingual document similarity and event tracking volume 55 pages 283316



been  kim caleb  m chacha and julie  a shah 2015 inferring team task plans from human meetings a generative modeling approach with logicbased prior volume 52 pages 361398



we aim to reduce the burden of programming and deploying autonomous systems to work in concert with people in timecritical domains such as military field operations and disaster response deployment plans for these operations are frequently negotiated onthefly by teams of human planners a human operator then translates the agreedupon plan into machine instructions for the robots we present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human teams planning conversation our hybrid approach combines probabilistic generative modeling with logical plan validation used to compute a highly structured prior over possible plans enabling us to overcome the challenge of performing inference over a large solution space with only a small amount of noisy data from the team planning session we validate the algorithm through human subject experimentations and show that it is able to infer a human teams final plan with 86 accuracy on average we also describe a robot demonstration in which two people plan and execute a firstresponse collaborative task with a pr2 robot to the best of our knowledge this is the first work to integrate a logical planning technique within a generative model to perform plan inference 









c  bettini s  mascetti and x   s wang 2007 supporting temporal reasoning by mapping calendar expressions to minimal periodic sets volume 28 pages 299348



the task of identifying synonymous relations and objects or synonym resolution is critical for highquality information extraction this paper investigates synonym resolution in the context of unsupervised information extraction where neither handtagged training examples nor domain knowledge is available the paper presents a scalable fullyimplemented system that runs in okn log n time in the number of extractions n and the maximum number of synonyms per word k the system called resolver  introduces a probabilistic relational model for predicting whether two strings are coreferential based on the similarity of the assertions containing them on a set of two million assertions extracted from the web resolver resolves objects with 78 precision and 68 recall and resolves relations with 90 precision and 35 recall several variations of resolvers probabilistic model are explored and experiments demonstrate that under appropriate conditions these variations can improve f1 by 5 an extension to the basic resolver system allows it to handle polysemous names with 97 precision and 95 recall on a data set from the trec corpus









p  gutierrez and p  meseguer 2012 removing redundant messages in nary bnbadopt volume 45 pages 287304



this note considers how to modify  bnbadopt a wellknown algorithm for optimally solving distributed constraint optimization problems with a double aim i   to avoid sending most of the redundant messages and ii to handle cost functions of any arity some of the messages exchanged by bnbadopt  turned out to be redundant removing most of the redundant messages increases substantially communication efficiency the number of exchanged messages is  in most cases  at least three times fewer keeping the other measures almost unchanged and termination and optimality are maintained on the other hand handling nary cost functions was addressed in the original work but the presence of thresholds makes their practical usage more complex both issues  removing most of the redundant messages and efficiently handling nary cost functions  can be combined producing the new version bnbadopt experimentally we show the benefits of this  version over the original one 



  concepttotext generation refers to the task of automatically producing textual output from nonlinguistic input we present a joint model that captures content selection what to say and surface realization how to say in an unsupervised domainindependent fashion  rather than breaking up the generation process into a sequence of local decisions we define a probabilistic contextfree grammar that globally describes the inherent structure of the input a corpus of database records and text describing some of them  we recast generation as the task of finding the best derivation tree for a set of database records and describe an algorithm for decoding in this framework that allows to intersect the grammar with additional information capturing fluency and syntactic wellformedness constraints experimental evaluation on several domains achieves results competitive with stateoftheart systems that use domain specific constraints explicit feature engineering or labeled data







y  liu and g  lakemeyer 2008 on the expressiveness of levesques normal form volume 31 pages 259272



levesque proposed a generalization of a database called a proper knowledge base kb which is equivalent to a possibly infinite consistent set of ground literals in contrast to databases proper kbs do not make the closedworld assumption and hence the entailment  problem becomes undecidable levesque then proposed a limited but efficient inference method v for proper kbs which is sound and when the query is in a certain normal form also logically complete  he conjectured that for every firstorder query there is an equivalent one in normal form in this note we show that this conjecture is false in fact we show that any class of formulas for which v is complete must be strictly less expressive than full firstorder logic moreover in the propositional case it is very unlikely that a formula always has a polynomialsize normal form





conjunctive regular path queries are an expressive extension of the wellknown class of conjunctive queries such queries have been extensively studied in the graph database community since they support a controlled form of recursion and enable sophisticated path navigation somewhat surprisingly there has been little work aimed at using such queries in the context of description logic dl knowledge bases particularly for the lightweight dls that are considered best suited for dataintensive applications this paper aims to bridge this gap by providing algorithms and tight complexity bounds for answering twoway conjunctive regular path queries over dl knowledge bases formulated in lightweight dls of the dllite and el families our results demonstrate that in data complexity the cost of moving to this richer query language is as low as one could wish for the problem is nlcomplete for dllite and pcomplete for el the combined complexity of query answering increases from np to pspacecomplete but for twoway regular path queries without conjunction we show that query answering is tractable even with respect to combined complexity our results reveal twoway conjunctive regular path queries as a promising language for querying data enriched by ontologies formulated in dls of the dllite and el families or the corresponding owl 2 ql and el profiles











n  l zhang and  w  liu 1997 a model approximation scheme for planning in partially observable stochastic domains volume 7 pages 199230









the paper presents a scheme for computing lower and upper bounds on the posterior marginals in bayesian networks with discrete variables its power lies in its ability to use any available scheme that bounds the probability of evidence or posterior marginals and enhance its performance in an anytime manner the scheme uses the cutset conditioning principle to tighten existing bounding schemes  and to facilitate anytime behavior utilizing  a fixed  number of cutset tuples the accuracy of the bounds improves as the number of used cutset tuples increases and so does the computation time we demonstrate empirically the value of our scheme for bounding posterior marginals and probability of evidence using a variant of the bound propagation algorithm as a plugin scheme







d  berrar 2014 an empirical evaluation of ranking measures with respect to robustness to noise volume 49 pages 241267



ranking measures play an important role in model evaluation and selection using both synthetic and realworld data sets we investigate how different types and levels of noise affect the area under the roc curve auc the area under the roc convex hull the scored auc the kolmogorovsmirnov statistic and the hmeasure in our experiments the auc was overall the most robust among these measures thereby reinvigorating it as a reliable metric despite its wellknown deficiencies this paper also introduces a novel ranking measure which is remarkably robust to noise yet conceptually simple









s  edelkamp 2003 taming numbers and durations in the model checking integrated planning system volume 20 pages 195238







o  arieli  m  denecker  b  van nuffelen and  m  bruynooghe 2004 coherent integration of databases by abductive logic programming volume 21 pages 245286







m  babaioff m  feldman and n  nisan 2010 mixed strategies in combinatorial agency volume 38 pages 339369







a  cimatti and  m  roveri 2000 conformant planning via symbolic model checking volume 13 pages 305338





j  huang and a  darwiche 2007 the language of search volume 29 pages 191219



this paper is concerned with a class of algorithms that perform exhaustive search on propositional knowledge bases we show that each of these algorithms defines and generates a propositional language specifically we show that the trace of a search can be interpreted as a combinational circuit and a search algorithm then defines a propositional language consisting of circuits that are generated across all possible executions of the algorithm in particular we show that several versions of exhaustive dpll search correspond to such wellknown languages as fbdd obdd and a preciselydefined subset of ddnnf by thus mapping search algorithms to propositional languages we provide a uniform and practical framework in which successful search techniques can be harnessed for compilation of knowledge into various languages of interest and a new methodology whereby the power and limitations of search algorithms can be understood by looking up the tractability and succinctness of the corresponding propositional languages



bayesian network structure learning is the notoriously difficult problem of discovering a bayesian network that optimally represents a given set of training data  in this paper we study the computational worstcase complexity of exact bayesian network structure learning under graph theoretic restrictions on the directed superstructure  the superstructure is an undirected graph that contains as subgraphs the skeletons of solution networks we introduce the directed superstructure as a natural generalization of its undirected counterpart our results apply to several variants of scorebased bayesian network structure learning where the score of a network decomposes into local scores of its nodes

results we show that exact bayesian network structure learning can be carried out in nonuniform polynomial time if the superstructure has bounded treewidth and in linear time if in addition the superstructure has bounded maximum degree furthermore we show that if the directed superstructure is acyclic then exact bayesian network structure learning can be carried out in quadratic time we complement these positive results with a number of hardness results we show that both restrictions treewidth and degree are essential and cannot be dropped without loosing uniform polynomial time tractability subject to a complexitytheoretic assumption similarly exact bayesian network structure learning remains nphard for almost acyclic directed superstructures  furthermore we show that the restrictions remain essential if we do not search for a globally optimal network but aim to improve a given network by means of at most k arc additions arc deletions or arc reversals kneighborhood local search  









r  sebastiani and m  vescovi 2009 automated reasoning in modal and description logics via sat encoding the case study of kmalcsatisfiability volume 35 pages 343389



in the last two decades modal and description logics have been applied to numerous areas of computer science including knowledge representation formal verification database theory distributed computing and more recently semantic web and ontologies for this reason the problem of automated reasoning in modal and description logics has been thoroughly investigated in particular many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic km and of its notational variant the description logic alc although simple in structure kmalc is computationally very hard to reason on its satisfiability being pspacecomplete  

in this paper we start exploring the idea of performing automated reasoning tasks in modal and description logics by encoding them into sat so that to be handled by stateoftheart sat tools as with most previous approaches we begin our investigation from the satisfiability in km we propose an efficient encoding and we test it on an extensive set of benchmarks comparing the approach with the main stateoftheart tools available although the encoding is necessarily worstcase exponential from our experiments we notice that in practice this approach can handle most or all the problems which are at the reach of  the other approaches with performances which are comparable with or even better than those of the current stateoftheart tools



qualitative spatial descriptions characterize essential properties of spatial objects or configurations by relying on relative comparisons rather than measuring typically in qualitative approaches only relatively coarse distinctions between configurations are made qualitative spatial knowledge can be used to represent incomplete and underdetermined knowledge in a systematic way this is especially useful if the task is to describe features of classes of configurations rather than individual configurations







p  haslum 2006 improving heuristics through relaxed search  an analysis of tp4 and hspa in the 2004 planning competition volume 25 pages 233267



the ihsupmsupi admissible heuristics for sequential and temporal regression planning are defined by a parameterized relaxation of the optimal cost function in the regression search space where the parameter imi offers a tradeoff between the accuracy and computational cost of theheuristic existing methods for computing the ihsupmsupi heuristic require time exponential in imi limiting them to small values im  2i the ihsupmsupi heuristic can also be viewed as the optimal cost function in a relaxation of the search space this paper presents emrelaxed searchem a method for computing this function partially by searching in the relaxed space the relaxed search method because it computes ihsupmsupi only partially is computationally cheaper and therefore usable for higher values of imi the complete ihsupmsupi heuristic is combined with partial ihsupmsupi heuristics for im  3i computed by relaxed search resulting in a more accurate heuristic









c  x ling 1994 learning the past tense of english verbs the symbolic pattern associator vs connectionist models volume 1 pages 209229







2004 ijcaijair best paper prize







p  cichosz 1995 truncating temporal differences on the efficient implementation of    tdlambda for reinforcement learning volume 2 pages 287318







d  h wolpert and  k  tumer 2002 collective intelligence data routing and braess paradox volume 16 pages 359387







h  chan and  a  darwiche 2002 when do numbers really matter volume 17 pages 265287







a  hunter and j  p delgrande 2011 iterated belief change due to actions and observations volume 40 pages 269304







s  b huffman and  j  e laird 1995 flexibly instructable agents volume 3 pages 271324



c  b228ckstr246m a  jonsson and p  jonsson 2014 automaton plans volume 51 pages 255291



macros have long been used in planning to represent subsequences of operators macros can be used in place of individual operators during search sometimes reducing the effort required to find a plan to the goal another use of macros is to compactly represent long plans in this paper we introduce a novel solution concept called automaton plans in which plans are represented using hierarchies of automata automaton plans can be viewed as an extension of macros that enables parameterization and branching we provide several examples that illustrate how automaton plans can be useful both as a compact representation of exponentially long plans and as an alternative to sequential solutions in benchmark domains such as logistics and grid we also compare automaton plans to other compact plan representations from the literature and find that automaton plans are strictly more expressive than macros but strictly less expressive than htns and certain representations allowing efficient sequential access to the operators of the plan









n  l zhang and  d  poole 1996 exploiting causal independence in bayesian network inference volume 5 pages 301328







fm  delle fave ax  jiang z  yin c  zhang m  tambe s  kraus and j  p sullivan 2014 gametheoretic patrolling with dynamic execution uncertainty and a case study on a real transit system volume 50 pages 321367



in this paper we show that a continuous spectrum of randomisation exists in which most existing tree randomisations are only operating around the two ends of the spectrum  that leaves a huge part of the spectrum largely unexplored we propose a base learner vrtree which generates trees with variablerandomness  vrtrees are able to span from the conventional deterministic trees to the completerandom trees using a probabilistic parameter using vrtrees as the base models we explore the entire spectrum of randomised ensembles together with bagging and random subspace  we discover that the two halves of the spectrum have their distinct characteristics and the understanding of which allows us to propose a new approach in building better decision tree ensembles  we name this approach coalescence which coalesces a number of points in the randomhalf of the spectrum coalescence acts as a committee of experts to cater for unforeseeable conditions presented in training data  coalescence is found to perform better than any single operating point in the spectrum without the need to tune to a specific level of randomness  in our empirical study coalescence ranks top among the benchmarking ensemble methods including random forests random subspace and c5 boosting and only coalescence is significantly better than bagging and maxdiverse ensemble among all the methods in the comparison  although coalescence is not significantly better than random forests we have identified conditions under which one will perform better than the other











e  marchiori 1996 practical methods for proving termination of general logic programs volume 4 pages 179208



methods for fusing document lists that were retrieved in response to a query often utilize the retrieval scores andor ranks of documents in the lists we present a novel fusion approach that is based on using in addition information induced from interdocument similarities specifically our methods let similar documents from different lists provide relevancestatus support to each other we use a graphbased method to model relevancestatus propagation between documents the propagation is governed by interdocumentsimilarities and by retrieval scores of documents in the lists empirical evaluation demonstrates the effectiveness of our methods in fusing trec runs the performance of our most effective methods transcends that of effective fusion methods that utilize only retrieval scores or ranks











c  basu  h  hirsh  w  w cohen and  c  nevillmanning 2001 technical paper recommendation a study in combining multiple information sources volume 14 pages 231252



icaps 2011 best paper award



efficient use of multiple batteries is a practical problem with wide and growing application the problem can be cast as a planning problem under uncertainty we describe the approach we have adopted to modelling and solving this problem seen as a markov decision problem building effective policies for battery switching in the face of stochastic load profiles 

application of the approach leads to construction of policies that in simulation significantly outperform those that are currently in use and the best published solutions to the battery management problem we achieve solutions that achieve more than 99 efficiency in simulation compared with the theoretical limit and do so with far fewer battery switches than existing policies behaviour of physical batteries does not exactly match the simulated models for many reasons so to confirm that our theoretical results can lead to real measured improvements in performance we also conduct and report experiments using a physical test system these results demonstrate that we can obtain 515 improvement in lifetimes in the case of a two battery system





m  j streeter and s  f smith 2006 how the landscape of random job shop scheduling instances depends on the ratio of jobs to machines volume 26 pages 247287



we characterize the search landscape of random instances of the job shop scheduling problem jsp  specifically we investigate how the expected values of 1 backbone size 2 distance between nearoptimal schedules and 3 makespan of random schedules vary as a function of the job to machine ratio nm  for the limiting cases nm approaches 0 and nm approaches infinity we provide analytical results while for intermediate values of nm we perform experiments  we prove that as nm approaches 0 backbone size approaches 100 while as nm approaches infinity the backbone vanishes  in the process we show that as nm approaches 0 resp nm approaches infinity simple priority rules almost surely generate an optimal schedule providing theoretical evidence of an easyhardeasy pattern of typicalcase instance difficulty in job shop scheduling  we also draw connections between our theoretical results and the big valley picture of jsp landscapes



