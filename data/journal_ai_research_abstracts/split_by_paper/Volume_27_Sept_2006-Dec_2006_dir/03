j  y chai z  prasov and s  qu 2006 cognitive principles in robust multimodal interpretation volume 27 pages 5583

multimodal conversational interfaces provide a natural means for users to communicate with computer systems through multiple modalities such as speech and gesture to build effective multimodal interfaces automated interpretation of user multimodal inputs is important inspired by the previous investigation on cognitive status in multimodal human machine interaction we have developed a greedy algorithm for interpreting user referring expressions ie multimodal reference resolution this algorithm incorporates the cognitive principles of conversational implicature and givenness hierarchy and applies constraints from various sources eg temporal semantic and contextual to resolve references our empirical results have shown the advantage of this algorithm in efficiently resolving a variety of user references because of its simplicity and generality this approach has the potential to improve the robustness of multimodal input interpretation

